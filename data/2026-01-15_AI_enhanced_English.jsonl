{"id": "2601.08900", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08900", "abs": "https://arxiv.org/abs/2601.08900", "authors": ["Anush Lakshman S", "Adam Haroon", "Beiwen Li"], "title": "Comprehensive Machine Learning Benchmarking for Fringe Projection Profilometry with Photorealistic Synthetic Data", "comment": null, "summary": "Machine learning approaches for fringe projection profilometry (FPP) are hindered by the lack of large, diverse datasets and comprehensive benchmarking protocols. This paper introduces the first open-source, photorealistic synthetic dataset for FPP, generated using NVIDIA Isaac Sim with 15,600 fringe images and 300 depth reconstructions across 50 diverse objects. We benchmark four neural network architectures (UNet, Hformer, ResUNet, Pix2Pix) on single-shot depth reconstruction, revealing that all models achieve similar performance (58-77 mm RMSE) despite substantial architectural differences. Our results demonstrate fundamental limitations of direct fringe-to-depth mapping without explicit phase information, with reconstruction errors approaching 75-95\\% of the typical object depth range. This resource provides standardized evaluation protocols enabling systematic comparison and development of learning-based FPP approaches.", "AI": {"tldr": "First open-source photorealistic synthetic dataset for fringe projection profilometry (FPP) with 15,600 fringe images and 300 depth reconstructions across 50 objects. Benchmark shows neural networks achieve similar performance (58-77 mm RMSE) despite architectural differences, revealing fundamental limitations of direct fringe-to-depth mapping without phase information.", "motivation": "Machine learning approaches for FPP lack large, diverse datasets and comprehensive benchmarking protocols, hindering systematic comparison and development of learning-based methods.", "method": "Created synthetic dataset using NVIDIA Isaac Sim with 15,600 fringe images and 300 depth reconstructions across 50 diverse objects. Benchmarked four neural network architectures (UNet, Hformer, ResUNet, Pix2Pix) on single-shot depth reconstruction.", "result": "All models achieved similar performance (58-77 mm RMSE) despite substantial architectural differences. Reconstruction errors approach 75-95% of typical object depth range, demonstrating fundamental limitations of direct fringe-to-depth mapping without explicit phase information.", "conclusion": "The resource provides standardized evaluation protocols enabling systematic comparison and development of learning-based FPP approaches, while revealing that current neural network architectures face fundamental limitations in direct fringe-to-depth mapping without phase information."}}
{"id": "2601.08920", "categories": ["eess.IV", "cs.CV", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.08920", "abs": "https://arxiv.org/abs/2601.08920", "authors": ["Md. Jahidul Islam"], "title": "W-DUALMINE: Reliability-Weighted Dual-Expert Fusion With Residual Correlation Preservation for Medical Image Fusion", "comment": null, "summary": "Medical image fusion integrates complementary information from multiple imaging modalities to improve clinical interpretation. However, existing deep learningbased methods, including recent spatial-frequency frameworks such as AdaFuse and ASFE-Fusion, often suffer from a fundamental trade-off between global statistical similaritymeasured by correlation coefficient (CC) and mutual information (MI)and local structural fidelity. This paper proposes W-DUALMINE, a reliability-weighted dual-expert fusion framework designed to explicitly resolve this trade-off through architectural constraints and a theoretically grounded loss design. The proposed method introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, and a soft gradient-based arbitration mechanism. Furthermore, we employ a residual-to-average fusion paradigm that guarantees the preservation of global correlation while enhancing local details. Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics while", "AI": {"tldr": "W-DUALMINE is a reliability-weighted dual-expert fusion framework that resolves the trade-off between global statistical similarity (CC/MI) and local structural fidelity in medical image fusion through architectural constraints and theoretically grounded loss design.", "motivation": "Existing deep learning-based medical image fusion methods, including recent spatial-frequency frameworks like AdaFuse and ASFE-Fusion, suffer from a fundamental trade-off between global statistical similarity (measured by correlation coefficient and mutual information) and local structural fidelity.", "method": "Introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, a soft gradient-based arbitration mechanism, and a residual-to-average fusion paradigm that guarantees preservation of global correlation while enhancing local details.", "result": "Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics.", "conclusion": "W-DUALMINE successfully resolves the trade-off between global statistical similarity and local structural fidelity in medical image fusion through its novel architectural design and loss formulation, achieving superior performance across multiple medical imaging modalities."}}
{"id": "2601.09006", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.09006", "abs": "https://arxiv.org/abs/2601.09006", "authors": ["Marc-Antoine Fortin", "Anne Louise Kristoffersen", "Paal Erik Goa"], "title": "GOUHFI 2.0: A Next-Generation Toolbox for Brain Segmentation and Cortex Parcellation at Ultra-High Field MRI", "comment": null, "summary": "Ultra-High Field MRI (UHF-MRI) is increasingly used in large-scale neuroimaging studies, yet automatic brain segmentation and cortical parcellation remain challenging due to signal inhomogeneities, heterogeneous contrasts and resolutions, and the limited availability of tools optimized for UHF data. Standard software packages such as FastSurferVINN and SynthSeg+ often yield suboptimal results when applied directly to UHF images, thereby restricting region-based quantitative analyses. To address this need, we introduce GOUHFI 2.0, an updated implementation of GOUHFI that incorporates increased training data variability and additional functionalities, including cortical parcellation and volumetry.\n  GOUHFI 2.0 preserves the contrast- and resolution-agnostic design of the original toolbox while introducing two independently trained 3D U-Net segmentation tasks. The first performs whole-brain segmentation into 35 labels across contrasts, resolutions, field strengths and populations, using a domain-randomization strategy and a training dataset of 238 subjects. Using the same training data, the second network performs cortical parcellation into 62 labels following the Desikan-Killiany-Tourville (DKT) protocol.\n  Across multiple datasets, GOUHFI 2.0 demonstrated improved segmentation accuracy relative to the original toolbox, particularly in heterogeneous cohorts, and produced reliable cortical parcellations. In addition, the integrated volumetry pipeline yielded results consistent with standard volumetric workflows. Overall, GOUHFI 2.0 provides a comprehensive solution for brain segmentation, parcellation and volumetry across field strengths, and constitutes the first deep-learning toolbox enabling robust cortical parcellation at UHF-MRI.", "AI": {"tldr": "GOUHFI 2.0 is an updated deep-learning toolbox for automatic brain segmentation and cortical parcellation in Ultra-High Field MRI, addressing challenges of signal inhomogeneities and limited UHF-optimized tools.", "motivation": "Ultra-High Field MRI faces challenges in automatic brain segmentation due to signal inhomogeneities, heterogeneous contrasts/resolutions, and limited optimized tools. Standard software yields suboptimal results for UHF data, restricting quantitative analyses.", "method": "GOUHFI 2.0 uses two independently trained 3D U-Net segmentation tasks: 1) whole-brain segmentation into 35 labels using domain-randomization strategy and 238 training subjects, 2) cortical parcellation into 62 DKT protocol labels. Preserves contrast- and resolution-agnostic design.", "result": "Improved segmentation accuracy compared to original toolbox, especially in heterogeneous cohorts. Produced reliable cortical parcellations. Integrated volumetry pipeline yielded results consistent with standard workflows.", "conclusion": "GOUHFI 2.0 provides comprehensive solution for brain segmentation, parcellation and volumetry across field strengths, constituting first deep-learning toolbox enabling robust cortical parcellation at UHF-MRI."}}
{"id": "2601.09025", "categories": ["eess.IV", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09025", "abs": "https://arxiv.org/abs/2601.09025", "authors": ["Tong Wu", "Tayab Uddin Wara", "Daniel Hernandez", "Sidong Lei"], "title": "Universal Latent Homeomorphic Manifolds: Cross-Domain Representation Learning via Homeomorphism Verification", "comment": null, "summary": "We present the Universal Latent Homeomorphic Manifold (ULHM), a framework that unifies semantic representations (e.g., human descriptions, diagnostic labels) and observation-driven machine representations (e.g., pixel intensities, sensor readings) into a single latent structure. Despite originating from fundamentally different pathways, both modalities capture the same underlying reality. We establish \\emph{homeomorphism}, a continuous bijection preserving topological structure, as the mathematical criterion for determining when latent manifolds induced by different semantic-observation pairs can be rigorously unified. This criterion provides theoretical guarantees for three critical applications: (1) semantic-guided sparse recovery from incomplete observations, (2) cross-domain transfer learning with verified structural compatibility, and (3) zero-shot compositional learning via valid transfer from semantic to observation space. Our framework learns continuous manifold-to-manifold transformations through conditional variational inference, avoiding brittle point-to-point mappings. We develop practical verification algorithms, including trust, continuity, and Wasserstein distance metrics, that empirically validate homeomorphic structure from finite samples. Experiments demonstrate: (1) sparse image recovery from 5\\% of CelebA pixels and MNIST digit reconstruction at multiple sparsity levels, (2) cross-domain classifier transfer achieving 86.73\\% accuracy from MNIST to Fashion-MNIST without retraining, and (3) zero-shot classification on unseen classes achieving 89.47\\% on MNIST, 84.70\\% on Fashion-MNIST, and 78.76\\% on CIFAR-10. Critically, the homeomorphism criterion correctly rejects incompatible datasets, preventing invalid unification and providing a feasible way to principled decomposition of general foundation models into verified domain-specific components.", "AI": {"tldr": "ULHM framework unifies semantic and observation representations via homeomorphic manifolds, enabling semantic-guided sparse recovery, cross-domain transfer, and zero-shot learning with theoretical guarantees.", "motivation": "Different modalities (semantic descriptions vs. observation data) capture the same underlying reality but exist in separate representations. There's a need to unify these disparate representations into a single latent structure with mathematical guarantees.", "method": "Establishes homeomorphism as criterion for unifying latent manifolds. Uses conditional variational inference to learn continuous manifold-to-manifold transformations. Develops verification algorithms (trust, continuity, Wasserstein metrics) to validate homeomorphic structure from finite samples.", "result": "Achieves: (1) sparse image recovery from 5% CelebA pixels and MNIST reconstruction, (2) 86.73% cross-domain transfer accuracy from MNIST to Fashion-MNIST without retraining, (3) zero-shot classification: 89.47% on MNIST, 84.70% on Fashion-MNIST, 78.76% on CIFAR-10. Framework correctly rejects incompatible datasets.", "conclusion": "ULHM provides principled unification of semantic and observation representations with homeomorphism guarantees, enabling robust applications while preventing invalid unification. Offers feasible decomposition of foundation models into verified domain-specific components."}}
{"id": "2601.08950", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08950", "abs": "https://arxiv.org/abs/2601.08950", "authors": ["Mayank Sharma", "Roy Pea", "Hari Subramonyam"], "title": "ConvoLearn: A Dataset of Constructivist Tutor-Student Dialogue", "comment": null, "summary": "In educational applications, LLMs exhibit several fundamental pedagogical limitations, such as their tendency to reveal solutions rather than support dialogic learning. We introduce ConvoLearn (https://huggingface.co/datasets/masharma/convolearn ), a dataset grounded in knowledge building theory that operationalizes six core pedagogical dimensions: cognitive engagement, formative assessment, accountability, cultural responsiveness, metacognition, and power dynamics. We construct a semi-synthetic dataset of 1250 tutor-student dialogues (20 turns each) in middle school Earth Science through controlled interactions between human teachers and a simulated student. Using QLoRA, we demonstrate that training on this dataset meaningfully shifts LLM behavior toward knowledge-building strategies. Human evaluation by 31 teachers shows our fine-tuned Mistral 7B (M = 4.10, SD = 1.03) significantly outperforms both its base version (M = 2.59, SD = 1.11) and Claude Sonnet 4.5 (M = 2.87, SD = 1.29) overall. This work establishes a potential framework to guide future development and evaluation of constructivist AI tutors.", "AI": {"tldr": "Fine-tuning LLMs on ConvoLearn dataset improves AI tutors' pedagogical skills by shifting them from solution-revealing to knowledge-building dialogic approaches.", "motivation": "Current LLMs in education have pedagogical limitations, particularly their tendency to reveal solutions directly rather than supporting dialogic learning and knowledge building.", "method": "Created ConvoLearn dataset with 1250 tutor-student dialogues grounded in knowledge building theory with six pedagogical dimensions. Used human teachers interacting with simulated student. Fine-tuned Mistral 7B using QLoRA on this dataset.", "result": "Fine-tuned Mistral 7B (M=4.10) significantly outperformed base Mistral 7B (M=2.59) and Claude Sonnet 4.5 (M=2.87) in human evaluation by 31 teachers. Training meaningfully shifted LLM behavior toward knowledge-building strategies.", "conclusion": "This work establishes a framework for developing and evaluating constructivist AI tutors, demonstrating that targeted fine-tuning on pedagogically-grounded datasets can address fundamental limitations of LLMs in educational applications."}}
{"id": "2601.08953", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08953", "abs": "https://arxiv.org/abs/2601.08953", "authors": ["Le Liu", "Bangguo Yu", "Nynke Vellinga", "Ming Cao"], "title": "Fairness risk and its privacy-enabled solution in AI-driven robotic applications", "comment": null, "summary": "Complex decision-making by autonomous machines and algorithms could underpin the foundations of future society. Generative AI is emerging as a powerful engine for such transitions. However, we show that Generative AI-driven developments pose a critical pitfall: fairness concerns. In robotic applications, although intuitions about fairness are common, a precise and implementable definition that captures user utility and inherent data randomness is missing. Here we provide a utility-aware fairness metric for robotic decision making and analyze fairness jointly with user-data privacy, deriving conditions under which privacy budgets govern fairness metrics. This yields a unified framework that formalizes and quantifies fairness and its interplay with privacy, which is tested in a robot navigation task. In view of the fact that under legal requirements, most robotic systems will enforce user privacy, the approach shows surprisingly that such privacy budgets can be jointly used to meet fairness targets. Addressing fairness concerns in the creative combined consideration of privacy is a step towards ethical use of AI and strengthens trust in autonomous robots deployed in everyday environments.", "AI": {"tldr": "The paper proposes a utility-aware fairness metric for robotic decision making and analyzes the interplay between fairness and user-data privacy, showing privacy budgets can help meet fairness targets.", "motivation": "Generative AI is enabling autonomous decision-making systems, but raises fairness concerns. While fairness intuitions exist in robotics, there's no precise, implementable definition that accounts for user utility and data randomness. Additionally, privacy requirements are common in robotic systems, creating a need to understand how fairness and privacy interact.", "method": "Develops a utility-aware fairness metric for robotic decision making, analyzes fairness jointly with user-data privacy, derives conditions where privacy budgets govern fairness metrics, and creates a unified framework to formalize and quantify fairness-privacy interplay. Tests the framework in a robot navigation task.", "result": "Shows that privacy budgets (required by legal regulations) can be jointly used to meet fairness targets. Demonstrates the approach in robot navigation, revealing surprising connections between privacy enforcement and fairness achievement.", "conclusion": "Addressing fairness through combined consideration of privacy represents a step toward ethical AI use and strengthens trust in autonomous robots deployed in everyday environments. The unified framework provides a way to formalize and quantify fairness-privacy relationships in robotic systems."}}
{"id": "2601.08891", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08891", "abs": "https://arxiv.org/abs/2601.08891", "authors": ["Yanhua Zhao"], "title": "Attention Consistency Regularization for Interpretable Early-Exit Neural Networks", "comment": "2 pages, 1 figure", "summary": "Early-exit neural networks enable adaptive inference by allowing predictions at intermediate layers, reducing computational cost. However, early exits often lack interpretability and may focus on different features than deeper layers, limiting trust and explainability. This paper presents Explanation-Guided Training (EGT), a multi-objective framework that improves interpretability and consistency in early-exit networks through attention-based regularization. EGT introduces an attention consistency loss that aligns early-exit attention maps with the final exit. The framework jointly optimizes classification accuracy and attention consistency through a weighted combination of losses. Experiments on a real-world image classification dataset demonstrate that EGT achieves up to 98.97% overall accuracy (matching baseline performance) with a 1.97x inference speedup through early exits, while improving attention consistency by up to 18.5% compared to baseline models. The proposed method provides more interpretable and consistent explanations across all exit points, making early-exit networks more suitable for explainable AI applications in resource-constrained environments.", "AI": {"tldr": "EGT improves early-exit network interpretability via attention consistency regularization, maintaining accuracy while boosting explanation consistency by 18.5% and achieving 1.97x speedup.", "motivation": "Early-exit networks reduce computation but lack interpretability and have inconsistent feature focus between early and final exits, limiting trust in explainable AI applications.", "method": "Proposes Explanation-Guided Training (EGT) - a multi-objective framework with attention consistency loss that aligns early-exit attention maps with the final exit, jointly optimizing classification accuracy and attention consistency.", "result": "Achieves 98.97% accuracy (matching baseline) with 1.97x inference speedup, while improving attention consistency by up to 18.5% compared to baseline models.", "conclusion": "EGT makes early-exit networks more interpretable and consistent across exits, suitable for explainable AI in resource-constrained environments."}}
{"id": "2601.08834", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.08834", "abs": "https://arxiv.org/abs/2601.08834", "authors": ["Yufeng Zhong", "Lei Chen", "Zhixiong Zeng", "Xuanle Zhao", "Deyang Jiang", "Liming Zheng", "Jing Huang", "Haibo Qiu", "Peng Shi", "Siqi Yang", "Lin Ma"], "title": "Reading or Reasoning? Format Decoupled Reinforcement Learning for Document OCR", "comment": "technical report", "summary": "Reading text from images or scanned documents via OCR models has been a longstanding focus of researchers. Intuitively, text reading is perceived as a straightforward perceptual task, and existing work primarily focuses on constructing enriched data engineering to enhance SFT capabilities. In this work, we observe that even advanced OCR models exhibit significantly higher entropy in formatted text (\\emph{e.g.}, formula, table, etc.) compared to plain text, often by an order of magnitude. These statistical patterns reveal that advanced OCR models struggle with high output uncertainty when dealing with format sensitive document, suggesting that reasoning over diverse reading pathways may improve OCR performance. To address this, we propose format decoupled reinforcement learning (FD-RL), which leverages high-entropy patterns for targeted optimization. Our approach employs entropy-based data filtration strategy to identify format-intensive instances, and adopt format decoupled rewards tailored to different format types, enabling format-level validation rather than token-level memorization. FD-RL achieves an average score of 90.41 on OmniDocBench, setting a new record for end-to-end models on this highly popular benchmark. More importantly, we conduct comprehensive ablation studies over data, training, filtering, and rewarding strategies, thoroughly validating their effectiveness.", "AI": {"tldr": "FD-RL uses entropy-based filtering and format-decoupled rewards to improve OCR performance on formatted text like formulas and tables, achieving state-of-the-art results on OmniDocBench.", "motivation": "Advanced OCR models show significantly higher entropy (uncertainty) when processing formatted text (formulas, tables) compared to plain text, indicating they struggle with format-sensitive documents despite being treated as simple perceptual tasks.", "method": "Format Decoupled Reinforcement Learning (FD-RL) with two key components: 1) entropy-based data filtration to identify format-intensive instances, and 2) format-decoupled rewards tailored to different format types for format-level validation rather than token-level memorization.", "result": "Achieves average score of 90.41 on OmniDocBench, setting new record for end-to-end models. Comprehensive ablation studies validate effectiveness of data, training, filtering, and rewarding strategies.", "conclusion": "OCR models need reasoning over diverse reading pathways rather than just data engineering. FD-RL's format-level optimization effectively addresses high uncertainty in formatted text reading, advancing OCR capabilities for complex documents."}}
{"id": "2601.08922", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.08922", "abs": "https://arxiv.org/abs/2601.08922", "authors": ["Ayda Nodel Hokmabadi", "Chadi Assi"], "title": "Joint Beamforming and Position Optimization for Movable-Antenna and Movable-Element RIS-Aided Full-Duplex 6G MISO Systems", "comment": null, "summary": "Full-duplex communication substantially enhances spectral efficiency by enabling simultaneous transmission and reception on the same time-frequency resources. However, its practical deployment remains hindered by strong residual self-interference and inter-user interference, which severely degrade system performance. This work investigates a full-duplex MISO network that leverages movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to overcome these limitations in next-generation 6G systems. Unlike conventional fixed-geometry architectures, the proposed framework jointly optimizes antenna and RIS element positions, together with RIS phase shifts, to strengthen desired links while suppressing interference. Our design objective is to maximize the system sum rate through the joint optimization of transmit and receive beamforming vectors, uplink transmit powers, RIS phase shifts, and the spatial locations of both the BS antennas and RIS elements. To solve this challenging nonconvex problem, an alternating optimization algorithm is developed, employing semidefinite relaxation for beamforming design and successive convex approximation for position optimization. Simulation results demonstrate that the proposed ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks. These findings highlight the potential of integrating movable antennas with movable RIS elements as a key enabler for high-performance full-duplex operation in future 6G wireless systems.", "AI": {"tldr": "This paper proposes a full-duplex MISO network using movable-antenna base stations and movable-element RIS to overcome interference limitations in 6G systems, achieving substantial performance gains over fixed-position architectures.", "motivation": "Full-duplex communication enhances spectral efficiency but faces practical deployment challenges due to strong residual self-interference and inter-user interference. Current fixed-geometry architectures cannot effectively address these interference issues in next-generation 6G systems.", "method": "The proposed framework uses movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to jointly optimize antenna/RIS element positions, RIS phase shifts, transmit/receive beamforming vectors, and uplink transmit powers. An alternating optimization algorithm with semidefinite relaxation for beamforming and successive convex approximation for position optimization solves the nonconvex problem.", "result": "Simulation results show the ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks, demonstrating significant performance improvements.", "conclusion": "Integrating movable antennas with movable RIS elements is a key enabler for high-performance full-duplex operation in future 6G wireless systems, overcoming interference limitations that hinder practical deployment."}}
{"id": "2601.08927", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08927", "abs": "https://arxiv.org/abs/2601.08927", "authors": ["Pavan Kumar", "Shayan Srinivasa Garani"], "title": "Two-dimensional Entanglement-assisted Quantum Quasi-cyclic Low-density Parity-check Codes", "comment": "9 pages, 4 figures", "summary": "For any positive integer $g \\ge 2$, we derive general conditions for the existence of a $2g$-cycle in the Tanner graph of two-dimensional ($2$-D) classical quasi-cyclic (QC) low-density parity-check (LDPC) codes. Based on these conditions, we construct a family of $2$-D classical QC-LDPC codes with girth greater than $4$ by stacking $p \\times p \\times p$ tensors, where $p$ is an odd prime. Furthermore, for composite values of $p$, we propose two additional families of $2$-D classical LDPC codes obtained via similar tensor stacking. In this case, one family achieves girth greater than $4$, while the other attains girth greater than $6$. All the proposed $2$-D classical QC-LDPC codes exhibit an erasure correction capability of at least $p \\times p$. Based on the constructed classical $2$-D QC-LDPC codes, we derive two families of $2$-D entanglement-assisted (EA) quantum low-density parity-check (QLDPC) codes. The first family of $2$-D EA-QLDPC codes is obtained from a pair of binary $2$-D classical LDPC codes and is designed such that the unassisted part of the Tanner graph of the resulting EA-QLDPC code is free of cycles of length four, while requiring only a single ebit to be shared across the quantum transceiver. The second family is constructed from a single $2$-D classical LDPC code whose Tanner graph is free from $4$-cycles. Moreover, the constructed EA-QLDPC codes inherit an erasure correction capability of $p \\times p$, as the underlying classical codes possess the same erasure correction property.", "AI": {"tldr": "The paper presents conditions for avoiding 2g-cycles in 2D QC-LDPC codes, constructs classical codes with girth >4 or >6, and derives two families of EA quantum LDPC codes with good erasure correction capabilities.", "motivation": "To develop high-performance 2D classical QC-LDPC codes with controlled cycle structure (girth) and leverage them to construct entanglement-assisted quantum LDPC codes with good error correction properties.", "method": "1. Derive conditions for 2g-cycle existence in 2D QC-LDPC Tanner graphs. 2. Construct classical codes using p\u00d7p\u00d7p tensor stacking for odd prime p. 3. For composite p, propose two additional families via similar tensor stacking. 4. Derive two families of EA-QLDPC codes from the classical constructions.", "result": "1. Classical QC-LDPC codes with girth >4 (for odd prime p) and >6 (for composite p). 2. Two families of EA-QLDPC codes: one from binary code pairs with single ebit requirement, another from single code without 4-cycles. 3. All codes achieve erasure correction capability of at least p\u00d7p.", "conclusion": "The paper successfully develops systematic methods for constructing 2D classical QC-LDPC codes with controlled girth and translates these to EA quantum LDPC codes with inherited erasure correction capabilities, providing practical quantum error correction solutions."}}
{"id": "2601.09044", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09044", "abs": "https://arxiv.org/abs/2601.09044", "authors": ["Fei Tan", "Ashok Vardhan Addala", "Bruno Astuto Arouche Nunes", "Xucheng Zhu", "Ravi Soni"], "title": "POWDR: Pathology-preserving Outpainting with Wavelet Diffusion for 3D MRI", "comment": null, "summary": "Medical imaging datasets often suffer from class imbalance and limited availability of pathology-rich cases, which constrains the performance of machine learning models for segmentation, classification, and vision-language tasks. To address this challenge, we propose POWDR, a pathology-preserving outpainting framework for 3D MRI based on a conditioned wavelet diffusion model. Unlike conventional augmentation or unconditional synthesis, POWDR retains real pathological regions while generating anatomically plausible surrounding tissue, enabling diversity without fabricating lesions.\n  Our approach leverages wavelet-domain conditioning to enhance high-frequency detail and mitigate blurring common in latent diffusion models. We introduce a random connected mask training strategy to overcome conditioning-induced collapse and improve diversity outside the lesion. POWDR is evaluated on brain MRI using BraTS datasets and extended to knee MRI to demonstrate tissue-agnostic applicability. Quantitative metrics (FID, SSIM, LPIPS) confirm image realism, while diversity analysis shows significant improvement with random-mask training (cosine similarity reduced from 0.9947 to 0.9580; KL divergence increased from 0.00026 to 0.01494). Clinically relevant assessments reveal gains in tumor segmentation performance using nnU-Net, with Dice scores improving from 0.6992 to 0.7137 when adding 50 synthetic cases. Tissue volume analysis indicates no significant differences for CSF and GM compared to real images.\n  These findings highlight POWDR as a practical solution for addressing data scarcity and class imbalance in medical imaging. The method is extensible to multiple anatomies and offers a controllable framework for generating diverse, pathology-preserving synthetic data to support robust model development.", "AI": {"tldr": "POWDR is a pathology-preserving outpainting framework for 3D MRI that generates anatomically plausible surrounding tissue while retaining real pathological regions, addressing data scarcity and class imbalance in medical imaging.", "motivation": "Medical imaging datasets often suffer from class imbalance and limited availability of pathology-rich cases, which constrains machine learning model performance for segmentation, classification, and vision-language tasks.", "method": "A conditioned wavelet diffusion model with wavelet-domain conditioning to enhance high-frequency detail and mitigate blurring, plus a random connected mask training strategy to overcome conditioning-induced collapse and improve diversity outside lesions.", "result": "Quantitative metrics confirm image realism (FID, SSIM, LPIPS), diversity analysis shows significant improvement with random-mask training (cosine similarity reduced, KL divergence increased), and tumor segmentation performance improves with synthetic data (Dice scores from 0.6992 to 0.7137).", "conclusion": "POWDR is a practical solution for addressing data scarcity and class imbalance in medical imaging, extensible to multiple anatomies, offering a controllable framework for generating diverse, pathology-preserving synthetic data."}}
{"id": "2601.08988", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08988", "abs": "https://arxiv.org/abs/2601.08988", "authors": ["Ananya Mantravadi", "Shivali Dalmia", "Abhishek Mukherji"], "title": "ART: Action-based Reasoning Task Benchmarking for Medical AI Agents", "comment": null, "summary": "Reliable clinical decision support requires medical AI agents capable of safe, multi-step reasoning over structured electronic health records (EHRs). While large language models (LLMs) show promise in healthcare, existing benchmarks inadequately assess performance on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic. We introduce ART, an Action-based Reasoning clinical Task benchmark for medical AI agents, which mines real-world EHR data to create challenging tasks targeting known reasoning weaknesses. Through analysis of existing benchmarks, we identify three dominant error categories: retrieval failures, aggregation errors, and conditional logic misjudgments. Our four-stage pipeline -- scenario identification, task generation, quality audit, and evaluation -- produces diverse, clinically validated tasks grounded in real patient data. Evaluating GPT-4o-mini and Claude 3.5 Sonnet on 600 tasks shows near-perfect retrieval after prompt refinement, but substantial gaps in aggregation (28--64%) and threshold reasoning (32--38%). By exposing failure modes in action-oriented EHR reasoning, ART advances toward more reliable clinical agents, an essential step for AI systems that reduce cognitive load and administrative burden, supporting workforce capacity in high-demand care settings", "AI": {"tldr": "ART is a new benchmark for medical AI agents that tests action-based reasoning over EHR data, revealing significant gaps in aggregation and threshold reasoning despite near-perfect retrieval performance.", "motivation": "Existing benchmarks inadequately assess medical AI agents on action-based tasks involving threshold evaluation, temporal aggregation, and conditional logic, which are essential for reliable clinical decision support systems that can reduce cognitive load and administrative burden in healthcare settings.", "method": "The authors developed a four-stage pipeline: 1) scenario identification from real-world EHR data, 2) task generation targeting known reasoning weaknesses, 3) quality audit, and 4) evaluation. They created 600 challenging tasks grounded in real patient data and evaluated models like GPT-4o-mini and Claude 3.5 Sonnet.", "result": "While models achieved near-perfect retrieval after prompt refinement, they showed substantial performance gaps in aggregation (28-64% error rates) and threshold reasoning (32-38% error rates), exposing critical weaknesses in action-oriented EHR reasoning.", "conclusion": "ART advances the development of more reliable clinical AI agents by exposing failure modes in action-based reasoning, which is an essential step toward AI systems that can effectively support healthcare workforce capacity in high-demand care settings."}}
{"id": "2601.09031", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09031", "abs": "https://arxiv.org/abs/2601.09031", "authors": ["Xuetao Li", "Wenke Huang", "Mang Ye", "Jifeng Xuan", "Bo Du", "Sheng Liu", "Miao Li"], "title": "Generalizable Geometric Prior and Recurrent Spiking Feature Learning for Humanoid Robot Manipulation", "comment": null, "summary": "Humanoid robot manipulation is a crucial research area for executing diverse human-level tasks, involving high-level semantic reasoning and low-level action generation. However, precise scene understanding and sample-efficient learning from human demonstrations remain critical challenges, severely hindering the applicability and generalizability of existing frameworks. This paper presents a novel RGMP-S, Recurrent Geometric-prior Multimodal Policy with Spiking features, facilitating both high-level skill reasoning and data-efficient motion synthesis. To ground high-level reasoning in physical reality, we leverage lightweight 2D geometric inductive biases to enable precise 3D scene understanding within the vision-language model. Specifically, we construct a Long-horizon Geometric Prior Skill Selector that effectively aligns the semantic instructions with spatial constraints, ultimately achieving robust generalization in unseen environments. For the data efficiency issue in robotic action generation, we introduce a Recursive Adaptive Spiking Network. We parameterize robot-object interactions via recursive spiking for spatiotemporal consistency, fully distilling long-horizon dynamic features while mitigating the overfitting issue in sparse demonstration scenarios. Extensive experiments are conducted across the Maniskill simulation benchmark and three heterogeneous real-world robotic systems, encompassing a custom-developed humanoid, a desktop manipulator, and a commercial robotic platform. Empirical results substantiate the superiority of our method over state-of-the-art baselines and validate the efficacy of the proposed modules in diverse generalization scenarios. To facilitate reproducibility, the source code and video demonstrations are publicly available at https://github.com/xtli12/RGMP-S.git.", "AI": {"tldr": "RGMP-S is a novel framework combining geometric-prior multimodal policy with spiking features for humanoid robot manipulation, enabling precise 3D scene understanding and data-efficient motion synthesis from sparse demonstrations.", "motivation": "Humanoid robot manipulation requires both high-level semantic reasoning and low-level action generation, but existing frameworks struggle with precise scene understanding and sample-efficient learning from human demonstrations, limiting their applicability and generalizability.", "method": "The method introduces RGMP-S with two key components: 1) Long-horizon Geometric Prior Skill Selector using lightweight 2D geometric inductive biases for precise 3D scene understanding within vision-language models, and 2) Recursive Adaptive Spiking Network that parameterizes robot-object interactions via recursive spiking for spatiotemporal consistency and efficient learning from sparse demonstrations.", "result": "Extensive experiments on Maniskill simulation benchmark and three heterogeneous real-world robotic systems (custom humanoid, desktop manipulator, commercial platform) show superiority over state-of-the-art baselines and validate efficacy in diverse generalization scenarios.", "conclusion": "RGMP-S effectively addresses critical challenges in humanoid robot manipulation by combining geometric reasoning with spiking neural networks, enabling robust generalization and data-efficient learning while making source code publicly available for reproducibility."}}
{"id": "2601.08893", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.08893", "abs": "https://arxiv.org/abs/2601.08893", "authors": ["Andrew Kiruluta"], "title": "Spectral Generative Flow Models: A Physics-Inspired Replacement for Vectorized Large Language Models", "comment": null, "summary": "We introduce Spectral Generative Flow Models (SGFMs), a physics-inspired alternative to transformer-based large language models. Instead of representing text or video as sequences of discrete tokens processed by attention, SGFMs treat generation as the evolution of a continuous field governed by constrained stochastic dynamics in a multiscale wavelet basis. This formulation replaces global attention with local operators, spectral projections, and Navier--Stokes-like transport, yielding a generative mechanism grounded in continuity, geometry, and physical structure.\n  Our framework provides three key innovations: (i) a field-theoretic ontology in which text and video are unified as trajectories of a stochastic partial differential equation; (ii) a wavelet-domain representation that induces sparsity, scale separation, and computational efficiency; and (iii) a constrained stochastic flow that enforces stability, coherence, and uncertainty propagation. Together, these components define a generative architecture that departs fundamentally from autoregressive modeling and diffusion-based approaches. SGFMs offer a principled path toward long-range coherence, multimodal generality, and physically structured inductive bias in next-generation generative models.", "AI": {"tldr": "Spectral Generative Flow Models (SGFMs) are physics-inspired generative models that treat text/video as continuous field evolution using stochastic dynamics in wavelet basis, replacing transformers with local operators and spectral projections.", "motivation": "To provide an alternative to transformer-based LLMs by grounding generative modeling in physical principles like continuity, geometry, and physical structure, aiming for better long-range coherence and multimodal generality.", "method": "Treats generation as evolution of continuous field governed by constrained stochastic dynamics in multiscale wavelet basis. Uses field-theoretic ontology (text/video as SPDE trajectories), wavelet-domain representation for sparsity/scale separation, and constrained stochastic flow for stability/coherence.", "result": "Proposes a novel generative architecture that fundamentally departs from autoregressive and diffusion-based approaches, offering a principled framework for next-generation generative models.", "conclusion": "SGFMs provide a physics-inspired alternative to transformers with potential advantages in long-range coherence, multimodal generality, and physically structured inductive bias for future generative AI."}}
{"id": "2601.08860", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08860", "abs": "https://arxiv.org/abs/2601.08860", "authors": ["Tarannum Mithila"], "title": "Bias Detection and Rotation-Robustness Mitigation in Vision-Language Models and Generative Image Models", "comment": "Preprint. This work is derived from the author's Master's research. Code and supplementary materials will be released separately", "summary": "Vision-Language Models (VLMs) and generative image models have achieved remarkable performance across multimodal tasks, yet their robustness and fairness under input transformations remain insufficiently explored. This work investigates bias propagation and robustness degradation in state-of-the-art vision-language and generative models, with a particular focus on image rotation and distributional shifts. We analyze how rotation-induced perturbations affect model predictions, confidence calibration, and demographic bias patterns. To address these issues, we propose rotation-robust mitigation strategies that combine data augmentation, representation alignment, and model-level regularization. Experimental results across multiple datasets demonstrate that the proposed methods significantly improve robustness while reducing bias amplification without sacrificing overall performance. This study highlights critical limitations of current multimodal systems and provides practical mitigation techniques for building more reliable and fair AI models.", "AI": {"tldr": "The paper investigates bias propagation and robustness issues in vision-language and generative models under image rotations and distributional shifts, proposing mitigation strategies that improve robustness while reducing bias.", "motivation": "Despite remarkable performance of Vision-Language Models (VLMs) and generative image models, their robustness and fairness under input transformations like image rotation remain insufficiently explored, with concerns about bias propagation and robustness degradation.", "method": "The study analyzes how rotation-induced perturbations affect model predictions, confidence calibration, and demographic bias patterns, then proposes rotation-robust mitigation strategies combining data augmentation, representation alignment, and model-level regularization.", "result": "Experimental results across multiple datasets show that the proposed methods significantly improve robustness while reducing bias amplification without sacrificing overall performance.", "conclusion": "The study highlights critical limitations of current multimodal systems and provides practical mitigation techniques for building more reliable and fair AI models."}}
{"id": "2601.08946", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08946", "abs": "https://arxiv.org/abs/2601.08946", "authors": ["Konstantinos D. Katsanos", "George C. Alexandropoulos"], "title": "Robust Consensus-Based Distributed Beamforming for Wideband Cell-free Multi-RIS MISO Systems", "comment": "5 pages, 1 figure, presented in Asilomar 2025", "summary": "The cell-free networking paradigm constitutes a revolutionary architecture for future generations of wireless networks, which has been recently considered in synergy with Reconfigurable Intelligent Surfaces (RISs), a promising physical-layer technology for signal propagation programmability. In this paper, we focus on wideband cell-free multi-RIS-empowered Multiple-Input Single-Output (MISO) systems and present a decentralized cooperative active and passive beamforming scheme, aiming to provide an efficient alternative towards the cooperation overhead of available centralized schemes depending on central processing unit. Considering imperfect channel information availability and realistic frequency selectivity behavior of each RIS's element response, we devise a distributed optimization approach based on consensus updates for the RISs' phase configurations. Our simulation results showcase that the proposed distributed design is superior to centralized schemes that are based on various Lorentzian-type wideband modeling approaches for the RISs.", "AI": {"tldr": "A decentralized cooperative beamforming scheme for wideband cell-free multi-RIS MISO systems that outperforms centralized approaches while reducing cooperation overhead.", "motivation": "To address the cooperation overhead of centralized schemes in cell-free multi-RIS MISO systems by providing an efficient distributed alternative that handles imperfect channel information and realistic frequency-selective RIS element behavior.", "method": "A distributed optimization approach based on consensus updates for RIS phase configurations, considering imperfect channel information and realistic frequency selectivity of each RIS element response in wideband systems.", "result": "Simulation results show the proposed distributed design outperforms centralized schemes based on various Lorentzian-type wideband modeling approaches for RISs.", "conclusion": "The decentralized cooperative beamforming scheme provides an efficient alternative to centralized approaches for cell-free multi-RIS MISO systems, offering superior performance while reducing cooperation overhead."}}
{"id": "2601.08929", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08929", "abs": "https://arxiv.org/abs/2601.08929", "authors": ["Zachary Roberston"], "title": "A Local Characterization of $f$-Divergences Yielding PSD Mutual-Information Matrices", "comment": null, "summary": "We study when the variable-indexed matrix of pairwise \\(f\\)-mutual informations \\(M^{(f)}_{ij}=I_f(X_i;X_j)\\) is positive semidefinite (PSD). Let \\(f:(0,\\infty)\\to\\mathbb{R}\\) be convex with \\(f(1)=0\\), finite in a neighborhood of \\(1\\), and with \\(f(0)<\\infty\\) so that diagonal terms are finite. We give a sharp \\emph{local} characterization around independence: there exists \\(\u03b4=\u03b4(f)>0\\) such that for every \\(n\\) and every finite-alphabet family \\((X_1,\\ldots,X_n)\\) whose pairwise joint-to-product ratios lie in \\((1-\u03b4,1+\u03b4)\\), the matrix \\(M^{(f)}\\) is PSD if and only if \\(f\\) is analytic at \\(1\\) with a convergent expansion \\(f(t)=\\sum_{m=2}^{\\infty} a_m (t-1)^m\\) and \\(a_m\\ge 0\\) on a neighborhood of \\(1\\). Consequently, any negative Taylor coefficient yields an explicit finite-alphabet counterexample under arbitrarily weak dependence, and non-analytic convex divergences (e.g.\\ total variation) are excluded. This PSD requirement is distinct from Hilbertian/metric properties of divergences between distributions (e.g.\\ \\(\\sqrt{\\mathrm{JS}}\\)): we study PSD of the \\emph{variable-indexed} mutual-information matrix. The proof combines a replica embedding that turns monomial terms into Gram matrices with a replica-forcing reduction to positive-definite dot-product kernels, enabling an application of the Schoenberg--Berg--Christensen--Ressel classification.", "AI": {"tldr": "The paper shows that for a convex divergence f, the matrix of pairwise f-mutual informations is positive semidefinite under weak dependence if and only if f is analytic at 1 with all Taylor coefficients nonnegative.", "motivation": "To understand when the variable-indexed matrix of pairwise f-mutual informations is positive semidefinite, which is important for applications in information theory, statistics, and machine learning where such matrices arise in clustering, dimensionality reduction, and network analysis.", "method": "Uses a replica embedding technique to transform monomial terms into Gram matrices, combined with a replica-forcing reduction to positive-definite dot-product kernels, then applies the Schoenberg-Berg-Christensen-Ressel classification theorem.", "result": "Provides a sharp local characterization: there exists \u03b4(f) > 0 such that for weakly dependent variables (pairwise joint-to-product ratios in (1-\u03b4,1+\u03b4)), the mutual information matrix is PSD if and only if f is analytic at 1 with a convergent expansion f(t) = \u03a3_{m=2}^\u221e a_m(t-1)^m and a_m \u2265 0 near 1.", "conclusion": "The PSD property of f-mutual information matrices under weak dependence requires analyticity and nonnegative Taylor coefficients of f at 1, distinguishing this from Hilbertian/metric properties of divergences and providing explicit counterexamples for functions with negative coefficients."}}
{"id": "2601.09130", "categories": ["eess.IV", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09130", "abs": "https://arxiv.org/abs/2601.09130", "authors": ["Fuyao Chen", "Yuexi Du", "El\u00e8onore V. Lieffrig", "Nicha C. Dvornek", "John A. Onofrey"], "title": "Equi-ViT: Rotational Equivariant Vision Transformer for Robust Histopathology Analysis", "comment": "Accepted by IEEE ISBI 2026 4-page paper", "summary": "Vision Transformers (ViTs) have gained rapid adoption in computational pathology for their ability to model long-range dependencies through self-attention, addressing the limitations of convolutional neural networks that excel at local pattern capture but struggle with global contextual reasoning. Recent pathology-specific foundation models have further advanced performance by leveraging large-scale pretraining. However, standard ViTs remain inherently non-equivariant to transformations such as rotations and reflections, which are ubiquitous variations in histopathology imaging. To address this limitation, we propose Equi-ViT, which integrates an equivariant convolution kernel into the patch embedding stage of a ViT architecture, imparting built-in rotational equivariance to learned representations. Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations. Our results on a public colorectal cancer dataset demonstrate that incorporating equivariant patch embedding enhances data efficiency and robustness, suggesting that equivariant transformers could potentially serve as more generalizable backbones for the application of ViT in histopathology, such as digital pathology foundation models.", "AI": {"tldr": "Equi-ViT integrates equivariant convolution into ViT patch embeddings to achieve rotational equivariance, improving robustness and data efficiency in histopathology applications.", "motivation": "Standard Vision Transformers lack equivariance to common histopathology image transformations like rotations and reflections, limiting their robustness in computational pathology applications where such variations are ubiquitous.", "method": "Proposes Equi-ViT which integrates an equivariant convolution kernel into the patch embedding stage of a Vision Transformer architecture, imparting built-in rotational equivariance to learned representations.", "result": "Equi-ViT achieves superior rotation-consistent patch embeddings and stable classification performance across image orientations on a public colorectal cancer dataset, demonstrating enhanced data efficiency and robustness.", "conclusion": "Equivariant transformers could serve as more generalizable backbones for ViT applications in histopathology, potentially improving foundation models for digital pathology."}}
{"id": "2601.09032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09032", "abs": "https://arxiv.org/abs/2601.09032", "authors": ["Logan Ritchie", "Sushant Mehta", "Nick Heiner", "Mason Yu", "Edwin Chen"], "title": "The Hierarchy of Agentic Capabilities: Evaluating Frontier Models on Realistic RL Environments", "comment": null, "summary": "The advancement of large language model (LLM) based agents has shifted AI evaluation from single-turn response assessment to multi-step task completion in interactive environments. We present an empirical study evaluating frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Our analysis reveals an empirically-derived \\emph{hierarchy of agentic capabilities} that models must master for real-world deployment: (1) tool use, (2) planning and goal formation, (3) adaptability, (4) groundedness, and (5) common-sense reasoning. Even the best-performing models fail approximately 40\\% of the tasks, with failures clustering predictably along this hierarchy. Weaker models struggle with fundamental tool use and planning, whereas stronger models primarily fail on tasks requiring contextual inference beyond explicit instructions. We introduce a task-centric design methodology for RL environments that emphasizes diversity and domain expert contributions, provide detailed failure analysis, and discuss implications for agent development. Our findings suggest that while current frontier models can demonstrate coherent multi-step behavior, substantial capability gaps remain before achieving human-level task completion in realistic workplace settings.", "AI": {"tldr": "Empirical study shows frontier AI models fail ~40% of workplace tasks in e-commerce environment, revealing a hierarchy of agentic capabilities needed for real-world deployment.", "motivation": "With LLM-based agents shifting AI evaluation from single-turn responses to multi-step task completion, there's a need to understand how well current models perform in realistic workplace settings and identify capability gaps for real-world deployment.", "method": "Evaluated frontier AI models on 150 workplace tasks within a realistic e-commerce RL environment from Surge. Used task-centric design methodology emphasizing diversity and domain expert contributions, with detailed failure analysis.", "result": "Best-performing models fail ~40% of tasks, revealing a hierarchy of agentic capabilities: (1) tool use, (2) planning/goal formation, (3) adaptability, (4) groundedness, (5) common-sense reasoning. Weaker models struggle with basic tool use/planning, while stronger models fail on contextual inference tasks.", "conclusion": "Current frontier models demonstrate coherent multi-step behavior but have substantial capability gaps before achieving human-level task completion in realistic workplace settings. The hierarchy provides a framework for agent development and evaluation."}}
{"id": "2601.09104", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09104", "abs": "https://arxiv.org/abs/2601.09104", "authors": ["Ko Yamamoto", "Kyosuke Ishibashi", "Hiroki Ishikawa", "Osamu Azami"], "title": "Design Methodology of Hydraulically-driven Soft Robotic Gripper for a Large and Heavy Object", "comment": null, "summary": "This paper presents a design methodology of a hydraulically-driven soft robotic gripper for grasping a large and heavy object -- approximately 10 - 20 kg with 20 - 30 cm diameter. Most existing soft grippers are pneumatically actuated with several hundred kPa pressure, and cannot generate output force sufficient for such a large and heavy object. Instead of pneumatic actuation, hydraulic actuation has a potential to generate much larger power by several MPa pressure. In this study, we develop a hydraulically-driven soft gripper, in which its basic design parameters are determined based on a mathematical model that represents the relationship among the driving pressure, bending angle, object mass and grasping force. Moreover, we selected materials suitable for grasping a heavier object, based on the finite element analysis result of the detailed design. We report experimental results on a 20 kg object grasping and closed-loop control of the finger bending angle.", "AI": {"tldr": "Hydraulically-driven soft robotic gripper designed for grasping large, heavy objects (10-20 kg, 20-30 cm diameter) using hydraulic actuation instead of pneumatic to generate higher forces.", "motivation": "Existing pneumatic soft grippers with several hundred kPa pressure cannot generate sufficient force for large, heavy objects (10-20 kg). Hydraulic actuation offers potential for much higher power with several MPa pressure.", "method": "Developed a hydraulically-driven soft gripper using mathematical modeling to relate driving pressure, bending angle, object mass, and grasping force. Used finite element analysis for material selection and detailed design optimization.", "result": "Successfully demonstrated grasping of a 20 kg object and implemented closed-loop control of finger bending angle.", "conclusion": "Hydraulic actuation enables soft grippers to handle much larger and heavier objects than pneumatic systems, with mathematical modeling and FEA providing effective design methodology."}}
{"id": "2601.08896", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.08896", "abs": "https://arxiv.org/abs/2601.08896", "authors": ["Sahaj Raj Malla", "Shreeyash Kayastha", "Rumi Suwal", "Harish Chandra Bhandari", "Rajendra Adhikari"], "title": "XGBoost Forecasting of NEPSE Index Log Returns with Walk Forward Validation", "comment": "9 pages, 4 figures, 3 tables", "summary": "This study develops a robust machine learning framework for one-step-ahead forecasting of daily log-returns in the Nepal Stock Exchange (NEPSE) Index using the XGBoost regressor. A comprehensive feature set is engineered, including lagged log-returns (up to 30 days) and established technical indicators such as short- and medium-term rolling volatility measures and the 14-period Relative Strength Index. Hyperparameter optimization is performed using Optuna with time-series cross-validation on the initial training segment. Out-of-sample performance is rigorously assessed via walk-forward validation under both expanding and fixed-length rolling window schemes across multiple lag configurations, simulating real-world deployment and avoiding lookahead bias. Predictive accuracy is evaluated using root mean squared error, mean absolute error, coefficient of determination (R-squared), and directional accuracy on both log-returns and reconstructed closing prices. Empirical results show that the optimal configuration, an expanding window with 20 lags, outperforms tuned ARIMA and Ridge regression benchmarks, achieving the lowest log-return RMSE (0.013450) and MAE (0.009814) alongside a directional accuracy of 65.15%. While the R-squared remains modest, consistent with the noisy nature of financial returns, primary emphasis is placed on relative error reduction and directional prediction. Feature importance analysis and visual inspection further enhance interpretability. These findings demonstrate the effectiveness of gradient boosting ensembles in modeling nonlinear dynamics in volatile emerging market time series and establish a reproducible benchmark for NEPSE Index forecasting.", "AI": {"tldr": "XGBoost-based ML framework for one-day-ahead forecasting of Nepal Stock Exchange returns, outperforming ARIMA and Ridge regression benchmarks with 65% directional accuracy.", "motivation": "To develop a robust machine learning framework for forecasting daily returns in the Nepal Stock Exchange (NEPSE), an emerging market with volatile time series, and establish reproducible benchmarks for this market.", "method": "Uses XGBoost regressor with engineered features including lagged log-returns (up to 30 days), rolling volatility measures, and RSI. Hyperparameter optimization via Optuna with time-series cross-validation. Walk-forward validation with expanding and rolling window schemes to avoid lookahead bias.", "result": "Optimal configuration (expanding window with 20 lags) achieved lowest log-return RMSE (0.013450) and MAE (0.009814) with 65.15% directional accuracy, outperforming ARIMA and Ridge regression benchmarks. R-squared remained modest due to noisy financial returns.", "conclusion": "Gradient boosting ensembles (XGBoost) are effective for modeling nonlinear dynamics in volatile emerging market time series, establishing a reproducible benchmark for NEPSE Index forecasting with practical trading implications through directional accuracy."}}
{"id": "2601.08867", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08867", "abs": "https://arxiv.org/abs/2601.08867", "authors": ["Qingyu Liu", "Zhongjie Ba", "Jianmin Guo", "Qiu Wang", "Zhibo Wang", "Jie Shi", "Kui Ren"], "title": "R$^2$BD: A Reconstruction-Based Method for Generalizable and Efficient Detection of Fake Images", "comment": null, "summary": "Recently, reconstruction-based methods have gained attention for AIGC image detection. These methods leverage pre-trained diffusion models to reconstruct inputs and measure residuals for distinguishing real from fake images. Their key advantage lies in reducing reliance on dataset-specific artifacts and improving generalization under distribution shifts. However, they are limited by significant inefficiency due to multi-step inversion and reconstruction, and their reliance on diffusion backbones further limits generalization to other generative paradigms such as GANs.\n  In this paper, we propose a novel fake image detection framework, called R$^2$BD, built upon two key designs: (1) G-LDM, a unified reconstruction model that simulates the generation behaviors of VAEs, GANs, and diffusion models, thereby broadening the detection scope beyond prior diffusion-only approaches; and (2) a residual bias calculation module that distinguishes real and fake images in a single inference step, which is a significant efficiency improvement over existing methods that typically require 20$+$ steps.\n  Extensive experiments on the benchmark from 10 public datasets demonstrate that R$^2$BD is over 22$\\times$ faster than existing reconstruction-based methods while achieving superior detection accuracy. In cross-dataset evaluations, it outperforms state-of-the-art methods by an average of 13.87\\%, showing strong efficiency and generalization across diverse generative methods. The code and dataset used for evaluation are available at https://github.com/QingyuLiu/RRBD.", "AI": {"tldr": "R\u00b2BD is a novel fake image detection framework that uses a unified reconstruction model (G-LDM) to simulate multiple generative paradigms and achieves single-step detection, making it 22\u00d7 faster than existing methods while improving accuracy.", "motivation": "Current reconstruction-based AIGC detection methods are inefficient (require 20+ steps) and limited to diffusion models, lacking generalization to other generative paradigms like GANs and VAEs.", "method": "Two key designs: (1) G-LDM - a unified reconstruction model that simulates generation behaviors of VAEs, GANs, and diffusion models; (2) residual bias calculation module for single-step inference distinguishing real vs fake images.", "result": "R\u00b2BD is over 22\u00d7 faster than existing reconstruction-based methods while achieving superior detection accuracy. In cross-dataset evaluations, it outperforms state-of-the-art methods by average 13.87%.", "conclusion": "R\u00b2BD demonstrates strong efficiency and generalization across diverse generative methods, addressing limitations of previous reconstruction-based approaches through unified modeling and single-step inference."}}
{"id": "2601.09148", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09148", "abs": "https://arxiv.org/abs/2601.09148", "authors": ["Zihan Shen", "Jiaqi Li", "Xudong Dong", "Xiaofei Zhang"], "title": "Joint DOA and Non-circular Phase Estimation of Non-circular Signals for Antenna Arrays: Block Sparse Bayesian Learning Method", "comment": null, "summary": "This letter proposes a block sparse Bayesian learning (BSBL) algorithm of non-circular (NC) signals for direction-of-arrival (DOA) estimation, which is suitable for arbitrary unknown NC phases. The block sparse NC signal representation model is constructed through a permutation strategy, capturing the available intra-block structure information to enhance recovery performance. After that, we create the sparse probability model and derive the cost function under BSBL framework. Finally, the fast marginal likelihood maximum (FMLM) algorithm is introduced, enabling the rapid implementation of signal recovery by the addition and removal of basis functions. Simulation results demonstrate the effectiveness and the superior performance of our proposed method.", "AI": {"tldr": "Proposes BSBL algorithm for DOA estimation of non-circular signals with arbitrary unknown phases, using block sparse representation and FMLM for fast implementation.", "motivation": "Need for DOA estimation methods that can handle non-circular signals with arbitrary unknown phases, leveraging block sparse structure for improved performance.", "method": "Constructs block sparse NC signal representation via permutation strategy, creates sparse probability model under BSBL framework, and implements FMLM algorithm for fast signal recovery through basis function addition/removal.", "result": "Simulation results demonstrate effectiveness and superior performance of the proposed method compared to existing approaches.", "conclusion": "The proposed BSBL algorithm successfully addresses DOA estimation for non-circular signals with arbitrary unknown phases, offering enhanced recovery performance through block sparse modeling and efficient FMLM implementation."}}
{"id": "2601.08986", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08986", "abs": "https://arxiv.org/abs/2601.08986", "authors": ["Sara Saeidian"], "title": "On the Information Leakage Envelope of the Gaussian Mechanism", "comment": null, "summary": "We study the pointwise maximal leakage (PML) envelope of the Gaussian mechanism, which characterizes the smallest information leakage bound that holds with high probability under arbitrary post-processing. For the Gaussian mechanism with a Gaussian secret, we derive a closed-form expression for the deterministic PML envelope for sufficiently small failure probabilities. We then extend this result to general unbounded secrets by identifying a sufficient condition under which the envelope coincides with the Gaussian case. In particular, we show that strongly log-concave priors satisfy this condition via an application of the Brascamp-Lieb inequality.", "AI": {"tldr": "The paper analyzes the pointwise maximal leakage envelope for Gaussian mechanisms, deriving closed-form expressions for Gaussian secrets and extending to general unbounded secrets under certain conditions.", "motivation": "To characterize the smallest information leakage bound that holds with high probability under arbitrary post-processing for Gaussian mechanisms, which is important for privacy analysis and risk assessment.", "method": "The authors study the pointwise maximal leakage (PML) envelope of the Gaussian mechanism. They derive a closed-form expression for deterministic PML envelope with Gaussian secrets for small failure probabilities, then extend to general unbounded secrets by identifying sufficient conditions using the Brascamp-Lieb inequality for strongly log-concave priors.", "result": "1) Closed-form expression for deterministic PML envelope of Gaussian mechanism with Gaussian secret for sufficiently small failure probabilities. 2) Extension to general unbounded secrets by identifying sufficient conditions where envelope coincides with Gaussian case. 3) Proof that strongly log-concave priors satisfy these conditions via Brascamp-Lieb inequality.", "conclusion": "The paper provides analytical tools for understanding information leakage bounds in Gaussian mechanisms, establishing connections between PML envelopes, secret distributions, and mathematical inequalities, with implications for privacy-preserving systems and risk quantification."}}
{"id": "2601.09008", "categories": ["cs.CV", "eess.IV", "eess.SP", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.09008", "abs": "https://arxiv.org/abs/2601.09008", "authors": ["Amar Kavuri", "Howard C. Gifford", "Mini Das"], "title": "Changes in Visual Attention Patterns for Detection Tasks due to Dependencies on Signal and Background Spatial Frequencies", "comment": "21 pages, 7 images", "summary": "We aim to investigate the impact of image and signal properties on visual attention mechanisms during a signal detection task in digital images. The application of insight yielded from this work spans many areas of digital imaging where signal or pattern recognition is involved in complex heterogenous background. We used simulated tomographic breast images as the platform to investigate this question. While radiologists are highly effective at analyzing medical images to detect and diagnose diseases, misdiagnosis still occurs. We selected digital breast tomosynthesis (DBT) images as a sample medical images with different breast densities and structures using digital breast phantoms (Bakic and XCAT). Two types of lesions (with distinct spatial frequency properties) were randomly inserted in the phantoms during projections to generate abnormal cases. Six human observers participated in observer study designed for a locating and detection of an 3-mm sphere lesion and 6-mm spicule lesion in reconstructed in-plane DBT slices. We collected eye-gaze data to estimate gaze metrics and to examine differences in visual attention mechanisms. We found that detection performance in complex visual environments is strongly constrained by later perceptual stages, with decision failures accounting for the largest proportion of errors. Signal detectability is jointly influenced by both target morphology and background complexity, revealing a critical interaction between local signal features and global anatomical noise. Increased fixation duration on spiculated lesions suggests that visual attention is differentially engaged depending on background and signal spatial frequency dependencies.", "AI": {"tldr": "This study investigates how image and signal properties affect visual attention during lesion detection in digital breast tomosynthesis images, finding that detection performance is constrained by perceptual stages and influenced by target morphology and background complexity interactions.", "motivation": "The research aims to understand how image and signal properties impact visual attention mechanisms during signal detection tasks in digital images, with applications in medical imaging and pattern recognition. The study addresses the persistent issue of misdiagnosis in radiology despite radiologists' effectiveness, focusing on breast cancer detection in complex anatomical backgrounds.", "method": "Used simulated tomographic breast images with digital breast phantoms (Bakic and XCAT) containing different breast densities and structures. Two lesion types (3-mm sphere and 6-mm spicule) with distinct spatial frequency properties were randomly inserted. Conducted observer study with six human participants performing locating and detection tasks on reconstructed DBT slices. Collected eye-gaze data to analyze visual attention mechanisms and gaze metrics.", "result": "Detection performance in complex visual environments is strongly constrained by later perceptual stages, with decision failures accounting for most errors. Signal detectability is jointly influenced by both target morphology and background complexity, showing critical interaction between local signal features and global anatomical noise. Increased fixation duration on spiculated lesions suggests visual attention is differentially engaged based on background and signal spatial frequency dependencies.", "conclusion": "Visual attention mechanisms during lesion detection are significantly influenced by the interaction between target morphology and background complexity. The findings highlight that detection errors primarily stem from decision-making failures rather than initial visual search, and that different lesion types engage visual attention differently based on their spatial frequency properties and background characteristics."}}
{"id": "2601.09072", "categories": ["cs.AI", "cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.09072", "abs": "https://arxiv.org/abs/2601.09072", "authors": ["Jean Feng", "Avni Kothari", "Patrick Vossler", "Andrew Bishara", "Lucas Zier", "Newton Addo", "Aaron Kornblith", "Yan Shuo Tan", "Chandan Singh"], "title": "Human-AI Co-design for Clinical Prediction Models", "comment": null, "summary": "Developing safe, effective, and practically useful clinical prediction models (CPMs) traditionally requires iterative collaboration between clinical experts, data scientists, and informaticists. This process refines the often small but critical details of the model building process, such as which features/patients to include and how clinical categories should be defined. However, this traditional collaboration process is extremely time- and resource-intensive, resulting in only a small fraction of CPMs reaching clinical practice. This challenge intensifies when teams attempt to incorporate unstructured clinical notes, which can contain an enormous number of concepts. To address this challenge, we introduce HACHI, an iterative human-in-the-loop framework that uses AI agents to accelerate the development of fully interpretable CPMs by enabling the exploration of concepts in clinical notes. HACHI alternates between (i) an AI agent rapidly exploring and evaluating candidate concepts in clinical notes and (ii) clinical and domain experts providing feedback to improve the CPM learning process. HACHI defines concepts as simple yes-no questions that are used in linear models, allowing the clinical AI team to transparently review, refine, and validate the CPM learned in each round. In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not included in commonly-used CPMs, and improves model generalizability across clinical sites and time periods. Furthermore, HACHI reveals the critical role of the clinical AI team, such as directing the AI agent to explore concepts that it had not previously considered, adjusting the granularity of concepts it considers, changing the objective function to better align with the clinical objectives, and identifying issues of data bias and leakage.", "AI": {"tldr": "HACHI is a human-in-the-loop AI framework that accelerates development of interpretable clinical prediction models by using AI agents to explore concepts in clinical notes, with clinical experts providing iterative feedback.", "motivation": "Traditional clinical prediction model development is extremely time- and resource-intensive, requiring extensive collaboration between clinical experts, data scientists, and informaticists. This process is particularly challenging when incorporating unstructured clinical notes containing numerous concepts, resulting in few models reaching clinical practice.", "method": "HACHI uses an iterative human-in-the-loop framework where AI agents rapidly explore and evaluate candidate concepts in clinical notes, while clinical experts provide feedback to improve the learning process. Concepts are defined as simple yes-no questions used in linear models, enabling transparent review and validation.", "result": "In two real-world prediction tasks (acute kidney injury and traumatic brain injury), HACHI outperforms existing approaches, surfaces new clinically relevant concepts not in commonly-used models, and improves model generalizability across clinical sites and time periods.", "conclusion": "HACHI successfully accelerates clinical prediction model development while maintaining interpretability, and demonstrates the critical role of clinical AI teams in directing AI agents, adjusting concept granularity, aligning objectives with clinical goals, and identifying data bias issues."}}
{"id": "2601.09163", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09163", "abs": "https://arxiv.org/abs/2601.09163", "authors": ["Tong Wu", "Shoujie Li", "Junhao Gong", "Changqing Guo", "Xingting Li", "Shilong Mu", "Wenbo Ding"], "title": "CEI: A Unified Interface for Cross-Embodiment Visuomotor Policy Learning in 3D Space", "comment": null, "summary": "Robotic foundation models trained on large-scale manipulation datasets have shown promise in learning generalist policies, but they often overfit to specific viewpoints, robot arms, and especially parallel-jaw grippers due to dataset biases. To address this limitation, we propose Cross-Embodiment Interface (\\CEI), a framework for cross-embodiment learning that enables the transfer of demonstrations across different robot arm and end-effector morphologies. \\CEI introduces the concept of \\textit{functional similarity}, which is quantified using Directional Chamfer Distance. Then it aligns robot trajectories through gradient-based optimization, followed by synthesizing observations and actions for unseen robot arms and end-effectors. In experiments, \\CEI transfers data and policies from a Franka Panda robot to \\textbf{16} different embodiments across \\textbf{3} tasks in simulation, and supports bidirectional transfer between a UR5+AG95 gripper robot and a UR5+Xhand robot across \\textbf{6} real-world tasks, achieving an average transfer ratio of 82.4\\%. Finally, we demonstrate that \\CEI can also be extended with spatial generalization and multimodal motion generation capabilities using our proposed techniques. Project website: https://cross-embodiment-interface.github.io/", "AI": {"tldr": "CEI enables cross-embodiment learning by transferring demonstrations across different robot arms and end-effectors using functional similarity and trajectory alignment.", "motivation": "Robotic foundation models trained on large datasets often overfit to specific viewpoints, robot arms, and parallel-jaw grippers due to dataset biases, limiting their generalizability across different robot embodiments.", "method": "Introduces functional similarity measured by Directional Chamfer Distance, aligns robot trajectories through gradient-based optimization, and synthesizes observations/actions for unseen robot morphologies.", "result": "Successfully transfers data and policies from Franka Panda to 16 different embodiments across 3 simulation tasks, and achieves bidirectional transfer between UR5+AG95 and UR5+Xhand robots across 6 real-world tasks with 82.4% average transfer ratio.", "conclusion": "CEI provides an effective framework for cross-embodiment learning that can be extended with spatial generalization and multimodal motion generation capabilities, addressing the overfitting problem in robotic foundation models."}}
{"id": "2601.08928", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08928", "abs": "https://arxiv.org/abs/2601.08928", "authors": ["Shahnawaz Alam", "Mohammed Abdul Rahman", "Bareera Sadeqa"], "title": "DriftGuard: A Hierarchical Framework for Concept Drift Detection and Remediation in Supply Chain Forecasting", "comment": null, "summary": "Supply chain forecasting models degrade over time as real-world conditions change. Promotions shift, consumer preferences evolve, and supply disruptions alter demand patterns, causing what is known as concept drift. This silent degradation leads to stockouts or excess inventory without triggering any system warnings. Current industry practice relies on manual monitoring and scheduled retraining every 3-6 months, which wastes computational resources during stable periods while missing rapid drift events. Existing academic methods focus narrowly on drift detection without addressing diagnosis or remediation, and they ignore the hierarchical structure inherent in supply chain data. What retailers need is an end-to-end system that detects drift early, explains its root causes, and automatically corrects affected models. We propose DriftGuard, a five-module framework that addresses the complete drift lifecycle. The system combines an ensemble of four complementary detection methods, namely error-based monitoring, statistical tests, autoencoder anomaly detection, and Cumulative Sum (CUSUM) change-point analysis, with hierarchical propagation analysis to identify exactly where drift occurs across product lines. Once detected, Shapley Additive Explanations (SHAP) analysis diagnoses the root causes, and a cost-aware retraining strategy selectively updates only the most affected models. Evaluated on over 30,000 time series from the M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.", "AI": {"tldr": "DriftGuard: An end-to-end system for detecting, diagnosing, and remedying concept drift in supply chain forecasting models using ensemble detection, hierarchical analysis, SHAP explanations, and cost-aware retraining.", "motivation": "Supply chain forecasting models degrade silently over time due to concept drift (promotions, consumer preferences, supply disruptions), causing stockouts or excess inventory without warnings. Current industry practice relies on inefficient manual monitoring and scheduled retraining, while academic methods only detect drift without addressing diagnosis or remediation, ignoring hierarchical supply chain data structures.", "method": "DriftGuard is a five-module framework with: 1) Ensemble of four complementary detection methods (error-based monitoring, statistical tests, autoencoder anomaly detection, CUSUM change-point analysis), 2) Hierarchical propagation analysis to identify drift across product lines, 3) SHAP analysis for root cause diagnosis, 4) Cost-aware retraining strategy that selectively updates only the most affected models.", "result": "Evaluated on over 30,000 time series from M5 retail dataset, DriftGuard achieves 97.8% detection recall within 4.2 days and delivers up to 417 return on investment through targeted remediation.", "conclusion": "DriftGuard provides a comprehensive solution to the complete drift lifecycle in supply chain forecasting, addressing detection, diagnosis, and remediation while considering hierarchical data structures and computational efficiency."}}
{"id": "2601.08868", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.08868", "abs": "https://arxiv.org/abs/2601.08868", "authors": ["Yi Wang", "Yinfeng Yu", "Bin Ren"], "title": "Residual Cross-Modal Fusion Networks for Audio-Visual Navigation", "comment": "Main paper (10 pages). Accepted for publication by the 14th international conference on Computational Visual Media (CVM 2026)", "summary": "Audio-visual embodied navigation aims to enable an agent to autonomously localize and reach a sound source in unseen 3D environments by leveraging auditory cues. The key challenge of this task lies in effectively modeling the interaction between heterogeneous features during multimodal fusion, so as to avoid single-modality dominance or information degradation, particularly in cross-domain scenarios. To address this, we propose a Cross-Modal Residual Fusion Network, which introduces bidirectional residual interactions between audio and visual streams to achieve complementary modeling and fine-grained alignment, while maintaining the independence of their representations. Unlike conventional methods that rely on simple concatenation or attention gating, CRFN explicitly models cross-modal interactions via residual connections and incorporates stabilization techniques to improve convergence and robustness. Experiments on the Replica and Matterport3D datasets demonstrate that CRFN significantly outperforms state-of-the-art fusion baselines and achieves stronger cross-domain generalization. Notably, our experiments also reveal that agents exhibit differentiated modality dependence across different datasets. The discovery of this phenomenon provides a new perspective for understanding the cross-modal collaboration mechanism of embodied agents.", "AI": {"tldr": "CRFN uses bidirectional residual interactions between audio and visual streams for better multimodal fusion in audio-visual embodied navigation, achieving state-of-the-art performance and improved cross-domain generalization.", "motivation": "Audio-visual embodied navigation faces challenges in effectively modeling interactions between heterogeneous features during multimodal fusion, avoiding single-modality dominance or information degradation, especially in cross-domain scenarios.", "method": "Proposes Cross-Modal Residual Fusion Network (CRFN) with bidirectional residual interactions between audio and visual streams for complementary modeling and fine-grained alignment while maintaining representation independence. Uses residual connections and stabilization techniques instead of simple concatenation or attention gating.", "result": "CRFN significantly outperforms state-of-the-art fusion baselines on Replica and Matterport3D datasets and achieves stronger cross-domain generalization. Also reveals that agents exhibit differentiated modality dependence across different datasets.", "conclusion": "CRFN effectively addresses multimodal fusion challenges in audio-visual navigation. The discovery of differentiated modality dependence provides new insights into cross-modal collaboration mechanisms for embodied agents."}}
{"id": "2601.09168", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09168", "abs": "https://arxiv.org/abs/2601.09168", "authors": ["Sojeong Park", "Yeongjun Kim", "Hyun Jong Yang"], "title": "User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing", "comment": null, "summary": "Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activated streams via covariance differencing. We analyze the covariance deviation induced by channel variations to establish a theoretical bound based on channel correlation for determining the sensing window size. To mitigate residual interference from finite sampling, a deep learning (DL) classifier is integrated. Simulations across both independent and identically distributed flat Rayleigh fading and standardized channel environments demonstrate that the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios.", "AI": {"tldr": "A differential stream sensing framework for grant-free massive connectivity that isolates newly activated streams via covariance differencing and uses DL to handle residual interference, outperforming baselines in overloaded scenarios.", "motivation": "Grant-free access is crucial for massive IoT connectivity but suffers from collision risks in uncoordinated transmissions. User-side sensing helps mitigate collisions, but conventional methods fail in overloaded scenarios where active streams exceed receive antennas.", "method": "Proposes a differential stream sensing framework that reframes the problem from estimating total stream count to isolating newly activated streams via covariance differencing. Analyzes covariance deviation from channel variations to determine sensing window size, and integrates a deep learning classifier to mitigate residual interference from finite sampling.", "result": "Simulations across both i.i.d. flat Rayleigh fading and standardized channel environments show the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios.", "conclusion": "The differential stream sensing framework with DL integration provides an effective solution for grant-free massive connectivity, maintaining performance even in overloaded scenarios where conventional methods fail."}}
{"id": "2601.09039", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09039", "abs": "https://arxiv.org/abs/2601.09039", "authors": ["Mete Erdogan", "Abhiram Gorle", "Shubham Chandak", "Mert Pilanci", "Tsachy Weissman"], "title": "An Information-Theoretic Perspective on LLM Tokenizers", "comment": null, "summary": "Large language model (LLM) tokenizers act as structured compressors: by mapping text to discrete token sequences, they determine token count (and thus compute and context usage) and the statistical structure seen by downstream models. Despite their central role in LLM pipelines, the link between tokenization, compression efficiency and induced structure is not well understood. We empirically demonstrate that tokenizer training scale redistributes entropy: as training data grows, the token stream becomes more diverse in aggregate (higher unigram entropy) yet markedly more predictable in-context (lower higher-order conditional entropies), indicating that tokenization absorbs substantial short-range regularity although these gains degrade under train-test domain mismatch. To ground these observations, we first benchmark i) pretrained GPT-family tokenizers as black-box compressors across various domains, and ii) learned tokenizers across configurations spanning vocabulary size, training scale, and domain. Next, we study tokenization as a transform for universal compression and introduce a compression-aware BPE variant. Finally, we adopt a channel lens and introduce capacity-utilization metrics to analyze tokenizer behaviour and outline implications for downstream modeling. Put together, our results expose various trade-offs between compression, induced structure, and robustness under domain shift, and motivate principled, compression-aware tokenizer design.", "AI": {"tldr": "Tokenizers act as structured compressors in LLMs, with training scale redistributing entropy: more diverse token streams overall but more predictable in context, though gains degrade with domain mismatch.", "motivation": "Despite tokenizers' central role in LLM pipelines, the relationship between tokenization, compression efficiency, and induced statistical structure is poorly understood, motivating empirical investigation of how tokenizer training affects compression properties and downstream modeling.", "method": "1) Benchmark pretrained GPT-family tokenizers as black-box compressors across domains; 2) Study learned tokenizers across vocabulary size, training scale, and domain configurations; 3) Analyze tokenization as a transform for universal compression and introduce compression-aware BPE variant; 4) Adopt channel lens with capacity-utilization metrics to analyze tokenizer behavior.", "result": "Tokenizer training scale redistributes entropy: as training data grows, token streams become more diverse overall (higher unigram entropy) but more predictable in context (lower higher-order conditional entropies). Tokenization absorbs substantial short-range regularity, though these compression gains degrade under train-test domain mismatch.", "conclusion": "The study reveals trade-offs between compression, induced structure, and robustness under domain shift, motivating principled, compression-aware tokenizer design for LLMs."}}
{"id": "2601.09240", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.09240", "abs": "https://arxiv.org/abs/2601.09240", "authors": ["Jiajun Chen", "Jing Xiao", "Shaohan Cao", "Yuming Zhu", "Liang Liao", "Jun Pan", "Mi Wang"], "title": "DeTracker: Motion-decoupled Vehicle Detection and Tracking in Unstabilized Satellite Videos", "comment": null, "summary": "Satellite videos provide continuous observations of surface dynamics but pose significant challenges for multi-object tracking (MOT), especially under unstabilized conditions where platform jitter and the weak appearance of tiny objects jointly degrade tracking performance. To address this problem, we propose DeTracker, a joint detection-and-tracking framework tailored for unstabilized satellite videos. DeTracker introduces a Global--Local Motion Decoupling (GLMD) module that explicitly separates satellite platform motion from true object motion through global alignment and local refinement, leading to improved trajectory stability and motion estimation accuracy. In addition, a Temporal Dependency Feature Pyramid (TDFP) module is developed to perform cross-frame temporal feature fusion, enhancing the continuity and discriminability of tiny-object representations. We further construct a new benchmark dataset, SDM-Car-SU, which simulates multi-directional and multi-speed platform motions to enable systematic evaluation of tracking robustness under varying motion perturbations. Extensive experiments on both simulated and real unstabilized satellite videos demonstrate that DeTracker significantly outperforms existing methods, achieving 61.1% MOTA on SDM-Car-SU and 47.3% MOTA on real satellite video data.", "AI": {"tldr": "DeTracker is a joint detection-and-tracking framework for unstabilized satellite videos that addresses platform jitter and tiny object tracking challenges through motion decoupling and temporal feature fusion.", "motivation": "Satellite videos provide continuous observations but face significant MOT challenges under unstabilized conditions where platform jitter and weak appearance of tiny objects degrade tracking performance.", "method": "Proposes DeTracker with: 1) Global-Local Motion Decoupling (GLMD) module to separate satellite platform motion from true object motion via global alignment and local refinement; 2) Temporal Dependency Feature Pyramid (TDFP) module for cross-frame temporal feature fusion to enhance tiny-object representations; 3) New benchmark dataset SDM-Car-SU simulating multi-directional platform motions.", "result": "Extensive experiments show DeTracker significantly outperforms existing methods, achieving 61.1% MOTA on SDM-Car-SU benchmark and 47.3% MOTA on real satellite video data.", "conclusion": "DeTracker effectively addresses tracking challenges in unstabilized satellite videos through explicit motion decoupling and temporal feature enhancement, demonstrating superior performance on both simulated and real-world data."}}
{"id": "2601.09097", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09097", "abs": "https://arxiv.org/abs/2601.09097", "authors": ["Derrick Goh Xin Deik", "Quanyu Long", "Zhengyuan Liu", "Nancy F. Chen", "Wenya Wang"], "title": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning", "comment": "8 pages of main text, 2 pages of references and and limitations, 37 pages of appendices", "summary": "Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.", "AI": {"tldr": "SCOPE is a framework that separates reasoning from execution for multi-constraint planning, achieving state-of-the-art performance with lower cost and latency compared to existing LLM approaches.", "motivation": "Existing LLM approaches for multi-constraint planning have limitations: pure reasoning paradigms suffer from inconsistency and error accumulation, while coding/solver-based approaches lack flexibility and fail to capture generalizable logic across diverse problems.", "method": "SCOPE (Scalable COde Planning Engine) disentangles query-specific reasoning from generic code execution, producing reusable solver functions that require only minimal parameter changes across different queries.", "result": "SCOPE achieves 93.1% success on TravelPlanner (61.6% gain over best baseline CoT) while cutting inference cost by 1.4x and time by ~4.67x using GPT-4o.", "conclusion": "By separating reasoning from execution, SCOPE produces consistent, deterministic, and reusable solver functions that outperform existing approaches in multi-constraint planning tasks while being more cost-effective and faster."}}
{"id": "2601.09178", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09178", "abs": "https://arxiv.org/abs/2601.09178", "authors": ["Paul Brunzema", "Thomas Lew", "Ray Zhang", "Takeru Shirasawa", "John Subosits", "Marcus Greiff"], "title": "Vision-Conditioned Variational Bayesian Last Layer Dynamics Models", "comment": "9 pages, 7 figures, currently under review", "summary": "Agile control of robotic systems often requires anticipating how the environment affects system behavior. For example, a driver must perceive the road ahead to anticipate available friction and plan actions accordingly. Achieving such proactive adaptation within autonomous frameworks remains a challenge, particularly under rapidly changing conditions. Traditional modeling approaches often struggle to capture abrupt variations in system behavior, while adaptive methods are inherently reactive and may adapt too late to ensure safety. We propose a vision-conditioned variational Bayesian last-layer dynamics model that leverages visual context to anticipate changes in the environment. The model first learns nominal vehicle dynamics and is then fine-tuned with feature-wise affine transformations of latent features, enabling context-aware dynamics prediction. The resulting model is integrated into an optimal controller for vehicle racing. We validate our method on a Lexus LC500 racing through water puddles. With vision-conditioning, the system completed all 12 attempted laps under varying conditions. In contrast, all baselines without visual context consistently lost control, demonstrating the importance of proactive dynamics adaptation in high-performance applications.", "AI": {"tldr": "Vision-conditioned variational Bayesian model enables proactive adaptation to environmental changes for autonomous racing, outperforming reactive baselines that fail in dynamic conditions.", "motivation": "Autonomous systems need to anticipate environmental changes (like road friction) for proactive adaptation, but traditional methods struggle with abrupt variations and adaptive methods are too reactive for safety-critical applications like high-performance racing.", "method": "Propose a vision-conditioned variational Bayesian last-layer dynamics model that learns nominal vehicle dynamics first, then fine-tunes with feature-wise affine transformations of latent features using visual context to enable context-aware dynamics prediction.", "result": "Tested on Lexus LC500 racing through water puddles: vision-conditioned system completed all 12 attempted laps under varying conditions, while all baselines without visual context consistently lost control.", "conclusion": "Vision-conditioned dynamics modeling enables proactive adaptation to environmental changes, demonstrating critical importance for safety and performance in high-performance autonomous applications like vehicle racing."}}
{"id": "2601.08963", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.08963", "abs": "https://arxiv.org/abs/2601.08963", "authors": ["Adrita Das", "Peiran Jiang", "Dantong Zhu", "Barnabas Poczos", "Jose Lugo-Martinez"], "title": "Breaking the Bottlenecks: Scalable Diffusion Models for 3D Molecular Generation", "comment": null, "summary": "Diffusion models have emerged as a powerful class of generative models for molecular design, capable of capturing complex structural distributions and achieving high fidelity in 3D molecule generation. However, their widespread use remains constrained by long sampling trajectories, stochastic variance in the reverse process, and limited structural awareness in denoising dynamics. The Directly Denoising Diffusion Model (DDDM) mitigates these inefficiencies by replacing stochastic reverse MCMC updates with deterministic denoising step, substantially reducing inference time. Yet, the theoretical underpinnings of such deterministic updates have remained opaque. In this work, we provide a principled reinterpretation of DDDM through the lens of the Reverse Transition Kernel (RTK) framework by Huang et al. 2024, unifying deterministic and stochastic diffusion under a shared probabilistic formalism. By expressing the DDDM reverse process as an approximate kernel operator, we show that the direct denoising process implicitly optimizes a structured transport map between noisy and clean samples. This perspective elucidates why deterministic denoising achieves efficient inference. Beyond theoretical clarity, this reframing resolves several long-standing bottlenecks in molecular diffusion. The RTK view ensures numerical stability by enforcing well-conditioned reverse kernels, improves sample consistency by eliminating stochastic variance, and enables scalable and symmetry-preserving denoisers that respect SE(3) equivariance. Empirically, we demonstrate that RTK-guided deterministic denoising achieves faster convergence and higher structural fidelity than stochastic diffusion models, while preserving chemical validity across GEOM-DRUGS dataset. Code, models, and datasets are publicly available in our project repository.", "AI": {"tldr": "DDDM's deterministic denoising is reinterpreted through Reverse Transition Kernel framework, showing it optimizes structured transport maps for faster, more stable molecular generation.", "motivation": "Diffusion models for molecular design suffer from slow sampling, stochastic variance, and limited structural awareness. DDDM addresses these with deterministic denoising, but its theoretical foundations were unclear.", "method": "Reinterpret DDDM through Reverse Transition Kernel (RTK) framework, expressing deterministic denoising as approximate kernel operator that implicitly optimizes transport maps between noisy and clean samples.", "result": "RTK-guided deterministic denoising achieves faster convergence, higher structural fidelity, and better chemical validity than stochastic diffusion models on GEOM-DRUGS dataset, with improved numerical stability and sample consistency.", "conclusion": "The RTK framework provides theoretical clarity for deterministic denoising, unifying stochastic and deterministic diffusion while resolving key bottlenecks in molecular diffusion models through stable, efficient, and symmetry-preserving denoising."}}
{"id": "2601.08873", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.08873", "abs": "https://arxiv.org/abs/2601.08873", "authors": ["Hema Hariharan Samson"], "title": "ForensicFormer: Hierarchical Multi-Scale Reasoning for Cross-Domain Image Forgery Detection", "comment": "9 pages, 4 figures, 5 tables. Technical report on hierarchical multi-scale image forgery detection", "summary": "The proliferation of AI-generated imagery and sophisticated editing tools has rendered traditional forensic methods ineffective for cross-domain forgery detection. We present ForensicFormer, a hierarchical multi-scale framework that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning via cross-attention transformers. Unlike prior single-paradigm approaches, which achieve <75% accuracy on out-of-distribution datasets, our method maintains 86.8% average accuracy across seven diverse test sets, spanning traditional manipulations, GAN-generated images, and diffusion model outputs - a significant improvement over state-of-the-art universal detectors. We demonstrate superior robustness to JPEG compression (83% accuracy at Q=70 vs. 66% for baselines) and provide pixel-level forgery localization with a 0.76 F1-score. Extensive ablation studies validate that each hierarchical component contributes 4-10% accuracy improvement, and qualitative analysis reveals interpretable forensic features aligned with human expert reasoning. Our work bridges classical image forensics and modern deep learning, offering a practical solution for real-world deployment where manipulation techniques are unknown a priori.", "AI": {"tldr": "ForensicFormer is a hierarchical multi-scale transformer framework that achieves 86.8% average accuracy for cross-domain forgery detection across diverse manipulation types, significantly outperforming existing methods.", "motivation": "Traditional forensic methods are ineffective against modern AI-generated imagery and sophisticated editing tools, especially for cross-domain detection where manipulation techniques are unknown beforehand.", "method": "A hierarchical multi-scale framework using cross-attention transformers that unifies low-level artifact detection, mid-level boundary analysis, and high-level semantic reasoning for comprehensive forgery analysis.", "result": "Achieves 86.8% average accuracy across seven diverse test sets, maintains 83% accuracy under JPEG compression (vs. 66% for baselines), and provides pixel-level localization with 0.76 F1-score. Each hierarchical component contributes 4-10% accuracy improvement.", "conclusion": "ForensicFormer bridges classical image forensics and modern deep learning, offering a practical, robust solution for real-world deployment where manipulation techniques are unknown a priori."}}
{"id": "2601.09179", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09179", "abs": "https://arxiv.org/abs/2601.09179", "authors": ["Haotian Zhang", "Shijian Gao", "Xiang Cheng"], "title": "WiFo-M$^2$: Plug-and-Play Multi-Modal Sensing via Foundation Model to Empower Wireless Communications", "comment": "13 pages, 8 figures, 7 tables", "summary": "The growing adoption of sensor-rich intelligent systems has boosted the use of multi-modal sensing to improve wireless communications. However, traditional methods require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits both development scalability and real-world deployment. To address this, we propose WiFo-M$^2$, a foundation model that can be easily plugged into existing deep learning-based transceivers for universal performance gains. To extract generalizable out-of-band (OOB) channel features from multi-modal sensing, we introduce ContraSoM, a contrastive pre-training strategy. Once pre-trained, WiFo-M$^2$ infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation. Experiments show that WiFo-M$^2$ improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios.", "AI": {"tldr": "WiFo-M\u00b2 is a foundation model that enhances wireless communications by extracting generalizable out-of-band channel features from multi-modal sensing data, requiring no manual design and providing universal performance gains across various transceiver designs.", "motivation": "Traditional multi-modal sensing approaches for wireless communications require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits development scalability and real-world deployment.", "method": "Proposes WiFo-M\u00b2 foundation model with ContraSoM contrastive pre-training strategy to extract generalizable out-of-band channel features from multi-modal sensing. Once pre-trained, it infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation.", "result": "Experiments show WiFo-M\u00b2 improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios.", "conclusion": "WiFo-M\u00b2 provides a scalable, plug-and-play solution for enhancing wireless communications through multi-modal sensing without requiring manual design efforts, enabling universal performance gains across different transceiver architectures."}}
{"id": "2601.09057", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09057", "abs": "https://arxiv.org/abs/2601.09057", "authors": ["Xiaoli Xu", "Yong Zeng"], "title": "Hybrid Mono- and Bi-static OFDM-ISAC via BS-UE Cooperation: Closed-Form CRLB and Coverage Analysis", "comment": "BS-UE cooperative ISAC, OFDM ISAC, hybrid mono- and bi-static sensing, CRLB", "summary": "This paper proposes a hybrid mono- and bi-static sensing framework, by leveraging the base station (BS) and user equipment (UE) cooperation in integrated sensing and communication (ISAC) systems. This scheme is built on 3GPP-supported sensing modes, and it does not incur any extra spectrum cost or inter-cell coordination. To reveal the fundamental performance limit of the proposed hybrid sensing mode, we derive closed-form Cram\u00e9r-Rao lower bound (CRLB) for sensing target localization and velocity estimation, as functions of target and UE positions. The results reveal that significant performance gains can be achieved over the purely mono- or bi-static sensing, especially when the BS-target-UE form a favorable geometry, which is close to a right triangle. The analytical results are validated by simulations using effective parameter estimation algorithm and weighted mean square error (MSE) fusion method. Based on the derived sensing bound, we further analyze the sensing coverage by varying the UE positions, which shows that sensing coverage first improves then degrades as the BS-UE separation increases. Furthermore, the sensing accuracy for a potential target with best UE selection is derived as a function of the UE density in the network.", "AI": {"tldr": "A hybrid mono-/bi-static sensing framework for ISAC systems using BS-UE cooperation without extra spectrum cost, with closed-form CRLB analysis showing performance gains when geometry forms right triangle.", "motivation": "To improve sensing performance in integrated sensing and communication (ISAC) systems by leveraging BS-UE cooperation without requiring additional spectrum or inter-cell coordination, addressing limitations of purely mono-static or bi-static sensing approaches.", "method": "Proposes a hybrid mono- and bi-static sensing framework built on 3GPP-supported sensing modes. Derives closed-form Cram\u00e9r-Rao lower bounds (CRLB) for target localization and velocity estimation as functions of target and UE positions. Uses effective parameter estimation algorithm and weighted MSE fusion method for validation.", "result": "Significant performance gains over purely mono- or bi-static sensing, especially when BS-target-UE geometry forms a right triangle. Sensing coverage improves then degrades as BS-UE separation increases. Sensing accuracy with best UE selection derived as function of UE density.", "conclusion": "The hybrid sensing framework provides substantial performance improvements over conventional approaches, with optimal performance achieved under favorable geometric conditions. The analysis provides fundamental performance limits and practical insights for ISAC system design and deployment."}}
{"id": "2601.09100", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09100", "abs": "https://arxiv.org/abs/2601.09100", "authors": ["Lixiang Zhang", "Chenggong Zhao", "Qing Gao", "Xiaoke Zhao", "Gengyi Bai", "Jinhu Lv"], "title": "DScheLLM: Enabling Dynamic Scheduling through a Fine-Tuned Dual-System Large language Model", "comment": "14 pages, 6 figures", "summary": "Production scheduling is highly susceptible to dynamic disruptions, such as variations in processing times, machine availability, and unexpected task insertions. Conventional approaches typically rely on event-specific models and explicit analytical formulations, which limits their adaptability and generalization across previously unseen disturbances. To overcome these limitations, this paper proposes DScheLLM, a dynamic scheduling approach that leverages fine-tuned large language models within a dual-system (fast-slow) reasoning architecture to address disturbances of different scales. A unified large language model-based framework is constructed to handle dynamic events, where training datasets for both fast and slow reasoning modes are generated using exact schedules obtained from an operations research solver. The Huawei OpenPangu Embedded-7B model is subsequently fine-tuned under the hybrid reasoning paradigms using LoRA. Experimental evaluations on standard job shop scheduling benchmarks demonstrate that the fast-thinking mode can efficiently generate high-quality schedules and the slow-thinking mode can produce solver-compatible and well-formatted decision inputs. To the best of our knowledge, this work represents one of the earliest studies applying large language models to job shop scheduling in dynamic environments, highlighting their considerable potential for intelligent and adaptive scheduling optimization.", "AI": {"tldr": "DScheLLM: A dynamic scheduling approach using fine-tuned LLMs with dual-system reasoning (fast-slow) to handle production disruptions, trained on exact schedules from OR solvers.", "motivation": "Conventional production scheduling approaches are limited in adaptability to dynamic disruptions like processing time variations, machine availability changes, and unexpected task insertions. They rely on event-specific models and explicit analytical formulations, which don't generalize well to unseen disturbances.", "method": "Proposes DScheLLM: a unified LLM-based framework with dual-system reasoning architecture (fast and slow modes). Uses Huawei OpenPangu Embedded-7B model fine-tuned with LoRA. Training datasets generated from exact schedules obtained from operations research solver for both reasoning modes.", "result": "Experimental evaluations on standard job shop scheduling benchmarks show: fast-thinking mode efficiently generates high-quality schedules; slow-thinking mode produces solver-compatible and well-formatted decision inputs. One of earliest studies applying LLMs to job shop scheduling in dynamic environments.", "conclusion": "LLMs show considerable potential for intelligent and adaptive scheduling optimization in dynamic production environments, overcoming limitations of conventional approaches through flexible reasoning capabilities."}}
{"id": "2601.09231", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09231", "abs": "https://arxiv.org/abs/2601.09231", "authors": ["Shuoye Li", "Zhiyuan Song", "Yulin Li", "Zhihai Bi", "Jun Ma"], "title": "Online Trajectory Optimization for Arbitrary-Shaped Mobile Robots via Polynomial Separating Hypersurfaces", "comment": null, "summary": "An emerging class of trajectory optimization methods enforces collision avoidance by jointly optimizing the robot's configuration and a separating hyperplane. However, as linear separators only apply to convex sets, these methods require convex approximations of both the robot and obstacles, which becomes an overly conservative assumption in cluttered and narrow environments. In this work, we unequivocally remove this limitation by introducing nonlinear separating hypersurfaces parameterized by polynomial functions. We first generalize the classical separating hyperplane theorem and prove that any two disjoint bounded closed sets in Euclidean space can be separated by a polynomial hypersurface, serving as the theoretical foundation for nonlinear separation of arbitrary geometries. Building on this result, we formulate a nonlinear programming (NLP) problem that jointly optimizes the robot's trajectory and the coefficients of the separating polynomials, enabling geometry-aware collision avoidance without conservative convex simplifications. The optimization remains efficiently solvable using standard NLP solvers. Simulation and real-world experiments with nonconvex robots demonstrate that our method achieves smooth, collision-free, and agile maneuvers in environments where convex-approximation baselines fail.", "AI": {"tldr": "The paper introduces polynomial hypersurfaces for collision avoidance in trajectory optimization, enabling geometry-aware planning without conservative convex approximations.", "motivation": "Existing methods use separating hyperplanes that require convex approximations of robots and obstacles, which is overly conservative in cluttered/narrow environments and fails with nonconvex geometries.", "method": "Generalizes separating hyperplane theorem to prove any two disjoint bounded closed sets can be separated by polynomial hypersurfaces. Formulates NLP that jointly optimizes robot trajectory and polynomial coefficients for geometry-aware collision avoidance.", "result": "Method achieves smooth, collision-free, agile maneuvers in environments where convex-approximation baselines fail. Optimization remains efficiently solvable with standard NLP solvers.", "conclusion": "Polynomial hypersurfaces remove limitations of linear separators, enabling nonconservative collision avoidance for arbitrary geometries while maintaining computational efficiency."}}
{"id": "2601.08976", "categories": ["cs.LG", "cs.CY", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.08976", "abs": "https://arxiv.org/abs/2601.08976", "authors": ["Subhodeep Ghosh", "Zhihui Du", "Angela Bonifati", "Manish Kumar", "David Bader", "Senjuti Basu Roy"], "title": "Continuous Fairness On Data Streams", "comment": null, "summary": "We study the problem of enforcing continuous group fairness over windows in data streams. We propose a novel fairness model that ensures group fairness at a finer granularity level (referred to as block) within each sliding window. This formulation is particularly useful when the window size is large, making it desirable to enforce fairness at a finer granularity. Within this framework, we address two key challenges: efficiently monitoring whether each sliding window satisfies block-level group fairness, and reordering the current window as effectively as possible when fairness is violated. To enable real-time monitoring, we design sketch-based data structures that maintain attribute distributions with minimal overhead. We also develop optimal, efficient algorithms for the reordering task, supported by rigorous theoretical guarantees. Our evaluation on four real-world streaming scenarios demonstrates the practical effectiveness of our approach. We achieve millisecond-level processing and a throughput of approximately 30,000 queries per second on average, depending on system parameters. The stream reordering algorithm improves block-level group fairness by up to 95% in certain cases, and by 50-60% on average across datasets. A qualitative study further highlights the advantages of block-level fairness compared to window-level fairness.", "AI": {"tldr": "The paper proposes a novel fairness model for data streams that enforces group fairness at a finer block-level granularity within sliding windows, with efficient monitoring and reordering algorithms.", "motivation": "When dealing with large sliding windows in data streams, enforcing fairness at the window level may be too coarse. There's a need for finer-grained fairness enforcement within windows to ensure more equitable treatment across groups.", "method": "The authors design sketch-based data structures for real-time monitoring of attribute distributions and develop optimal, efficient algorithms for reordering windows when fairness is violated, with rigorous theoretical guarantees.", "result": "The approach achieves millisecond-level processing with ~30,000 queries/second throughput. The reordering algorithm improves block-level group fairness by up to 95% in some cases and 50-60% on average across datasets.", "conclusion": "Block-level fairness provides advantages over window-level fairness for data streams, and the proposed framework offers practical, efficient solutions for real-time fairness enforcement with significant improvements in fairness metrics."}}
{"id": "2601.08875", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08875", "abs": "https://arxiv.org/abs/2601.08875", "authors": ["Jiahao Qin", "Yiwen Wang"], "title": "Learning Domain-Invariant Representations for Cross-Domain Image Registration via Scene-Appearance Disentanglement", "comment": "12 pages, 7 figures, 4 tables. Code and data available at https://github.com/D-ST-Sword/SAR-NET", "summary": "Image registration under domain shift remains a fundamental challenge in computer vision and medical imaging: when source and target images exhibit systematic intensity differences, the brightness constancy assumption underlying conventional registration methods is violated, rendering correspondence estimation ill-posed. We propose SAR-Net, a unified framework that addresses this challenge through principled scene-appearance disentanglement. Our key insight is that observed images can be decomposed into domain-invariant scene representations and domain-specific appearance codes, enabling registration via re-rendering rather than direct intensity matching. We establish theoretical conditions under which this decomposition enables consistent cross-domain alignment (Proposition 1) and prove that our scene consistency loss provides a sufficient condition for geometric correspondence in the shared latent space (Proposition 2). Empirically, we validate SAR-Net on bidirectional scanning microscopy, where coupled domain shift and geometric distortion create a challenging real-world testbed. Our method achieves 0.885 SSIM and 0.979 NCC, representing 3.1x improvement over the strongest baseline, while maintaining real-time performance (77 fps). Ablation studies confirm that both scene consistency and domain alignment losses are necessary: removing either degrades performance by 90% SSIM or causes 223x increase in latent alignment error, respectively. Code and data are available at https://github.com/D-ST-Sword/SAR-NET.", "AI": {"tldr": "SAR-Net is a unified framework for image registration under domain shift that disentangles scene geometry from appearance, enabling cross-domain alignment through re-rendering rather than direct intensity matching.", "motivation": "Image registration under domain shift is challenging because systematic intensity differences violate the brightness constancy assumption, making correspondence estimation ill-posed when source and target images have different appearances.", "method": "Proposes scene-appearance disentanglement where images are decomposed into domain-invariant scene representations and domain-specific appearance codes. Registration is performed via re-rendering rather than direct intensity matching, with theoretical guarantees for cross-domain alignment.", "result": "Achieves 0.885 SSIM and 0.979 NCC on bidirectional scanning microscopy, representing 3.1x improvement over strongest baseline while maintaining real-time performance (77 fps). Ablation shows both scene consistency and domain alignment losses are essential.", "conclusion": "SAR-Net provides a principled solution to domain-shift registration by disentangling scene geometry from appearance, enabling robust cross-domain alignment with theoretical guarantees and strong empirical performance."}}
{"id": "2601.09186", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09186", "abs": "https://arxiv.org/abs/2601.09186", "authors": ["Weibo Wen", "Shijian Gao", "Haotian Zhang", "Xiang Cheng", "Liuqing Yang"], "title": "WiFo-E: A Scalable Wireless Foundation Model for End-to-End FDD Precoding in Communication Networks", "comment": null, "summary": "Accurate precoding in massive multiple-input multiple-output (MIMO) frequency-division duplexing (FDD) systems relies on efficient channel state information (CSI) acquisition. End-to-end learning frameworks improve performance by jointly optimizing this process, but they lack scalability and fail to generalize across different system configurations, such as varying numbers of antennas and users. To overcome this limitation, we introduce WiFo-E, a wireless foundation model designed for scalable end-to-end precoding. WiFo-E employs multi-task pretraining on a diverse set of configurations to learn transferable representations of underlying wireless principles. Central to the model is a sparse Mixture-of-Experts (MoE) Transformer architecture, which mitigates task interference and enhances training efficiency by activating specialized parameter subsets adaptively. Extensive simulations demonstrate that WiFo-E outperforms conventional per-configuration training and shows strong generalization to unseen system configurations, providing a flexible and efficient foundation for adaptive massive MIMO precoding.", "AI": {"tldr": "WiFo-E is a wireless foundation model using sparse Mixture-of-Experts Transformer for scalable end-to-end precoding in massive MIMO FDD systems, enabling generalization across different antenna/user configurations.", "motivation": "Current end-to-end learning frameworks for massive MIMO FDD precoding lack scalability and fail to generalize across different system configurations (varying numbers of antennas and users), limiting their practical deployment.", "method": "WiFo-E employs multi-task pretraining on diverse configurations to learn transferable wireless representations, using a sparse Mixture-of-Experts (MoE) Transformer architecture that adaptively activates specialized parameter subsets to mitigate task interference and improve training efficiency.", "result": "Extensive simulations show WiFo-E outperforms conventional per-configuration training and demonstrates strong generalization to unseen system configurations.", "conclusion": "WiFo-E provides a flexible and efficient foundation model for adaptive massive MIMO precoding that can scale across different system configurations."}}
{"id": "2601.09098", "categories": ["cs.IT", "eess.SP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09098", "abs": "https://arxiv.org/abs/2601.09098", "authors": ["Yifeng Qin", "Jing Chen", "Zhi Hao Jiang", "Zhi Ning Chen", "Yongming Huang"], "title": "Overcoming the Shadow: Bending Airy Beams for Radiative Near-Field Multi-User Access in Half-Space Blockage Scenarios", "comment": null, "summary": "The move to next-generation wireless communications with extremely large-scale antenna arrays (ELAAs) brings the communications into the radiative near-field (RNF) region, where distance-aware focusing is feasible. However, high-frequency RNF links are highly vulnerable to blockage in indoor environments dominated by half-space obstacles (walls, corners) that create knife-edge shadows. Conventional near-field focused beams offer high gain in line-of-sight (LoS) scenarios but suffer from severe energy truncation and effective-rank collapse in shadowed regions, making hardware remedies such as reconfigurable intelligent surfaces (RIS) impractical. We propose a beamforming strategy that exploits the auto-bending property of Airy beams to mitigate half-space blockage without additional hardware. The Airy beam is designed to ``ride'' the diffraction edge, accelerating its main lobe into the shadow to restore connectivity. Our contributions are threefold: (i) a Green's function-based RNF multi-user channel model that analytically reveals singular-value collapse behind knife-edge obstacles; (ii) an Airy analog beamforming scheme that optimizes the bending trajectory to recover the effective channel rank; and (iii) an Airy null-steering method that aligns oscillatory nulls with bright-region users to suppress interference in mixed shadow/bright scenarios. Simulations show that the proposed edge-riding Airy strategy achieves an SNR improvement of over 20 dB and restores full-rank connectivity in shadowed links compared to conventional RNF focusing, virtually eliminating outage in geometric shadows and increasing multi-user spectral efficiency by approximately 35\\% under typical indoor ELAA configurations. These results demonstrate robust RNF multi-user access in half-space blockage scenarios without relying on RIS.", "AI": {"tldr": "Proposes Airy beamforming to mitigate half-space blockage in radiative near-field communications using auto-bending beams that ride diffraction edges to restore connectivity without additional hardware.", "motivation": "Next-generation wireless with extremely large-scale antenna arrays operates in radiative near-field region, making links vulnerable to blockage from walls and corners that create knife-edge shadows. Conventional near-field beams suffer severe energy truncation and effective-rank collapse in shadowed areas.", "method": "1) Green's function-based radiative near-field multi-user channel model revealing singular-value collapse behind obstacles; 2) Airy analog beamforming optimizing bending trajectory to recover channel rank; 3) Airy null-steering aligning oscillatory nulls with bright-region users to suppress interference.", "result": "Achieves over 20 dB SNR improvement, restores full-rank connectivity in shadowed links, virtually eliminates outage in geometric shadows, and increases multi-user spectral efficiency by approximately 35% under typical indoor ELAA configurations.", "conclusion": "Airy beamforming enables robust radiative near-field multi-user access in half-space blockage scenarios without relying on reconfigurable intelligent surfaces, demonstrating practical solution for next-generation wireless communications."}}
{"id": "2601.09105", "categories": ["cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09105", "abs": "https://arxiv.org/abs/2601.09105", "authors": ["Wenbin Li", "Jingling Wu", "Xiaoyong Lin. Jing Chen", "Cong Chen"], "title": "AviationLMM: A Large Multimodal Foundation Model for Civil Aviation", "comment": "Accepted by 2025 7th International Conference on Interdisciplinary Computer Science and Engineering (ICICSE 2025) conference, Chongqing, China; 9 pages,1 figure,5 tables", "summary": "Civil aviation is a cornerstone of global transportation and commerce, and ensuring its safety, efficiency and customer satisfaction is paramount. Yet conventional Artificial Intelligence (AI) solutions in aviation remain siloed and narrow, focusing on isolated tasks or single modalities. They struggle to integrate heterogeneous data such as voice communications, radar tracks, sensor streams and textual reports, which limits situational awareness, adaptability, and real-time decision support. This paper introduces the vision of AviationLMM, a Large Multimodal foundation Model for civil aviation, designed to unify the heterogeneous data streams of civil aviation and enable understanding, reasoning, generation and agentic applications. We firstly identify the gaps between existing AI solutions and requirements. Secondly, we describe the model architecture that ingests multimodal inputs such as air-ground voice, surveillance, on-board telemetry, video and structured texts, and performs cross-modal alignment and fusion, and produces flexible outputs ranging from situation summaries and risk alerts to predictive diagnostics and multimodal incident reconstructions. In order to fully realize this vision, we identify key research opportunities to address, including data acquisition, alignment and fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation. By articulating the design and challenges of AviationLMM, we aim to boost the civil aviation foundation model progress and catalyze coordinated research efforts toward an integrated, trustworthy and privacy-preserving aviation AI ecosystem.", "AI": {"tldr": "Proposes AviationLMM, a Large Multimodal foundation Model for civil aviation to unify heterogeneous data streams (voice, radar, sensors, text) for comprehensive understanding, reasoning, and decision support.", "motivation": "Current AI solutions in aviation are siloed and narrow, focusing on isolated tasks or single modalities, which limits situational awareness, adaptability, and real-time decision support due to inability to integrate heterogeneous data streams.", "method": "Introduces AviationLMM architecture that ingests multimodal inputs (air-ground voice, surveillance, telemetry, video, structured texts), performs cross-modal alignment and fusion, and produces flexible outputs including situation summaries, risk alerts, predictive diagnostics, and incident reconstructions.", "result": "Identifies key research opportunities including data acquisition, alignment/fusion, pretraining, reasoning, trustworthiness, privacy, robustness to missing modalities, and synthetic scenario generation to realize the AviationLMM vision.", "conclusion": "Aims to boost civil aviation foundation model progress and catalyze coordinated research toward an integrated, trustworthy, and privacy-preserving aviation AI ecosystem by articulating the design and challenges of AviationLMM."}}
{"id": "2601.09318", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09318", "abs": "https://arxiv.org/abs/2601.09318", "authors": ["Ro'i Lang", "Elon Rimon"], "title": "Feedback-Based Mobile Robot Navigation in 3-D Environments Using Artificial Potential Functions Technical Report", "comment": null, "summary": "This technical report presents the construction and analysis of polynomial navigation functions for motion planning in 3-D workspaces populated by spherical and cylindrical obstacles. The workspace is modeled as a bounded spherical region, and obstacles are encoded using smooth polynomial implicit functions. We establish conditions under which the proposed navigation functions admit a unique non-degenerate minimum at the target while avoiding local minima, including in the presence of pairwise intersecting obstacles. Gradient and Hessian analyses are provided, and the theoretical results are validated through numerical simulations in obstacle rich 3-D environments.", "AI": {"tldr": "Construction of polynomial navigation functions for 3D motion planning with spherical/cylindrical obstacles, ensuring unique target minimum without local minima even with intersecting obstacles.", "motivation": "Need for reliable motion planning in 3D environments with obstacles, requiring navigation functions that guarantee convergence to target without getting stuck in local minima, especially in complex scenarios with intersecting obstacles.", "method": "Model workspace as bounded spherical region, encode obstacles using smooth polynomial implicit functions, construct polynomial navigation functions with mathematical conditions to ensure unique non-degenerate minimum at target while avoiding local minima.", "result": "Established conditions for navigation functions to work correctly, provided gradient and Hessian analyses, validated theoretical results through numerical simulations in obstacle-rich 3D environments.", "conclusion": "Polynomial navigation functions can be successfully constructed for 3D motion planning with spherical/cylindrical obstacles, providing theoretical guarantees and practical validation for obstacle avoidance even in challenging scenarios with intersecting obstacles."}}
{"id": "2601.08991", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08991", "abs": "https://arxiv.org/abs/2601.08991", "authors": ["Emile Dos Santos Ferreira", "Neil D. Lawrence", "Andrei Paleyes"], "title": "Optimising for Energy Efficiency and Performance in Machine Learning", "comment": "Accepted to CAIN'26", "summary": "The ubiquity of machine learning (ML) and the demand for ever-larger models bring an increase in energy consumption and environmental impact. However, little is known about the energy scaling laws in ML, and existing research focuses on training cost -- ignoring the larger cost of inference. Furthermore, tools for measuring the energy consumption of ML do not provide actionable feedback.\n  To address these gaps, we developed Energy Consumption Optimiser (ECOpt): a hyperparameter tuner that optimises for energy efficiency and model performance. ECOpt quantifies the trade-off between these metrics as an interpretable Pareto frontier. This enables ML practitioners to make informed decisions about energy cost and environmental impact, while maximising the benefit of their models and complying with new regulations.\n  Using ECOpt, we show that parameter and floating-point operation counts can be unreliable proxies for energy consumption, and observe that the energy efficiency of Transformer models for text generation is relatively consistent across hardware. These findings motivate measuring and publishing the energy metrics of ML models. We further show that ECOpt can have a net positive environmental impact and use it to uncover seven models for CIFAR-10 that improve upon the state of the art, when considering accuracy and energy efficiency together.", "AI": {"tldr": "ECOpt is a hyperparameter tuner that optimizes for both energy efficiency and model performance, enabling ML practitioners to make informed decisions about energy costs while maintaining model quality.", "motivation": "The paper addresses the growing energy consumption and environmental impact of ML models, noting that existing research focuses only on training costs while ignoring inference costs, and current measurement tools lack actionable feedback for optimization.", "method": "Developed ECOpt, a hyperparameter tuner that quantifies the trade-off between energy efficiency and model performance as an interpretable Pareto frontier, allowing practitioners to balance these competing objectives.", "result": "Found that parameter and FLOP counts are unreliable proxies for energy consumption; Transformer models for text generation show consistent energy efficiency across hardware; discovered 7 CIFAR-10 models that improve state-of-the-art when considering both accuracy and energy efficiency.", "conclusion": "ECOpt enables net positive environmental impact by helping practitioners optimize energy consumption while maintaining performance, and motivates the measurement and publication of energy metrics for ML models to address environmental concerns."}}
{"id": "2601.08876", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08876", "abs": "https://arxiv.org/abs/2601.08876", "authors": ["Shuai Chen", "Hao Chen", "Yuanchen Bei", "Tianyang Zhao", "Zhibo Zhou", "Feiran Huang"], "title": "The Semantic Lifecycle in Embodied AI: Acquisition, Representation and Storage via Foundation Models", "comment": null, "summary": "Semantic information in embodied AI is inherently multi-source and multi-stage, making it challenging to fully leverage for achieving stable perception-to-action loops in real-world environments. Early studies have combined manual engineering with deep neural networks, achieving notable progress in specific semantic-related embodied tasks. However, as embodied agents encounter increasingly complex environments and open-ended tasks, the demand for more generalizable and robust semantic processing capabilities has become imperative. Recent advances in foundation models (FMs) address this challenge through their cross-domain generalization abilities and rich semantic priors, reshaping the landscape of embodied AI research. In this survey, we propose the Semantic Lifecycle as a unified framework to characterize the evolution of semantic knowledge within embodied AI driven by foundation models. Departing from traditional paradigms that treat semantic processing as isolated modules or disjoint tasks, our framework offers a holistic perspective that captures the continuous flow and maintenance of semantic knowledge. Guided by this embodied semantic lifecycle, we further analyze and compare recent advances across three key stages: acquisition, representation, and storage. Finally, we summarize existing challenges and outline promising directions for future research.", "AI": {"tldr": "This survey paper proposes the Semantic Lifecycle framework to unify how embodied AI systems process semantic knowledge using foundation models, analyzing acquisition, representation, and storage stages.", "motivation": "Semantic information in embodied AI is complex (multi-source, multi-stage), making stable perception-to-action loops challenging. Traditional manual engineering approaches struggle with increasingly complex environments and open-ended tasks, requiring more generalizable and robust semantic processing capabilities.", "method": "The authors propose the Semantic Lifecycle as a unified framework to characterize semantic knowledge evolution in embodied AI driven by foundation models. This holistic perspective captures continuous flow and maintenance of semantic knowledge, departing from traditional isolated module approaches.", "result": "The framework enables systematic analysis and comparison of recent advances across three key stages: acquisition, representation, and storage of semantic knowledge in embodied AI systems using foundation models.", "conclusion": "Foundation models reshape embodied AI research through cross-domain generalization and rich semantic priors. The Semantic Lifecycle framework provides a comprehensive perspective for understanding semantic knowledge evolution, with identified challenges and promising future research directions."}}
{"id": "2601.09205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09205", "abs": "https://arxiv.org/abs/2601.09205", "authors": ["Ruisi He", "Mi Yang", "Zhengyu Zhang", "Bo Ai", "Zhangdui Zhong"], "title": "Artificial Intelligence Empowered Channel Prediction: A New Paradigm for Propagation Channel Modeling", "comment": null, "summary": "This paper proposes a novel paradigm centered on Artificial Intelligence (AI)-empowered propagation channel prediction to address the limitations of traditional channel modeling. We present a comprehensive framework that deeply integrates heterogeneous environmental data and physical propagation knowledge into AI models for site-specific channel prediction, which referred to as channel inference. By leveraging AI to infer site-specific wireless channel states, the proposed paradigm enables accurate prediction of channel characteristics at both link and area levels, capturing spatio-temporal evolution of radio propagation. Some novel strategies to realize the paradigm are introduced and discussed, including AI-native and AI-hybrid inference approaches. This paper also investigates how to enhance model generalization through transfer learning and improve interpretability via explainable AI techniques. Our approach demonstrates significant practical efficacy, achieving an average path loss prediction root mean square error (RMSE) of $\\sim$ 4 dB and reducing training time by 60\\%-75\\%. This new modeling paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks.", "AI": {"tldr": "AI-powered channel prediction framework integrates environmental data and physical knowledge for site-specific wireless channel inference, achieving ~4dB RMSE and 60-75% faster training.", "motivation": "To overcome limitations of traditional channel modeling by creating a more accurate, site-specific approach that captures spatio-temporal evolution of radio propagation for future communication networks.", "method": "Proposes AI-empowered channel prediction framework integrating heterogeneous environmental data and physical propagation knowledge. Introduces AI-native and AI-hybrid inference approaches, uses transfer learning for generalization, and explainable AI for interpretability.", "result": "Achieves average path loss prediction RMSE of ~4 dB and reduces training time by 60-75%, demonstrating significant practical efficacy for site-specific channel prediction.", "conclusion": "The AI-empowered channel prediction paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks."}}
{"id": "2601.09124", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09124", "abs": "https://arxiv.org/abs/2601.09124", "authors": ["Rachel St. Clair", "John Austin Cook", "Peter Sutor", "Victor Cavero", "Garrett Mindt"], "title": "The .serva Standard: One Primitive for All AI Cost Reduced, Barriers Removed", "comment": null, "summary": "Artificial Intelligence (AI) infrastructure faces two compounding crises. Compute payload - the unsustainable energy and capital costs of training and inference - threatens to outpace grid capacity and concentrate capability among a handful of organizations. Data chaos - the 80% of project effort consumed by preparation, conversion, and preprocessing - strangles development velocity and locks datasets to single model architectures. Current approaches treat these as separate problems, managing each with incremental optimization while increasing ecosystem complexity. This paper presents ServaStack: a universal data format (.serva) paired with a universal AI compute engine (Chimera). The .serva format achieves lossless compression by encoding information using laser holography principles, while Chimera converts compute operations into a representational space where computation occurs directly on .serva files without decompression. The result is automatic data preprocessing. The Chimera engine enables any existing model to operate on .serva data without retraining, preserving infrastructure investments while revamping efficiency. Internal benchmarks demonstrate 30-374x energy efficiency improvements (96-99% reduction), 4x-34x lossless storage compression, and 68x compute payload reduction without accuracy loss when compared to RNN, CNN, and MLP models on FashionMNIST and MNIST datasets. At hyperscale with one billion daily iterations, these gains translate to $4.85M savings per petabyte per training cycle. When any data flows to any model on any hardware, the AI development paradigm shifts. The bottleneck moves from infrastructure to imagination.", "AI": {"tldr": "ServaStack introduces a universal data format (.serva) using laser holography for lossless compression and a universal AI compute engine (Chimera) that processes compressed data directly, dramatically reducing energy, storage, and compute costs while eliminating data preprocessing bottlenecks.", "motivation": "AI infrastructure faces two major crises: 1) Compute payload - unsustainable energy and capital costs threatening grid capacity and concentrating capability among few organizations, and 2) Data chaos - 80% of project effort consumed by data preparation, conversion, and preprocessing, slowing development and locking datasets to specific model architectures.", "method": "Two components: 1) .serva format - universal data format using laser holography principles for lossless compression, and 2) Chimera engine - universal AI compute engine that converts compute operations into a representational space where computation occurs directly on .serva files without decompression, enabling automatic data preprocessing.", "result": "30-374x energy efficiency improvements (96-99% reduction), 4x-34x lossless storage compression, 68x compute payload reduction without accuracy loss on FashionMNIST and MNIST datasets. At hyperscale: $4.85M savings per petabyte per training cycle. Existing models can operate on .serva data without retraining.", "conclusion": "ServaStack fundamentally shifts AI development paradigm by eliminating infrastructure bottlenecks, moving the bottleneck from infrastructure to imagination. It enables any data to flow to any model on any hardware while preserving existing infrastructure investments."}}
{"id": "2601.09113", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09113", "abs": "https://arxiv.org/abs/2601.09113", "authors": ["Zixia Jia", "Jiaqi Li", "Yipeng Kang", "Yuxuan Wang", "Tong Wu", "Quansen Wang", "Xiaobo Wang", "Shuyi Zhang", "Junzhe Shen", "Qing Li", "Siyuan Qi", "Yitao Liang", "Di He", "Zilong Zheng", "Song-Chun Zhu"], "title": "The AI Hippocampus: How Far are We From Human Memory?", "comment": null, "summary": "Memory plays a foundational role in augmenting the reasoning, adaptability, and contextual fidelity of modern Large Language Models and Multi-Modal LLMs. As these models transition from static predictors to interactive systems capable of continual learning and personalized inference, the incorporation of memory mechanisms has emerged as a central theme in their architectural and functional evolution. This survey presents a comprehensive and structured synthesis of memory in LLMs and MLLMs, organizing the literature into a cohesive taxonomy comprising implicit, explicit, and agentic memory paradigms. Specifically, the survey delineates three primary memory frameworks. Implicit memory refers to the knowledge embedded within the internal parameters of pre-trained transformers, encompassing their capacity for memorization, associative retrieval, and contextual reasoning. Recent work has explored methods to interpret, manipulate, and reconfigure this latent memory. Explicit memory involves external storage and retrieval components designed to augment model outputs with dynamic, queryable knowledge representations, such as textual corpora, dense vectors, and graph-based structures, thereby enabling scalable and updatable interaction with information sources. Agentic memory introduces persistent, temporally extended memory structures within autonomous agents, facilitating long-term planning, self-consistency, and collaborative behavior in multi-agent systems, with relevance to embodied and interactive AI. Extending beyond text, the survey examines the integration of memory within multi-modal settings, where coherence across vision, language, audio, and action modalities is essential. Key architectural advances, benchmark tasks, and open challenges are discussed, including issues related to memory capacity, alignment, factual consistency, and cross-system interoperability.", "AI": {"tldr": "A comprehensive survey paper that organizes memory mechanisms in LLMs and MLLMs into three paradigms: implicit (internal knowledge), explicit (external storage), and agentic (persistent structures for autonomous agents), with discussion of multimodal integration and open challenges.", "motivation": "Memory is crucial for enhancing reasoning, adaptability, and contextual fidelity in LLMs and MLLMs as they evolve from static predictors to interactive systems capable of continual learning and personalized inference. The field lacks a structured synthesis of memory approaches.", "method": "The paper presents a survey that organizes existing literature into a cohesive taxonomy of three memory paradigms: implicit memory (knowledge embedded in model parameters), explicit memory (external storage and retrieval components), and agentic memory (persistent structures for autonomous agents). It also examines multimodal memory integration across vision, language, audio, and action modalities.", "result": "The survey provides a structured framework for understanding memory in LLMs and MLLMs, delineating key architectural advances, benchmark tasks, and research directions across the three memory paradigms and their multimodal extensions.", "conclusion": "Memory mechanisms are central to the evolution of LLMs and MLLMs toward interactive, continual learning systems. The survey identifies open challenges including memory capacity, alignment, factual consistency, and cross-system interoperability that need to be addressed for future progress."}}
{"id": "2601.09377", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09377", "abs": "https://arxiv.org/abs/2601.09377", "authors": ["Xuemei Yao", "Xiao Yang", "Jianbin Sun", "Liuwei Xie", "Xuebin Shao", "Xiyu Fang", "Hang Su", "Kewei Yang"], "title": "ReflexDiffusion: Reflection-Enhanced Trajectory Planning for High-lateral-acceleration Scenarios in Autonomous Driving", "comment": "Accepted by AAAI 2026", "summary": "Generating safe and reliable trajectories for autonomous vehicles in long-tail scenarios remains a significant challenge, particularly for high-lateral-acceleration maneuvers such as sharp turns, which represent critical safety situations. Existing trajectory planners exhibit systematic failures in these scenarios due to data imbalance. This results in insufficient modelling of vehicle dynamics, road geometry, and environmental constraints in high-risk situations, leading to suboptimal or unsafe trajectory prediction when vehicles operate near their physical limits. In this paper, we introduce ReflexDiffusion, a novel inference-stage framework that enhances diffusion-based trajectory planners through reflective adjustment. Our method introduces a gradient-based adjustment mechanism during the iterative denoising process: after each standard trajectory update, we compute the gradient between the conditional and unconditional noise predictions to explicitly amplify critical conditioning signals, including road curvature and lateral vehicle dynamics. This amplification enforces strict adherence to physical constraints, particularly improving stability during high-lateral-acceleration maneuvers where precise vehicle-road interaction is paramount. Evaluated on the nuPlan Test14-hard benchmark, ReflexDiffusion achieves a 14.1% improvement in driving score for high-lateral-acceleration scenarios over the state-of-the-art (SOTA) methods. This demonstrates that inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The framework's architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering a practical solution for improving autonomous vehicle safety in challenging driving conditions.", "AI": {"tldr": "ReflexDiffusion improves diffusion-based trajectory planners for autonomous vehicles in high-lateral-acceleration scenarios through inference-time gradient adjustment that amplifies critical conditioning signals like road curvature and vehicle dynamics.", "motivation": "Existing trajectory planners fail in long-tail scenarios like sharp turns due to data imbalance, leading to insufficient modeling of vehicle dynamics and road geometry in high-risk situations where vehicles operate near physical limits.", "method": "Introduces ReflexDiffusion, an inference-stage framework with gradient-based adjustment during iterative denoising. After each standard trajectory update, computes gradient between conditional and unconditional noise predictions to amplify critical conditioning signals (road curvature, lateral vehicle dynamics), enforcing strict adherence to physical constraints.", "result": "Achieves 14.1% improvement in driving score for high-lateral-acceleration scenarios on nuPlan Test14-hard benchmark compared to state-of-the-art methods.", "conclusion": "Inference-time trajectory optimization can effectively compensate for training data sparsity by dynamically reinforcing safety-critical constraints near handling limits. The architecture-agnostic design enables direct deployment to existing diffusion-based planners, offering practical safety improvements for autonomous vehicles in challenging conditions."}}
{"id": "2601.08999", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08999", "abs": "https://arxiv.org/abs/2601.08999", "authors": ["Pranjal Patil", "Anli Ji", "Berkay Aydin"], "title": "Physics-Guided Counterfactual Explanations for Large-Scale Multivariate Time Series: Application in Scalable and Interpretable SEP Event Prediction", "comment": "This is a pre-print of an accepted paper at IEEE BigData 2025, SS 11:Towards an Understanding of Artificial Intelligence: Bridging Theory, Explainability, and Practical Applications", "summary": "Accurate prediction of solar energetic particle events is vital for safeguarding satellites, astronauts, and space-based infrastructure. Modern space weather monitoring generates massive volumes of high-frequency, multivariate time series (MVTS) data from sources such as the Geostationary perational Environmental Satellites (GOES). Machine learning (ML) models trained on this data show strong predictive power, but most existing methods overlook domain-specific feasibility constraints. Counterfactual explanations have emerged as a key tool for improving model interpretability, yet existing approaches rarely enforce physical plausibility. This work introduces a Physics-Guided Counterfactual Explanation framework, a novel method for generating counterfactual explanations in time series classification tasks that remain consistent with underlying physical principles. Applied to solar energetic particles (SEP) forecasting, this framework achieves over 80% reduction in Dynamic Time Warping (DTW) distance increasing the proximity, produces counterfactual explanations with higher sparsity, and reduces runtime by nearly 50% compared to state-of-the-art baselines such as DiCE. Beyond numerical improvements, this framework ensures that generated counterfactual explanations are physically plausible and actionable in scientific domains. In summary, the framework generates counterfactual explanations that are both valid and physically consistent, while laying the foundation for scalable counterfactual generation in big data environments.", "AI": {"tldr": "Physics-guided counterfactual explanation framework for solar energetic particle forecasting that ensures physical plausibility while improving proximity, sparsity, and runtime efficiency.", "motivation": "Solar energetic particle event prediction is critical for space safety, but existing ML models lack interpretability and ignore physical feasibility constraints. Counterfactual explanations need to be physically plausible to be actionable in scientific domains.", "method": "Introduces a Physics-Guided Counterfactual Explanation framework for time series classification that incorporates domain-specific physical principles to generate physically consistent counterfactual explanations.", "result": "Achieves over 80% reduction in Dynamic Time Warping distance (improving proximity), produces sparser counterfactual explanations, and reduces runtime by nearly 50% compared to state-of-the-art baselines like DiCE.", "conclusion": "The framework generates valid and physically consistent counterfactual explanations, establishing a foundation for scalable counterfactual generation in big data environments while ensuring scientific actionability."}}
{"id": "2601.08881", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08881", "abs": "https://arxiv.org/abs/2601.08881", "authors": ["Yu Xu", "Hongbin Yan", "Juan Cao", "Yiji Cheng", "Tiankai Hang", "Runze He", "Zijin Yin", "Shiyi Zhang", "Yuxin Zhang", "Jintao Li", "Chunyu Wang", "Qinglin Lu", "Tong-Yee Lee", "Fan Tang"], "title": "TAG-MoE: Task-Aware Gating for Unified Generative Mixture-of-Experts", "comment": "Project page: https://yuci-gpt.github.io/TAG-MoE/", "summary": "Unified image generation and editing models suffer from severe task interference in dense diffusion transformers architectures, where a shared parameter space must compromise between conflicting objectives (e.g., local editing v.s. subject-driven generation). While the sparse Mixture-of-Experts (MoE) paradigm is a promising solution, its gating networks remain task-agnostic, operating based on local features, unaware of global task intent. This task-agnostic nature prevents meaningful specialization and fails to resolve the underlying task interference. In this paper, we propose a novel framework to inject semantic intent into MoE routing. We introduce a Hierarchical Task Semantic Annotation scheme to create structured task descriptors (e.g., scope, type, preservation). We then design Predictive Alignment Regularization to align internal routing decisions with the task's high-level semantics. This regularization evolves the gating network from a task-agnostic executor to a dispatch center. Our model effectively mitigates task interference, outperforming dense baselines in fidelity and quality, and our analysis shows that experts naturally develop clear and semantically correlated specializations.", "AI": {"tldr": "A novel framework that injects semantic intent into Mixture-of-Experts routing for unified image generation/editing models, using hierarchical task annotation and predictive alignment regularization to resolve task interference.", "motivation": "Unified image generation and editing models suffer from severe task interference in dense diffusion transformers, where shared parameters must compromise between conflicting objectives like local editing vs. subject-driven generation. While sparse MoE is promising, its task-agnostic gating networks prevent meaningful specialization and fail to resolve task interference.", "method": "Proposes a framework to inject semantic intent into MoE routing: 1) Hierarchical Task Semantic Annotation scheme to create structured task descriptors (scope, type, preservation), 2) Predictive Alignment Regularization to align internal routing decisions with high-level task semantics, evolving gating networks from task-agnostic executors to dispatch centers.", "result": "The model effectively mitigates task interference, outperforming dense baselines in fidelity and quality. Analysis shows that experts naturally develop clear and semantically correlated specializations.", "conclusion": "Injecting semantic intent into MoE routing through hierarchical task annotation and predictive alignment regularization successfully resolves task interference in unified image generation/editing models, enabling meaningful expert specialization and improved performance."}}
{"id": "2601.09317", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09317", "abs": "https://arxiv.org/abs/2601.09317", "authors": ["Nadav Neuberger", "Simon Kollecker", "Martin Kaeske"], "title": "Range-Doppler-Acceleration Estimation for Fast-Moving and Accelerating Targets", "comment": null, "summary": "A central aspect of every pulsed radar signal processor is the targets Range-Doppler estimation within a Coherent Processing Interval. Conventional methods typically rely on simplifying assumptions, such as linear target motion, narrowband operation, or constant velocity, to enable fast computation. However, these assumptions break down in scenarios involving quadratic range-time behavior, high radial velocities or accelerations, or wideband signals, leading to undesired effects such as intra-pulse Doppler shift/stretch and target migration across Range-Doppler cells. This paper presents a generalized waveform-independent Range-Doppler compression approach that compensates for these effects while maintaining minimal Signal-to-Noise-Ratio loss and practical computational efficiency. The performance limits of the proposed method are analyzed and expressed through a unified metric that depends on both scene and system parameters. Comparison with other approaches is presented, showing their estimation bias and performance degradation.", "AI": {"tldr": "A generalized Range-Doppler compression method that handles nonlinear target motion and wideband effects without SNR loss, outperforming conventional approaches.", "motivation": "Conventional Range-Doppler estimation methods fail in scenarios with quadratic range-time behavior, high velocities/accelerations, or wideband signals due to simplifying assumptions about linear motion, narrowband operation, and constant velocity.", "method": "A generalized waveform-independent Range-Doppler compression approach that compensates for intra-pulse Doppler shift/stretch and target migration across cells while maintaining SNR and computational efficiency.", "result": "Performance limits are analyzed through a unified metric based on scene and system parameters. Comparison shows conventional methods suffer from estimation bias and performance degradation.", "conclusion": "The proposed method effectively handles complex radar scenarios with nonlinear motion and wideband effects while maintaining practical computational efficiency and minimal SNR loss."}}
{"id": "2601.09137", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09137", "abs": "https://arxiv.org/abs/2601.09137", "authors": ["Mingyu Hu", "Nan Liu", "Wei Kang"], "title": "Movable Antenna Assisted Dual-Polarized Multi-Cell Cooperative AirComp: An Alternating Optimization Approach", "comment": null, "summary": "Over-the-air computation (AirComp) is a key enabler for distributed optimization, since it leverages analog waveform superposition to perform aggregation and thereby mitigates the communication bottleneck caused by iterative information exchange. However, AirComp is sensitive to wireless environment and conventional systems with fixed single-polarized base-station arrays cannot fully exploit spatial degrees of freedom while also suffering from polarization mismatch. To overcome these limitations, this paper proposes a multi-cell cooperative air-computation framework assisted by dual-polarized movable antennas (D-PMA), and formulates a mean squared error (MSE) minimization problem by jointly optimizing the combining matrix, polarization vectors, antenna positions, and user transmit coefficients. The resulting problem is highly nonconvex, so an alternating algorithm is developed in which closed-form updates are obtained for the combining matrix and transmit coefficients. Then a method based on successive convex approximation (SCA) and semidefinite relaxation (SDR) is proposed to refine polarization vectors, and the antenna positions are updated using a gradient-based method. In addition, we develop a statistical-channel-based scheme for optimizing the antenna locations, and we further present the corresponding algorithm to efficiently obtain the solution. Numerical results show that the proposed movable dual-polarized scheme consistently outperforms movable single-polarized and fixed-antenna baselines under both instantaneous and statistical channels.", "AI": {"tldr": "A multi-cell cooperative AirComp framework using dual-polarized movable antennas (D-PMA) to improve distributed optimization performance by jointly optimizing combining matrix, polarization vectors, antenna positions, and user transmit coefficients.", "motivation": "AirComp enables efficient distributed optimization via analog waveform superposition, but conventional fixed single-polarized base-station arrays suffer from limited spatial degrees of freedom and polarization mismatch, limiting performance in wireless environments.", "method": "Proposed a multi-cell cooperative AirComp framework with D-PMA, formulated MSE minimization problem, developed alternating algorithm with closed-form updates for combining matrix/transmit coefficients, SCA-SDR for polarization vectors, gradient-based antenna position updates, and statistical-channel-based optimization scheme.", "result": "Numerical results show the proposed movable dual-polarized scheme consistently outperforms both movable single-polarized and fixed-antenna baselines under both instantaneous and statistical channels.", "conclusion": "Dual-polarized movable antennas significantly enhance AirComp performance by exploiting spatial and polarization degrees of freedom, with the proposed optimization framework effectively solving the nonconvex joint optimization problem."}}
{"id": "2601.09152", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09152", "abs": "https://arxiv.org/abs/2601.09152", "authors": ["Yiwen Tu", "Xuan Liu", "Lianhui Qin", "Haojian Jin"], "title": "PrivacyReasoner: Can LLM Emulate a Human-like Privacy Mind?", "comment": null, "summary": "This paper introduces PRA, an AI-agent design for simulating how individual users form privacy concerns in response to real-world news. Moving beyond population-level sentiment analysis, PRA integrates privacy and cognitive theories to simulate user-specific privacy reasoning grounded in personal comment histories and contextual cues. The agent reconstructs each user's \"privacy mind\", dynamically activates relevant privacy memory through a contextual filter that emulates bounded rationality, and generates synthetic comments reflecting how that user would likely respond to new privacy scenarios. A complementary LLM-as-a-Judge evaluator, calibrated against an established privacy concern taxonomy, quantifies the faithfulness of generated reasoning. Experiments on real-world Hacker News discussions show that \\PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.", "AI": {"tldr": "PRA is an AI agent that simulates individual users' privacy concern formation by integrating privacy theories with personal comment histories and contextual cues, outperforming baselines in predicting privacy concerns across multiple domains.", "motivation": "Current approaches focus on population-level sentiment analysis, but there's a need to understand how individual users form privacy concerns in response to real-world news, requiring user-specific privacy reasoning grounded in personal histories and context.", "method": "PRA integrates privacy and cognitive theories to reconstruct each user's \"privacy mind,\" uses a contextual filter to activate relevant privacy memory through bounded rationality emulation, generates synthetic comments reflecting user responses to new privacy scenarios, and employs an LLM-as-a-Judge evaluator calibrated against an established privacy concern taxonomy.", "result": "Experiments on real-world Hacker News discussions show PRA outperforms baseline agents in privacy concern prediction and captures transferable reasoning patterns across domains including AI, e-commerce, and healthcare.", "conclusion": "PRA successfully simulates individual users' privacy concern formation by integrating theoretical frameworks with personal histories, demonstrating practical effectiveness in predicting privacy concerns and capturing cross-domain reasoning patterns."}}
{"id": "2601.09444", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09444", "abs": "https://arxiv.org/abs/2601.09444", "authors": ["Lauri Suomela", "Naoki Takahata", "Sasanka Kuruppu Arachchige", "Harry Edelman", "Joni-Kristian K\u00e4m\u00e4r\u00e4inen"], "title": "Data Scaling for Navigation in Unknown Environments", "comment": null, "summary": "Generalization of imitation-learned navigation policies to environments unseen in training remains a major challenge. We address this by conducting the first large-scale study of how data quantity and data diversity affect real-world generalization in end-to-end, map-free visual navigation. Using a curated 4,565-hour crowd-sourced dataset collected across 161 locations in 35 countries, we train policies for point goal navigation and evaluate their closed-loop control performance on sidewalk robots operating in four countries, covering 125 km of autonomous driving.\n  Our results show that large-scale training data enables zero-shot navigation in unknown environments, approaching the performance of policies trained with environment-specific demonstrations. Critically, we find that data diversity is far more important than data quantity. Doubling the number of geographical locations in a training set decreases navigation errors by ~15%, while performance benefit from adding data from existing locations saturates with very little data. We also observe that, with noisy crowd-sourced data, simple regression-based models outperform generative and sequence-based architectures. We release our policies, evaluation setup and example videos on the project page.", "AI": {"tldr": "Large-scale study shows data diversity (geographic locations) is more important than data quantity for zero-shot generalization of imitation-learned navigation policies to unseen environments.", "motivation": "Generalization of imitation-learned navigation policies to unseen environments remains a major challenge, and there's limited understanding of how data quantity and diversity affect real-world generalization in end-to-end visual navigation.", "method": "Used a curated 4,565-hour crowd-sourced dataset from 161 locations across 35 countries to train policies for point goal navigation. Evaluated closed-loop control performance on sidewalk robots in four countries covering 125 km of autonomous driving.", "result": "Large-scale training enables zero-shot navigation in unknown environments, approaching performance of environment-specific policies. Data diversity (geographic locations) is far more important than data quantity - doubling locations decreases errors by ~15%, while adding data from existing locations saturates quickly. Simple regression-based models outperform generative/sequence-based architectures with noisy crowd-sourced data.", "conclusion": "For real-world generalization of visual navigation policies, prioritizing data diversity (geographic coverage) over data quantity is crucial, and simpler regression models work better with noisy crowd-sourced data than complex architectures."}}
{"id": "2601.09000", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09000", "abs": "https://arxiv.org/abs/2601.09000", "authors": ["Annalisa Belloni", "Lorenzo Noci", "Antonio Orvieto"], "title": "Universal Dynamics of Warmup Stable Decay: understanding WSD beyond Transformers", "comment": "Accepted at the 2025 HiLD and MOSS Workshops at ICML", "summary": "The Warmup Stable Decay (WSD) learning rate scheduler has recently become popular, largely due to its good performance and flexibility when training large language models. It remains an open question whether the remarkable performance of WSD - using a decaying learning rate for only a fraction of training compared to cosine decay - is a phenomenon specific to transformer-based language models that can potentially offer new theoretical insights into their training dynamics. Inspired by the usage of learning rate schedulers as a new lens into understanding landscape geometry (e.g., river valley, connected minima, progressive sharpening), in this work we compare the WSD path of the Adam optimizer on a Pythia-like language model to that of a small CNN trained to classify CIFAR10 images. We observe most training signals, optimizer path features, and sharpness dynamics to be qualitatively similar in such architectures. This consistency points to shared geometric characteristics of the loss landscapes of old and new nonconvex problems, and hints to future research questions around the geometry of high dimensional optimization problems.", "AI": {"tldr": "WSD scheduler's success isn't transformer-specific - similar training dynamics observed in both language models and CNNs, suggesting shared loss landscape geometry across architectures.", "motivation": "To investigate whether the remarkable performance of Warmup Stable Decay (WSD) scheduler is specific to transformer-based language models or reveals broader insights about training dynamics and loss landscape geometry.", "method": "Compare WSD optimizer paths on a Pythia-like language model with those on a small CNN trained on CIFAR10, analyzing training signals, optimizer path features, and sharpness dynamics.", "result": "Most training signals, optimizer path features, and sharpness dynamics are qualitatively similar across both architectures, indicating shared geometric characteristics.", "conclusion": "WSD's success reveals shared loss landscape geometry across different nonconvex problems, suggesting future research directions in high-dimensional optimization geometry."}}
{"id": "2601.08882", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08882", "abs": "https://arxiv.org/abs/2601.08882", "authors": ["Thomas Snyder", "H. Lexie Yang", "Stefan Schnake", "Steffen Schotth\u00f6fer"], "title": "Compressing Vision Transformers in Geospatial Transfer Learning with Manifold-Constrained Optimization", "comment": null, "summary": "Deploying geospatial foundation models on resource-constrained edge devices demands compact architectures that maintain high downstream performance. However, their large parameter counts and the accuracy loss often induced by compression limit practical adoption. In this work, we leverage manifold-constrained optimization framework DLRT to compress large vision transformer-based geospatial foundation models during transfer learning. By enforcing structured low-dimensional parameterizations aligned with downstream objectives, this approach achieves strong compression while preserving task-specific accuracy. We show that the method outperforms of-the-shelf low-rank methods as LoRA. Experiments on diverse geospatial benchmarks confirm substantial parameter reduction with minimal accuracy loss, enabling high-performing, on-device geospatial models.", "AI": {"tldr": "DLRT compression framework reduces geospatial foundation model size for edge deployment while maintaining accuracy through manifold-constrained optimization during transfer learning.", "motivation": "Geospatial foundation models are too large for resource-constrained edge devices, and existing compression methods cause significant accuracy loss, limiting practical adoption.", "method": "Uses manifold-constrained optimization framework DLRT to compress vision transformer-based geospatial foundation models during transfer learning, enforcing structured low-dimensional parameterizations aligned with downstream objectives.", "result": "Outperforms standard low-rank methods like LoRA, achieves substantial parameter reduction with minimal accuracy loss across diverse geospatial benchmarks, enabling high-performing on-device models.", "conclusion": "DLRT enables effective compression of geospatial foundation models for edge deployment, balancing model size reduction with task-specific accuracy preservation."}}
{"id": "2601.09336", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09336", "abs": "https://arxiv.org/abs/2601.09336", "authors": ["Gabriele Bertoli", "Kai Schroeter", "Rossella Arcucci", "Enrica Caporali"], "title": "A Hybrid Machine Learning Framework for Improved Short-Term Peak-Flow Forecasting", "comment": "Comments: 16 pages, 6 figures. Revised version in preparation for journal submission", "summary": "Reliable river flow forecasting is an essential component of flood risk management and early warning systems. It enables improved emergency response coordination and is critical for protecting infrastructure, communities, and ecosystems from extreme hydrological events. Process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows. To address this limitation, this study introduces a hybrid forecasting framework that couples Extreme Gradient Boosting (XGBoost) and Random Forest (RF). XGBoost is employed for continuous streamflow forecasting, while RF is specifically trained for peak-flow prediction, and the two outputs are combined into an enhanced forecast. The approach is implemented across 857 catchments of the LamaH-CE dataset, using rainfall and discharge observations at 6-hour resolution. Results demonstrate consistently high skill, with 71% of catchments achieving a Kling-Gupta Efficiency (KGE) greater than 0.90. Peak-flow detection reaches 87%, with a false-alarm rate of 13%. Compared to the European Flood Awareness System (EFAS), the framework achieves lower peak-magnitude errors, fewer false alarms, and improved streamflow and peak-flow forecasting accuracy. The proposed framework is computationally lightweight, scalable, and easily transferable across watersheds, with training times of only seconds on standard CPUs. These findings highlight the potential of integrating hydrological understanding with efficient machine learning to improve the accuracy and reliability of operational flood forecasting, and outline future directions for hybrid hydrological-machine learning model development.", "AI": {"tldr": "Hybrid XGBoost-RF framework improves river flow forecasting, especially peak flows, achieving high accuracy across 857 catchments with better performance than existing systems.", "motivation": "Current process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows, which is critical for flood risk management and early warning systems.", "method": "Hybrid framework combining Extreme Gradient Boosting (XGBoost) for continuous streamflow forecasting and Random Forest (RF) specifically trained for peak-flow prediction, implemented across 857 catchments using rainfall and discharge data at 6-hour resolution.", "result": "71% of catchments achieved KGE > 0.90, peak-flow detection reached 87% with 13% false-alarm rate, outperformed EFAS with lower peak-magnitude errors, fewer false alarms, and improved accuracy; computationally lightweight with seconds of training time.", "conclusion": "The hybrid framework demonstrates potential for integrating hydrological understanding with efficient machine learning to improve operational flood forecasting accuracy and reliability, offering a scalable and transferable solution."}}
{"id": "2601.09188", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09188", "abs": "https://arxiv.org/abs/2601.09188", "authors": ["Yaqian Zhang", "Jingke Xu"], "title": "Reducing The Sub-packetization Level of Optimal-Access Cooperative MSR Codes", "comment": null, "summary": "Cooperative MSR codes are a kind of storage codes which enable optimal-bandwidth repair of any $h\\geq2$ node erasures in a cooperative way, while retaining the minimum storage as an $[n,k]$ MDS code. Each code coordinate (node) is assumed to store an array of $\\ell$ symbols, where $\\ell$ is termed as sub-packetization. Large sub-packetization tends to induce high complexity, large input/output in practice. To address the disk IO capability, a cooperative MSR code is said to have optimal-access property, if during node repair, the amount of data accessed at each helper node meets a theoretical lower bound.\n  In this paper, we focus on reducing the sub-packetization of optimal-access cooperative MSR codes with two erasures. At first, we design two crucial MDS array codes for repairing a specific repair pattern of two erasures with optimal access. Then, using the two codes as building blocks and by stacking up of the two codes for several times, we obtain an optimal-access cooperative MSR code with two erasures. The derived code has sub-packetization $\\ell=r^{\\binom{n}{2}-\\lfloor\\frac{n}{r}\\rfloor(\\binom{r}{2}-1)}$ where $r=n-k$, and it reduces $\\ell$ by a fraction of $1/r^{\\lfloor\\frac{n}{r}\\rfloor(\\binom{r}{2}-1)}$ compared with the state of the art ($\\ell=r^{\\binom{n}{2}}$).", "AI": {"tldr": "This paper presents new optimal-access cooperative MSR codes for two erasures with significantly reduced sub-packetization compared to existing constructions.", "motivation": "Large sub-packetization in storage codes leads to high complexity and large I/O overhead. The paper aims to reduce sub-packetization while maintaining optimal-access property for cooperative MSR codes with two erasures.", "method": "The authors first design two crucial MDS array codes for repairing a specific two-erasure pattern with optimal access. Then they use these as building blocks, stacking them multiple times to construct an optimal-access cooperative MSR code.", "result": "The derived code achieves sub-packetization \u2113 = r^(C(n,2) - \u230an/r\u230b(C(r,2)-1)), where r = n-k. This reduces \u2113 by a factor of 1/r^(\u230an/r\u230b(C(r,2)-1)) compared to the state-of-the-art \u2113 = r^(C(n,2)).", "conclusion": "The paper successfully reduces sub-packetization for optimal-access cooperative MSR codes with two erasures while maintaining the optimal-access property, addressing practical complexity and I/O concerns."}}
{"id": "2601.09182", "categories": ["cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09182", "abs": "https://arxiv.org/abs/2601.09182", "authors": ["JungMin Yun", "JuneHyoung Kwon", "MiHyeon Kim", "YoungBin Kim"], "title": "Position on LLM-Assisted Peer Review: Addressing Reviewer Gap through Mentoring and Feedback", "comment": "Accepted to AAAI 2026 Workshop on AI for Scientific Research (AI4Research)", "summary": "The rapid expansion of AI research has intensified the Reviewer Gap, threatening the peer-review sustainability and perpetuating a cycle of low-quality evaluations. This position paper critiques existing LLM approaches that automatically generate reviews and argues for a paradigm shift that positions LLMs as tools for assisting and educating human reviewers. We define the core principles of high-quality peer review and propose two complementary systems grounded in these foundations: (i) an LLM-assisted mentoring system that cultivates reviewers' long-term competencies, and (ii) an LLM-assisted feedback system that helps reviewers refine the quality of their reviews. This human-centered approach aims to strengthen reviewer expertise and contribute to building a more sustainable scholarly ecosystem.", "AI": {"tldr": "The paper proposes using LLMs as educational tools to assist and train human reviewers, rather than fully automating review generation, to address the sustainability crisis in peer review.", "motivation": "The rapid expansion of AI research has created a \"Reviewer Gap\" that threatens peer-review sustainability and perpetuates low-quality evaluations. Current approaches using LLMs to automatically generate reviews are insufficient and need rethinking.", "method": "Proposes a paradigm shift positioning LLMs as tools for assisting and educating human reviewers. Defines core principles of high-quality peer review and introduces two complementary systems: (1) LLM-assisted mentoring system for cultivating reviewers' long-term competencies, and (2) LLM-assisted feedback system for helping reviewers refine review quality.", "result": "This is a position paper proposing a framework rather than presenting empirical results. The proposed approach aims to strengthen reviewer expertise and build a more sustainable scholarly ecosystem through human-centered LLM assistance.", "conclusion": "A human-centered approach using LLMs as educational tools for reviewers, rather than review generators, can address the peer-review sustainability crisis by developing reviewer competencies and improving review quality over time."}}
{"id": "2601.09512", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09512", "abs": "https://arxiv.org/abs/2601.09512", "authors": ["Ralf R\u00f6mer", "Yi Zhang", "Angela P. Schoellig"], "title": "CLARE: Continual Learning for Vision-Language-Action Models via Autonomous Adapter Routing and Expansion", "comment": "Project page: https://tum-lsy.github.io/clare. 9 pages, 5 figures", "summary": "To teach robots complex manipulation tasks, it is now a common practice to fine-tune a pre-trained vision-language-action model (VLA) on task-specific data. However, since this recipe updates existing representations, it is unsuitable for long-term operation in the real world, where robots must continually adapt to new tasks and environments while retaining the knowledge they have already acquired. Existing continual learning methods for robotics commonly require storing previous data (exemplars), struggle with long task sequences, or rely on task identifiers for deployment. To address these limitations, we propose CLARE, a general, parameter-efficient framework for exemplar-free continual learning with VLAs. CLARE introduces lightweight modular adapters into selected feedforward layers and autonomously expands the model only where necessary when learning a new task, guided by layer-wise feature similarity. During deployment, an autoencoder-based routing mechanism dynamically activates the most relevant adapters without requiring task labels. Through extensive experiments on the LIBERO benchmark, we show that CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks, significantly outperforming even exemplar-based methods. Code and data are available at https://tum-lsy.github.io/clare.", "AI": {"tldr": "CLARE is a parameter-efficient continual learning framework for vision-language-action models that uses lightweight modular adapters and autoencoder-based routing to prevent catastrophic forgetting without storing previous data.", "motivation": "Current fine-tuning approaches for VLAs cause catastrophic forgetting when learning new tasks, making them unsuitable for long-term real-world robot operation. Existing continual learning methods require storing previous data, struggle with long task sequences, or need task identifiers.", "method": "CLARE introduces lightweight modular adapters into selected feedforward layers, autonomously expands the model only where necessary based on layer-wise feature similarity, and uses an autoencoder-based routing mechanism to dynamically activate relevant adapters without task labels.", "result": "CLARE achieves high performance on new tasks without catastrophic forgetting of earlier tasks on the LIBERO benchmark, significantly outperforming even exemplar-based methods.", "conclusion": "CLARE provides a general, parameter-efficient framework for exemplar-free continual learning with VLAs that enables robots to continually adapt to new tasks while retaining previous knowledge, suitable for long-term real-world operation."}}
{"id": "2601.09018", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09018", "abs": "https://arxiv.org/abs/2601.09018", "authors": ["Samuel Myren", "Nidhi Parikh", "Natalie Klein"], "title": "Meta-learning to Address Data Shift in Time Series Classification", "comment": null, "summary": "Across engineering and scientific domains, traditional deep learning (TDL) models perform well when training and test data share the same distribution. However, the dynamic nature of real-world data, broadly termed \\textit{data shift}, renders TDL models prone to rapid performance degradation, requiring costly relabeling and inefficient retraining. Meta-learning, which enables models to adapt quickly to new data with few examples, offers a promising alternative for mitigating these challenges. Here, we systematically compare TDL with fine-tuning and optimization-based meta-learning algorithms to assess their ability to address data shift in time-series classification. We introduce a controlled, task-oriented seismic benchmark (SeisTask) and show that meta-learning typically achieves faster and more stable adaptation with reduced overfitting in data-scarce regimes and smaller model architectures. As data availability and model capacity increase, its advantages diminish, with TDL with fine-tuning performing comparably. Finally, we examine how task diversity influences meta-learning and find that alignment between training and test distributions, rather than diversity alone, drives performance gains. Overall, this work provides a systematic evaluation of when and why meta-learning outperforms TDL under data shift and contributes SeisTask as a benchmark for advancing adaptive learning research in time-series domains.", "AI": {"tldr": "Meta-learning outperforms traditional deep learning with fine-tuning for time-series classification under data shift, especially with limited data and smaller models, but advantages diminish with more data and larger architectures.", "motivation": "Traditional deep learning models degrade under data shift (distribution changes), requiring costly relabeling and retraining. Meta-learning offers a promising alternative for quick adaptation to new data with few examples.", "method": "Systematic comparison of traditional deep learning with fine-tuning vs. optimization-based meta-learning algorithms using a controlled seismic benchmark (SeisTask) for time-series classification under data shift conditions.", "result": "Meta-learning achieves faster, more stable adaptation with reduced overfitting in data-scarce regimes and smaller models. As data availability and model capacity increase, traditional deep learning with fine-tuning performs comparably. Task diversity alone doesn't drive performance - alignment between training and test distributions is key.", "conclusion": "Meta-learning is superior for data shift scenarios with limited data and smaller architectures, but traditional deep learning with fine-tuning becomes competitive with sufficient data and model capacity. The SeisTask benchmark is contributed for advancing adaptive learning research in time-series domains."}}
{"id": "2601.08885", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08885", "abs": "https://arxiv.org/abs/2601.08885", "authors": ["Sixian Jia", "Ruo-Syuan Mei", "Chenhui Shao"], "title": "Adaptive few-shot learning for robust part quality classification in two-photon lithography", "comment": null, "summary": "Two-photon lithography (TPL) is an advanced additive manufacturing (AM) technique for fabricating high-precision micro-structures. While computer vision (CV) is proofed for automated quality control, existing models are often static, rendering them ineffective in dynamic manufacturing environments. These models typically cannot detect new, unseen defect classes, be efficiently updated from scarce data, or adapt to new part geometries. To address this gap, this paper presents an adaptive CV framework for the entire life-cycle of quality model maintenance. The proposed framework is built upon a same, scale-robust backbone model and integrates three key methodologies: (1) a statistical hypothesis testing framework based on Linear Discriminant Analysis (LDA) for novelty detection, (2) a two-stage, rehearsal-based strategy for few-shot incremental learning, and (3) a few-shot Domain-Adversarial Neural Network (DANN) for few-shot domain adaptation. The framework was evaluated on a TPL dataset featuring hemisphere as source domain and cube as target domain structures, with each domain categorized into good, minor damaged, and damaged quality classes. The hypothesis testing method successfully identified new class batches with 99-100% accuracy. The incremental learning method integrated a new class to 92% accuracy using only K=20 samples. The domain adaptation model bridged the severe domain gap, achieving 96.19% accuracy on the target domain using only K=5 shots. These results demonstrate a robust and data-efficient solution for deploying and maintaining CV models in evolving production scenarios.", "AI": {"tldr": "Adaptive computer vision framework for quality control in two-photon lithography that handles novelty detection, incremental learning, and domain adaptation with minimal data.", "motivation": "Existing computer vision models for quality control in additive manufacturing are static and ineffective in dynamic environments - they can't detect new defect classes, update efficiently from scarce data, or adapt to new part geometries.", "method": "Three-component framework: 1) LDA-based statistical hypothesis testing for novelty detection, 2) rehearsal-based few-shot incremental learning for new classes, 3) few-shot Domain-Adversarial Neural Network for domain adaptation across different geometries.", "result": "99-100% accuracy for novelty detection, 92% accuracy for incremental learning with only 20 samples, and 96.19% accuracy for domain adaptation with just 5 shots, bridging severe domain gaps between different part geometries.", "conclusion": "The framework provides a robust, data-efficient solution for deploying and maintaining computer vision models in evolving production scenarios, addressing key limitations of static models in dynamic manufacturing environments."}}
{"id": "2601.09364", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09364", "abs": "https://arxiv.org/abs/2601.09364", "authors": ["Radim Zedka", "Roman Marsalek", "Marek Bobula", "Arman Farhang"], "title": "Unique Word Channel Estimation for Oversampled OTFS", "comment": "17 pages", "summary": "Practical aspects of orthogonal time frequency space (OTFS), such as channel estimation and its performance in fractional delay-Doppler (DD) channels, are a lively topic in the OTFS community. Oversampling and pulse shaping are also discussed in the existing literature, but not in the context of channel estimation. To the best of our knowledge, this paper is the first to address the problem of data-to-pilot and vice versa energy leakage caused by oversampling and pulse shaping in OTFS. Theoretical analysis is performed on an oversampled, pulse-shaped OTFS implementing the embedded pilot channel estimation technique, revealing a trade-off between the amount of energy leakage and excess bandwidth introduced by the pulse shape. Next, a novel variant of OTFS is introduced, called UW-OTFS, which is designed to overcome the leakage problem by placing the pilot in the oversampled time domain instead of the DD domain. The unique structure of UW-OTFS offers 36 percent higher spectral efficiency than the OTFS with embedded pilot. UW-OTFS also outperforms traditional OTFS in terms of bit error ratio and out-of-band emissions.", "AI": {"tldr": "This paper addresses energy leakage issues in OTFS channel estimation caused by oversampling and pulse shaping, and proposes a novel UW-OTFS variant that improves spectral efficiency and performance.", "motivation": "The paper addresses practical challenges in OTFS systems, specifically energy leakage between data and pilot signals caused by oversampling and pulse shaping during channel estimation, which hasn't been adequately studied in existing literature.", "method": "The authors perform theoretical analysis on oversampled, pulse-shaped OTFS with embedded pilot channel estimation, then introduce UW-OTFS which places pilots in the oversampled time domain instead of the delay-Doppler domain to overcome leakage problems.", "result": "UW-OTFS achieves 36% higher spectral efficiency than traditional OTFS with embedded pilots, and demonstrates better performance in terms of bit error ratio and out-of-band emissions.", "conclusion": "The proposed UW-OTFS variant effectively solves the energy leakage problem in OTFS channel estimation while significantly improving spectral efficiency and overall system performance."}}
{"id": "2601.09196", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09196", "abs": "https://arxiv.org/abs/2601.09196", "authors": ["K V Harsha", "Jithin Ravi", "Tobias Koch"], "title": "Second-Order Asymptotics of Two-Sample Tests", "comment": "Submitted to the 2026 IEEE International Symposium on Information Theory", "summary": "In two-sampling testing, one observes two independent sequences of independent and identically distributed random variables distributed according to the distributions $P_1$ and $P_2$ and wishes to decide whether $P_1=P_2$ (null hypothesis) or $P_1\\neq P_2$ (alternative hypothesis). The Gutman test for this problem compares the empirical distributions of the observed sequences and decides on the null hypothesis if the Jensen-Shannon (JS) divergence between these empirical distributions is below a given threshold. This paper proposes a generalization of the Gutman test, termed \\emph{divergence test}, which replaces the JS divergence by an arbitrary divergence. For this test, the exponential decay of the type-II error probability for a fixed type-I error probability is studied. First, it is shown that the divergence test achieves the optimal first-order exponent, irrespective of the choice of divergence. Second, it is demonstrated that the divergence test with an invariant divergence achieves the same second-order asymptotics as the Gutman test. In addition, it is shown that the Gutman test is the GLRT for the two-sample testing problem, and a connection between two-sample testing and robust goodness-of-fit testing is established.", "AI": {"tldr": "The paper proposes a generalization of the Gutman test for two-sample testing by replacing JS divergence with arbitrary divergences, analyzes error exponents, and establishes connections to GLRT and robust goodness-of-fit testing.", "motivation": "To generalize the Gutman test beyond Jensen-Shannon divergence and analyze the performance of divergence-based tests for two-sample hypothesis testing problems.", "method": "Proposes a divergence test framework that replaces JS divergence in the Gutman test with arbitrary divergences, analyzes type-II error probability decay rates (first-order and second-order exponents), and establishes theoretical connections.", "result": "1) Divergence test achieves optimal first-order exponent regardless of divergence choice. 2) With invariant divergences, achieves same second-order asymptotics as Gutman test. 3) Shows Gutman test is GLRT for two-sample testing. 4) Establishes connection between two-sample testing and robust goodness-of-fit testing.", "conclusion": "The divergence test generalizes the Gutman test effectively, maintains optimal error exponents under certain conditions, and reveals important theoretical connections between different statistical testing frameworks."}}
{"id": "2601.09259", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09259", "abs": "https://arxiv.org/abs/2601.09259", "authors": ["Jian Zhang", "Zhiyuan Wang", "Zhangqi Wang", "Yu He", "Haoran Luo", "li yuan", "Lingling Zhang", "Rui Mao", "Qika Lin", "Jun Liu"], "title": "MAXS: Meta-Adaptive Exploration with LLM Agents", "comment": null, "summary": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.", "AI": {"tldr": "MAXS is a meta-adaptive reasoning framework for LLM agents that uses lookahead planning and trajectory convergence to improve global effectiveness and computational efficiency in multi-tool reasoning.", "motivation": "Existing LLM agent methods suffer from two key issues: (1) locally myopic generation due to lack of lookahead planning, and (2) trajectory instability where minor early errors escalate into divergent reasoning paths. These problems make it difficult to balance global effectiveness with computational efficiency.", "method": "MAXS employs a lookahead strategy to extend reasoning paths several steps ahead, estimating advantage values for tool usage. It combines step consistency variance and inter-step trend slopes to select stable, consistent, high-value reasoning steps. A trajectory convergence mechanism halts further rollouts once path consistency is achieved, balancing resource efficiency with global effectiveness.", "result": "Extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets demonstrate that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of the lookahead strategy and tool usage.", "conclusion": "MAXS successfully addresses the limitations of existing LLM agent methods by providing a meta-adaptive reasoning framework that flexibly integrates tool execution and reasoning planning, achieving better balance between computational efficiency and global effectiveness in multi-tool reasoning tasks."}}
{"id": "2601.09518", "categories": ["cs.RO", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09518", "abs": "https://arxiv.org/abs/2601.09518", "authors": ["Wei-Jin Huang", "Yue-Yi Zhang", "Yi-Lin Wei", "Zhi-Wei Xia", "Juantao Tan", "Yuan-Ming Li", "Zhilin Zhao", "Wei-Shi Zheng"], "title": "Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations", "comment": null, "summary": "Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.", "AI": {"tldr": "PAIR+D-STAR: A two-part framework that first retargets human-human interaction data to humanoid robots using physics-aware contact preservation, then trains hierarchical policies that decouple temporal reasoning from spatial action generation for robust human-robot interaction.", "motivation": "Humanoid robots need to physically interact with humans, but progress is limited by scarce high-quality Human-Humanoid Interaction (HHoI) data. While abundant Human-Human Interaction (HHI) data exists, standard retargeting fails by breaking essential contacts, and even with good data, conventional imitation learning lacks interactive understanding.", "method": "Two-stage approach: 1) PAIR (Physics-Aware Interaction Retargeting) - contact-centric pipeline preserving contact semantics across morphology differences to generate physically consistent HHoI data from HHI data. 2) D-STAR (Decoupled Spatio-Temporal Action Reasoner) - hierarchical policy with Phase Attention (when to act) and Multi-Scale Spatial module (where to act) fused by diffusion head to produce synchronized whole-body behaviors beyond simple mimicry.", "result": "The framework demonstrates significant performance gains over baseline approaches through extensive simulations. PAIR successfully generates physically consistent HHoI data, and D-STAR enables responsive, synchronized collaboration by learning robust temporal phases without being distracted by spatial noise.", "conclusion": "The paper presents a complete, effective pipeline for learning complex whole-body interactions from HHI data, addressing both data scarcity (via PAIR) and interactive understanding limitations (via D-STAR) to enable robust humanoid robot interaction with humans."}}
{"id": "2601.09026", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09026", "abs": "https://arxiv.org/abs/2601.09026", "authors": ["Shuai Jiang", "Marc Salvado", "Eric C. Cyr", "Alena Kopani\u010d\u00e1kov\u00e1", "Rolf Krause", "Jacob B. Schroder"], "title": "Layer-Parallel Training for Transformers", "comment": "20 pages, 12 figures", "summary": "We present a new training methodology for transformers using a multilevel, layer-parallel approach. Through a neural ODE formulation of transformers, our application of a multilevel parallel-in-time algorithm for the forward and backpropagation phases of training achieves parallel acceleration over the layer dimension. This dramatically enhances parallel scalability as the network depth increases, which is particularly useful for increasingly large foundational models. However, achieving this introduces errors that cause systematic bias in the gradients, which in turn reduces convergence when closer to the minima. We develop an algorithm to detect this critical transition and either switch to serial training or systematically increase the accuracy of layer-parallel training. Results, including BERT, GPT2, ViT, and machine translation architectures, demonstrate parallel-acceleration as well as accuracy commensurate with serial pre-training while fine-tuning is unaffected.", "AI": {"tldr": "A new layer-parallel training method for transformers using neural ODE formulation and multilevel parallel-in-time algorithms achieves parallel acceleration across layers, with mechanisms to handle gradient bias issues near convergence.", "motivation": "To improve parallel scalability for increasingly deep transformer models, especially large foundational models, by enabling parallel acceleration across the layer dimension during training.", "method": "Uses neural ODE formulation of transformers and applies multilevel parallel-in-time algorithms for forward and backpropagation phases, with algorithms to detect critical transitions and switch to serial training or increase layer-parallel accuracy when needed.", "result": "Demonstrates parallel acceleration across BERT, GPT2, ViT, and machine translation architectures while maintaining accuracy comparable to serial pre-training, with fine-tuning unaffected by the approach.", "conclusion": "The layer-parallel training methodology enables scalable parallel acceleration for deep transformers while maintaining training accuracy through adaptive mechanisms that handle gradient bias issues near convergence."}}
{"id": "2601.08956", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08956", "abs": "https://arxiv.org/abs/2601.08956", "authors": ["Satyaki Roy Chowdhury", "Golrokh Mirzaei"], "title": "Variance-Penalized MC-Dropout as a Learned Smoothing Prior for Brain Tumour Segmentation", "comment": "Accepted by ISBI 2026", "summary": "Brain tumor segmentation is essential for diagnosis and treatment planning, yet many CNN and U-Net based approaches produce noisy boundaries in regions of tumor infiltration. We introduce UAMSA-UNet, an Uncertainty-Aware Multi-Scale Attention-based Bayesian U-Net that in- stead leverages Monte Carlo Dropout to learn a data-driven smoothing prior over its predictions, while fusing multi-scale features and attention maps to capture both fine details and global context. Our smoothing-regularized loss augments binary cross-entropy with a variance penalty across stochas- tic forward passes, discouraging spurious fluctuations and yielding spatially coherent masks. On BraTS2023, UAMSA- UNet improves Dice Similarity Coefficient by up to 3.3% and mean IoU by up to 2.7% over U-Net; on BraTS2024, it delivers up to 4.5% Dice and 4.0% IoU gains over the best baseline. Remarkably, it also reduces FLOPs by 42.5% rel- ative to U-Net++ while maintaining higher accuracy. These results demonstrate that, by combining multi-scale attention with a learned smoothing prior, UAMSA-UNet achieves both better segmentation quality and computational efficiency, and provides a flexible foundation for future integration with transformer-based modules for further enhanced segmenta- tion results.", "AI": {"tldr": "UAMSA-UNet improves brain tumor segmentation by combining uncertainty-aware Bayesian modeling with multi-scale attention, achieving better accuracy and computational efficiency than U-Net baselines.", "motivation": "Existing CNN and U-Net based approaches for brain tumor segmentation produce noisy boundaries in tumor infiltration regions, which is problematic for accurate diagnosis and treatment planning.", "method": "UAMSA-UNet uses Monte Carlo Dropout to learn a data-driven smoothing prior over predictions, fuses multi-scale features and attention maps to capture fine details and global context, and employs a smoothing-regularized loss combining binary cross-entropy with variance penalty across stochastic forward passes.", "result": "On BraTS2023: 3.3% Dice Similarity Coefficient improvement and 2.7% mean IoU improvement over U-Net. On BraTS2024: 4.5% Dice and 4.0% IoU gains over best baseline. Also reduces FLOPs by 42.5% relative to U-Net++ while maintaining higher accuracy.", "conclusion": "Combining multi-scale attention with a learned smoothing prior enables UAMSA-UNet to achieve better segmentation quality and computational efficiency, providing a flexible foundation for future integration with transformer-based modules."}}
{"id": "2601.09384", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09384", "abs": "https://arxiv.org/abs/2601.09384", "authors": ["Utku U\u00e7ak", "Fariba Armandoust", "Matthias Mehlhose", "Daniel Sch\u00e4ufele", "Jochen Fink", "Renato L. G. Cavalcante", "S\u0142awomir Sta\u0144czak"], "title": "Uplink Multi-User MIMO Implementation in OpenAirInterface for a Cell-Free O-RAN Testbed", "comment": "7 pages, 7 figures. Submitted to IEEE ICC 2026", "summary": "Cell-Free Multiple-Input Multiple-Output (MIMO) and Open Radio Access Network (O-RAN) have been active research topics in the wireless communication community in recent years. As an open-source software implementation of the 3rd Generation Partnership Project (3GPP) 5th Generation (5G) protocol stack, OpenAirInterface (OAI) has become a valuable tool for deploying and testing new ideas in wireless communication systems. In this paper, we present our OAI based real-time uplink Multi-User MIMO (MU-MIMO) testbed developed at Fraunhofer HHI. As a part of our Cell-Free MIMO testbed development, we built a 2x2 MU-MIMO system using general purpose computers and commercially available software defined radios (SDRs). Using a modified OAI next-Generation Node-B (gNB) and two unmodified OAI user equipment (UE), we show that it is feasible to use Sounding Reference Signal (SRS) channel estimates to compute uplink combiners. Our results verify that this method can be used to separate and decode signals from two users transmitting in nonorthogonal time-frequency resources. This work serves as an important verification step to build a complete Cell-Free MU-MIMO system that leverages time domain duplexing (TDD) reciprocity to do downlink beamforming over multiple cells.", "AI": {"tldr": "Real-time uplink MU-MIMO testbed using OAI and SDRs demonstrates feasibility of using SRS channel estimates for uplink combining to separate nonorthogonal user signals.", "motivation": "To develop a practical testbed for Cell-Free MIMO and O-RAN research using open-source tools, specifically addressing the need for real-time MU-MIMO systems that can leverage TDD reciprocity for downlink beamforming across multiple cells.", "method": "Built a 2x2 MU-MIMO system using general-purpose computers and commercial SDRs with modified OAI gNB and unmodified OAI UEs. Uses Sounding Reference Signal (SRS) channel estimates to compute uplink combiners for separating user signals.", "result": "Successfully demonstrated that SRS-based channel estimation can separate and decode signals from two users transmitting in nonorthogonal time-frequency resources, verifying the feasibility of the approach.", "conclusion": "This work provides an important verification step toward building a complete Cell-Free MU-MIMO system that can leverage TDD reciprocity for downlink beamforming over multiple cells, using open-source OAI and commercially available hardware."}}
{"id": "2601.09222", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09222", "abs": "https://arxiv.org/abs/2601.09222", "authors": ["Ling Liu", "Qi Cao", "Liping Li", "Baoming Bai"], "title": "On Polar Coding with Feedback", "comment": "7 pages, 7 figures and 2 tables; A short version will be submitted to IEEE for possible publication", "summary": "In this work, we investigate the performance of polar codes with the assistance of feedback in communication systems. Although it is well known that feedback does not improve the capacity of memoryless channels, we show that the finite length performance of polar codes can be significantly improved as feedback enables genie-aided decoding and allows more flexible thresholds for the polar coding construction. To analyze the performance under the new construction, we then propose an accurate characterization of the distribution of the error event under the genie-aided successive cancellation (SC) decoding. This characterization can be also used to predict the performance of the standard SC decoding of polar codes with rates close to capacity.", "AI": {"tldr": "Polar codes with feedback significantly improve finite-length performance through genie-aided decoding and flexible construction thresholds, with new error distribution characterization for SC decoding.", "motivation": "While feedback doesn't improve channel capacity for memoryless channels, it can enhance finite-length performance of polar codes by enabling genie-aided decoding and more flexible construction thresholds.", "method": "Propose polar coding construction with feedback that enables genie-aided decoding and flexible thresholds. Develop accurate characterization of error event distribution under genie-aided successive cancellation (SC) decoding.", "result": "Feedback significantly improves finite-length performance of polar codes. The proposed error distribution characterization accurately predicts performance of standard SC decoding for polar codes with rates close to capacity.", "conclusion": "Feedback provides substantial benefits for polar codes in practical finite-length scenarios despite not affecting channel capacity, with new analytical tools for performance prediction."}}
{"id": "2601.09260", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09260", "abs": "https://arxiv.org/abs/2601.09260", "authors": ["Yan Liu", "Feng Zhang", "Zhanyu Ma", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He", "Han Liu", "Yangdong Deng"], "title": "Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models", "comment": null, "summary": "High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.", "AI": {"tldr": "CoT-Flow: A framework that treats reasoning steps as continuous probabilistic flow to quantify step-wise information gain, enabling flow-guided decoding for efficient inference and flow-based RL for verifier-free optimization.", "motivation": "Current chain-of-thought paradigms treat reasoning as indivisible sequences without quantifying step-wise information gain, leading to inference inefficiency from redundant exploration and optimization difficulty due to sparse supervision or costly external verifiers.", "method": "Reconceptualizes discrete reasoning steps as continuous probabilistic flow to quantify each step's contribution toward ground-truth answer. Enables two complementary methodologies: 1) flow-guided decoding with greedy flow-based strategy for information-efficient paths, and 2) flow-based reinforcement learning with verifier-free dense reward function.", "result": "Experiments on challenging benchmarks demonstrate CoT-Flow achieves superior balance between inference efficiency and reasoning performance.", "conclusion": "CoT-Flow provides a principled framework for quantifying reasoning step contributions, addressing both inference efficiency and optimization challenges in chain-of-thought reasoning."}}
{"id": "2601.09578", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09578", "abs": "https://arxiv.org/abs/2601.09578", "authors": ["Jiajun Sun", "Yangyi Ou", "Haoyuan Zheng", "Chao yang", "Yue Ma"], "title": "Multimodal Signal Processing For Thermo-Visible-Lidar Fusion In Real-time 3D Semantic Mapping", "comment": "5 pages,7 figures. Under review", "summary": "In complex environments, autonomous robot navigation and environmental perception pose higher requirements for SLAM technology. This paper presents a novel method for semantically enhancing 3D point cloud maps with thermal information. By first performing pixel-level fusion of visible and infrared images, the system projects real-time LiDAR point clouds onto this fused image stream. It then segments heat source features in the thermal channel to instantly identify high temperature targets and applies this temperature information as a semantic layer on the final 3D map. This approach generates maps that not only have accurate geometry but also possess a critical semantic understanding of the environment, making it highly valuable for specific applications like rapid disaster assessment and industrial preventive maintenance.", "AI": {"tldr": "A novel SLAM method that semantically enhances 3D point cloud maps with thermal information by fusing visible and infrared images, projecting LiDAR data onto fused images, segmenting heat sources, and applying temperature semantics to 3D maps.", "motivation": "Autonomous robot navigation in complex environments requires advanced SLAM technology with better environmental perception capabilities. There's a need for maps that go beyond geometric accuracy to include semantic understanding, particularly for applications like disaster assessment and industrial maintenance where thermal information is critical.", "method": "1) Perform pixel-level fusion of visible and infrared images. 2) Project real-time LiDAR point clouds onto the fused image stream. 3) Segment heat source features in the thermal channel to identify high-temperature targets. 4) Apply temperature information as a semantic layer on the final 3D point cloud map.", "result": "The approach generates 3D maps with both accurate geometry and semantic understanding of thermal properties. It enables instant identification of high-temperature targets and creates semantically enriched maps valuable for specific applications.", "conclusion": "The proposed method successfully enhances SLAM technology by adding thermal semantic information to 3D maps, making it particularly valuable for applications requiring environmental thermal understanding such as disaster assessment and industrial preventive maintenance."}}
{"id": "2601.09042", "categories": ["cs.LG", "cs.DS", "math.OC", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.09042", "abs": "https://arxiv.org/abs/2601.09042", "authors": ["Neelkamal Bhuyan", "Debankur Mukherjee", "Adam Wierman"], "title": "SCaLE: Switching Cost aware Learning and Exploration", "comment": "42 pages", "summary": "This work addresses the fundamental problem of unbounded metric movement costs in bandit online convex optimization, by considering high-dimensional dynamic quadratic hitting costs and $\\ell_2$-norm switching costs in a noisy bandit feedback model. For a general class of stochastic environments, we provide the first algorithm SCaLE that provably achieves a distribution-agnostic sub-linear dynamic regret, without the knowledge of hitting cost structure. En-route, we present a novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret. Extensive numerical experiments, against online-learning baselines, corroborate our claims, and highlight statistical consistency of our algorithm.", "AI": {"tldr": "First algorithm (SCaLE) achieves sub-linear dynamic regret for high-dimensional bandit online convex optimization with quadratic hitting costs and switching costs, without knowing cost structure.", "motivation": "Addresses fundamental problem of unbounded metric movement costs in bandit online convex optimization, particularly in noisy bandit feedback settings with high-dimensional dynamic quadratic hitting costs and switching costs.", "method": "Proposes SCaLE algorithm with novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret for general stochastic environments.", "result": "First algorithm that provably achieves distribution-agnostic sub-linear dynamic regret without knowledge of hitting cost structure; extensive numerical experiments show statistical consistency and outperform online-learning baselines.", "conclusion": "Successfully addresses unbounded metric movement costs in bandit optimization through spectral analysis approach, enabling sub-linear dynamic regret in high-dimensional settings with switching costs."}}
{"id": "2601.08977", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08977", "abs": "https://arxiv.org/abs/2601.08977", "authors": ["Chao Yang", "Haoyuan Zheng", "Yue Ma"], "title": "Thermo-LIO: A Novel Multi-Sensor Integrated System for Structural Health Monitoring", "comment": "27pages,12figures", "summary": "Traditional two-dimensional thermography, despite being non-invasive and useful for defect detection in the construction field, is limited in effectively assessing complex geometries, inaccessible areas, and subsurface defects. This paper introduces Thermo-LIO, a novel multi-sensor system that can enhance Structural Health Monitoring (SHM) by fusing thermal imaging with high-resolution LiDAR. To achieve this, the study first develops a multimodal fusion method combining thermal imaging and LiDAR, enabling precise calibration and synchronization of multimodal data streams to create accurate representations of temperature distributions in buildings. Second, it integrates this fusion approach with LiDAR-Inertial Odometry (LIO), enabling full coverage of large-scale structures and allowing for detailed monitoring of temperature variations and defect detection across inspection cycles. Experimental validations, including case studies on a bridge and a hall building, demonstrate that Thermo-LIO can detect detailed thermal anomalies and structural defects more accurately than traditional methods. The system enhances diagnostic precision, enables real-time processing, and expands inspection coverage, highlighting the crucial role of multimodal sensor integration in advancing SHM methodologies for large-scale civil infrastructure.", "AI": {"tldr": "Thermo-LIO: A novel multi-sensor system combining thermal imaging with LiDAR for enhanced structural health monitoring, enabling better defect detection in complex geometries and large-scale structures.", "motivation": "Traditional 2D thermography is limited in assessing complex geometries, inaccessible areas, and subsurface defects in construction. There's a need for more comprehensive structural health monitoring that can handle large-scale civil infrastructure with better coverage and accuracy.", "method": "1) Developed multimodal fusion method combining thermal imaging and LiDAR with precise calibration and synchronization. 2) Integrated this fusion approach with LiDAR-Inertial Odometry (LIO) to enable full coverage of large-scale structures and detailed monitoring across inspection cycles.", "result": "Experimental validations on a bridge and hall building demonstrated that Thermo-LIO can detect detailed thermal anomalies and structural defects more accurately than traditional methods. The system enhances diagnostic precision, enables real-time processing, and expands inspection coverage.", "conclusion": "Thermo-LIO highlights the crucial role of multimodal sensor integration in advancing SHM methodologies for large-scale civil infrastructure, providing superior defect detection capabilities compared to traditional thermography approaches."}}
{"id": "2601.09426", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09426", "abs": "https://arxiv.org/abs/2601.09426", "authors": ["Heedong Do", "Angel Lozano"], "title": "Beamforming Gain with Nonideal Phase Shifters", "comment": null, "summary": "This research sets forth a universal framework to characterize the beamforming gain achievable with arbitrarily nonideal phase shifters. Precisely, the maximum possible shortfall relative to the gain attainable with ideal phase shifters is established. Such shortfall is shown to be fundamentally determined by the perimeter of the convex hull of the set of feasible beamforming coefficients on the complex plane. This result holds regardless of whether the beamforming is at the transmitter, at the receiver, or at a reconfigurable intelligent surface. In i.i.d. fading channels, the shortfall hardens to the maximum possible shortfall as the number of antennas grows.", "AI": {"tldr": "A universal framework characterizes beamforming gain achievable with nonideal phase shifters, establishing maximum shortfall relative to ideal phase shifters determined by perimeter of convex hull of feasible beamforming coefficients.", "motivation": "To understand the fundamental limitations of beamforming systems using nonideal phase shifters, which are common in practical implementations due to hardware imperfections, and to establish universal performance bounds applicable to various beamforming scenarios.", "method": "Develops a mathematical framework to characterize beamforming gain with arbitrary nonideal phase shifters, analyzing the shortfall relative to ideal phase shifters through geometric properties of feasible beamforming coefficients on the complex plane.", "result": "The maximum possible shortfall is fundamentally determined by the perimeter of the convex hull of feasible beamforming coefficients, holds for transmitter, receiver, or RIS beamforming, and hardens to maximum shortfall in i.i.d. fading channels as antenna count grows.", "conclusion": "The research provides universal performance bounds for beamforming with nonideal phase shifters, revealing fundamental geometric relationships that govern performance degradation across various beamforming architectures."}}
{"id": "2601.09254", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09254", "abs": "https://arxiv.org/abs/2601.09254", "authors": ["Changshuo Wang", "Zijian Liang", "Kai Niu", "Ping Zhang"], "title": "A Theoretical Framework for Rate-Distortion Limits in Learned Image Compression", "comment": "14 pages, 6 figures. arXiv version", "summary": "We present a novel systematic theoretical framework to analyze the rate-distortion (R-D) limits of learned image compression. While recent neural codecs have achieved remarkable empirical results, their distance from the information-theoretic limit remains unclear. Our work addresses this gap by decomposing the R-D performance loss into three key components: variance estimation, quantization strategy, and context modeling. First, we derive the optimal latent variance as the second moment under a Gaussian assumption, providing a principled alternative to hyperprior-based estimation. Second, we quantify the gap between uniform quantization and the Gaussian test channel derived from the reverse water-filling theorem. Third, we extend our framework to include context modeling, and demonstrate that accurate mean prediction yields substantial entropy reduction. Unlike prior R-D estimators, our method provides a structurally interpretable perspective that aligns with real compression modules and enables fine-grained analysis. Through joint simulation and end-to-end training, we derive a tight and actionable approximation of the theoretical R-D limits, offering new insights into the design of more efficient learned compression systems.", "AI": {"tldr": "The paper presents a theoretical framework to analyze rate-distortion limits of learned image compression, decomposing performance loss into variance estimation, quantization, and context modeling components.", "motivation": "While neural codecs achieve impressive empirical results, their distance from information-theoretic limits remains unclear. The paper aims to bridge this gap by providing a systematic theoretical analysis of learned compression systems.", "method": "The framework decomposes R-D performance loss into three components: (1) deriving optimal latent variance as second moment under Gaussian assumption, (2) quantifying gap between uniform quantization and Gaussian test channel, (3) extending to context modeling to show entropy reduction from accurate mean prediction. Uses joint simulation and end-to-end training.", "result": "Develops a tight and actionable approximation of theoretical R-D limits, providing structurally interpretable perspective that aligns with real compression modules and enables fine-grained analysis.", "conclusion": "The framework offers new insights into designing more efficient learned compression systems by providing a principled theoretical analysis of the components contributing to R-D performance loss."}}
{"id": "2601.09264", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09264", "abs": "https://arxiv.org/abs/2601.09264", "authors": ["Ziyi Shi", "Xusen Guo", "Hongliang Lu", "Mingxing Peng", "Haotian Wang", "Zheng Zhu", "Zhenning Li", "Yuxuan Liang", "Xinhu Zheng", "Hai Yang"], "title": "Coordinated Pandemic Control with Large Language Model Agents as Policymaking Assistants", "comment": "20pages, 6 figures, a 60-page supporting material pdf file", "summary": "Effective pandemic control requires timely and coordinated policymaking across administrative regions that are intrinsically interdependent. However, human-driven responses are often fragmented and reactive, with policies formulated in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global pandemic mitigation. To address this challenge, here we propose a large language model (LLM) multi-agent policymaking framework that supports coordinated and proactive pandemic control across regions. Within our framework, each administrative region is assigned an LLM agent as an AI policymaking assistant. The agent reasons over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies. By integrating real-world data, a pandemic evolution simulator, and structured inter-agent communication, our framework enables agents to jointly explore counterfactual intervention scenarios and synthesize coordinated policy decisions through a closed-loop simulation process. We validate the proposed framework using state-level COVID-19 data from the United States between April and December 2020, together with real-world mobility records and observed policy interventions. Compared with real-world pandemic outcomes, our approach reduces cumulative infections and deaths by up to 63.7% and 40.1%, respectively, at the individual state level, and by 39.0% and 27.0%, respectively, when aggregated across states. These results demonstrate that LLM multi-agent systems can enable more effective pandemic control with coordinated policymaking...", "AI": {"tldr": "LLM multi-agent framework enables coordinated pandemic policymaking across regions, reducing COVID-19 infections by up to 63.7% and deaths by 40.1% compared to real-world outcomes.", "motivation": "Human pandemic responses are often fragmented and reactive, with policies made in isolation and adjusted only after outbreaks escalate, undermining proactive intervention and global mitigation.", "method": "Assigns each administrative region an LLM agent as AI policymaking assistant; agents reason over region-specific epidemiological dynamics while communicating with other agents to account for cross-regional interdependencies; integrates real-world data, pandemic evolution simulator, and structured inter-agent communication.", "result": "Reduces cumulative infections by up to 63.7% and deaths by 40.1% at individual state level, and by 39.0% and 27.0% when aggregated across states, using US COVID-19 data from April-December 2020.", "conclusion": "LLM multi-agent systems can enable more effective pandemic control through coordinated policymaking, demonstrating significant improvements over real-world fragmented responses."}}
{"id": "2601.09051", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09051", "abs": "https://arxiv.org/abs/2601.09051", "authors": ["Yiming Du", "Ziyu Wang", "Jian Li", "Rui Ning", "Lusi Li"], "title": "Deep Incomplete Multi-View Clustering via Hierarchical Imputation and Alignment", "comment": "Accepted by AAAI 2026", "summary": "Incomplete multi-view clustering (IMVC) aims to discover shared cluster structures from multi-view data with partial observations. The core challenges lie in accurately imputing missing views without introducing bias, while maintaining semantic consistency across views and compactness within clusters. To address these challenges, we propose DIMVC-HIA, a novel deep IMVC framework that integrates hierarchical imputation and alignment with four key components: (1) view-specific autoencoders for latent feature extraction, coupled with a view-shared clustering predictor to produce soft cluster assignments; (2) a hierarchical imputation module that first estimates missing cluster assignments based on cross-view contrastive similarity, and then reconstructs missing features using intra-view, intra-cluster statistics; (3) an energy-based semantic alignment module, which promotes intra-cluster compactness by minimizing energy variance around low-energy cluster anchors; and (4) a contrastive assignment alignment module, which enhances cross-view consistency and encourages confident, well-separated cluster predictions. Experiments on benchmarks demonstrate that our framework achieves superior performance under varying levels of missingness.", "AI": {"tldr": "DIMVC-HIA is a deep incomplete multi-view clustering framework that uses hierarchical imputation and energy-based alignment to handle missing views while maintaining cluster consistency.", "motivation": "Incomplete multi-view clustering faces challenges in accurately imputing missing views without bias while maintaining semantic consistency across views and compactness within clusters.", "method": "Four key components: 1) view-specific autoencoders with shared clustering predictor, 2) hierarchical imputation module using cross-view contrastive similarity and intra-cluster statistics, 3) energy-based semantic alignment for intra-cluster compactness, 4) contrastive assignment alignment for cross-view consistency.", "result": "Experiments on benchmarks demonstrate superior performance under varying levels of missingness.", "conclusion": "The proposed DIMVC-HIA framework effectively addresses incomplete multi-view clustering challenges through integrated hierarchical imputation and alignment mechanisms."}}
{"id": "2601.08982", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.08982", "abs": "https://arxiv.org/abs/2601.08982", "authors": ["Constantin Kolomiiets", "Miroslav Purkrabek", "Jiri Matas"], "title": "SAM-pose2seg: Pose-Guided Human Instance Segmentation in Crowds", "comment": "GitHub: https://github.com/MiraPurkrabek/BBoxMaskPose/", "summary": "Segment Anything (SAM) provides an unprecedented foundation for human segmentation, but may struggle under occlusion, where keypoints may be partially or fully invisible. We adapt SAM 2.1 for pose-guided segmentation with minimal encoder modifications, retaining its strong generalization. Using a fine-tuning strategy called PoseMaskRefine, we incorporate pose keypoints with high visibility into the iterative correction process originally employed by SAM, yielding improved robustness and accuracy across multiple datasets. During inference, we simplify prompting by selecting only the three keypoints with the highest visibility. This strategy reduces sensitivity to common errors, such as missing body parts or misclassified clothing, and allows accurate mask prediction from as few as a single keypoint. Our results demonstrate that pose-guided fine-tuning of SAM enables effective, occlusion-aware human segmentation while preserving the generalization capabilities of the original model. The code and pretrained models will be available at https://mirapurkrabek.github.io/BBox-MaskPose.", "AI": {"tldr": "Fine-tuning SAM 2.1 with pose keypoints for occlusion-aware human segmentation using PoseMaskRefine strategy", "motivation": "SAM struggles with occlusion where keypoints may be partially or fully invisible, requiring improved robustness for human segmentation in challenging scenarios", "method": "Adapt SAM 2.1 with minimal encoder modifications, use PoseMaskRefine fine-tuning strategy to incorporate pose keypoints with high visibility into SAM's iterative correction process, simplify inference by selecting only three highest visibility keypoints", "result": "Improved robustness and accuracy across multiple datasets, reduced sensitivity to errors like missing body parts or misclassified clothing, accurate mask prediction from as few as single keypoint", "conclusion": "Pose-guided fine-tuning enables effective occlusion-aware human segmentation while preserving SAM's generalization capabilities"}}
{"id": "2601.09463", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09463", "abs": "https://arxiv.org/abs/2601.09463", "authors": ["Ying Gao", "Qingqing Wu", "Ziyuan Zheng", "Yanze Zhu", "Wen Chen", "Xin Lin", "Shanpu Shen"], "title": "Two-Scale Spatial Deployment for Cost-Effective Wireless Networks via Cooperative IRSs and Movable Antennas", "comment": "13 pages, 7 figures, submitted to an IEEE journal for possible publication", "summary": "This paper proposes a two-scale spatial deployment strategy to ensure reliable coverage for multiple target areas, integrating macroscopic intelligent reflecting surfaces (IRSs) and fine-grained movable antennas (MAs). Specifically, IRSs are selectively deployed from candidate sites to shape the propagation geometry, while MAs are locally repositioned among discretized locations to exploit small-scale channel variations. The objective is to minimize the total deployment cost of MAs and IRSs by jointly optimizing the IRS site selection, MA positions, transmit precoding, and IRS phase shifts, subject to the signal-to-noise ratio (SNR) requirements for all target areas. This leads to a challenging mixed-integer non-convex optimization problem that is intractable to solve directly. To address this, we first formulate an auxiliary problem to verify the feasibility. A penalty-based double-loop algorithm integrating alternating optimization and successive convex approximation (SCA) is developed to solve this feasibility issue, which is subsequently adapted to obtain a suboptimal solution for the original cost minimization problem. Finally, based on the obtained solution, we formulate an element refinement problem to further reduce the deployment cost, which is solved by a penalty-based SCA algorithm. Simulation results demonstrate that the proposed designs consistently outperform benchmarks relying on independent area planning or full IRS deployment in terms of cost-efficiency. Moreover, for cost minimization, MA architectures are preferable in large placement apertures, whereas fully populated FPA architectures excel in compact ones; for worst-case SNR maximization, MA architectures exhibit a lower cost threshold for feasibility, while FPA architectures can attain peak SNR at a lower total cost.", "AI": {"tldr": "Two-scale spatial deployment strategy combining macroscopic IRSs and fine-grained MAs to minimize deployment cost while ensuring reliable coverage for multiple target areas.", "motivation": "Need for cost-efficient wireless coverage solutions that leverage both large-scale propagation shaping (via IRS) and small-scale channel variations (via MA) to provide reliable coverage for multiple target areas.", "method": "Joint optimization of IRS site selection, MA positions, transmit precoding, and IRS phase shifts using penalty-based double-loop algorithm with alternating optimization and successive convex approximation (SCA), plus element refinement for further cost reduction.", "result": "Proposed design outperforms benchmarks in cost-efficiency; MA architectures preferred for large placement apertures while FPA architectures excel in compact ones; MA has lower cost threshold for feasibility in worst-case SNR maximization.", "conclusion": "Two-scale spatial deployment strategy effectively balances IRS and MA deployment to minimize cost while meeting coverage requirements, with architecture selection depending on placement aperture and optimization objective."}}
{"id": "2601.09300", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09300", "abs": "https://arxiv.org/abs/2601.09300", "authors": ["Minhan Gao", "Kenneth Shum"], "title": "Regenerating codes with minimal disk I/O cost achieving optimal tradeoff between storage and repair bandwidth", "comment": null, "summary": "There are multiple performance metrics in the design of coding schemes for distributed storage systems. The first metric is called repair bandwidth, which measures the network resources required during the repair process. Another critical metric for repair efficiency is disk I/O cost, defined as the amount of data packets accessed at helper nodes to repair the failed node. In an encoding scheme with optimal I/O cost, the number of packets sent to the newcomer is exactly the same as the number of packets read from memory. This mode of repair is referred to as uncoded repair, as no coding operations are performed at the helper node. In addition to minimizing disk I/O cost, an uncoded repair mechanism has the advantage of incurring minimal computational overhead at the helper node. In this paper, we demonstrate that for single node failures, if all surviving nodes participate in the repair of the failed node, we can achieve all points on the fundamental tradeoff curve between storage and repair bandwidth. The design of the proposed encoding scheme is based on the theory of gammoids, a specialized class of graph-based matroids. We prove that this scheme can tolerate an unlimited number of node repair iterations over a field of fixed size.", "AI": {"tldr": "The paper proposes a coding scheme for distributed storage that achieves optimal storage-repair bandwidth tradeoff with uncoded repair, minimizing disk I/O and computational overhead.", "motivation": "Existing distributed storage coding schemes need to optimize multiple performance metrics: repair bandwidth (network resources) and disk I/O cost (data accessed at helper nodes). Uncoded repair, where the number of packets sent equals the number read, minimizes both I/O cost and computational overhead at helper nodes.", "method": "The encoding scheme is based on gammoids, a specialized class of graph-based matroids. The design achieves all points on the fundamental tradeoff curve between storage and repair bandwidth for single node failures when all surviving nodes participate in repair.", "result": "The scheme can tolerate unlimited node repair iterations over a fixed-size field while achieving optimal storage-repair bandwidth tradeoff with uncoded repair, minimizing both disk I/O cost and computational overhead.", "conclusion": "The paper demonstrates that uncoded repair schemes can achieve the fundamental storage-repair bandwidth tradeoff using gammoid theory, providing an efficient solution for distributed storage systems with minimal I/O and computational costs."}}
{"id": "2601.09269", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09269", "abs": "https://arxiv.org/abs/2601.09269", "authors": ["Wencheng Ye", "Liang Peng", "Xiaoyang Yuan", "Yi Bin", "Pengpeng Zeng", "Hengyu Jin", "Heng Tao Shen"], "title": "RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering", "comment": null, "summary": "Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.", "AI": {"tldr": "RISER is a plug-and-play activation steering framework that uses a Router to dynamically compose reusable reasoning vectors for adaptive LLM reasoning enhancement without parameter updates.", "motivation": "Existing activation steering methods use static, manual interventions that don't adapt to the dynamic nature of complex reasoning, while training-intensive approaches require parameter updates.", "method": "RISER constructs a library of reusable reasoning vectors and employs a lightweight Router optimized via reinforcement learning to dynamically compose them for each input, activating latent cognitive primitives.", "result": "Across seven benchmarks, RISER achieves 3.4-6.5% average zero-shot accuracy improvements over base models, surpasses CoT-style reasoning with 2-3x higher token efficiency, and shows robust accuracy gains.", "conclusion": "RISER enables more controllable and efficient LLM reasoning through adaptive, compositional activation steering that autonomously combines reasoning vectors into interpretable control strategies."}}
{"id": "2601.09107", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09107", "abs": "https://arxiv.org/abs/2601.09107", "authors": ["Lachlan Holden", "Feras Dayoub", "Alberto Candela", "David Harvey", "Tat-Jun Chin"], "title": "Vision Foundation Models for Domain Generalisable Cross-View Localisation in Planetary Ground-Aerial Robotic Teams", "comment": "7 pages, 10 figures. Presented at the International Conference on Space Robotics (iSpaRo) 2025 in Sendai, Japan. Dataset available: https://doi.org/10.5281/zenodo.17364038", "summary": "Accurate localisation in planetary robotics enables the advanced autonomy required to support the increased scale and scope of future missions. The successes of the Ingenuity helicopter and multiple planetary orbiters lay the groundwork for future missions that use ground-aerial robotic teams. In this paper, we consider rovers using machine learning to localise themselves in a local aerial map using limited field-of-view monocular ground-view RGB images as input. A key consideration for machine learning methods is that real space data with ground-truth position labels suitable for training is scarce. In this work, we propose a novel method of localising rovers in an aerial map using cross-view-localising dual-encoder deep neural networks. We leverage semantic segmentation with vision foundation models and high volume synthetic data to bridge the domain gap to real images. We also contribute a new cross-view dataset of real-world rover trajectories with corresponding ground-truth localisation data captured in a planetary analogue facility, plus a high volume dataset of analogous synthetic image pairs. Using particle filters for state estimation with the cross-view networks allows accurate position estimation over simple and complex trajectories based on sequences of ground-view images.", "AI": {"tldr": "Rovers localize in aerial maps using cross-view neural networks with semantic segmentation and synthetic data, validated with real-world planetary analogue datasets.", "motivation": "Future planetary missions require advanced autonomy for ground-aerial robotic teams, but real space data with ground-truth labels for training is scarce, necessitating new approaches for rover localization.", "method": "Cross-view-localising dual-encoder deep neural networks using semantic segmentation with vision foundation models, high-volume synthetic data, and particle filters for state estimation with sequences of ground-view images.", "result": "Accurate position estimation over simple and complex trajectories using sequences of ground-view images, validated with new cross-view datasets from planetary analogue facilities.", "conclusion": "The proposed method enables accurate rover localization in aerial maps despite scarce real space data, supporting future planetary robotic missions through cross-view neural networks and synthetic data bridging."}}
{"id": "2601.09071", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09071", "abs": "https://arxiv.org/abs/2601.09071", "authors": ["Parian Haghighat", "Hadis Anahideh", "Cynthia Rudin"], "title": "Resolving Predictive Multiplicity for the Rashomon Set", "comment": null, "summary": "The existence of multiple, equally accurate models for a given predictive task leads to predictive multiplicity, where a ``Rashomon set'' of models achieve similar accuracy but diverges in their individual predictions. This inconsistency undermines trust in high-stakes applications where we want consistent predictions. We propose three approaches to reduce inconsistency among predictions for the members of the Rashomon set. The first approach is \\textbf{outlier correction}. An outlier has a label that none of the good models are capable of predicting correctly. Outliers can cause the Rashomon set to have high variance predictions in a local area, so fixing them can lower variance. Our second approach is local patching. In a local region around a test point, models may disagree with each other because some of them are biased. We can detect and fix such biases using a validation set, which also reduces multiplicity. Our third approach is pairwise reconciliation, where we find pairs of models that disagree on a region around the test point. We modify predictions that disagree, making them less biased. These three approaches can be used together or separately, and they each have distinct advantages. The reconciled predictions can then be distilled into a single interpretable model for real-world deployment. In experiments across multiple datasets, our methods reduce disagreement metrics while maintaining competitive accuracy.", "AI": {"tldr": "Proposes three methods to reduce predictive multiplicity in Rashomon sets: outlier correction, local patching, and pairwise reconciliation, which can be combined to create consistent, interpretable models.", "motivation": "Predictive multiplicity (multiple equally accurate models making different predictions) undermines trust in high-stakes applications where consistent predictions are crucial.", "method": "Three approaches: 1) Outlier correction - fixing data points that no good model can predict correctly; 2) Local patching - detecting and fixing model biases in local regions using validation data; 3) Pairwise reconciliation - modifying disagreeing predictions between model pairs to reduce bias.", "result": "Experiments across multiple datasets show the methods reduce disagreement metrics while maintaining competitive accuracy. The reconciled predictions can be distilled into a single interpretable model.", "conclusion": "The proposed approaches effectively address predictive multiplicity in Rashomon sets, enabling creation of more consistent and trustworthy models for real-world deployment."}}
{"id": "2601.09004", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09004", "abs": "https://arxiv.org/abs/2601.09004", "authors": ["Xiaoyu Ji", "Chenhao Zhang", "Tyler James Downard", "Zoltan Nagy", "Ali Shakouri", "Fengqing Zhu"], "title": "Instance camera focus prediction for crystal agglomeration classification", "comment": null, "summary": "Agglomeration refers to the process of crystal clustering due to interparticle forces. Crystal agglomeration analysis from microscopic images is challenging due to the inherent limitations of two-dimensional imaging. Overlapping crystals may appear connected even when located at different depth layers. Because optical microscopes have a shallow depth of field, crystals that are in-focus and out-of-focus in the same image typically reside on different depth layers and do not constitute true agglomeration. To address this, we first quantified camera focus with an instance camera focus prediction network to predict 2 class focus level that aligns better with visual observations than traditional image processing focus measures. Then an instance segmentation model is combined with the predicted focus level for agglomeration classification. Our proposed method has a higher agglomeration classification and segmentation accuracy than the baseline models on ammonium perchlorate crystal and sugar crystal dataset.", "AI": {"tldr": "A method combining instance camera focus prediction with segmentation to improve crystal agglomeration classification from microscopic images by distinguishing true agglomeration from overlapping crystals at different depth layers.", "motivation": "Crystal agglomeration analysis from 2D microscopic images is challenging because overlapping crystals at different depth layers may appear connected but don't constitute true agglomeration, and traditional focus measures don't align well with visual observations.", "method": "First, an instance camera focus prediction network quantifies camera focus with 2-class focus level prediction. Then, an instance segmentation model is combined with the predicted focus level for agglomeration classification.", "result": "The proposed method achieves higher agglomeration classification and segmentation accuracy than baseline models on both ammonium perchlorate crystal and sugar crystal datasets.", "conclusion": "The focus-aware approach effectively addresses depth-related challenges in crystal agglomeration analysis from microscopic images, improving classification accuracy by distinguishing true agglomeration from overlapping crystals at different depths."}}
{"id": "2601.09484", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09484", "abs": "https://arxiv.org/abs/2601.09484", "authors": ["Marouan Mizmizi", "Stefano Tebaldini", "Umberto Spagnolini"], "title": "Echo-Side Integrated Sensing and Communication via Space-Time Reconfigurable Intelligent Surfaces", "comment": null, "summary": "This paper presents an echo-side modulation framework for integrated sensing and communication (ISAC) systems. A space-time reconfigurable intelligent surface (ST-RIS) impresses a continuous-phase modulation onto the radar echo, enabling uplink data transmission with a phase modulation of the transmitted radar-like waveform. The received signal is a multiplicative composition of the sensing waveform and the phase for communication. Both functionalities share the same physical signal and perceive each other as impairments.\n  The achievable communication rate is expressed as a function of a coupling parameter that links sensing accuracy to phase error accumulation. Under a fixed bandwidth constraint, the sensing and communication figures of merit define a convex Pareto frontier. The optimal bandwidth allocation satisfying a minimum sensing requirement is derived in closed form. The modified Cramer-Rao bound (MCRB) for range estimation is derived in closed form; this parameter must be estimated to compensate for the frequency offset before data demodulation. Frame synchronization is formulated as a generalized likelihood ratio test (GLRT), and the detection probability is obtained through characteristic function inversion, accounting for residual frequency errors from imperfect range estimation. Numerical results validate the theoretical bounds and characterize the trade-off across the operating range.", "AI": {"tldr": "ST-RIS enables integrated sensing and communication by modulating radar echoes with continuous-phase modulation for uplink data transmission, creating a trade-off between sensing accuracy and communication rate under bandwidth constraints.", "motivation": "To develop an integrated sensing and communication (ISAC) framework that enables simultaneous radar sensing and data communication using the same physical signal, addressing the challenge of mutual interference between these functions.", "method": "Uses a space-time reconfigurable intelligent surface (ST-RIS) to impress continuous-phase modulation onto radar echoes for uplink communication. Derives achievable communication rate as function of coupling parameter, optimal bandwidth allocation, modified Cramer-Rao bound for range estimation, and GLRT-based frame synchronization.", "result": "Establishes a convex Pareto frontier between sensing and communication performance under fixed bandwidth. Derives closed-form optimal bandwidth allocation and MCRB for range estimation. Validates theoretical bounds through numerical results characterizing the trade-off across operating range.", "conclusion": "The echo-side modulation framework enables efficient ISAC with ST-RIS, demonstrating fundamental trade-offs between sensing accuracy and communication rate, with practical solutions for bandwidth allocation, range estimation, and synchronization."}}
{"id": "2601.09308", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.09308", "abs": "https://arxiv.org/abs/2601.09308", "authors": ["Peter Harremo\u00ebs"], "title": "An Information Theoretic Proof of the Radon-Nikodym Theorem", "comment": "7 pages", "summary": "The Radon-Nikodym theorem plays a significant role in the definition of Shannon entropy, f-divergences, and other basic quantities in information theory. The existence of Radon Nikodym derivates appear in many text books in measure theory but in text books on probability or information theory it is often omitted because the proof is often considered to be too difficult.", "AI": {"tldr": "The paper discusses how the Radon-Nikodym theorem is fundamental to information theory concepts like Shannon entropy and f-divergences, but its proof is often omitted in probability/information theory textbooks due to perceived difficulty.", "motivation": "To highlight the importance of the Radon-Nikodym theorem in information theory foundations while addressing why its proof is frequently excluded from probability and information theory textbooks.", "method": "The paper appears to be a theoretical discussion/analysis paper that examines the role of the Radon-Nikodym theorem in information theory and the pedagogical challenges surrounding its inclusion in textbooks.", "result": "Identifies the Radon-Nikodym theorem as crucial for defining Shannon entropy and f-divergences, while noting that its proof is often omitted from probability/information theory textbooks due to perceived mathematical difficulty.", "conclusion": "The Radon-Nikodym theorem is essential for information theory foundations, but there's a pedagogical gap where its proof is excluded from many textbooks in the field, possibly creating an incomplete understanding of the theoretical underpinnings."}}
{"id": "2601.09274", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09274", "abs": "https://arxiv.org/abs/2601.09274", "authors": ["Jian Zhang", "Yu He", "Zhiyuan Wang", "Zhangqi Wang", "Kai He", "Fangzhi Xu", "Qika Lin", "Jun Liu"], "title": "$A^3$-Bench: Benchmarking Memory-Driven Scientific Reasoning via Anchor and Attractor Activation", "comment": null, "summary": "Scientific reasoning relies not only on logical inference but also on activating prior knowledge and experiential structures. Memory can efficiently reuse knowledge and enhance reasoning consistency and stability. However, existing benchmarks mainly evaluate final answers or step-by-step coherence, overlooking the \\textit{memory-driven} mechanisms that underlie human reasoning, which involves activating anchors and attractors, then integrating them into multi-step inference. To address this gap, we propose $A^3$-Bench~ https://a3-bench.github.io, a benchmark designed to evaluate scientific reasoning through dual-scale memory-driven activation, grounded in Anchor and Attractor Activation. First, we annotate 2,198 science reasoning problems across domains using the SAPM process(subject, anchor & attractor, problem, and memory developing). Second, we introduce a dual-scale memory evaluation framework utilizing anchors and attractors, along with the AAUI(Anchor--Attractor Utilization Index) metric to measure memory activation rates. Finally, through experiments with various base models and paradigms, we validate $A^3$-Bench and analyze how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.", "AI": {"tldr": "A\u00b3-Bench is a new benchmark for evaluating scientific reasoning through memory-driven activation mechanisms (anchors and attractors), addressing gaps in existing benchmarks that overlook memory's role in reasoning.", "motivation": "Existing benchmarks focus on final answers or step-by-step coherence but overlook memory-driven mechanisms in scientific reasoning. Human reasoning involves activating prior knowledge (anchors and attractors) and integrating them into multi-step inference, which current evaluation frameworks don't capture.", "method": "1) Annotated 2,198 science reasoning problems using SAPM process (subject, anchor & attractor, problem, memory developing). 2) Created dual-scale memory evaluation framework using anchors and attractors. 3) Introduced AAUI (Anchor-Attractor Utilization Index) metric to measure memory activation rates. 4) Conducted experiments with various base models and paradigms.", "result": "Validated A\u00b3-Bench through experiments and analyzed how memory activation impacts reasoning performance, providing insights into memory-driven scientific reasoning.", "conclusion": "A\u00b3-Bench addresses the gap in evaluating memory-driven scientific reasoning mechanisms and provides a framework to understand how memory activation influences reasoning performance, offering valuable insights for improving AI reasoning systems."}}
{"id": "2601.09605", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09605", "abs": "https://arxiv.org/abs/2601.09605", "authors": ["Jeremiah Coholich", "Justin Wit", "Robert Azarcon", "Zsolt Kira"], "title": "Sim2real Image Translation Enables Viewpoint-Robust Policies from Fixed-Camera Datasets", "comment": null, "summary": "Vision-based policies for robot manipulation have achieved significant recent success, but are still brittle to distribution shifts such as camera viewpoint variations. Robot demonstration data is scarce and often lacks appropriate variation in camera viewpoints. Simulation offers a way to collect robot demonstrations at scale with comprehensive coverage of different viewpoints, but presents a visual sim2real challenge. To bridge this gap, we propose MANGO -- an unpaired image translation method with a novel segmentation-conditioned InfoNCE loss, a highly-regularized discriminator design, and a modified PatchNCE loss. We find that these elements are crucial for maintaining viewpoint consistency during sim2real translation. When training MANGO, we only require a small amount of fixed-camera data from the real world, but show that our method can generate diverse unseen viewpoints by translating simulated observations. In this domain, MANGO outperforms all other image translation methods we tested. Imitation-learning policies trained on data augmented by MANGO are able to achieve success rates as high as 60\\% on views that the non-augmented policy fails completely on.", "AI": {"tldr": "MANGO is an unpaired image translation method that enables sim2real transfer for robot manipulation by generating diverse real-world viewpoints from simulated data using novel segmentation-conditioned losses and regularized discriminator design.", "motivation": "Vision-based robot manipulation policies are brittle to camera viewpoint variations, and real robot demonstration data is scarce with limited viewpoint diversity. Simulation can provide large-scale demonstrations with comprehensive viewpoint coverage, but faces visual sim2real challenges.", "method": "MANGO uses unpaired image translation with three key components: 1) segmentation-conditioned InfoNCE loss, 2) highly-regularized discriminator design, and 3) modified PatchNCE loss. These elements maintain viewpoint consistency during sim2real translation.", "result": "MANGO outperforms other image translation methods in this domain. Policies trained on MANGO-augmented data achieve up to 60% success rates on viewpoints where non-augmented policies completely fail, using only small amounts of fixed-camera real-world data.", "conclusion": "MANGO effectively bridges the sim2real gap for robot manipulation by generating diverse real-world viewpoints from simulation, enabling robust vision-based policies that handle viewpoint variations without requiring extensive real-world demonstration data."}}
{"id": "2601.09076", "categories": ["cs.LG", "cs.DC", "cs.IT", "cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09076", "abs": "https://arxiv.org/abs/2601.09076", "authors": ["Zhoubin Kou", "Zihan Chen", "Jing Yang", "Cong Shen"], "title": "Lean Clients, Full Accuracy: Hybrid Zeroth- and First-Order Split Federated Learning", "comment": null, "summary": "Split Federated Learning (SFL) enables collaborative training between resource-constrained edge devices and a compute-rich server. Communication overhead is a central issue in SFL and can be mitigated with auxiliary networks. Yet, the fundamental client-side computation challenge remains, as back-propagation requires substantial memory and computation costs, severely limiting the scale of models that edge devices can support. To enable more resource-efficient client computation and reduce the client-server communication, we propose HERON-SFL, a novel hybrid optimization framework that integrates zeroth-order (ZO) optimization for local client training while retaining first-order (FO) optimization on the server. With the assistance of auxiliary networks, ZO updates enable clients to approximate local gradients using perturbed forward-only evaluations per step, eliminating memory-intensive activation caching and avoiding explicit gradient computation in the traditional training process. Leveraging the low effective rank assumption, we theoretically prove that HERON-SFL's convergence rate is independent of model dimensionality, addressing a key scalability concern common to ZO algorithms. Empirically, on ResNet training and language model (LM) fine-tuning tasks, HERON-SFL matches benchmark accuracy while reducing client peak memory by up to 64% and client-side compute cost by up to 33% per step, substantially expanding the range of models that can be trained or adapted on resource-limited devices.", "AI": {"tldr": "HERON-SFL is a hybrid optimization framework for Split Federated Learning that combines zeroth-order optimization on clients with first-order optimization on the server to reduce client memory/computation costs and communication overhead.", "motivation": "Split Federated Learning faces two main challenges: communication overhead and client-side computation bottlenecks. While auxiliary networks help with communication, back-propagation on edge devices requires substantial memory and computation, limiting the scale of models that resource-constrained devices can support.", "method": "HERON-SFL integrates zeroth-order optimization for local client training while retaining first-order optimization on the server. Clients use perturbed forward-only evaluations to approximate gradients, eliminating memory-intensive activation caching and avoiding explicit gradient computation. This is combined with auxiliary networks to reduce communication.", "result": "Theoretical analysis shows convergence rate is independent of model dimensionality. Empirical results on ResNet training and language model fine-tuning demonstrate matching benchmark accuracy while reducing client peak memory by up to 64% and client-side compute cost by up to 33% per step.", "conclusion": "HERON-SFL substantially expands the range of models that can be trained or adapted on resource-limited devices by addressing both communication and computation challenges in Split Federated Learning through a hybrid optimization approach."}}
{"id": "2601.09701", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09701", "abs": "https://arxiv.org/abs/2601.09701", "authors": ["Fahimeh Orvati Nia", "Shima Salehi", "Joshua Peeples"], "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems", "comment": "Accepted to IEEE Texas Power and Energy Conference (TPEC) 2026. 6 pages, 5 figures. Code available at https://github.com/fahimehorvatinia/GAN-LSTM-Smart-Meter-Anomaly-Detection", "summary": "Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available", "AI": {"tldr": "GAN-LSTM framework outperforms six baselines for smart meter anomaly detection, achieving F1-score of 0.89 on LEAD dataset with 406 buildings' hourly data.", "motivation": "Advanced metering infrastructure provides valuable electricity consumption data, but anomaly detection is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions.", "method": "Systematic evaluation of GAN-LSTM framework for smart meter anomaly detection using LEAD dataset (1 year of hourly measurements from 406 buildings). Pipeline includes consistent preprocessing, temporal windowing, threshold selection, and comparison against six baselines (statistical, kernel-based, reconstruction-based, and GAN-based models).", "result": "GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89, outperforming all six baseline methods.", "conclusion": "Adversarial temporal modeling (GAN-LSTM) shows strong potential as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks."}}
{"id": "2601.09328", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.09328", "abs": "https://arxiv.org/abs/2601.09328", "authors": ["Adrien Vandenbroucque", "Amedeo Roberto Esposito", "Michael Gastpar"], "title": "Contraction of R\u00e9nyi Divergences for Discrete Channels: Properties and Applications", "comment": null, "summary": "This work explores properties of Strong Data-Processing constants for R\u00e9nyi Divergences. Parallels are made with the well-studied $\\varphi$-Divergences, and it is shown that the order $\u03b1$ of R\u00e9nyi Divergences dictates whether certain properties of the contraction of $\\varphi$-Divergences are mirrored or not. In particular, we demonstrate that when $\u03b1>1$, the contraction properties can deviate quite strikingly from those of $\\varphi$-Divergences. We also uncover specific characteristics of contraction for the $\\infty$-R\u00e9nyi Divergence and relate it to $\\varepsilon$-Local Differential Privacy. The results are then applied to bound the speed of convergence of Markov chains, where we argue that the contraction of R\u00e9nyi Divergences offers a new perspective on the contraction of $L^\u03b1$-norms commonly studied in the literature.", "AI": {"tldr": "This paper analyzes Strong Data-Processing constants for R\u00e9nyi Divergences, comparing them with \u03c6-Divergences and showing how contraction properties differ based on the order \u03b1, with applications to Markov chain convergence.", "motivation": "The motivation is to understand the contraction properties of R\u00e9nyi Divergences through Strong Data-Processing constants, comparing them with the well-studied \u03c6-Divergences, and to apply these insights to analyze Markov chain convergence rates.", "method": "The method involves analyzing Strong Data-Processing constants for R\u00e9nyi Divergences, comparing their properties with \u03c6-Divergences, examining how contraction behavior depends on the order \u03b1, and investigating special cases including the \u221e-R\u00e9nyi Divergence and its connection to \u03b5-Local Differential Privacy.", "result": "The results show that when \u03b1>1, R\u00e9nyi Divergence contraction properties can deviate strikingly from \u03c6-Divergences. The paper uncovers specific characteristics of contraction for \u221e-R\u00e9nyi Divergence and relates it to \u03b5-Local Differential Privacy, then applies these findings to bound Markov chain convergence speeds.", "conclusion": "The contraction of R\u00e9nyi Divergences offers a new perspective on the contraction of L^\u03b1-norms commonly studied in Markov chain literature, providing alternative tools for analyzing convergence rates through Strong Data-Processing constants."}}
{"id": "2601.09278", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09278", "abs": "https://arxiv.org/abs/2601.09278", "authors": ["Xiaohan Yu", "Chao Feng", "Lang Mei", "Chong Chen"], "title": "M$^3$Searcher: Modular Multimodal Information Seeking Agency with Retrieval-Oriented Reasoning", "comment": null, "summary": "Recent advances in DeepResearch-style agents have demonstrated strong capabilities in autonomous information acquisition and synthesize from real-world web environments. However, existing approaches remain fundamentally limited to text modality. Extending autonomous information-seeking agents to multimodal settings introduces critical challenges: the specialization-generalization trade-off that emerges when training models for multimodal tool-use at scale, and the severe scarcity of training data capturing complex, multi-step multimodal search trajectories. To address these challenges, we propose M$^3$Searcher, a modular multimodal information-seeking agent that explicitly decouples information acquisition from answer derivation. M$^3$Searcher is optimized with a retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. In addition, we develop MMSearchVQA, a multimodal multi-hop dataset to support retrieval centric RL training. Experimental results demonstrate that M$^3$Searcher outperforms existing approaches, exhibits strong transfer adaptability and effective reasoning in complex multimodal tasks.", "AI": {"tldr": "M\u00b3Searcher is a modular multimodal information-seeking agent that decouples information acquisition from answer derivation, trained with retrieval-oriented multi-objective rewards and evaluated on a new multimodal multi-hop dataset.", "motivation": "Existing DeepResearch-style agents are limited to text modality, and extending them to multimodal settings faces challenges: specialization-generalization trade-off in training multimodal tool-use models at scale, and scarcity of training data for complex multi-step multimodal search trajectories.", "method": "Proposes M\u00b3Searcher, a modular multimodal agent that explicitly decouples information acquisition from answer derivation. Uses retrieval-oriented multi-objective reward that jointly encourages factual accuracy, reasoning soundness, and retrieval fidelity. Also develops MMSearchVQA, a multimodal multi-hop dataset for retrieval-centric RL training.", "result": "Experimental results show M\u00b3Searcher outperforms existing approaches, exhibits strong transfer adaptability, and demonstrates effective reasoning in complex multimodal tasks.", "conclusion": "M\u00b3Searcher successfully addresses the challenges of multimodal information-seeking agents through modular design and retrieval-oriented training, enabling effective autonomous information acquisition in multimodal environments."}}
{"id": "2601.09708", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.09708", "abs": "https://arxiv.org/abs/2601.09708", "authors": ["Chi-Pin Huang", "Yunze Man", "Zhiding Yu", "Min-Hung Chen", "Jan Kautz", "Yu-Chiang Frank Wang", "Fu-En Yang"], "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning", "comment": "Project page: https://jasper0314-huang.github.io/fast-thinkact/", "summary": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.", "AI": {"tldr": "Fast-ThinkAct is an efficient VLA framework that uses verbalizable latent reasoning to achieve compact planning with 89.3% reduced inference latency while maintaining strong performance.", "motivation": "Current reasoning VLAs with explicit chain-of-thought suffer from high inference latency due to lengthy reasoning traces, limiting their practical application in dynamic embodied environments.", "method": "Learns efficient latent reasoning through distillation from a teacher model, using preference-guided objective to align manipulation trajectories and transfer linguistic/visual planning capabilities for embodied control.", "result": "Achieves strong performance across diverse embodied manipulation and reasoning benchmarks with up to 89.3% reduced inference latency while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.", "conclusion": "Fast-ThinkAct enables efficient reasoning-enhanced policy learning that effectively connects compact reasoning to action execution, making VLA systems more practical for real-world embodied tasks."}}
{"id": "2601.09083", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09083", "abs": "https://arxiv.org/abs/2601.09083", "authors": ["Chi-Chih Chang", "Siqi Zhu", "Zhichen Zeng", "Haibin Lin", "Jiaxuan You", "Mohamed S. Abdelfattah", "Ziheng Jiang", "Xuehai Qian"], "title": "SRT: Accelerating Reinforcement Learning via Speculative Rollout with Tree-Structured Cache", "comment": null, "summary": "We present Speculative Rollout with Tree-Structured Cache (SRT), a simple, model-free approach to accelerate on-policy reinforcement learning (RL) for language models without sacrificing distributional correctness. SRT exploits the empirical similarity of rollouts for the same prompt across training steps by storing previously generated continuations in a per-prompt tree-structured cache. During generation, the current policy uses this tree as the draft model for performing speculative decoding. To keep the cache fresh and improve draft model quality, SRT updates trees online from ongoing rollouts and proactively performs run-ahead generation during idle GPU bubbles. Integrated into standard RL pipelines (\\textit{e.g.}, PPO, GRPO and DAPO) and multi-turn settings, SRT consistently reduces generation and step latency and lowers per-token inference cost, achieving up to 2.08x wall-clock time speedup during rollout.", "AI": {"tldr": "SRT accelerates on-policy RL for language models using a tree-structured cache for speculative decoding, achieving up to 2.08x speedup without sacrificing distributional correctness.", "motivation": "On-policy RL for language models is computationally expensive due to slow rollouts. Existing methods either sacrifice distributional correctness or require complex model modifications. There's a need for a simple, model-free approach to accelerate RL training while maintaining correctness.", "method": "SRT stores previously generated continuations in a per-prompt tree-structured cache. During generation, the current policy uses this tree as a draft model for speculative decoding. The cache is kept fresh through online updates from ongoing rollouts and proactive run-ahead generation during idle GPU bubbles.", "result": "SRT consistently reduces generation and step latency, lowers per-token inference cost, and achieves up to 2.08x wall-clock time speedup during rollout. It integrates well with standard RL pipelines (PPO, GRPO, DAPO) and multi-turn settings.", "conclusion": "SRT provides a simple, effective approach to accelerate on-policy RL for language models without compromising distributional correctness, making RL training more efficient while maintaining quality."}}
{"id": "2601.09040", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09040", "abs": "https://arxiv.org/abs/2601.09040", "authors": ["Jonas R\u00f6mer", "Timo Dickscheid"], "title": "Depth-Wise Representation Development Under Blockwise Self-Supervised Learning for Video Vision Transformers", "comment": null, "summary": "End-to-end backpropagation couples all layers through a global error signal, enabling coordinated learning but requiring long-range credit assignment. Motivated by recent progress in blockwise self-supervised learning (BWSSL), we ask whether masked video transformers can be trained without end-to-end backpropagation. Applying BWSSL to masked video modeling remains relatively underexplored and must handle spatiotemporal context and long-range temporal structure. More broadly, analyses that compare BWSSL and end-to-end training in terms of learning dynamics and depth-wise representation development remain sparse. We apply blockwise learning to a masked autoencoding video vision transformer by partitioning the encoder into blocks, each of which is optimized with a local masked reconstruction loss. Across model sizes and partition granularities, training converges and yields representations close to matched end-to-end baselines under linear-probe and retrieval proxies. In order to compare intermediate representations, we analyze depth-wise decodability, inter-block similarity, and patch-level diagnostics. Blockwise training exposes higher-level structure earlier, while later blocks saturate and operate in a more geometry-preserving regime. It can also induce token-level shifts consistent with stronger early mixing that pooled metrics can miss. These findings point to late-block saturation and interface formation as contributors to the remaining gap.", "AI": {"tldr": "Blockwise self-supervised learning can train masked video transformers without end-to-end backpropagation, achieving representations close to end-to-end baselines while revealing different learning dynamics.", "motivation": "To explore whether masked video transformers can be trained without end-to-end backpropagation, addressing the underexplored application of blockwise self-supervised learning to spatiotemporal video modeling and the sparse analysis comparing BWSSL and end-to-end training dynamics.", "method": "Apply blockwise learning to masked autoencoding video vision transformers by partitioning the encoder into blocks, each optimized with a local masked reconstruction loss. Analyze depth-wise decodability, inter-block similarity, and patch-level diagnostics to compare intermediate representations.", "result": "Blockwise training converges and yields representations close to end-to-end baselines under linear-probe and retrieval metrics. It exposes higher-level structure earlier, with later blocks saturating and operating in a geometry-preserving regime, while revealing token-level shifts missed by pooled metrics.", "conclusion": "Blockwise training is viable for masked video modeling, achieving competitive performance while revealing different learning dynamics. Late-block saturation and interface formation contribute to the remaining performance gap with end-to-end training."}}
{"id": "2601.09329", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09329", "abs": "https://arxiv.org/abs/2601.09329", "authors": ["Jun Su", "Guangyue Han", "Shlomo Shamai"], "title": "Generalized Schalkwijk-Kailath Coding for Autoregressive Gaussian Channels", "comment": null, "summary": "We propose a Gaussian random coding scheme for AR($p$) Gaussian channels that generalizes the celebrated Schalkwijk-Kailath (SK) coding scheme. This constructive coding scheme, termed the SK(2) coding scheme, yields a closed-form characterization for the corresponding achievable rate. Among many others, this result shows that the celebrated SK coding scheme is not universally optimal, and therefore, disprove the conjecture proposed by Butman in \\cite{butman1976linear}.", "AI": {"tldr": "The paper proposes SK(2) coding scheme for AR(p) Gaussian channels, generalizing Schalkwijk-Kailath coding, showing SK scheme is not universally optimal and disproving Butman's conjecture.", "motivation": "To generalize the celebrated Schalkwijk-Kailath coding scheme for AR(p) Gaussian channels and investigate its optimality properties.", "method": "Proposes a Gaussian random coding scheme called SK(2) that extends the original SK coding to AR(p) Gaussian channels, providing constructive coding with closed-form achievable rate characterization.", "result": "Shows that the SK coding scheme is not universally optimal, disproving Butman's 1976 conjecture about its optimality.", "conclusion": "The SK(2) coding scheme provides a generalization of SK coding with closed-form rate characterization, demonstrating limitations of the original SK scheme and resolving a long-standing conjecture."}}
{"id": "2601.09281", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09281", "abs": "https://arxiv.org/abs/2601.09281", "authors": ["Jingjing Zhou", "Gaoxiang Cong", "Li Su", "Liang Li"], "title": "STaR: Sensitive Trajectory Regulation for Unlearning in Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have advanced automated multi-step reasoning, but their ability to generate complex Chain-of-Thought (CoT) trajectories introduces severe privacy risks, as sensitive information may be deeply embedded throughout the reasoning process. Existing Large Language Models (LLMs) unlearning approaches that typically focus on modifying only final answers are insufficient for LRMs, as they fail to remove sensitive content from intermediate steps, leading to persistent privacy leakage and degraded security. To address these challenges, we propose Sensitive Trajectory Regulation (STaR), a parameter-free, inference-time unlearning framework that achieves robust privacy protection throughout the reasoning process. Specifically, we first identify sensitive content via semantic-aware detection. Then, we inject global safety constraints through secure prompt prefix. Next, we perform trajectory-aware suppression to dynamically block sensitive content across the entire reasoning chain. Finally, we apply token-level adaptive filtering to prevent both exact and paraphrased sensitive tokens during generation. Furthermore, to overcome the inadequacies of existing evaluation protocols, we introduce two metrics: Multi-Decoding Consistency Assessment (MCS), which measures the consistency of unlearning across diverse decoding strategies, and Multi-Granularity Membership Inference Attack (MIA) Evaluation, which quantifies privacy protection at both answer and reasoning-chain levels. Experiments on the R-TOFU benchmark demonstrate that STaR achieves comprehensive and stable unlearning with minimal utility loss, setting a new standard for privacy-preserving reasoning in LRMs.", "AI": {"tldr": "STaR is a parameter-free inference-time unlearning framework that protects privacy in Large Reasoning Models by removing sensitive content from both final answers and intermediate reasoning steps.", "motivation": "Large Reasoning Models generate complex Chain-of-Thought trajectories that embed sensitive information throughout the reasoning process. Existing LLM unlearning approaches only modify final answers, failing to remove sensitive content from intermediate steps, leading to persistent privacy leakage.", "method": "Four-step framework: 1) Semantic-aware sensitive content detection, 2) Global safety constraint injection via secure prompt prefix, 3) Trajectory-aware suppression to block sensitive content across reasoning chain, 4) Token-level adaptive filtering to prevent exact and paraphrased sensitive tokens.", "result": "Experiments on R-TOFU benchmark show STaR achieves comprehensive and stable unlearning with minimal utility loss. Introduces new evaluation metrics (MCS and multi-granularity MIA) that demonstrate superior privacy protection.", "conclusion": "STaR sets a new standard for privacy-preserving reasoning in LRMs by addressing the unique challenges of multi-step reasoning privacy risks through a parameter-free inference-time approach that protects both answers and reasoning chains."}}
{"id": "2601.09085", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.09085", "abs": "https://arxiv.org/abs/2601.09085", "authors": ["Kangda Wei", "Ruihong Huang"], "title": "MMR-GRPO: Accelerating GRPO-Style Training through Diversity-Aware Reward Reweighting", "comment": null, "summary": "Group Relative Policy Optimization (GRPO) has become a standard approach for training mathematical reasoning models; however, its reliance on multiple completions per prompt makes training computationally expensive. Although recent work has reduced the number of training steps required to reach peak performance, the overall wall-clock training time often remains unchanged or even increases due to higher per-step cost. We propose MMR-GRPO, which integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity. Our key insight is that semantically redundant completions contribute limited marginal learning signal; prioritizing diverse solutions yields more informative updates and accelerates convergence. Extensive evaluations across three model sizes (1.5B, 7B, 8B), three GRPO variants, and five mathematical reasoning benchmarks show that MMR-GRPO achieves comparable peak performance while requiring on average 47.9% fewer training steps and 70.2% less wall-clock time. These gains are consistent across models, methods, and benchmarks. We will release our code, trained models, and experimental protocols.", "AI": {"tldr": "MMR-GRPO accelerates mathematical reasoning model training by using Maximal Marginal Relevance to prioritize diverse completions, reducing training steps by 47.9% and wall-clock time by 70.2% while maintaining performance.", "motivation": "GRPO (Group Relative Policy Optimization) is computationally expensive due to requiring multiple completions per prompt. While recent work reduced training steps, overall wall-clock time often remains unchanged or increases due to higher per-step costs.", "method": "Proposes MMR-GRPO which integrates Maximal Marginal Relevance to reweigh rewards based on completion diversity. The key insight is that semantically redundant completions provide limited learning signal, so prioritizing diverse solutions yields more informative updates and accelerates convergence.", "result": "Extensive evaluations across three model sizes (1.5B, 7B, 8B), three GRPO variants, and five mathematical reasoning benchmarks show MMR-GRPO achieves comparable peak performance while requiring 47.9% fewer training steps and 70.2% less wall-clock time on average.", "conclusion": "MMR-GRPO significantly reduces computational costs of training mathematical reasoning models while maintaining performance, with consistent gains across models, methods, and benchmarks. The approach addresses the computational bottleneck of GRPO training through diversity-aware reward weighting."}}
{"id": "2601.09078", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09078", "abs": "https://arxiv.org/abs/2601.09078", "authors": ["Junze Shi", "Yang Yu", "Jian Shi", "Haibo Luo"], "title": "Exploring Reliable Spatiotemporal Dependencies for Efficient Visual Tracking", "comment": "8 pages, 6 figures", "summary": "Recent advances in transformer-based lightweight object tracking have established new standards across benchmarks, leveraging the global receptive field and powerful feature extraction capabilities of attention mechanisms. Despite these achievements, existing methods universally employ sparse sampling during training--utilizing only one template and one search image per sequence--which fails to comprehensively explore spatiotemporal information in videos. This limitation constrains performance and cause the gap between lightweight and high-performance trackers. To bridge this divide while maintaining real-time efficiency, we propose STDTrack, a framework that pioneers the integration of reliable spatiotemporal dependencies into lightweight trackers. Our approach implements dense video sampling to maximize spatiotemporal information utilization. We introduce a temporally propagating spatiotemporal token to guide per-frame feature extraction. To ensure comprehensive target state representation, we disign the Multi-frame Information Fusion Module (MFIFM), which augments current dependencies using historical context. The MFIFM operates on features stored in our constructed Spatiotemporal Token Maintainer (STM), where a quality-based update mechanism ensures information reliability. Considering the scale variation among tracking targets, we develop a multi-scale prediction head to dynamically adapt to objects of different sizes. Extensive experiments demonstrate state-of-the-art results across six benchmarks. Notably, on GOT-10k, STDTrack rivals certain high-performance non-real-time trackers (e.g., MixFormer) while operating at 192 FPS(GPU) and 41 FPS(CPU).", "AI": {"tldr": "STDTrack introduces a lightweight object tracking framework that integrates spatiotemporal dependencies through dense video sampling, temporal propagation tokens, and multi-frame information fusion to bridge the performance gap between lightweight and high-performance trackers while maintaining real-time efficiency.", "motivation": "Existing lightweight trackers use sparse sampling (one template + one search image per sequence), which fails to explore comprehensive spatiotemporal information in videos, creating a performance gap between lightweight and high-performance trackers.", "method": "Proposes STDTrack with: 1) Dense video sampling for spatiotemporal information utilization; 2) Temporally propagating spatiotemporal token for per-frame feature guidance; 3) Multi-frame Information Fusion Module (MFIFM) using historical context; 4) Spatiotemporal Token Maintainer (STM) with quality-based update mechanism; 5) Multi-scale prediction head for varying target sizes.", "result": "Achieves state-of-the-art results across six benchmarks. On GOT-10k, rivals high-performance non-real-time trackers like MixFormer while operating at 192 FPS (GPU) and 41 FPS (CPU).", "conclusion": "STDTrack successfully bridges the performance gap between lightweight and high-performance trackers by effectively integrating spatiotemporal dependencies while maintaining real-time efficiency, demonstrating that lightweight trackers can achieve competitive performance without sacrificing speed."}}
{"id": "2601.09347", "categories": ["cs.IT", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.09347", "abs": "https://arxiv.org/abs/2601.09347", "authors": ["Pierre Jean-Claude Robert Bertrand"], "title": "A Constructive Method to Minimize the Index of Coincidence under Marginal Constraints", "comment": null, "summary": "We consider the problem of minimizing the index of coincidence of a joint distribution under fixed marginal constraints. This objective is motivated by several applications in information theory, where the index of coincidence naturally arises. A closed-form solution is known when the marginals satisfy a strong feasibility condition, but this condition is rarely met in practice. We first show that the measure of the set of marginals for which condition applies vanishes as the dimension grows. We then characterize the structure of the optimal coupling in the general case, proving that it exhibits a monotone staircase of zero entries. Based on this structure, we propose an explicit iterative construction and prove that it converges in finitely many steps to a minimizer. Main result of the paper is a complete constructive solution of index-of-coincidence minimization.", "AI": {"tldr": "The paper provides a complete constructive solution for minimizing the index of coincidence of joint distributions under fixed marginal constraints, addressing cases where previous strong feasibility conditions rarely hold in practice.", "motivation": "The index of coincidence minimization problem arises naturally in several information theory applications. While a closed-form solution exists when marginals satisfy a strong feasibility condition, this condition is rarely met in practice, creating a need for a general solution.", "method": "The authors first analyze the vanishing measure of marginals satisfying the strong feasibility condition as dimension grows. They then characterize the optimal coupling structure (monotone staircase of zero entries) and propose an explicit iterative construction that converges in finitely many steps to a minimizer.", "result": "The paper proves that the measure of marginals satisfying the strong feasibility condition vanishes with growing dimension, characterizes the optimal coupling structure, and provides a finite-step convergent iterative algorithm for constructing minimizers.", "conclusion": "The main contribution is a complete constructive solution for index-of-coincidence minimization under fixed marginal constraints, overcoming the practical limitations of previous approaches that required rarely-satisfied feasibility conditions."}}
{"id": "2601.09282", "categories": ["cs.AI", "cs.DC", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.09282", "abs": "https://arxiv.org/abs/2601.09282", "authors": ["Leszek Sliwko", "Jolanta Mizeria-Pietraszko"], "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing", "comment": null, "summary": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.", "AI": {"tldr": "LLM-based semantic scheduling for Kubernetes using natural language hints achieves >95% parsing accuracy and superior placement in complex scenarios.", "motivation": "Cluster workload allocation requires complex configurations, creating a usability gap. The paper aims to simplify this through natural language interfaces.", "method": "Semantic intent-driven scheduling using LLMs integrated via Kubernetes scheduler extender. System includes cluster state cache and intent analyzer (AWS Bedrock) to interpret natural language annotations for soft affinity preferences.", "result": "High LLM parsing accuracy (>95% Subset Accuracy) with top models (Amazon Nova Pro/Premier, Mistral Pixtral Large). Scheduling tests across six scenarios showed superior/equivalent placement vs standard Kubernetes, especially in complex/quantitative scenarios and conflicting soft preferences.", "conclusion": "Validates LLMs for accessible scheduling but notes limitations like synchronous LLM latency. Suggests asynchronous processing for production. Confirms viability of semantic soft affinity for simplifying workload orchestration."}}
{"id": "2601.09088", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09088", "abs": "https://arxiv.org/abs/2601.09088", "authors": ["Shaotian Yan", "Kaiyuan Liu", "Chen Shen", "Bing Wang", "Sinan Fan", "Jun Zhang", "Yue Wu", "Zheng Wang", "Jieping Ye"], "title": "Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning", "comment": "Project Page: https://github.com/D2I-ai/dasd-thinking", "summary": "In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.", "AI": {"tldr": "DASD-4B-Thinking is a lightweight open-source reasoning model that achieves SOTA performance with only 448K training samples by addressing limitations in current sequence-level distillation methods.", "motivation": "Current sequence-level distillation approaches focus too much on SFT data filtering heuristics and overlook the core distillation principle of learning the teacher's full output distribution, leading to inadequate teacher representation, misalignment with student capacity, and exposure bias.", "method": "Proposes methodological innovations for enhanced sequence-level distillation training pipeline that addresses three critical limitations: inadequate teacher distribution representation, misalignment between teacher distribution and student learning capacity, and exposure bias from teacher-forced training.", "result": "DASD-4B-Thinking achieves SOTA performance among open-source models of comparable scale on mathematics, scientific reasoning, and code generation benchmarks, outperforming several larger models, using only 448K training samples (order of magnitude fewer than existing approaches).", "conclusion": "The paper demonstrates that addressing fundamental limitations in sequence-level distillation through explicit teacher-student interaction enables highly efficient and capable reasoning models with minimal training data, advancing open-source reasoning capabilities."}}
{"id": "2601.09362", "categories": ["cs.IT", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.09362", "abs": "https://arxiv.org/abs/2601.09362", "authors": ["Yuto Mizunuma", "Yuichiro Fujiwara"], "title": "Asymptotic Rate Bounds and Constructions for the Inclusive Variant of Disjunct Matrices", "comment": "9 pages, 2 figures", "summary": "Disjunct matrices, also known as cover-free families and superimposed codes, are combinatorial arrays widely used in group testing. Among their variants, those that satisfy an additional combinatorial property called inclusiveness form a special class suitable for computationally efficient and highly error-tolerant group testing under the general inhibitor complex model, a broad framework that subsumes practical settings such as DNA screening. Despite this relevance, the asymptotic behavior of the inclusive variant of disjunct matrices has remained largely unexplored. In particular, it was not previously known whether this variant can achieve an asymptotically positive rate, a requirement for scalable group testing designs. In this work, we establish the first nontrivial asymptotic lower bound on the maximum achievable rate of the inclusive variant, which matches the strongest known upper bound up to a logarithmic factor. Our proof is based on the probabilistic method and yields a simple and efficient randomized construction. Furthermore, we derandomize this construction to obtain a deterministic polynomial-time construction. These results clarify the asymptotic potential of robust and scalable group testing under the general inhibitor complex model.", "AI": {"tldr": "First asymptotic lower bound for inclusive disjunct matrices matching known upper bound up to log factor, enabling scalable group testing under inhibitor complex model.", "motivation": "Inclusive disjunct matrices are crucial for efficient, error-tolerant group testing under the general inhibitor complex model (includes DNA screening), but their asymptotic behavior was unknown - specifically whether they could achieve positive rates for scalable designs.", "method": "Probabilistic method for randomized construction, then derandomization to obtain deterministic polynomial-time construction.", "result": "First nontrivial asymptotic lower bound on maximum achievable rate of inclusive variant, matching strongest known upper bound up to logarithmic factor.", "conclusion": "Clarifies asymptotic potential of robust and scalable group testing under general inhibitor complex model, providing both randomized and deterministic constructions."}}
{"id": "2601.09293", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09293", "abs": "https://arxiv.org/abs/2601.09293", "authors": ["Sofiene Lassoued", "Stefan Lier", "Andreas Schwung"], "title": "Policy-Based Reinforcement Learning with Action Masking for Dynamic Job Shop Scheduling under Uncertainty: Handling Random Arrivals and Machine Failures", "comment": null, "summary": "We present a novel framework for solving Dynamic Job Shop Scheduling Problems under uncertainty, addressing the challenges introduced by stochastic job arrivals and unexpected machine breakdowns. Our approach follows a model-based paradigm, using Coloured Timed Petri Nets to represent the scheduling environment, and Maskable Proximal Policy Optimization to enable dynamic decision-making while restricting the agent to feasible actions at each decision point. To simulate realistic industrial conditions, dynamic job arrivals are modeled using a Gamma distribution, which captures complex temporal patterns such as bursts, clustering, and fluctuating workloads. Machine failures are modeled using a Weibull distribution to represent age-dependent degradation and wear-out dynamics. These stochastic models enable the framework to reflect real-world manufacturing scenarios better. In addition, we study two action-masking strategies: a non-gradient approach that overrides the probabilities of invalid actions, and a gradient-based approach that assigns negative gradients to invalid actions within the policy network. We conduct extensive experiments on dynamic JSSP benchmarks, demonstrating that our method consistently outperforms traditional heuristic and rule-based approaches in terms of makespan minimization. The results highlight the strength of combining interpretable Petri-net-based models with adaptive reinforcement learning policies, yielding a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments.", "AI": {"tldr": "A framework combining Coloured Timed Petri Nets and Maskable Proximal Policy Optimization for dynamic job shop scheduling under uncertainty, with stochastic job arrivals (Gamma distribution) and machine failures (Weibull distribution).", "motivation": "Address challenges in Dynamic Job Shop Scheduling Problems under uncertainty, including stochastic job arrivals and unexpected machine breakdowns in real-world manufacturing scenarios.", "method": "Model-based approach using Coloured Timed Petri Nets to represent scheduling environment, Maskable Proximal Policy Optimization for dynamic decision-making with action masking (non-gradient and gradient-based strategies), and stochastic modeling of job arrivals (Gamma distribution) and machine failures (Weibull distribution).", "result": "Outperforms traditional heuristic and rule-based approaches in makespan minimization on dynamic JSSP benchmarks, demonstrating resilience and scalability.", "conclusion": "Combining interpretable Petri-net-based models with adaptive reinforcement learning yields a resilient, scalable, and explainable framework for real-time scheduling in dynamic and uncertain manufacturing environments."}}
{"id": "2601.09093", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09093", "abs": "https://arxiv.org/abs/2601.09093", "authors": ["Zhixiang Liang", "Beichen Huang", "Zheng Wang", "Minjia Zhang"], "title": "Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling", "comment": null, "summary": "Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process has relied on similarity-based or confidence-based pruning, but these signals do not reliably indicate trace quality. To address these limitations, we propose STEP: Step-level Trace Evaluation and Pruning, a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation. We train a lightweight step scorer to estimate trace quality, and design a GPU memory-aware pruning strategy that triggers pruning as the GPU memory is saturated by KV cache to reduce end-to-end latency. Experiments across challenging reasoning benchmarks demonstrate that STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy. Our code is released at: https://github.com/Supercomputing-System-AI-Lab/STEP", "AI": {"tldr": "STEP is a pruning framework that uses hidden states to evaluate reasoning steps and dynamically prunes unpromising traces during LLM generation to reduce latency while improving accuracy.", "motivation": "Current methods for accelerating LLM reasoning with multiple traces rely on unreliable similarity-based or confidence-based pruning signals, and the combination of lengthy reasoning traces with multiple sampling creates high computation and latency overhead.", "method": "Proposes STEP: Step-level Trace Evaluation and Pruning, which trains a lightweight step scorer to estimate trace quality using hidden states, and implements a GPU memory-aware pruning strategy that triggers pruning when GPU memory is saturated by KV cache.", "result": "STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy across challenging reasoning benchmarks.", "conclusion": "STEP provides an effective framework for accelerating LLM reasoning by using hidden states for reliable step evaluation and memory-aware dynamic pruning, achieving both latency reduction and accuracy improvement."}}
{"id": "2601.09108", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09108", "abs": "https://arxiv.org/abs/2601.09108", "authors": ["Yanguang Sun", "Chao Wang", "Jian Yang", "Lei Luo"], "title": "Small but Mighty: Dynamic Wavelet Expert-Guided Fine-Tuning of Large-Scale Models for Optical Remote Sensing Object Segmentation", "comment": "Accepted at AAAI 2026", "summary": "Accurately localizing and segmenting relevant objects from optical remote sensing images (ORSIs) is critical for advancing remote sensing applications. Existing methods are typically built upon moderate-scale pre-trained models and employ diverse optimization strategies to achieve promising performance under full-parameter fine-tuning. In fact, deeper and larger-scale foundation models can provide stronger support for performance improvement. However, due to their massive number of parameters, directly adopting full-parameter fine-tuning leads to pronounced training difficulties, such as excessive GPU memory consumption and high computational costs, which result in extremely limited exploration of large-scale models in existing works. In this paper, we propose a novel dynamic wavelet expert-guided fine-tuning paradigm with fewer trainable parameters, dubbed WEFT, which efficiently adapts large-scale foundation models to ORSIs segmentation tasks by leveraging the guidance of wavelet experts. Specifically, we introduce a task-specific wavelet expert extractor to model wavelet experts from different perspectives and dynamically regulate their outputs, thereby generating trainable features enriched with task-specific information for subsequent fine-tuning. Furthermore, we construct an expert-guided conditional adapter that first enhances the fine-grained perception of frozen features for specific tasks by injecting trainable features, and then iteratively updates the information of both types of feature, allowing for efficient fine-tuning. Extensive experiments show that our WEFT not only outperforms 21 state-of-the-art (SOTA) methods on three ORSIs datasets, but also achieves optimal results in camouflage, natural, and medical scenarios. The source code is available at: https://github.com/CSYSI/WEFT.", "AI": {"tldr": "WEFT: A dynamic wavelet expert-guided fine-tuning paradigm that efficiently adapts large foundation models to remote sensing segmentation with fewer trainable parameters.", "motivation": "Large-scale foundation models offer strong performance potential for remote sensing segmentation, but full-parameter fine-tuning is impractical due to massive GPU memory and computational costs, limiting exploration of these models in existing works.", "method": "Introduces a task-specific wavelet expert extractor to model wavelet experts from different perspectives and dynamically regulate outputs, generating trainable features. Uses expert-guided conditional adapter to enhance fine-grained perception of frozen features and iteratively update both feature types for efficient fine-tuning.", "result": "Outperforms 21 state-of-the-art methods on three ORSIs datasets and achieves optimal results in camouflage, natural, and medical scenarios.", "conclusion": "WEFT provides an efficient fine-tuning paradigm that successfully adapts large-scale foundation models to remote sensing segmentation tasks with reduced computational requirements while achieving superior performance."}}
{"id": "2601.09390", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09390", "abs": "https://arxiv.org/abs/2601.09390", "authors": ["Devansh Jain", "Lakshmi Prasad Natarajan"], "title": "On Decoding First- and Second-Order BiD Codes", "comment": "11 pages, 4 figures", "summary": "BiD codes, which are a new family of algebraic codes of length $3^m$, achieve the erasure channel capacity under bit-MAP decoding and offer asymptotically larger minimum distance than Reed-Muller (RM) codes. In this paper we propose fast maximum-likelihood (ML) and max-log-MAP decoders for first-order BiD codes. For second-order codes, we identify their minimum-weight parity checks and ascertain a code property known as 'projection' in the RM coding literature. We use these results to design a belief propagation decoder that performs within 1 dB of ML decoder for block lengths 81 and 243.", "AI": {"tldr": "Fast ML and max-log-MAP decoders for first-order BiD codes, and belief propagation decoder for second-order BiD codes that performs within 1 dB of ML for lengths 81 and 243.", "motivation": "BiD codes are a new family of algebraic codes that achieve erasure channel capacity under bit-MAP decoding and have asymptotically larger minimum distance than Reed-Muller codes, but need efficient decoding algorithms.", "method": "For first-order BiD codes: propose fast maximum-likelihood (ML) and max-log-MAP decoders. For second-order codes: identify minimum-weight parity checks and ascertain the 'projection' property, then design a belief propagation decoder based on these findings.", "result": "The belief propagation decoder for second-order BiD codes performs within 1 dB of ML decoder performance for block lengths 81 and 243.", "conclusion": "Efficient decoding algorithms for BiD codes have been developed, with the belief propagation decoder achieving near-ML performance for practical block lengths, making BiD codes more practical for real-world applications."}}
{"id": "2601.09353", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09353", "abs": "https://arxiv.org/abs/2601.09353", "authors": ["Ioannis Peridis", "Dimitrios Troullinos", "Georgios Chalkiadakis", "Pantelis Giankoulidis", "Ioannis Papamichail", "Markos Papageorgiou"], "title": "Monte-Carlo Tree Search with Neural Network Guidance for Lane-Free Autonomous Driving", "comment": null, "summary": "Lane-free traffic environments allow vehicles to better harness the lateral capacity of the road without being restricted to lane-keeping, thereby increasing the traffic flow rates. As such, we have a distinct and more challenging setting for autonomous driving. In this work, we consider a Monte-Carlo Tree Search (MCTS) planning approach for single-agent autonomous driving in lane-free traffic, where the associated Markov Decision Process we formulate is influenced from existing approaches tied to reinforcement learning frameworks. In addition, MCTS is equipped with a pre-trained neural network (NN) that guides the selection phase. This procedure incorporates the predictive capabilities of NNs for a more informed tree search process under computational constraints. In our experimental evaluation, we consider metrics that address both safety (through collision rates) and efficacy (through measured speed). Then, we examine: (a) the influence of isotropic state information for vehicles in a lane-free environment, resulting in nudging behaviour--vehicles' policy reacts due to the presence of faster tailing ones, (b) the acceleration of performance for the NN-guided variant of MCTS, and (c) the trade-off between computational resources and solution quality.", "AI": {"tldr": "This paper proposes a Monte-Carlo Tree Search (MCTS) approach with neural network guidance for autonomous driving in lane-free traffic environments, evaluating safety, efficiency, and computational trade-offs.", "motivation": "Lane-free traffic environments offer higher traffic flow by utilizing lateral road capacity without lane restrictions, but create more challenging autonomous driving scenarios that require advanced planning approaches.", "method": "The authors use Monte-Carlo Tree Search (MCTS) planning for single-agent autonomous driving in lane-free traffic, formulated as a Markov Decision Process. The MCTS is enhanced with a pre-trained neural network that guides the selection phase, incorporating predictive capabilities for more informed tree search under computational constraints.", "result": "Experimental evaluation examines: (a) isotropic state information leads to nudging behavior where vehicles react to faster tailing vehicles, (b) NN-guided MCTS accelerates performance, and (c) there's a trade-off between computational resources and solution quality. Metrics address both safety (collision rates) and efficacy (measured speed).", "conclusion": "The proposed NN-guided MCTS approach shows promise for autonomous driving in lane-free environments, demonstrating improved performance through neural network guidance while balancing computational efficiency with solution quality."}}
{"id": "2601.09096", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09096", "abs": "https://arxiv.org/abs/2601.09096", "authors": ["Md Asiful Islam", "Md Ahmed Al Muzaddid", "Afia Jahin Prema", "Sreenath Reddy Vuske"], "title": "Comparative Assessment of Concrete Compressive Strength Prediction at Industry Scale Using Embedding-based Neural Networks, Transformers, and Traditional Machine Learning Approaches", "comment": null, "summary": "Concrete is the most widely used construction material worldwide; however, reliable prediction of compressive strength remains challenging due to material heterogeneity, variable mix proportions, and sensitivity to field and environmental conditions. Recent advances in artificial intelligence enable data-driven modeling frameworks capable of supporting automated decision-making in construction quality control. This study leverages an industry-scale dataset consisting of approximately 70,000 compressive strength test records to evaluate and compare multiple predictive approaches, including linear regression, decision trees, random forests, transformer-based neural networks, and embedding-based neural networks. The models incorporate key mixture design and placement variables such as water cement ratio, cementitious material content, slump, air content, temperature, and placement conditions. Results indicate that the embedding-based neural network consistently outperforms traditional machine learning and transformer-based models, achieving a mean 28-day prediction error of approximately 2.5%. This level of accuracy is comparable to routine laboratory testing variability, demonstrating the potential of embedding-based learning frameworks to enable automated, data-driven quality control and decision support in large-scale construction operations.", "AI": {"tldr": "Embedding-based neural networks achieve ~2.5% error in predicting concrete compressive strength, outperforming traditional ML and transformer models on 70K industry test records.", "motivation": "Concrete compressive strength prediction is challenging due to material heterogeneity, variable mix proportions, and environmental sensitivity. Reliable prediction is crucial for construction quality control, but traditional methods struggle with these complexities.", "method": "Used industry-scale dataset of ~70,000 compressive strength test records to evaluate multiple approaches: linear regression, decision trees, random forests, transformer-based neural networks, and embedding-based neural networks. Models incorporated mixture design and placement variables including water-cement ratio, cementitious content, slump, air content, temperature, and placement conditions.", "result": "Embedding-based neural network consistently outperformed all other models, achieving mean 28-day prediction error of approximately 2.5%. This accuracy level is comparable to routine laboratory testing variability.", "conclusion": "Embedding-based learning frameworks show strong potential for automated, data-driven quality control and decision support in large-scale construction operations, offering accuracy comparable to laboratory testing."}}
{"id": "2601.09110", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09110", "abs": "https://arxiv.org/abs/2601.09110", "authors": ["Kai Hu", "Yaozu Feng", "Vladimir Lysenko", "Ya Guo Member", "Huayi Wu"], "title": "SAM-Aug: Leveraging SAM Priors for Few-Shot Parcel Segmentation in Satellite Time Series", "comment": "13 pages, 6 figures", "summary": "Few-shot semantic segmentation of time-series remote sensing images remains a critical challenge, particularly in regions where labeled data is scarce or costly to obtain. While state-of-the-art models perform well under full supervision, their performance degrades significantly under limited labeling, limiting their real-world applicability. In this work, we propose SAM-Aug, a new annotation-efficient framework that leverages the geometry-aware segmentation capability of the Segment Anything Model (SAM) to improve few-shot land cover mapping. Our approach constructs cloud-free composite images from temporal sequences and applies SAM in a fully unsupervised manner to generate geometry-aware mask priors. These priors are then integrated into training through a proposed loss function called RegionSmoothLoss, which enforces prediction consistency within each SAM-derived region across temporal frames, effectively regularizing the model to respect semantically coherent structures. Extensive experiments on the PASTIS-R benchmark under a 5 percent labeled setting demonstrate the effectiveness and robustness of SAM-Aug. Averaged over three random seeds (42, 2025, 4090), our method achieves a mean test mIoU of 36.21 percent, outperforming the state-of-the-art baseline by +2.33 percentage points, a relative improvement of 6.89 percent. Notably, on the most favorable split (seed=42), SAM-Aug reaches a test mIoU of 40.28 percent, representing an 11.2 percent relative gain with no additional labeled data. The consistent improvement across all seeds confirms the generalization power of leveraging foundation model priors under annotation scarcity. Our results highlight that vision models like SAM can serve as useful regularizers in few-shot remote sensing learning, offering a scalable and plug-and-play solution for land cover monitoring without requiring manual annotations or model fine-tuning.", "AI": {"tldr": "SAM-Aug leverages Segment Anything Model's geometry-aware segmentation to improve few-shot land cover mapping from time-series remote sensing images without additional labeled data.", "motivation": "Few-shot semantic segmentation of remote sensing images is challenging due to scarce labeled data. While state-of-the-art models perform well under full supervision, their performance degrades significantly under limited labeling, limiting real-world applicability.", "method": "Constructs cloud-free composite images from temporal sequences, applies SAM in unsupervised manner to generate geometry-aware mask priors, integrates priors through RegionSmoothLoss that enforces prediction consistency within SAM-derived regions across temporal frames.", "result": "Achieves mean test mIoU of 36.21% (5% labeled setting), outperforming state-of-the-art baseline by +2.33 percentage points (6.89% relative improvement). On most favorable split (seed=42), reaches 40.28% mIoU (11.2% relative gain).", "conclusion": "Vision models like SAM can serve as useful regularizers in few-shot remote sensing learning, offering scalable plug-and-play solution for land cover monitoring without requiring manual annotations or model fine-tuning."}}
{"id": "2601.09406", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09406", "abs": "https://arxiv.org/abs/2601.09406", "authors": ["Akira Kamatsuka", "Takahiro Yoshida"], "title": "A Generalized Leakage Interpretation of Alpha-Mutual Information", "comment": null, "summary": "This paper presents a unified interpretation of $\u03b1$-mutual information ($\u03b1$-MI) in terms of generalized $g$-leakage. Specifically, we present a novel interpretation of $\u03b1$-MI within an extended framework for quantitative information flow based on adversarial generalized decision problems. This framework employs the Kolmogorov-Nagumo mean and the $q$-logarithm to characterize adversarial gain. Furthermore, we demonstrate that, within this framework, the parameter $\u03b1$ can be interpreted as a measure of the adversary's risk aversion.", "AI": {"tldr": "The paper provides a unified interpretation of \u03b1-mutual information as generalized g-leakage within an adversarial decision framework, linking \u03b1 to risk aversion.", "motivation": "To establish a coherent interpretation of \u03b1-mutual information within quantitative information flow analysis, connecting it to adversarial decision-making and risk preferences.", "method": "Extends quantitative information flow framework using adversarial generalized decision problems, employing Kolmogorov-Nagumo mean and q-logarithm to characterize adversarial gain.", "result": "Shows that \u03b1-mutual information can be interpreted as generalized g-leakage, with parameter \u03b1 representing the adversary's degree of risk aversion.", "conclusion": "Provides a unified framework connecting \u03b1-mutual information to adversarial risk preferences in information flow analysis, offering new insights into information leakage quantification."}}
{"id": "2601.09382", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09382", "abs": "https://arxiv.org/abs/2601.09382", "authors": ["Qinglong Shi", "Donghai Wang", "Hantao Zhou", "Jiguo Li", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "Long-term Task-oriented Agent: Proactive Long-term Intent Maintenance in Dynamic Environments", "comment": "8 pages, 2 figures", "summary": "Current large language model agents predominantly operate under a reactive paradigm, responding only to immediate user queries within short-term sessions. This limitation hinders their ability to maintain long-term user's intents and dynamically adapt to evolving external environments. In this paper, we propose a novel interaction paradigm for proactive Task-oriented Agents capable of bridging the gap between relatively static user's needs and a dynamic environment. We formalize proactivity through two key capabilities, (i) Intent-Conditioned Monitoring: The agent autonomously formulates trigger conditions based on dialog history; (ii) Event-Triggered Follow-up: The agent actively engages the user upon detecting useful environmental updates. We introduce a high-quality data synthesis pipeline to construct complex, multi-turn dialog data in a dynamic environment. Furthermore, we attempt to address the lack of evaluation criteria of task-oriented interaction in a dynamic environment by proposing a new benchmark, namely ChronosBench. We evaluated some leading close-source and open-source models at present and revealed their flaws in long-term task-oriented interaction. Furthermore, our fine-tuned model trained using synthetic data for supervised learning achieves a task completion rate of 85.19% for complex tasks including shifts in user intent, outperforming other models under test. And the result validated the effectiveness of our data-driven strategy.", "AI": {"tldr": "Proactive Task-oriented Agents with intent-conditioned monitoring and event-triggered follow-up for long-term user interactions in dynamic environments.", "motivation": "Current LLM agents are reactive and short-term focused, unable to maintain long-term user intents or adapt to evolving environments, creating a gap between static user needs and dynamic environments.", "method": "Proposed proactive paradigm with two capabilities: (1) Intent-Conditioned Monitoring - agents autonomously formulate trigger conditions from dialog history, and (2) Event-Triggered Follow-up - agents actively engage users upon detecting useful environmental updates. Created data synthesis pipeline for complex multi-turn dialogs and introduced ChronosBench benchmark.", "result": "Fine-tuned model using synthetic data achieved 85.19% task completion rate for complex tasks with user intent shifts, outperforming other tested models. Evaluation revealed flaws in current models for long-term task-oriented interaction.", "conclusion": "The proactive agent paradigm effectively bridges static user needs and dynamic environments, with data-driven strategy validated through superior performance on complex tasks involving intent shifts and environmental changes."}}
{"id": "2601.09103", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09103", "abs": "https://arxiv.org/abs/2601.09103", "authors": ["Haijian Shao", "Wei Liu", "Xing Deng", "Daze Lu"], "title": "Enhancing Imbalanced Electrocardiogram Classification: A Novel Approach Integrating Data Augmentation through Wavelet Transform and Interclass Fusion", "comment": "18 pages, 9 figures, 3 tables, 1 algorithm", "summary": "Imbalanced electrocardiogram (ECG) data hampers the efficacy and resilience of algorithms in the automated processing and interpretation of cardiovascular diagnostic information, which in turn impedes deep learning-based ECG classification. Notably, certain cardiac conditions that are infrequently encountered are disproportionately underrepresented in these datasets. Although algorithmic generation and oversampling of specific ECG signal types can mitigate class skew, there is a lack of consensus regarding the effectiveness of such techniques in ECG classification. Furthermore, the methodologies and scenarios of ECG acquisition introduce noise, further complicating the processing of ECG data. This paper presents a significantly enhanced ECG classifier that simultaneously addresses both class imbalance and noise-related challenges in ECG analysis, as observed in the CPSC 2018 dataset. Specifically, we propose the application of feature fusion based on the wavelet transform, with a focus on wavelet transform-based interclass fusion, to generate the training feature library and the test set feature library. Subsequently, the original training and test data are amalgamated with their respective feature databases, resulting in more balanced training and test datasets. Employing this approach, our ECG model achieves recognition accuracies of up to 99%, 98%, 97%, 98%, 96%, 92%, and 93% for Normal, AF, I-AVB, LBBB, RBBB, PAC, PVC, STD, and STE, respectively. Furthermore, the average recognition accuracy for these categories ranges between 92\\% and 98\\%. Notably, our proposed data fusion methodology surpasses any known algorithms in terms of ECG classification accuracy in the CPSC 2018 dataset.", "AI": {"tldr": "The paper proposes a wavelet transform-based feature fusion method to address class imbalance and noise in ECG classification, achieving 92-99% accuracy on CPSC 2018 dataset.", "motivation": "ECG data suffers from class imbalance (rare cardiac conditions underrepresented) and noise from acquisition methods, which hampers deep learning-based ECG classification performance.", "method": "Wavelet transform-based interclass feature fusion to generate training and test feature libraries, then combining original data with feature databases to create balanced datasets.", "result": "Achieved 92-99% recognition accuracy across 9 ECG categories (Normal, AF, I-AVB, LBBB, RBBB, PAC, PVC, STD, STE) with average accuracy between 92-98%, outperforming existing algorithms on CPSC 2018.", "conclusion": "The proposed data fusion methodology effectively addresses both class imbalance and noise challenges in ECG analysis, achieving state-of-the-art classification accuracy."}}
{"id": "2601.09111", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09111", "abs": "https://arxiv.org/abs/2601.09111", "authors": ["Yang Li", "Aming Wu", "Zihao Zhang", "Yahong Han"], "title": "Towards Open Environments and Instructions: General Vision-Language Navigation via Fast-Slow Interactive Reasoning", "comment": null, "summary": "Vision-Language Navigation aims to enable agents to navigate to a target location based on language instructions. Traditional VLN often follows a close-set assumption, i.e., training and test data share the same style of the input images and instructions. However, the real world is open and filled with various unseen environments, posing enormous difficulties for close-set methods. To this end, we focus on the General Scene Adaptation (GSA-VLN) task, aiming to learn generalized navigation ability by introducing diverse environments and inconsistent intructions.Towards this task, when facing unseen environments and instructions, the challenge mainly lies in how to enable the agent to dynamically produce generalized strategies during the navigation process. Recent research indicates that by means of fast and slow cognition systems, human beings could generate stable policies, which strengthen their adaptation for open world. Inspired by this idea, we propose the slow4fast-VLN, establishing a dynamic interactive fast-slow reasoning framework. The fast-reasoning module, an end-to-end strategy network, outputs actions via real-time input. It accumulates execution records in a history repository to build memory. The slow-reasoning module analyze the memories generated by the fast-reasoning module. Through deep reflection, it extracts experiences that enhance the generalization ability of decision-making. These experiences are structurally stored and used to continuously optimize the fast-reasoning module. Unlike traditional methods that treat fast-slow reasoning as independent mechanisms, our framework enables fast-slow interaction. By leveraging the experiences from slow reasoning. This interaction allows the system to continuously adapt and efficiently execute navigation tasks when facing unseen scenarios.", "AI": {"tldr": "The paper proposes slow4fast-VLN, a dynamic interactive fast-slow reasoning framework for Vision-Language Navigation that addresses generalization to unseen environments and instructions through a dual-system approach.", "motivation": "Traditional VLN methods assume closed-set training and testing with similar environments and instructions, but real-world navigation requires adaptation to diverse unseen scenarios. The paper introduces the General Scene Adaptation (GSA-VLN) task to address this generalization challenge.", "method": "Proposes slow4fast-VLN with two interactive modules: 1) Fast-reasoning module - an end-to-end strategy network that processes real-time inputs and stores execution records in a history repository; 2) Slow-reasoning module - analyzes accumulated memories, extracts generalization-enhancing experiences through deep reflection, and structurally stores them to continuously optimize the fast-reasoning module.", "result": "The framework enables continuous adaptation and efficient navigation in unseen scenarios by allowing interaction between fast and slow reasoning systems, unlike traditional methods that treat them independently.", "conclusion": "The proposed slow4fast-VLN framework addresses the generalization challenge in VLN by establishing dynamic interaction between fast and slow reasoning systems, inspired by human cognitive processes, enabling better adaptation to diverse unseen environments and instructions."}}
{"id": "2601.09498", "categories": ["cs.IT", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.09498", "abs": "https://arxiv.org/abs/2601.09498", "authors": ["Leonhard Grosse", "Sara Saeidian", "Tobias J. Oechtering", "Mikael Skoglund"], "title": "Dobrushin Coefficients of Private Mechanisms Beyond Local Differential Privacy", "comment": null, "summary": "We investigate Dobrushin coefficients of discrete Markov kernels that have bounded pointwise maximal leakage (PML) with respect to all distributions with a minimum probability mass bounded away from zero by a constant $c>0$. This definition recovers local differential privacy (LDP) for $c\\to 0$. We derive achievable bounds on contraction in terms of a kernels PML guarantees, and provide mechanism constructions that achieve the presented bounds. Further, we extend the results to general $f$-divergences by an application of Binette's inequality. Our analysis yields tighter bounds for mechanisms satisfying LDP and extends beyond the LDP regime to any discrete kernel.", "AI": {"tldr": "Analysis of Dobrushin coefficients for Markov kernels with bounded pointwise maximal leakage, extending beyond LDP to general discrete kernels with tighter bounds.", "motivation": "The paper aims to analyze contraction properties of Markov kernels under privacy constraints, extending beyond the standard local differential privacy (LDP) framework to more general privacy guarantees via pointwise maximal leakage (PML).", "method": "Investigates Dobrushin coefficients for discrete Markov kernels with bounded PML, derives achievable contraction bounds, constructs mechanisms achieving these bounds, and extends results to general f-divergences using Binette's inequality.", "result": "Obtains tighter bounds for LDP mechanisms and extends analysis to any discrete kernel beyond the LDP regime, providing mechanism constructions that achieve the derived bounds.", "conclusion": "The framework generalizes LDP analysis through PML, provides tighter contraction bounds, and enables privacy analysis for broader classes of discrete Markov kernels beyond traditional LDP mechanisms."}}
{"id": "2601.09465", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09465", "abs": "https://arxiv.org/abs/2601.09465", "authors": ["Shuo Zhang", "Chaofa Yuan", "Ryan Guo", "Xiaomin Yu", "Rui Xu", "Zhangquan Chen", "Zinuo Li", "Zhi Yang", "Shuhao Guan", "Zhenheng Tang", "Sen Hu", "Liwen Zhang", "Ronghao Chen", "Huacan Wang"], "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines", "comment": null, "summary": "While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.", "AI": {"tldr": "EvoFSM is a structured self-evolving framework that evolves Finite State Machines for LLM-based agents, enabling adaptability while maintaining control through decoupled Flow and Skill optimization with guided refinement.", "motivation": "Existing LLM-based agents use fixed workflows that struggle with open-ended queries, while recent self-evolution approaches suffer from instability, hallucinations, and instruction drift due to unconstrained optimization.", "method": "EvoFSM evolves explicit Finite State Machines by decoupling optimization into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors). It uses a critic mechanism for guided refinement with constrained operations and incorporates self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints.", "result": "Extensive evaluations on five multi-hop QA benchmarks show effectiveness, with EvoFSM achieving 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks validate its generalization capability.", "conclusion": "EvoFSM provides a structured approach to self-evolving agents that balances adaptability with control, addressing limitations of both fixed workflows and unconstrained self-evolution methods through FSM-based optimization and guided refinement."}}
{"id": "2601.09142", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09142", "abs": "https://arxiv.org/abs/2601.09142", "authors": ["Shijian Ma", "Yan Lin", "Yi Yang"], "title": "EvasionBench: Detecting Evasive Answers in Financial Q&A via Multi-Model Consensus and LLM-as-Judge", "comment": "Shijian Ma and Yan Lin contributed equally. Corresponding author: Yan Lin", "summary": "Detecting evasive answers in earnings calls is critical for financial transparency, yet progress is hindered by the lack of large-scale benchmarks. We introduce EvasionBench, comprising 30,000 training samples and 1,000 human-annotated test samples (Cohen's Kappa 0.835) across three evasion levels. Our key contribution is a multi-model annotation framework leveraging a core insight: disagreement between frontier LLMs signals hard examples most valuable for training. We mine boundary cases where two strong annotators conflict, using a judge to resolve labels. This approach outperforms single-model distillation by 2.4 percent, with judge-resolved samples improving generalization despite higher training loss (0.421 vs 0.393) - evidence that disagreement mining acts as implicit regularization. Our trained model Eva-4B (4B parameters) achieves 81.3 percent accuracy, outperforming its base by 25 percentage points and approaching frontier LLM performance at a fraction of inference cost.", "AI": {"tldr": "EvasionBench: A large-scale benchmark for detecting evasive answers in earnings calls, using multi-model annotation framework that mines disagreement between frontier LLMs to identify hard examples, resulting in Eva-4B model with 81.3% accuracy.", "motivation": "Detecting evasive answers in earnings calls is critical for financial transparency, but progress has been hindered by the lack of large-scale benchmarks. Existing approaches lack sufficient training data and effective methods for identifying challenging evasion cases.", "method": "Introduced EvasionBench with 30,000 training samples and 1,000 human-annotated test samples. Developed a multi-model annotation framework that leverages disagreement between frontier LLMs to identify hard examples (boundary cases). When two strong annotators conflict, a judge model resolves the labels. This approach mines valuable training examples from model disagreements.", "result": "The disagreement mining approach outperforms single-model distillation by 2.4%. Judge-resolved samples improve generalization despite higher training loss (0.421 vs 0.393), suggesting disagreement mining acts as implicit regularization. The trained Eva-4B model (4B parameters) achieves 81.3% accuracy, outperforming its base model by 25 percentage points and approaching frontier LLM performance at a fraction of inference cost.", "conclusion": "The multi-model annotation framework that mines disagreement between frontier LLMs effectively identifies valuable hard examples for training. This approach serves as implicit regularization and enables creation of high-performing specialized models like Eva-4B that approach frontier LLM performance while being much more efficient for inference."}}
{"id": "2601.09116", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09116", "abs": "https://arxiv.org/abs/2601.09116", "authors": ["Haoyan Gong", "Hongbin Liu"], "title": "LP-LLM: End-to-End Real-World Degraded License Plate Text Recognition via Large Multimodal Models", "comment": null, "summary": "Real-world License Plate Recognition (LPR) faces significant challenges from severe degradations such as motion blur, low resolution, and complex illumination. The prevailing \"restoration-then-recognition\" two-stage paradigm suffers from a fundamental flaw: the pixel-level optimization objectives of image restoration models are misaligned with the semantic goals of character recognition, leading to artifact interference and error accumulation. While Vision-Language Models (VLMs) have demonstrated powerful general capabilities, they lack explicit structural modeling for license plate character sequences (e.g., fixed length, specific order). To address this, we propose an end-to-end structure-aware multimodal reasoning framework based on Qwen3-VL. The core innovation lies in the Character-Aware Multimodal Reasoning Module (CMRM), which introduces a set of learnable Character Slot Queries. Through a cross-attention mechanism, these queries actively retrieve fine-grained evidence corresponding to character positions from visual features. Subsequently, we inject these character-aware representations back into the visual tokens via residual modulation, enabling the language model to perform autoregressive generation based on explicit structural priors. Furthermore, combined with the LoRA parameter-efficient fine-tuning strategy, the model achieves domain adaptation while retaining the generalization capabilities of the large model. Extensive experiments on both synthetic and real-world severely degraded datasets demonstrate that our method significantly outperforms existing restoration-recognition combinations and general VLMs, validating the superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.", "AI": {"tldr": "Proposes an end-to-end structure-aware multimodal reasoning framework for license plate recognition that addresses misalignment between restoration and recognition objectives by introducing character-aware reasoning with learnable slot queries.", "motivation": "Real-world LPR suffers from severe degradations (motion blur, low resolution, complex illumination). Traditional two-stage \"restoration-then-recognition\" approach has fundamental flaws: pixel-level restoration objectives misalign with semantic recognition goals, causing artifacts and error accumulation. Vision-Language Models lack explicit structural modeling for license plate character sequences (fixed length, specific order).", "method": "End-to-end structure-aware multimodal reasoning framework based on Qwen3-VL. Core innovation: Character-Aware Multimodal Reasoning Module (CMRM) with learnable Character Slot Queries. These queries actively retrieve fine-grained evidence for character positions from visual features via cross-attention, then inject character-aware representations back into visual tokens via residual modulation. Uses LoRA parameter-efficient fine-tuning for domain adaptation while retaining generalization capabilities.", "result": "Extensive experiments on synthetic and real-world severely degraded datasets show the method significantly outperforms existing restoration-recognition combinations and general VLMs. Validates superiority of incorporating structured reasoning into large models for low-quality text recognition tasks.", "conclusion": "The proposed structure-aware multimodal reasoning framework effectively addresses the misalignment problem in traditional LPR approaches by introducing explicit character-level structural modeling, achieving superior performance on degraded license plate recognition while maintaining generalization through efficient fine-tuning."}}
{"id": "2601.09519", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09519", "abs": "https://arxiv.org/abs/2601.09519", "authors": ["Henrique K. Miyamoto", "Sheng Yang"], "title": "Error Exponents for Randomised List Decoding", "comment": "12 pages, 1 figure", "summary": "This paper studies random-coding error exponents of randomised list decoding, in which the decoder randomly selects $L$ messages with probabilities proportional to the decoding metric of the codewords. The exponents (or bounds) are given for mismatched, and then particularised to matched and universal decoding metrics. Two regimes are studied: for fixed list size, we derive an ensemble-tight random-coding error exponent, and show that, for the matched metric, it does not improve the error exponent of ordinary decoding. For list sizes growing exponentially with the block-length, we provide a non-trivial lower bound to the error exponent that is tight at high rates under the matched metric.", "AI": {"tldr": "Random-coding error exponents for randomized list decoding where decoder selects L messages probabilistically based on decoding metric, analyzed for mismatched and matched metrics in two regimes.", "motivation": "To analyze the error performance of randomized list decoding schemes where the decoder doesn't simply pick the top L codewords but selects them probabilistically based on decoding metric values, and to understand how this affects error exponents compared to ordinary decoding.", "method": "Studies random-coding error exponents for randomized list decoding with probabilistic message selection. Analyzes mismatched decoding metrics first, then particularizes to matched and universal metrics. Examines two regimes: fixed list size L and exponentially growing list size with block length.", "result": "For fixed list size: derived ensemble-tight random-coding error exponent, showing no improvement over ordinary decoding for matched metric. For exponentially growing list size: provided non-trivial lower bound to error exponent that is tight at high rates under matched metric.", "conclusion": "Randomized list decoding with probabilistic selection has different error exponent behavior depending on list size scaling: fixed list size doesn't improve matched metric performance, but exponentially growing list size can provide improved error exponents at high rates."}}
{"id": "2601.09503", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09503", "abs": "https://arxiv.org/abs/2601.09503", "authors": ["Siyuan Liu", "Hongbang Yuan", "Xinze Li", "Ziyue Zhu", "Yixin Cao", "Yu-Gang Jiang"], "title": "What Do LLM Agents Know About Their World? Task2Quiz: A Paradigm for Studying Environment Understanding", "comment": null, "summary": "Large language model (LLM) agents have demonstrated remarkable capabilities in complex decision-making and tool-use tasks, yet their ability to generalize across varying environments remains a under-examined concern. Current evaluation paradigms predominantly rely on trajectory-based metrics that measure task success, while failing to assess whether agents possess a grounded, transferable model of the environment. To address this gap, we propose Task-to-Quiz (T2Q), a deterministic and automated evaluation paradigm designed to decouple task execution from world-state understanding. We instantiate this paradigm in T2QBench, a suite comprising 30 environments and 1,967 grounded QA pairs across multiple difficulty levels. Our extensive experiments reveal that task success is often a poor proxy for environment understanding, and that current memory machanism can not effectively help agents acquire a grounded model of the environment. These findings identify proactive exploration and fine-grained state representation as primary bottlenecks, offering a robust foundation for developing more generalizable autonomous agents.", "AI": {"tldr": "T2Q is a new evaluation paradigm that separates task execution from world-state understanding, revealing that current LLM agents' task success doesn't correlate well with actual environment comprehension.", "motivation": "Current LLM agent evaluations focus on task success metrics but fail to assess whether agents truly understand the environment, creating a gap in measuring generalization capabilities across different environments.", "method": "Proposed Task-to-Quiz (T2Q) paradigm that decouples task execution from world-state understanding, and created T2QBench with 30 environments and 1,967 grounded QA pairs across multiple difficulty levels.", "result": "Task success is often a poor proxy for environment understanding, and current memory mechanisms don't effectively help agents acquire grounded environment models. Proactive exploration and fine-grained state representation are identified as primary bottlenecks.", "conclusion": "The T2Q paradigm provides a robust foundation for developing more generalizable autonomous agents by addressing the disconnect between task execution success and actual environment comprehension."}}
{"id": "2601.09143", "categories": ["cs.LG", "math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.09143", "abs": "https://arxiv.org/abs/2601.09143", "authors": ["Jinshuai Bai", "Haolin Li", "Zahra Sharif Khodaei", "M. H. Aliabadi", "YuanTong Gu", "Xi-Qiao Feng"], "title": "Discrete Solution Operator Learning for Geometry-Dependent PDEs", "comment": "15 pages main text, 40 pages SI", "summary": "Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the effective computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated regimes and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.", "AI": {"tldr": "DiSOL learns discrete solution procedures for PDEs with varying geometry, handling topological changes and discontinuous boundaries that break traditional neural operator assumptions.", "motivation": "Neural operators struggle with varying geometry that causes discrete structural changes (topological changes, abrupt boundary changes, computational domain changes), breaking the smooth-variation premise needed for continuous function-space operators.", "method": "DiSOL factorizes the solver into learnable stages mirroring classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, preserving procedure-level consistency while adapting to geometry-dependent discrete structures.", "result": "Across geometry-dependent Poisson, advection-diffusion, linear elasticity, and spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes.", "conclusion": "Procedural operator representations are needed in geometry-dominated regimes, and discrete solution operator learning represents a distinct, complementary direction in scientific machine learning."}}
{"id": "2601.09118", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09118", "abs": "https://arxiv.org/abs/2601.09118", "authors": ["Jackie Alex", "Guoqiang Huan"], "title": "LPCAN: Lightweight Pyramid Cross-Attention Network for Rail Surface Defect Detection Using RGB-D Data", "comment": null, "summary": "This paper addresses the limitations of current vision-based rail defect detection methods, including high computational complexity, excessive parameter counts, and suboptimal accuracy. We propose a Lightweight Pyramid Cross-Attention Network (LPCANet) that leverages RGB-D data for efficient and accurate defect identification. The architecture integrates MobileNetv2 as a backbone for RGB feature extraction with a lightweight pyramid module (LPM) for depth processing, coupled with a cross-attention mechanism (CAM) for multimodal fusion and a spatial feature extractor (SFE) for enhanced structural analysis. Comprehensive evaluations on three unsupervised RGB-D rail datasets (NEU-RSDDS-AUG, RSDD-TYPE1, RSDD-TYPE2) demonstrate that LPCANet achieves state-of-the-art performance with only 9.90 million parameters, 2.50 G FLOPs, and 162.60 fps inference speed. Compared to 18 existing methods, LPCANet shows significant improvements, including +1.48\\% in $S_\u03b1$, +0.86\\% in IOU, and +1.77\\% in MAE over the best-performing baseline. Ablation studies confirm the critical roles of CAM and SFE, while experiments on non-rail datasets (DAGM2007, MT, Kolektor-SDD2) validate its generalization capability. The proposed framework effectively bridges traditional and deep learning approaches, offering substantial practical value for industrial defect inspection. Future work will focus on further model compression for real-time deployment.", "AI": {"tldr": "LPCANet: Lightweight Pyramid Cross-Attention Network for efficient RGB-D rail defect detection with state-of-the-art performance using only 9.90M parameters and 2.50 G FLOPs.", "motivation": "Current vision-based rail defect detection methods suffer from high computational complexity, excessive parameter counts, and suboptimal accuracy, limiting practical deployment in industrial inspection scenarios.", "method": "Proposes LPCANet with MobileNetv2 backbone for RGB features, lightweight pyramid module for depth processing, cross-attention mechanism for multimodal fusion, and spatial feature extractor for enhanced structural analysis.", "result": "Achieves SOTA on three RGB-D rail datasets with 9.90M parameters, 2.50 G FLOPs, 162.60 fps; outperforms 18 baselines (+1.48% S\u03b1, +0.86% IOU, +1.77% MAE). Validates generalization on non-rail datasets.", "conclusion": "LPCANet effectively bridges traditional and deep learning approaches for industrial defect inspection, offering practical value with lightweight design and strong generalization. Future work focuses on further compression for real-time deployment."}}
{"id": "2601.09550", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09550", "abs": "https://arxiv.org/abs/2601.09550", "authors": ["Roberto Bruno", "Adrien Vandenbroucque", "Amedeo Roberto Esposito"], "title": "A Finite-Sample Strong Converse for Binary Hypothesis Testing via (Reverse) R\u00e9nyi Divergence", "comment": "An extended version, with proofs, of a paper submitted to ISIT 2026", "summary": "This work investigates binary hypothesis testing between $H_0\\sim P_0$ and $H_1\\sim P_1$ in the finite-sample regime under asymmetric error constraints. By employing the ``reverse\" R\u00e9nyi divergence, we derive novel non-asymptotic bounds on the Type II error probability which naturally establish a strong converse result. Furthermore, when the Type I error is constrained to decay exponentially with a rate $c$, we show that the Type II error converges to 1 exponentially fast if $c$ exceeds the Kullback-Leibler divergence $D(P_1\\|P_0)$, and vanishes exponentially fast if $c$ is smaller. Finally, we present numerical examples demonstrating that the proposed converse bounds strictly improve upon existing finite-sample results in the literature.", "AI": {"tldr": "Novel finite-sample bounds for binary hypothesis testing using reverse R\u00e9nyi divergence, establishing strong converse results and characterizing error exponents under asymmetric constraints.", "motivation": "To address binary hypothesis testing in finite-sample regime with asymmetric error constraints, improving upon existing finite-sample results and establishing strong converse properties.", "method": "Employ reverse R\u00e9nyi divergence to derive non-asymptotic bounds on Type II error probability, analyze error exponents when Type I error decays exponentially at rate c.", "result": "Derived novel converse bounds that strictly improve existing finite-sample results; showed Type II error converges to 1 exponentially if c > D(P\u2081\u2225P\u2080), vanishes exponentially if c < D(P\u2081\u2225P\u2080).", "conclusion": "Reverse R\u00e9nyi divergence provides powerful tool for finite-sample hypothesis testing analysis, yielding improved bounds and establishing threshold behavior at KL divergence boundary."}}
{"id": "2601.09536", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09536", "abs": "https://arxiv.org/abs/2601.09536", "authors": ["Dongjie Cheng", "Yongqi Li", "Zhixin Ma", "Hongru Cai", "Yupeng Hu", "Wenjie Wang", "Liqiang Nie", "Wenjie Li"], "title": "Omni-R1: Towards the Unified Generative Paradigm for Multimodal Reasoning", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) are making significant progress in multimodal reasoning. Early approaches focus on pure text-based reasoning. More recent studies have incorporated multimodal information into the reasoning steps; however, they often follow a single task-specific reasoning pattern, which limits their generalizability across various multimodal tasks. In fact, there are numerous multimodal tasks requiring diverse reasoning skills, such as zooming in on a specific region or marking an object within an image. To address this, we propose unified generative multimodal reasoning, which unifies diverse multimodal reasoning skills by generating intermediate images during the reasoning process. We instantiate this paradigm with Omni-R1, a two-stage SFT+RL framework featuring perception alignment loss and perception reward, thereby enabling functional image generation. Additionally, we introduce Omni-R1-Zero, which eliminates the need for multimodal annotations by bootstrapping step-wise visualizations from text-only reasoning data. Empirical results show that Omni-R1 achieves unified generative reasoning across a wide range of multimodal tasks, and Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting a promising direction for generative multimodal reasoning.", "AI": {"tldr": "Omni-R1 introduces unified generative multimodal reasoning that generates intermediate images during reasoning, enabling diverse multimodal tasks through a two-stage SFT+RL framework with perception alignment and reward.", "motivation": "Current MLLMs either use pure text-based reasoning or single task-specific multimodal reasoning patterns, limiting generalizability across diverse multimodal tasks that require different reasoning skills like zooming or object marking.", "method": "Proposes unified generative multimodal reasoning that generates intermediate images during reasoning. Implements Omni-R1 with two-stage SFT+RL framework featuring perception alignment loss and perception reward for functional image generation. Also introduces Omni-R1-Zero that bootstraps step-wise visualizations from text-only reasoning data without multimodal annotations.", "result": "Omni-R1 achieves unified generative reasoning across wide range of multimodal tasks. Omni-R1-Zero can match or even surpass Omni-R1 on average, suggesting promising direction for generative multimodal reasoning without multimodal annotations.", "conclusion": "Unified generative multimodal reasoning through intermediate image generation enables diverse multimodal tasks, and bootstrapping from text-only data offers promising approach for scalable multimodal reasoning without extensive annotations."}}
{"id": "2601.09151", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09151", "abs": "https://arxiv.org/abs/2601.09151", "authors": ["Yang Nan", "Qihao Wen", "Jiahao Wang", "Pengfei He", "Ravi Tandon", "Yong Ge", "Han Xu"], "title": "Interpretable Probability Estimation with LLMs via Shapley Reconstruction", "comment": null, "summary": "Large Language Models (LLMs) demonstrate potential to estimate the probability of uncertain events, by leveraging their extensive knowledge and reasoning capabilities. This ability can be applied to support intelligent decision-making across diverse fields, such as financial forecasting and preventive healthcare. However, directly prompting LLMs for probability estimation faces significant challenges: their outputs are often noisy, and the underlying predicting process is opaque. In this paper, we propose PRISM: Probability Reconstruction via Shapley Measures, a framework that brings transparency and precision to LLM-based probability estimation. PRISM decomposes an LLM's prediction by quantifying the marginal contribution of each input factor using Shapley values. These factor-level contributions are then aggregated to reconstruct a calibrated final estimate. In our experiments, we demonstrate PRISM improves predictive accuracy over direct prompting and other baselines, across multiple domains including finance, healthcare, and agriculture. Beyond performance, PRISM provides a transparent prediction pipeline: our case studies visualize how individual factors shape the final estimate, helping build trust in LLM-based decision support systems.", "AI": {"tldr": "PRISM framework uses Shapley values to decompose LLM predictions into factor contributions for transparent and calibrated probability estimation.", "motivation": "LLMs show potential for probability estimation in decision-making fields like finance and healthcare, but direct prompting produces noisy, opaque outputs that lack transparency and precision.", "method": "PRISM (Probability Reconstruction via Shapley Measures) decomposes LLM predictions by quantifying marginal contributions of each input factor using Shapley values, then aggregates these factor-level contributions to reconstruct calibrated final estimates.", "result": "PRISM improves predictive accuracy over direct prompting and other baselines across multiple domains (finance, healthcare, agriculture) and provides transparent visualization of how individual factors shape final estimates.", "conclusion": "PRISM offers a transparent and precise framework for LLM-based probability estimation that builds trust in decision support systems by making the prediction process interpretable."}}
{"id": "2601.09121", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09121", "abs": "https://arxiv.org/abs/2601.09121", "authors": ["Xin Yuan", "Meiqi Wan", "Wei Liu", "Xin Xu", "Zheng Wang"], "title": "Beyond Seen Bounds: Class-Centric Polarization for Single-Domain Generalized Deep Metric Learning", "comment": "Submitted to ACM TOMM", "summary": "Single-domain generalized deep metric learning (SDG-DML) faces the dual challenge of both category and domain shifts during testing, limiting real-world applications. Therefore, aiming to learn better generalization ability on both unseen categories and domains is a realistic goal for the SDG-DML task. To deliver the aspiration, existing SDG-DML methods employ the domain expansion-equalization strategy to expand the source data and generate out-of-distribution samples. However, these methods rely on proxy-based expansion, which tends to generate samples clustered near class proxies, failing to simulate the broad and distant domain shifts encountered in practice. To alleviate the problem, we propose CenterPolar, a novel SDG-DML framework that dynamically expands and constrains domain distributions to learn a generalizable DML model for wider target domain distributions. Specifically, \\textbf{CenterPolar} contains two collaborative class-centric polarization phases: (1) Class-Centric Centrifugal Expansion ($C^3E$) and (2) Class-Centric Centripetal Constraint ($C^4$). In the first phase, $C^3E$ drives the source domain distribution by shifting the source data away from class centroids using centrifugal expansion to generalize to more unseen domains. In the second phase, to consolidate domain-invariant class information for the generalization ability to unseen categories, $C^4$ pulls all seen and unseen samples toward their class centroids while enforcing inter-class separation via centripetal constraint. Extensive experimental results on widely used CUB-200-2011 Ext., Cars196 Ext., DomainNet, PACS, and Office-Home datasets demonstrate the superiority and effectiveness of our CenterPolar over existing state-of-the-art methods. The code will be released after acceptance.", "AI": {"tldr": "CenterPolar is a novel framework for single-domain generalized deep metric learning that addresses both category and domain shifts through class-centric polarization with centrifugal expansion and centripetal constraint.", "motivation": "Existing SDG-DML methods use proxy-based expansion that generates samples clustered near class proxies, failing to simulate the broad and distant domain shifts encountered in real-world applications. There's a need to learn better generalization ability on both unseen categories and domains.", "method": "CenterPolar uses two collaborative class-centric polarization phases: 1) Class-Centric Centrifugal Expansion (C\u00b3E) that shifts source data away from class centroids to generalize to more unseen domains, and 2) Class-Centric Centripetal Constraint (C\u2074) that pulls all samples toward their class centroids while enforcing inter-class separation to consolidate domain-invariant class information.", "result": "Extensive experiments on CUB-200-2011 Ext., Cars196 Ext., DomainNet, PACS, and Office-Home datasets demonstrate the superiority and effectiveness of CenterPolar over existing state-of-the-art methods.", "conclusion": "CenterPolar effectively addresses the dual challenge of category and domain shifts in SDG-DML by dynamically expanding and constraining domain distributions, enabling better generalization to wider target domain distributions."}}
{"id": "2601.09554", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09554", "abs": "https://arxiv.org/abs/2601.09554", "authors": ["Rayan Chouity", "Charbel Hannoun", "Jihad Fahs", "Ibrahim Abou-Faycal"], "title": "On Linear Estimators for some Stable Vectors", "comment": null, "summary": "We consider the estimation problem for jointly stable random variables. Under two specific dependency models: a linear transformation of two independent stable variables and a sub-Gaussian symmetric $\u03b1$-stable (S$\u03b1$S) vector, we show that the conditional mean estimator is linear in both cases. Moreover, we find dispersion optimal linear estimators. Interestingly, for the sub-Gaussian (S$\u03b1$S) vector, both estimators are identical generalizing the well-known Gaussian result of the conditional mean being the best linear minimum-mean square estimator.", "AI": {"tldr": "The paper shows that for jointly stable random variables under two dependency models, the conditional mean estimator is linear, and dispersion optimal linear estimators are found. For sub-Gaussian S\u03b1S vectors, both estimators coincide, generalizing the Gaussian result.", "motivation": "The motivation is to extend estimation theory beyond Gaussian distributions to stable distributions, which are important for modeling heavy-tailed phenomena. The paper aims to understand estimation properties for jointly stable random variables under specific dependency structures.", "method": "The authors consider two specific dependency models: 1) linear transformation of two independent stable variables, and 2) sub-Gaussian symmetric \u03b1-stable (S\u03b1S) vectors. They analyze the conditional mean estimator and derive dispersion optimal linear estimators for these models.", "result": "The conditional mean estimator is shown to be linear in both dependency models. Dispersion optimal linear estimators are found. Interestingly, for the sub-Gaussian S\u03b1S vector, both the conditional mean estimator and the dispersion optimal linear estimator are identical, generalizing the well-known Gaussian result where the conditional mean equals the best linear minimum-mean square estimator.", "conclusion": "The paper establishes that for jointly stable random variables under specific dependency structures, linear estimation properties hold similar to Gaussian cases. The equivalence of conditional mean and optimal linear estimators for sub-Gaussian S\u03b1S vectors extends classical Gaussian estimation theory to stable distributions."}}
{"id": "2601.09635", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09635", "abs": "https://arxiv.org/abs/2601.09635", "authors": ["Kuo Liang", "Yuhang Lu", "Jianming Mao", "Shuyi Sun", "Chunwei Yang", "Congcong Zeng", "Xiao Jin", "Hanzhang Qin", "Ruihao Zhu", "Chung-Piaw Teo"], "title": "LLM for Large-Scale Optimization Model Auto-Formulation: A Lightweight Few-Shot Learning Approach", "comment": "Updated version of https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5329027", "summary": "Large-scale optimization is a key backbone of modern business decision-making. However, building these models is often labor-intensive and time-consuming. We address this by proposing LEAN-LLM-OPT, a LightwEight AgeNtic workflow construction framework for LLM-assisted large-scale OPTimization auto-formulation. LEAN-LLM-OPT takes as input a problem description together with associated datasets and orchestrates a team of LLM agents to produce an optimization formulation. Specifically, upon receiving a query, two upstream LLM agents dynamically construct a workflow that specifies, step-by-step, how optimization models for similar problems can be formulated. A downstream LLM agent then follows this workflow to generate the final output. Leveraging LLMs' text-processing capabilities and common modeling practices, the workflow decomposes the modeling task into a sequence of structured sub-tasks and offloads mechanical data-handling operations to auxiliary tools. This design alleviates the downstream agent's burden related to planning and data handling, allowing it to focus on the most challenging components that cannot be readily standardized. Extensive simulations show that LEAN-LLM-OPT, instantiated with GPT-4.1 and the open source gpt-oss-20B, achieves strong performance on large-scale optimization modeling tasks and is competitive with state-of-the-art approaches. In addition, in a Singapore Airlines choice-based revenue management use case, LEAN-LLM-OPT demonstrates practical value by achieving leading performance across a range of scenarios. Along the way, we introduce Large-Scale-OR and Air-NRM, the first comprehensive benchmarks for large-scale optimization auto-formulation. The code and data of this work is available at https://github.com/CoraLiang01/lean-llm-opt.", "AI": {"tldr": "LEAN-LLM-OPT is a lightweight LLM-based framework that automates large-scale optimization model formulation using a multi-agent workflow approach.", "motivation": "Building large-scale optimization models is labor-intensive and time-consuming, creating a need for automated formulation tools to accelerate business decision-making processes.", "method": "Uses a multi-agent LLM workflow: two upstream agents dynamically construct step-by-step workflows for similar problems, while a downstream agent follows the workflow to generate final optimization formulations, offloading mechanical data-handling to auxiliary tools.", "result": "Achieves strong performance on large-scale optimization tasks, competitive with state-of-the-art approaches, and demonstrates practical value in Singapore Airlines revenue management use case with leading performance across scenarios.", "conclusion": "LEAN-LLM-OPT effectively automates optimization model formulation through LLM orchestration, introduces new benchmarks (Large-Scale-OR and Air-NRM), and shows practical applicability in real-world business scenarios."}}
{"id": "2601.09156", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09156", "abs": "https://arxiv.org/abs/2601.09156", "authors": ["Woojin Kim", "Changkwon Lee", "Hyeoncheol Kim"], "title": "KTCF: Actionable Recourse in Knowledge Tracing via Counterfactual Explanations for Education", "comment": "Accepted to AAAI-26 Special Track AI for Social Impact (oral presentation)", "summary": "Using Artificial Intelligence to improve teaching and learning benefits greater adaptivity and scalability in education. Knowledge Tracing (KT) is recognized for student modeling task due to its superior performance and application potential in education. To this end, we conceptualize and investigate counterfactual explanation as the connection from XAI for KT to education. Counterfactual explanations offer actionable recourse, are inherently causal and local, and easy for educational stakeholders to understand who are often non-experts. We propose KTCF, a counterfactual explanation generation method for KT that accounts for knowledge concept relationships, and a post-processing scheme that converts a counterfactual explanation into a sequence of educational instructions. We experiment on a large-scale educational dataset and show our KTCF method achieves superior and robust performance over existing methods, with improvements ranging from 5.7% to 34% across metrics. Additionally, we provide a qualitative evaluation of our post-processing scheme, demonstrating that the resulting educational instructions help in reducing large study burden. We show that counterfactuals have the potential to advance the responsible and practical use of AI in education. Future works on XAI for KT may benefit from educationally grounded conceptualization and developing stakeholder-centered methods.", "AI": {"tldr": "KTCF: A counterfactual explanation method for Knowledge Tracing that generates educational instructions to help students improve learning outcomes with reduced study burden.", "motivation": "To bridge XAI for Knowledge Tracing with practical education by providing actionable, causal, and understandable explanations for non-expert educational stakeholders.", "method": "Proposed KTCF method that generates counterfactual explanations accounting for knowledge concept relationships, with post-processing to convert explanations into educational instruction sequences.", "result": "Superior performance over existing methods (5.7% to 34% improvements across metrics) on large-scale educational dataset, with qualitative evaluation showing reduced study burden through educational instructions.", "conclusion": "Counterfactual explanations advance responsible AI in education; future XAI for KT should focus on educationally grounded conceptualization and stakeholder-centered methods."}}
{"id": "2601.09136", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09136", "abs": "https://arxiv.org/abs/2601.09136", "authors": ["Lijun Liu", "Linwei Chen", "Zhishou Zhang", "Meng Tian", "Hengfu Cui", "Ruiyang Li", "Zhaocheng Liu", "Qiang Ju", "Qianxi Li", "Hong-Yu Zhou"], "title": "SkinFlow: Efficient Information Transmission for Open Dermatological Diagnosis via Dynamic Visual Encoding and Staged RL", "comment": null, "summary": "General-purpose Large Vision-Language Models (LVLMs), despite their massive scale, often falter in dermatology due to \"diffuse attention\" - the inability to disentangle subtle pathological lesions from background noise. In this paper, we challenge the assumption that parameter scaling is the only path to medical precision. We introduce SkinFlow, a framework that treats diagnosis as an optimization of visual information transmission efficiency. Our approach utilizes a Virtual-Width Dynamic Vision Encoder (DVE) to \"unfold\" complex pathological manifolds without physical parameter expansion, coupled with a two-stage Reinforcement Learning strategy. This strategy sequentially aligns explicit medical descriptions (Stage I) and reconstructs implicit diagnostic textures (Stage II) within a constrained semantic space. Furthermore, we propose a clinically grounded evaluation protocol that prioritizes diagnostic safety and hierarchical relevance over rigid label matching. Empirical results are compelling: our 7B model establishes a new state-of-the-art on the Fitzpatrick17k benchmark, achieving a +12.06% gain in Top-1 accuracy and a +28.57% boost in Top-6 accuracy over the massive general-purpose models (e.g., Qwen3VL-235B and GPT-5.2). These findings demonstrate that optimizing geometric capacity and information flow yields superior diagnostic reasoning compared to raw parameter scaling.", "AI": {"tldr": "SkinFlow introduces a framework that optimizes visual information transmission efficiency for dermatology diagnosis, achieving state-of-the-art performance with a 7B model through geometric capacity optimization rather than parameter scaling.", "motivation": "General-purpose LVLMs fail in dermatology due to \"diffuse attention\" - they can't separate subtle pathological lesions from background noise. The paper challenges the assumption that parameter scaling is the only path to medical precision.", "method": "SkinFlow uses a Virtual-Width Dynamic Vision Encoder to \"unfold\" complex pathological manifolds without physical parameter expansion, coupled with a two-stage Reinforcement Learning strategy that aligns explicit medical descriptions (Stage I) and reconstructs implicit diagnostic textures (Stage II) within a constrained semantic space.", "result": "The 7B model establishes new SOTA on Fitzpatrick17k benchmark: +12.06% gain in Top-1 accuracy and +28.57% boost in Top-6 accuracy over massive general-purpose models like Qwen3VL-235B and GPT-5.2.", "conclusion": "Optimizing geometric capacity and information flow yields superior diagnostic reasoning compared to raw parameter scaling, demonstrating that medical precision can be achieved through architectural innovation rather than just scaling model size."}}
{"id": "2601.09564", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09564", "abs": "https://arxiv.org/abs/2601.09564", "authors": ["Bar\u0131\u015f Nakibo\u011flu"], "title": "The Spectral Representations Of The Simple Hypothesis Testing Problem", "comment": "16 Pages", "summary": "The convex conjugate (i.e., the Legendre transform) of Type II error probability (volume) as a function of Type I error probability (volume) is determined for the hypothesis testing problem with randomized detectors. The derivation relies on properties of likelihood ratio quantiles and is general enough to extend to the case of $\u03c3$-finite measures in all non-trivial cases. The convex conjugate of the Type II error volume, called the primitive entropy spectrum, is expressed as an integral of the complementary distribution function of the likelihood ratio using a standard spectral identity. The resulting dual characterization of the Type II error volume leads to state of the art bounds for the case of product measures via Berry--Esseen theorem through a brief analysis relying on properties of the Gaussian Mills ratio, both with and without tilting.", "AI": {"tldr": "The paper derives the convex conjugate (Legendre transform) of Type II error probability as a function of Type I error for hypothesis testing with randomized detectors, extending to \u03c3-finite measures, and applies this to obtain state-of-the-art bounds for product measures.", "motivation": "To develop a dual characterization of hypothesis testing error probabilities through convex analysis, enabling better theoretical understanding and derivation of tight bounds for statistical inference problems, particularly for product measures.", "method": "Uses properties of likelihood ratio quantiles to derive the convex conjugate of Type II error probability (called primitive entropy spectrum), expressed as an integral of the complementary distribution function of the likelihood ratio. Extends to \u03c3-finite measures and applies Berry-Esseen theorem with Gaussian Mills ratio analysis (both with and without tilting) for product measures.", "result": "Successfully determines the convex conjugate of Type II error probability for randomized detectors, establishes the primitive entropy spectrum representation, and obtains state-of-the-art bounds for product measures through dual characterization and Berry-Esseen analysis.", "conclusion": "The convex conjugate approach provides a powerful dual characterization of hypothesis testing errors that enables derivation of tight bounds for statistical inference, particularly valuable for analyzing product measures and establishing fundamental limits in detection theory."}}
{"id": "2601.09636", "categories": ["cs.AI", "cs.CV", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09636", "abs": "https://arxiv.org/abs/2601.09636", "authors": ["Yibo Lyu", "Gongwei Chen", "Rui Shao", "Weili Guan", "Liqiang Nie"], "title": "PersonalAlign: Hierarchical Implicit Intent Alignment for Personalized GUI Agent with Long-Term User-Centric Records", "comment": null, "summary": "While GUI agents have shown strong performance under explicit and completion instructions, real-world deployment requires aligning with users' more complex implicit intents. In this work, we highlight Hierarchical Implicit Intent Alignment for Personalized GUI Agent (PersonalAlign), a new agent task that requires agents to leverage long-term user records as persistent context to resolve omitted preferences in vague instructions and anticipate latent routines by user state for proactive assistance. To facilitate this study, we introduce AndroidIntent, a benchmark designed to evaluate agents' ability in resolving vague instructions and providing proactive suggestions through reasoning over long-term user records. We annotated 775 user-specific preferences and 215 routines from 20k long-term records across different users for evaluation. Furthermore, we introduce Hierarchical Intent Memory Agent (HIM-Agent), which maintains a continuously updating personal memory and hierarchically organizes user preferences and routines for personalization. Finally, we evaluate a range of GUI agents on AndroidIntent, including GPT-5, Qwen3-VL, and UI-TARS, further results show that HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3%.", "AI": {"tldr": "PersonalAlign introduces a hierarchical implicit intent alignment task for GUI agents using long-term user records to resolve vague instructions and anticipate routines, with a new AndroidIntent benchmark and HIM-Agent achieving significant performance improvements.", "motivation": "Real-world GUI agent deployment requires aligning with users' complex implicit intents beyond explicit instructions, leveraging long-term user records to understand omitted preferences and anticipate latent routines for personalized proactive assistance.", "method": "Introduces AndroidIntent benchmark with 775 user-specific preferences and 215 routines from 20k long-term records, and proposes HIM-Agent with continuously updating personal memory that hierarchically organizes user preferences and routines for personalization.", "result": "HIM-Agent significantly improves both execution and proactive performance by 15.7% and 7.3% compared to other GUI agents (GPT-5, Qwen3-VL, UI-TARS) on the AndroidIntent benchmark.", "conclusion": "The work establishes a new direction for personalized GUI agents through hierarchical implicit intent alignment, demonstrating the importance of leveraging long-term user records for resolving vague instructions and providing proactive assistance."}}
{"id": "2601.09162", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.09162", "abs": "https://arxiv.org/abs/2601.09162", "authors": ["G Dhinesh Chandran", "Kota Srinivas Reddy", "Srikrishna Bhashyam"], "title": "Efficient Clustering in Stochastic Bandits", "comment": null, "summary": "We study the Bandit Clustering (BC) problem under the fixed confidence setting, where the objective is to group a collection of data sequences (arms) into clusters through sequential sampling from adaptively selected arms at each time step while ensuring a fixed error probability at the stopping time. We consider a setting where arms in a cluster may have different distributions. Unlike existing results in this setting, which assume Gaussian-distributed arms, we study a broader class of vector-parametric distributions that satisfy mild regularity conditions. Existing asymptotically optimal BC algorithms require solving an optimization problem as part of their sampling rule at each step, which is computationally costly. We propose an Efficient Bandit Clustering algorithm (EBC), which, instead of solving the full optimization problem, takes a single step toward the optimal value at each time step, making it computationally efficient while remaining asymptotically optimal. We also propose a heuristic variant of EBC, called EBC-H, which further simplifies the sampling rule, with arm selection based on quantities computed as part of the stopping rule. We highlight the computational efficiency of EBC and EBC-H by comparing their per-sample run time with that of existing algorithms. The asymptotic optimality of EBC is supported through simulations on the synthetic datasets. Through simulations on both synthetic and real-world datasets, we show the performance gain of EBC and EBC-H over existing approaches.", "AI": {"tldr": "Efficient Bandit Clustering (EBC) algorithm for sequential clustering of data sequences with fixed confidence, offering computational efficiency while maintaining asymptotic optimality for vector-parametric distributions.", "motivation": "Existing Bandit Clustering algorithms require solving costly optimization problems at each step and are limited to Gaussian distributions. There's a need for computationally efficient algorithms that work with broader distribution classes.", "method": "Proposes EBC algorithm that takes incremental steps toward optimal values instead of solving full optimization at each time step. Also introduces EBC-H heuristic variant that simplifies sampling using quantities from stopping rule.", "result": "EBC achieves asymptotic optimality while being computationally efficient. Both EBC and EBC-H outperform existing approaches in simulations on synthetic and real-world datasets, with significantly lower per-sample run time.", "conclusion": "EBC provides a practical solution for bandit clustering by balancing computational efficiency with asymptotic optimality, extending applicability beyond Gaussian distributions to broader vector-parametric classes."}}
{"id": "2601.09147", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09147", "abs": "https://arxiv.org/abs/2601.09147", "authors": ["Chenhao Fu", "Han Fang", "Xiuzheng Zheng", "Wenbo Wei", "Yonghua Li", "Hao Sun", "Xuelong Li"], "title": "SSVP: Synergistic Semantic-Visual Prompting for Industrial Zero-Shot Anomaly Detection", "comment": null, "summary": "Zero-Shot Anomaly Detection (ZSAD) leverages Vision-Language Models (VLMs) to enable supervision-free industrial inspection. However, existing ZSAD paradigms are constrained by single visual backbones, which struggle to balance global semantic generalization with fine-grained structural discriminability. To bridge this gap, we propose Synergistic Semantic-Visual Prompting (SSVP), that efficiently fuses diverse visual encodings to elevate model's fine-grained perception. Specifically, SSVP introduces the Hierarchical Semantic-Visual Synergy (HSVS) mechanism, which deeply integrates DINOv3's multi-scale structural priors into the CLIP semantic space. Subsequently, the Vision-Conditioned Prompt Generator (VCPG) employs cross-modal attention to guide dynamic prompt generation, enabling linguistic queries to precisely anchor to specific anomaly patterns. Furthermore, to address the discrepancy between global scoring and local evidence, the Visual-Text Anomaly Mapper (VTAM) establishes a dual-gated calibration paradigm. Extensive evaluations on seven industrial benchmarks validate the robustness of our method; SSVP achieves state-of-the-art performance with 93.0\\% Image-AUROC and 92.2\\% Pixel-AUROC on MVTec-AD, significantly outperforming existing zero-shot approaches.", "AI": {"tldr": "SSVP introduces a synergistic approach combining DINOv3's structural priors with CLIP's semantic space for zero-shot anomaly detection, achieving SOTA performance on industrial benchmarks.", "motivation": "Existing zero-shot anomaly detection methods rely on single visual backbones that struggle to balance global semantic generalization with fine-grained structural discriminability needed for industrial inspection.", "method": "Proposes Synergistic Semantic-Visual Prompting (SSVP) with three components: 1) Hierarchical Semantic-Visual Synergy (HSVS) integrates DINOv3's multi-scale structural priors into CLIP semantic space, 2) Vision-Conditioned Prompt Generator (VCPG) uses cross-modal attention for dynamic prompt generation, 3) Visual-Text Anomaly Mapper (VTAM) establishes dual-gated calibration for global-local alignment.", "result": "Achieves state-of-the-art performance with 93.0% Image-AUROC and 92.2% Pixel-AUROC on MVTec-AD, validated across seven industrial benchmarks, significantly outperforming existing zero-shot approaches.", "conclusion": "SSVP effectively bridges the gap between semantic generalization and structural discriminability in zero-shot anomaly detection by synergistically fusing diverse visual encodings, enabling precise anomaly pattern localization without supervision."}}
{"id": "2601.09581", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09581", "abs": "https://arxiv.org/abs/2601.09581", "authors": ["Dorsa Fathollahi", "V. Arvind Rameshwar", "V. Lalitha"], "title": "On the Error Probability of RPA Decoding of Reed-Muller Codes over BMS Channels", "comment": "7 pages, to be submitted to the IEEE for possible publication", "summary": "We analyze the performance of the Recursive Projection-Aggregation (RPA) decoder of Ye and Abbe (2020), for Reed-Muller (RM) codes, over general binary memoryless symmetric (BMS) channels. Our work is a significant generalization of a recent result of Rameshwar and Lalitha (2025) that showed that the RPA decoder provably achieves vanishing error probabilities for \"low-rate\" RM codes, over the binary symmetric channel (BSC). While a straightforward generalization of the proof strategy in that paper will require additional, restrictive assumptions on the BMS channel, our technique, which employs an equivalence between the RPA projection operation and a part of the \"channel combining\" phase in polar codes, requires no such assumptions. Interestingly, such an equivalence allows for the use of a generic union bound on the error probability of the first-order RM code (the \"base case\" of the RPA decoder), under maximum-likelihood decoding, which holds for any BMS channel. We then exploit these observations in the proof strategy outlined in the work of Rameshwar and Lalitha (2025), and argue that, much like in the case of the BSC, one can obtain vanishing error probabilities, in the large $n$ limit (where $n$ is the blocklength), for RM orders that scale roughly as $\\log \\log n$, for all BMS channels.", "AI": {"tldr": "The paper analyzes the Recursive Projection-Aggregation (RPA) decoder for Reed-Muller codes over general binary memoryless symmetric channels, showing it achieves vanishing error probabilities for low-rate RM codes across all BMS channels.", "motivation": "To generalize previous results on RPA decoder performance from binary symmetric channels to all binary memoryless symmetric channels, overcoming limitations of prior proof strategies that required restrictive channel assumptions.", "method": "Establishes an equivalence between RPA projection operation and polar code channel combining, enabling use of generic union bounds for first-order RM codes under ML decoding. Applies this equivalence within the proof framework from prior work to analyze decoder performance.", "result": "Proves that RPA decoder achieves vanishing error probabilities for RM codes with orders scaling roughly as log log n (low-rate regime) over all BMS channels, without requiring additional restrictive channel assumptions.", "conclusion": "The RPA decoder's performance guarantees extend from BSC to all BMS channels for low-rate RM codes, using a novel connection between RPA projections and polar code channel combining that eliminates previous proof limitations."}}
{"id": "2601.09667", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09667", "abs": "https://arxiv.org/abs/2601.09667", "authors": ["Zhiyuan Hu", "Yunhai Hu", "Juncheng Liu", "Shuyue Stella Li", "Yucheng Wang", "Zhen Xu", "See-Kiong Ng", "Anh Tuan Luu", "Xinxing Xu", "Bryan Hooi", "Cynthia Breazeal", "Hae Won Park"], "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning", "comment": "Work in Progress", "summary": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.", "AI": {"tldr": "MATTRL introduces test-time reinforcement learning for multi-agent systems, injecting structured textual experience into deliberation at inference time to improve performance without additional training.", "motivation": "Multi-agent RL training is resource-intensive and unstable due to co-adaptation non-stationarity and sparse, high-variance rewards, creating a need for more efficient approaches.", "method": "Forms multi-expert team for discussions, retrieves/integrates test-time experiences, reaches consensus decisions, and studies credit assignment for turn-level experience pool construction and reinjection.", "result": "Improves accuracy by 3.67% over multi-agent baseline and 8.67% over single-agent baselines across medicine, math, and education benchmarks; ablation studies examine credit-assignment schemes.", "conclusion": "MATTRL provides stable, effective, efficient path to distribution-shift-robust multi-agent reasoning without tuning, addressing key limitations of traditional MARL training."}}
{"id": "2601.09165", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09165", "abs": "https://arxiv.org/abs/2601.09165", "authors": ["Aaron R. Flouro", "Shawn P. Chadwick"], "title": "Multi-Teacher Ensemble Distillation: A Mathematical Framework for Probability-Domain Knowledge Aggregation", "comment": "7 pages, 1 table", "summary": "Building on the probability-domain distillation framework of Sparse-KD, we develop an axiomatic, operator-theoretic framework for multi-teacher ensemble knowledge distillation. Rather than prescribing a specific aggregation formula, we define five core axioms governing valid knowledge aggregation operators, encompassing convexity, positivity, continuity, weight monotonicity, and temperature coherence. We prove the existence and non-uniqueness of operator families satisfying these axioms, establishing that multiple distinct aggregation mechanisms conform to the same foundational principles.\n  Within this framework, we establish operator-agnostic guarantees showing that multi-teacher aggregation reduces both stochastic variance and systematic supervisory bias under heterogeneous teachers, while providing Jensen-type bounds, log-loss guarantees, and safety attenuation properties. For aggregation operators linear in teacher weights, we further establish classical ensemble variance-reduction results under standard independence assumptions, with extensions to correlated-error regimes. The framework provides theoretical grounding for multi-teacher distillation from diverse frontier models while admitting multiple valid implementation strategies.", "AI": {"tldr": "The paper develops an axiomatic framework for multi-teacher knowledge distillation, defining five core axioms for valid aggregation operators rather than prescribing specific formulas.", "motivation": "To provide theoretical grounding for multi-teacher knowledge distillation from diverse frontier models by establishing foundational principles rather than specific aggregation formulas.", "method": "Develops an operator-theoretic framework with five core axioms (convexity, positivity, continuity, weight monotonicity, temperature coherence) governing valid knowledge aggregation operators, building on Sparse-KD's probability-domain distillation.", "result": "Proves existence and non-uniqueness of operator families satisfying the axioms, establishes operator-agnostic guarantees showing multi-teacher aggregation reduces stochastic variance and systematic supervisory bias, and provides Jensen-type bounds, log-loss guarantees, and safety attenuation properties.", "conclusion": "The framework provides theoretical grounding for multi-teacher distillation from diverse models while admitting multiple valid implementation strategies, with extensions to correlated-error regimes for linear aggregation operators."}}
{"id": "2601.09153", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09153", "abs": "https://arxiv.org/abs/2601.09153", "authors": ["Josu\u00e9 Mart\u00ednez-Mart\u00ednez", "Olivia Brown", "Giselle Zeno", "Pooya Khorrami", "Rajmonda Caceres"], "title": "From Snow to Rain: Evaluating Robustness, Calibration, and Complexity of Model-Based Robust Training", "comment": "11 pages", "summary": "Robustness to natural corruptions remains a critical challenge for reliable deep learning, particularly in safety-sensitive domains. We study a family of model-based training approaches that leverage a learned nuisance variation model to generate realistic corruptions, as well as new hybrid strategies that combine random coverage with adversarial refinement in nuisance space. Using the Challenging Unreal and Real Environments for Traffic Sign Recognition dataset (CURE-TSR), with Snow and Rain corruptions, we evaluate accuracy, calibration, and training complexity across corruption severities. Our results show that model-based methods consistently outperform baselines Vanilla, Adversarial Training, and AugMix baselines, with model-based adversarial training providing the strongest robustness under across all corruptions but at the expense of higher computation and model-based data augmentation achieving comparable robustness with $T$ less computational complexity without incurring a statistically significant drop in performance. These findings highlight the importance of learned nuisance models for capturing natural variability, and suggest a promising path toward more resilient and calibrated models under challenging conditions.", "AI": {"tldr": "Model-based training with learned nuisance variation models outperforms baselines for traffic sign recognition robustness to natural corruptions like snow and rain, with model-based adversarial training being strongest but computationally expensive.", "motivation": "Robustness to natural corruptions is critical for reliable deep learning in safety-sensitive domains like autonomous driving, where models need to handle challenging conditions like snow and rain.", "method": "Family of model-based training approaches using learned nuisance variation models to generate realistic corruptions, plus hybrid strategies combining random coverage with adversarial refinement in nuisance space. Evaluated on CURE-TSR dataset with Snow and Rain corruptions.", "result": "Model-based methods consistently outperform Vanilla, Adversarial Training, and AugMix baselines. Model-based adversarial training provides strongest robustness across all corruptions but with higher computation. Model-based data augmentation achieves comparable robustness with T times less computational complexity without significant performance drop.", "conclusion": "Learned nuisance models are important for capturing natural variability, offering a promising path toward more resilient and calibrated models under challenging conditions, with trade-offs between robustness and computational efficiency."}}
{"id": "2601.09640", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09640", "abs": "https://arxiv.org/abs/2601.09640", "authors": ["David Miller", "R\u00e9mi A. Chou"], "title": "Secret sharing with additive access structures from correlated random variables", "comment": "7 pages, to be submitted to ISIT 2026", "summary": "We generalize secret-sharing models that rely on correlated randomness and public communication, originally designed for a fixed access structure, to support a sequence of dynamic access structures, which we term an Additive Access Structure. Specifically, the access structure is allowed to monotonically grow by having any subset of participants added to it at a given time step, and the dealer only learns of these changes to the access structure on the time step that they occur. For this model, we prove the existence of a secret sharing strategy that achieves the same secret rate at each time step as the best known strategy for the fixed access structure version of this model. We also prove that there exists a strategy that is capacity-achieving at any time step where the access structure is a threshold access structure.", "AI": {"tldr": "Generalizes secret-sharing with correlated randomness and public communication from fixed to dynamic access structures (Additive Access Structure), achieving same secret rates as fixed case and capacity-achieving for threshold structures.", "motivation": "Traditional secret-sharing models assume fixed access structures, but real-world scenarios often involve dynamic systems where authorized sets can change over time. The paper aims to extend secret-sharing to support sequences of dynamic access structures that grow monotonically.", "method": "Generalizes secret-sharing models that use correlated randomness and public communication to support Additive Access Structures, where access structures can monotonically grow by adding participant subsets at each time step. The dealer learns changes only when they occur.", "result": "Proves existence of a secret sharing strategy that achieves the same secret rate at each time step as the best known strategy for fixed access structures. Also proves existence of a capacity-achieving strategy for any time step where the access structure is a threshold access structure.", "conclusion": "The paper successfully extends secret-sharing to dynamic access structures while maintaining performance guarantees, showing that dynamic systems can achieve the same rates as their fixed counterparts and achieve capacity for threshold structures."}}
{"id": "2601.09680", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09680", "abs": "https://arxiv.org/abs/2601.09680", "authors": ["Sara AlMahri", "Liming Xu", "Alexandra Brintrup"], "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach", "comment": null, "summary": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.", "AI": {"tldr": "AI agent framework autonomously monitors and responds to supply chain disruptions across multi-tier networks using LLMs, achieving high accuracy and dramatically faster response times than manual methods.", "motivation": "Modern supply chains lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until disruptions cascade downstream. Current approaches are reactive rather than proactive, with companies having limited ability to monitor deep-tier networks for emerging risks.", "method": "A minimally supervised agentic AI framework with seven specialized agents powered by large language models and deterministic tools. The system autonomously detects disruption signals from unstructured news, maps them to multi-tier supplier networks, evaluates exposure based on network structure, and recommends mitigations like alternative sourcing options.", "result": "Evaluation across 30 synthesized scenarios covering three automotive manufacturers and five disruption classes shows high accuracy (F1 scores between 0.962 and 0.991). The system performs full end-to-end analyses in a mean of 3.83 minutes at $0.0836 per disruption, representing a reduction of more than three orders of magnitude in response time compared to multi-day, analyst-driven assessments. A real-world case study of the 2022 Russia-Ukraine conflict demonstrates operational applicability.", "conclusion": "This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks, moving from reactive recovery to proactive resilience."}}
{"id": "2601.09166", "categories": ["cs.LG", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09166", "abs": "https://arxiv.org/abs/2601.09166", "authors": ["Sidhant R. Nair", "Tanmay Sen", "Mrinmay Sen"], "title": "DP-FEDSOFIM: Differentially Private Federated Stochastic Optimization using Regularized Fisher Information Matrix", "comment": "17 pages, 1 figure. Submitted to ICML 2026", "summary": "Differentially private federated learning (DP-FL) suffers from slow convergence under tight privacy budgets due to the overwhelming noise introduced to preserve privacy. While adaptive optimizers can accelerate convergence, existing second-order methods such as DP-FedNew require O(d^2) memory at each client to maintain local feature covariance matrices, making them impractical for high-dimensional models. We propose DP-FedSOFIM, a server-side second-order optimization framework that leverages the Fisher Information Matrix (FIM) as a natural gradient preconditioner while requiring only O(d) memory per client. By employing the Sherman-Morrison formula for efficient matrix inversion, DP-FedSOFIM achieves O(d) computational complexity per round while maintaining the convergence benefits of second-order methods. Our analysis proves that the server-side preconditioning preserves (epsilon, delta)-differential privacy through the post-processing theorem. Empirical evaluation on CIFAR-10 demonstrates that DP-FedSOFIM achieves superior test accuracy compared to first-order baselines across multiple privacy regimes.", "AI": {"tldr": "DP-FedSOFIM: A server-side second-order federated learning framework with O(d) memory/computation per client that uses Fisher Information Matrix for faster convergence under differential privacy constraints.", "motivation": "DP-FL suffers from slow convergence under tight privacy budgets due to excessive noise. Existing second-order methods require O(d\u00b2) memory per client, making them impractical for high-dimensional models.", "method": "Proposes DP-FedSOFIM, a server-side second-order optimization framework using Fisher Information Matrix as natural gradient preconditioner. Employs Sherman-Morrison formula for efficient O(d) matrix inversion and computational complexity per round.", "result": "Achieves superior test accuracy compared to first-order baselines on CIFAR-10 across multiple privacy regimes. Maintains (\u03b5,\u03b4)-differential privacy through server-side preconditioning and post-processing theorem.", "conclusion": "DP-FedSOFIM provides an efficient second-order optimization solution for DP-FL with only O(d) memory/computation overhead, enabling faster convergence under privacy constraints without the impractical O(d\u00b2) requirements of existing methods."}}
{"id": "2601.09169", "categories": ["cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09169", "abs": "https://arxiv.org/abs/2601.09169", "authors": ["Jamie Magrill", "Leah Gornstein", "Sandra Seekins", "Barry Magrill"], "title": "Architecture inside the mirage: evaluating generative image models on architectural style, elements, and typologies", "comment": "24 pages, 7 figures", "summary": "Generative artificial intelligence (GenAI) text-to-image systems are increasingly used to generate architectural imagery, yet their capacity to reproduce accurate images in a historically rule-bound field remains poorly characterized. We evaluated five widely used GenAI image platforms (Adobe Firefly, DALL-E 3, Google Imagen 3, Microsoft Image Generator, and Midjourney) using 30 architectural prompts spanning styles, typologies, and codified elements. Each prompt-generator pair produced four images (n = 600 images total). Two architectural historians independently scored each image for accuracy against predefined criteria, resolving disagreements by consensus. Set-level performance was summarized as zero to four accurate images per four-image set. Image output from Common prompts was 2.7-fold more accurate than from Rare prompts (p < 0.05). Across platforms, overall accuracy was limited (highest accuracy score 52 percent; lowest 32 percent; mean 42 percent). All-correct (4 out of 4) outcomes were similar across platforms. By contrast, all-incorrect (0 out of 4) outcomes varied substantially, with Imagen 3 exhibiting the fewest failures and Microsoft Image Generator exhibiting the highest number of failures. Qualitative review of the image dataset identified recurring patterns including over-embellishment, confusion between medieval styles and their later revivals, and misrepresentation of descriptive prompts (for example, egg-and-dart, banded column, pendentive). These findings support the need for visible labeling of GenAI synthetic content, provenance standards for future training datasets, and cautious educational use of GenAI architectural imagery.", "AI": {"tldr": "Study evaluates 5 GenAI image platforms on architectural accuracy using 30 prompts, finding limited overall accuracy (32-52%) with better performance on common vs rare prompts, and identifies recurring error patterns.", "motivation": "To characterize the capacity of GenAI text-to-image systems to reproduce accurate architectural imagery in a historically rule-bound field, as their increasing use for architectural imagery contrasts with poorly understood accuracy limitations.", "method": "Evaluated 5 GenAI platforms (Adobe Firefly, DALL-E 3, Google Imagen 3, Microsoft Image Generator, Midjourney) using 30 architectural prompts spanning styles, typologies, and codified elements. Each prompt-generator pair produced 4 images (600 total). Two architectural historians independently scored images for accuracy against predefined criteria, resolving disagreements by consensus. Set-level performance summarized as 0-4 accurate images per four-image set.", "result": "Common prompts produced 2.7-fold more accurate images than rare prompts (p<0.05). Overall accuracy was limited across platforms (highest 52%, lowest 32%, mean 42%). All-correct outcomes were similar across platforms, but all-incorrect outcomes varied substantially (Imagen 3 had fewest failures, Microsoft Image Generator had highest). Qualitative review identified recurring error patterns: over-embellishment, confusion between medieval styles and revivals, misrepresentation of descriptive prompts.", "conclusion": "Findings support need for visible labeling of GenAI synthetic content, provenance standards for future training datasets, and cautious educational use of GenAI architectural imagery due to limited accuracy and systematic error patterns."}}
{"id": "2601.09674", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09674", "abs": "https://arxiv.org/abs/2601.09674", "authors": ["Lei Huang"], "title": "Counting and Entropy Bounds for Structure-Avoiding Spatially-Coupled LDPC Constructions", "comment": null, "summary": "Designing large coupling memory quasi-cyclic spatially-coupled LDPC (QC-SC-LDPC) codes with low error floors requires eliminating specific harmful substructures (e.g., short cycles) induced by edge spreading and lifting. Building on our work~\\cite{r15} that introduced a Clique Lov\u00e1sz Local Lemma (CLLL)-based design principle and a Moser--Tardos (MT)-type constructive approach, this work quantifies the size and structure of the feasible design space. Using the quantitative CLLL, we derive explicit lower bounds on the number of partition matrices satisfying a given family of structure-avoidance constraints, and further obtain bounds on the number of non-equivalent solutions under row/column permutations. Moreover, via R\u00e9nyi-entropy bounds for the MT distribution, we provide a computable lower bound on the number of distinct solutions that the MT algorithm can output, giving a concrete diversity guarantee for randomized constructions. Specializations for eliminating 4-cycle candidates yield closed-form bounds as functions of system parameters, offering a principled way to size memory/lifting and to estimate the remaining search space.", "AI": {"tldr": "Quantifying feasible design space for QC-SC-LDPC codes using quantitative CLLL and MT algorithm to bound number of structure-avoiding solutions", "motivation": "Need to design large coupling memory QC-SC-LDPC codes with low error floors by eliminating harmful substructures like short cycles, requiring understanding of feasible design space size", "method": "Uses quantitative Clique Lov\u00e1sz Local Lemma (CLLL) to derive lower bounds on partition matrices satisfying structure-avoidance constraints, and R\u00e9nyi-entropy bounds for Moser-Tardos distribution to bound distinct solutions from randomized construction", "result": "Explicit lower bounds on number of partition matrices and non-equivalent solutions, computable lower bound on distinct MT algorithm outputs, closed-form bounds for eliminating 4-cycles", "conclusion": "Provides principled way to size memory/lifting and estimate remaining search space for QC-SC-LDPC code design with diversity guarantees"}}
{"id": "2601.09172", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09172", "abs": "https://arxiv.org/abs/2601.09172", "authors": ["Pengyang Shao", "Naixin Zhai", "Lei Chen", "Yonghui Yang", "Fengbin Zhu", "Xun Yang", "Meng Wang"], "title": "BalDRO: A Distributionally Robust Optimization based Framework for Large Language Model Unlearning", "comment": null, "summary": "As Large Language Models (LLMs) increasingly shape online content, removing targeted information from well-trained LLMs (also known as LLM unlearning) has become critical for web governance. A key challenge lies in sample-wise imbalance within the forget set: different samples exhibit widely varying unlearning difficulty, leading to asynchronous forgetting where some knowledge remains insufficiently erased while others become over-forgotten. To address this, we propose BalDRO, a novel and efficient framework for balanced LLM unlearning. BalDRO formulates unlearning as a min-sup process: an inner step identifies a worst-case data distribution that emphasizes hard-to-unlearn samples, while an outer step updates model parameters under this distribution. We instantiate BalDRO via two efficient variants: BalDRO-G, a discrete GroupDRO-based approximation focusing on high-loss subsets, and BalDRO-DV, a continuous Donsker-Varadhan dual method enabling smooth adaptive weighting within standard training pipelines. Experiments on TOFU and MUSE show that BalDRO significantly improves both forgetting quality and model utility over existing methods, and we release code for reproducibility.", "AI": {"tldr": "BalDRO: A balanced LLM unlearning framework that addresses sample-wise imbalance in forget sets by formulating unlearning as a min-sup process with worst-case distribution optimization.", "motivation": "As LLMs increasingly shape online content, removing targeted information (LLM unlearning) is critical for web governance. A key challenge is sample-wise imbalance in forget sets where different samples have varying unlearning difficulty, leading to asynchronous forgetting (some knowledge insufficiently erased while others over-forgotten).", "method": "BalDRO formulates unlearning as a min-sup process: inner step identifies worst-case data distribution emphasizing hard-to-unlearn samples, outer step updates model parameters under this distribution. Two efficient variants: BalDRO-G (discrete GroupDRO-based approximation focusing on high-loss subsets) and BalDRO-DV (continuous Donsker-Varadhan dual method enabling smooth adaptive weighting).", "result": "Experiments on TOFU and MUSE datasets show BalDRO significantly improves both forgetting quality and model utility over existing methods.", "conclusion": "BalDRO provides an effective solution to the sample-wise imbalance problem in LLM unlearning, achieving balanced forgetting while maintaining model utility, with code released for reproducibility."}}
{"id": "2601.09170", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09170", "abs": "https://arxiv.org/abs/2601.09170", "authors": ["Dung Ta Nguyen Duc", "Thanh Bui Dang", "Hoang Le Minh", "Tung Nguyen Viet", "Huong Nguyen Thanh", "Dong Trinh Cong"], "title": "N-EIoU-YOLOv9: A Signal-Aware Bounding Box Regression Loss for Lightweight Mobile Detection of Rice Leaf Diseases", "comment": null, "summary": "In this work, we propose N EIoU YOLOv9, a lightweight detection framework based on a signal aware bounding box regression loss derived from non monotonic gradient focusing and geometric decoupling principles, referred to as N EIoU (Non monotonic Efficient Intersection over Union). The proposed loss reshapes localization gradients by combining non monotonic focusing with decoupled width and height optimization, thereby enhancing weak regression signals for hard samples with low overlap while reducing gradient interference. This design is particularly effective for small and low contrast targets commonly observed in agricultural disease imagery. The proposed N EIoU loss is integrated into a lightweight YOLOv9t architecture and evaluated on a self collected field dataset comprising 5908 rice leaf images across four disease categories and healthy leaves. Experimental results demonstrate consistent performance gains over the standard CIoU loss, achieving a mean Average Precision of 90.3 percent, corresponding to a 4.3 percent improvement over the baseline, with improved localization accuracy under stricter evaluation criteria. For practical validation, the optimized model is deployed on an Android device using TensorFlow Lite with Float16 quantization, achieving an average inference time of 156 milliseconds per frame while maintaining accuracy. These results confirm that the proposed approach effectively balances accuracy, optimization stability, and computational efficiency for edge based agricultural monitoring systems.", "AI": {"tldr": "NEIoU YOLOv9 is a lightweight detection framework using a novel bounding box regression loss that combines non-monotonic gradient focusing with geometric decoupling to improve detection of small, low-contrast agricultural disease targets.", "motivation": "Agricultural disease detection often involves small, low-contrast targets that are challenging for standard detection models. Existing bounding box regression losses like CIoU struggle with weak regression signals for hard samples with low overlap, leading to poor localization accuracy for agricultural applications.", "method": "Proposes NEIoU (Non-monotonic Efficient IoU) loss that reshapes localization gradients by combining non-monotonic focusing with decoupled width and height optimization. This enhances weak regression signals for hard samples while reducing gradient interference. The loss is integrated into a lightweight YOLOv9t architecture and evaluated on a custom rice leaf disease dataset.", "result": "Achieves 90.3% mAP, a 4.3% improvement over CIoU baseline, with better localization accuracy under strict evaluation. When deployed on Android with TensorFlow Lite Float16 quantization, maintains accuracy with 156ms average inference time per frame.", "conclusion": "The NEIoU loss effectively balances accuracy, optimization stability, and computational efficiency for edge-based agricultural monitoring systems, demonstrating practical value for real-world deployment on mobile devices."}}
{"id": "2601.09679", "categories": ["cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.09679", "abs": "https://arxiv.org/abs/2601.09679", "authors": ["Adel Javanmard", "David P. Woodruff"], "title": "Progress on the Courtade-Kumar Conjecture: Optimal High-Noise Entropy Bounds and Generalized Coordinate-wise Mutual Information", "comment": "16 pages", "summary": "The Courtade-Kumar conjecture posits that dictatorship functions maximize the mutual information between the function's output and a noisy version of its input over the Boolean hypercube. We present two significant advancements related to this conjecture. First, we resolve an open question posed by Courtade and Kumar, proving that for any Boolean function (regardless of bias), the sum of mutual information between the function's output and the individual noisy input coordinates is bounded by $1-H(\u03b1)$, where $\u03b1$ is the noise parameter of the Binary Symmetric Channel. This generalizes their previous result which was restricted to balanced Boolean functions. Second, we advance the study of the main conjecture in the high noise regime. We establish an optimal error bound of $O(\u03bb^2)$ for the asymptotic entropy expansion, where $\u03bb= (1-2\u03b1)^2$, improving upon the previous best-known bounds. This refined analysis leads to a sharp, linear Fourier concentration bound for highly informative functions and significantly extends the range of the noise parameter $\u03bb$ for which the conjecture is proven to hold.", "AI": {"tldr": "The paper makes two key contributions to the Courtade-Kumar conjecture: 1) proves that for any Boolean function (not just balanced), the sum of mutual information between output and individual noisy inputs is bounded by 1-H(\u03b1); 2) establishes optimal O(\u03bb\u00b2) error bound for entropy expansion in high noise regime, extending the proven range of the conjecture.", "motivation": "The Courtade-Kumar conjecture is an important open problem in information theory and Boolean analysis that seeks to characterize which Boolean functions maximize mutual information under noise. Previous results were limited to balanced functions and had suboptimal bounds in high noise regimes, motivating the need for more general and tighter results.", "method": "The authors use information-theoretic and Fourier-analytic techniques to analyze Boolean functions under Binary Symmetric Channel noise. They develop refined entropy expansion methods and leverage properties of mutual information to establish their bounds. The approach involves careful analysis of the asymptotic behavior of entropy in high noise regimes.", "result": "1) Resolved an open question by proving the mutual information sum bound holds for all Boolean functions regardless of bias. 2) Achieved optimal O(\u03bb\u00b2) error bound for entropy expansion where \u03bb=(1-2\u03b1)\u00b2, improving previous bounds. This leads to sharp Fourier concentration bounds and significantly extends the proven range of the Courtade-Kumar conjecture.", "conclusion": "The paper makes substantial progress on the Courtade-Kumar conjecture by removing the balanced function restriction and establishing optimal bounds in high noise regimes. These results provide deeper understanding of Boolean function behavior under noise and bring researchers closer to resolving the full conjecture."}}
{"id": "2601.09173", "categories": ["cs.LG", "cs.CL", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.09173", "abs": "https://arxiv.org/abs/2601.09173", "authors": ["Prashant C. Raju"], "title": "Geometric Stability: The Missing Axis of Representations", "comment": null, "summary": "Analysis of learned representations has a blind spot: it focuses on $similarity$, measuring how closely embeddings align with external references, but similarity reveals only what is represented, not whether that structure is robust. We introduce $geometric$ $stability$, a distinct dimension that quantifies how reliably representational geometry holds under perturbation, and present $Shesha$, a framework for measuring it. Across 2,463 configurations in seven domains, we show that stability and similarity are empirically uncorrelated ($\u03c1\\approx 0.01$) and mechanistically distinct: similarity metrics collapse after removing the top principal components, while stability retains sensitivity to fine-grained manifold structure. This distinction yields actionable insights: for safety monitoring, stability acts as a functional geometric canary, detecting structural drift nearly 2$\\times$ more sensitively than CKA while filtering out the non-functional noise that triggers false alarms in rigid distance metrics; for controllability, supervised stability predicts linear steerability ($\u03c1= 0.89$-$0.96$); for model selection, stability dissociates from transferability, revealing a geometric tax that transfer optimization incurs. Beyond machine learning, stability predicts CRISPR perturbation coherence and neural-behavioral coupling. By quantifying $how$ $reliably$ systems maintain structure, geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems.", "AI": {"tldr": "The paper introduces geometric stability as a new dimension for analyzing representations, distinct from similarity, that measures how reliably representational geometry holds under perturbation.", "motivation": "Current representation analysis focuses only on similarity (what is represented) but ignores whether that structure is robust and reliable under perturbation. There's a need to quantify how reliably systems maintain their representational structure.", "method": "The authors introduce geometric stability and present Shesha, a framework for measuring it. They analyze 2,463 configurations across seven domains, comparing stability with similarity metrics like CKA, and examine how these metrics behave under various manipulations (removing top principal components, etc.).", "result": "Stability and similarity are empirically uncorrelated (\u03c1\u22480.01) and mechanistically distinct. Stability serves as a functional geometric canary for safety monitoring (2\u00d7 more sensitive than CKA), predicts linear steerability (\u03c1=0.89-0.96), and reveals a geometric tax in transfer optimization. It also predicts CRISPR perturbation coherence and neural-behavioral coupling.", "conclusion": "Geometric stability provides a necessary complement to similarity for auditing representations across biological and computational systems, quantifying how reliably systems maintain structure rather than just what they represent."}}
{"id": "2601.09191", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09191", "abs": "https://arxiv.org/abs/2601.09191", "authors": ["Qizhen Lan", "Aaron Choi", "Jun Ma", "Bo Wang", "Zhaogming Zhao", "Xiaoqian Jiang", "Yu-Chun Hsu"], "title": "From Performance to Practice: Knowledge-Distilled Segmentator for On-Premises Clinical Workflows", "comment": null, "summary": "Deploying medical image segmentation models in routine clinical workflows is often constrained by on-premises infrastructure, where computational resources are fixed and cloud-based inference may be restricted by governance and security policies. While high-capacity models achieve strong segmentation accuracy, their computational demands hinder practical deployment and long-term maintainability in hospital environments. We present a deployment-oriented framework that leverages knowledge distillation to translate a high-performing segmentation model into a scalable family of compact student models, without modifying the inference pipeline. The proposed approach preserves architectural compatibility with existing clinical systems while enabling systematic capacity reduction. The framework is evaluated on a multi-site brain MRI dataset comprising 1,104 3D volumes, with independent testing on 101 curated cases, and is further examined on abdominal CT to assess cross-modality generalizability. Under aggressive parameter reduction (94%), the distilled student model preserves nearly all of the teacher's segmentation accuracy (98.7%), while achieving substantial efficiency gains, including up to a 67% reduction in CPU inference latency without additional deployment overhead. These results demonstrate that knowledge distillation provides a practical and reliable pathway for converting research-grade segmentation models into maintainable, deployment-ready components for on-premises clinical workflows in real-world health systems.", "AI": {"tldr": "Knowledge distillation framework converts high-capacity medical image segmentation models into compact, deployment-ready versions for on-premises clinical workflows while preserving accuracy.", "motivation": "Clinical deployment of medical image segmentation models faces constraints from fixed on-premises infrastructure, governance/security restrictions on cloud inference, and computational demands of high-capacity models that hinder practical deployment in hospital environments.", "method": "Deployment-oriented framework using knowledge distillation to translate high-performing segmentation models into scalable family of compact student models without modifying inference pipeline, preserving architectural compatibility with existing clinical systems while enabling systematic capacity reduction.", "result": "Evaluated on multi-site brain MRI dataset (1,104 3D volumes) with independent testing on 101 curated cases, plus abdominal CT for cross-modality generalizability. Under 94% parameter reduction, distilled student model preserves 98.7% of teacher's segmentation accuracy while achieving 67% reduction in CPU inference latency without additional deployment overhead.", "conclusion": "Knowledge distillation provides practical and reliable pathway for converting research-grade segmentation models into maintainable, deployment-ready components for on-premises clinical workflows in real-world health systems."}}
{"id": "2601.09176", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09176", "abs": "https://arxiv.org/abs/2601.09176", "authors": ["Lang Xiong", "Ning Liu", "Ao Ren", "Yuheng Bai", "Haining Fang", "BinYan Zhang", "Zhe Jiang", "Yujuan Tan", "Duo Liu"], "title": "$D^2Prune$: Sparsifying Large Language Models via Dual Taylor Expansion and Attention Distribution Awareness", "comment": null, "summary": "Large language models (LLMs) face significant deployment challenges due to their massive computational demands. % While pruning offers a promising compression solution, existing methods suffer from two critical limitations: (1) They neglect activation distribution shifts between calibration data and test data, resulting in inaccurate error estimations; (2) They overlook the long-tail distribution characteristics of activations in the attention module. To address these limitations, this paper proposes a novel pruning method, $D^2Prune$. First, we propose a dual Taylor expansion-based method that jointly models weight and activation perturbations for precise error estimation, leading to precise pruning mask selection and weight updating and facilitating error minimization during pruning. % Second, we propose an attention-aware dynamic update strategy that preserves the long-tail attention pattern by jointly minimizing the KL divergence of attention distributions and the reconstruction error. Extensive experiments show that $D^2Prune$ consistently outperforms SOTA methods across various LLMs (e.g., OPT-125M, LLaMA2/3, and Qwen3). Moreover, the dynamic attention update mechanism also generalizes well to ViT-based vision models like DeiT, achieving superior accuracy on ImageNet-1K.", "AI": {"tldr": "D\u00b2Prune: A novel pruning method for LLMs that addresses activation distribution shifts and attention long-tail patterns through dual Taylor expansion and attention-aware dynamic updates.", "motivation": "LLMs have massive computational demands requiring compression. Existing pruning methods fail to account for activation distribution shifts between calibration and test data, and overlook long-tail distribution characteristics in attention module activations.", "method": "1) Dual Taylor expansion-based method jointly models weight and activation perturbations for precise error estimation, enabling accurate pruning mask selection and weight updating. 2) Attention-aware dynamic update strategy preserves long-tail attention patterns by jointly minimizing KL divergence of attention distributions and reconstruction error.", "result": "D\u00b2Prune consistently outperforms state-of-the-art methods across various LLMs (OPT-125M, LLaMA2/3, Qwen3). The dynamic attention update mechanism also generalizes well to ViT-based vision models like DeiT, achieving superior accuracy on ImageNet-1K.", "conclusion": "The proposed D\u00b2Prune effectively addresses key limitations in existing pruning methods by considering activation distribution shifts and attention long-tail patterns, achieving superior compression performance across both language and vision transformer models."}}
{"id": "2601.09207", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09207", "abs": "https://arxiv.org/abs/2601.09207", "authors": ["Bahar Khodabakhshian", "Nima Hashemi", "Armin Saadat", "Zahra Gholami", "In-Chang Hwang", "Samira Sojoudi", "Christina Luong", "Purang Abolmaesumi", "Teresa Tsang"], "title": "Point Tracking as a Temporal Cue for Robust Myocardial Segmentation in Echocardiography Videos", "comment": null, "summary": "Purpose: Myocardium segmentation in echocardiography videos is a challenging task due to low contrast, noise, and anatomical variability. Traditional deep learning models either process frames independently, ignoring temporal information, or rely on memory-based feature propagation, which accumulates error over time. Methods: We propose Point-Seg, a transformer-based segmentation framework that integrates point tracking as a temporal cue to ensure stable and consistent segmentation of myocardium across frames. Our method leverages a point-tracking module trained on a synthetic echocardiography dataset to track key anatomical landmarks across video sequences. These tracked trajectories provide an explicit motion-aware signal that guides segmentation, reducing drift and eliminating the need for memory-based feature accumulation. Additionally, we incorporate a temporal smoothing loss to further enhance temporal consistency across frames. Results: We evaluate our approach on both public and private echocardiography datasets. Experimental results demonstrate that Point-Seg has statistically similar accuracy in terms of Dice to state-of-the-art segmentation models in high quality echo data, while it achieves better segmentation accuracy in lower quality echo with improved temporal stability. Furthermore, Point-Seg has the key advantage of pixel-level myocardium motion information as opposed to other segmentation methods. Such information is essential in the computation of other downstream tasks such as myocardial strain measurement and regional wall motion abnormality detection. Conclusion: Point-Seg demonstrates that point tracking can serve as an effective temporal cue for consistent video segmentation, offering a reliable and generalizable approach for myocardium segmentation in echocardiography videos. The code is available at https://github.com/DeepRCL/PointSeg.", "AI": {"tldr": "Point-Seg uses point tracking as temporal cue for myocardium segmentation in echocardiography videos, improving consistency and providing motion information for downstream tasks.", "motivation": "Myocardium segmentation in echocardiography is challenging due to low contrast, noise, and anatomical variability. Traditional deep learning models either ignore temporal information or accumulate errors through memory-based feature propagation.", "method": "Transformer-based segmentation framework with point tracking module trained on synthetic echocardiography data to track anatomical landmarks. Uses tracked trajectories as motion-aware signal to guide segmentation, plus temporal smoothing loss for consistency.", "result": "Statistically similar Dice accuracy to SOTA in high-quality echo data, better accuracy in lower-quality data with improved temporal stability. Provides pixel-level myocardium motion information essential for downstream tasks like strain measurement.", "conclusion": "Point tracking serves as effective temporal cue for consistent video segmentation, offering reliable and generalizable approach for myocardium segmentation in echocardiography videos."}}
{"id": "2601.09220", "categories": ["cs.LG", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.09220", "abs": "https://arxiv.org/abs/2601.09220", "authors": ["Xinzi Tan", "Kejian Zhang", "Junhan Yu", "Doudou Zhou"], "title": "From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences", "comment": null, "summary": "Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.", "AI": {"tldr": "The paper proposes Hawkes Attention, a novel attention operator derived from multivariate Hawkes process theory for Marked Temporal Point Processes, using learnable per-type neural kernels to capture heterogeneous temporal effects.", "motivation": "Existing Transformer-based methods for MTPPs rely on shared or parametric decay structures via positional encodings, which limits their ability to capture heterogeneous and type-specific temporal effects in domains like medical, social, commercial, and financial applications.", "method": "Derives Hawkes Attention from multivariate Hawkes process theory, using learnable per-type neural kernels to modulate query, key and value projections in attention mechanism, replacing corresponding parts in traditional attention to unify event timing and content interaction.", "result": "The method achieves better performance compared to baselines on MTPP tasks and can also be easily applied to specific temporal structures like time series forecasting.", "conclusion": "Hawkes Attention effectively captures both time-relevant behavior and type-specific excitation patterns from data, addressing limitations of existing Transformer-based approaches for temporal point processes."}}
{"id": "2601.09209", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09209", "abs": "https://arxiv.org/abs/2601.09209", "authors": ["Qiang Hu", "Qimei Wang", "Yingjie Guo", "Qiang Li", "Zhiwei Wang"], "title": "Pairing-free Group-level Knowledge Distillation for Robust Gastrointestinal Lesion Classification in White-Light Endoscopy", "comment": "Accepted to AAAI 2026", "summary": "White-Light Imaging (WLI) is the standard for endoscopic cancer screening, but Narrow-Band Imaging (NBI) offers superior diagnostic details. A key challenge is transferring knowledge from NBI to enhance WLI-only models, yet existing methods are critically hampered by their reliance on paired NBI-WLI images of the same lesion, a costly and often impractical requirement that leaves vast amounts of clinical data untapped. In this paper, we break this paradigm by introducing PaGKD, a novel Pairing-free Group-level Knowledge Distillation framework that that enables effective cross-modal learning using unpaired WLI and NBI data. Instead of forcing alignment between individual, often semantically mismatched image instances, PaGKD operates at the group level to distill more complete and compatible knowledge across modalities. Central to PaGKD are two complementary modules: (1) Group-level Prototype Distillation (GKD-Pro) distills compact group representations by extracting modality-invariant semantic prototypes via shared lesion-aware queries; (2) Group-level Dense Distillation (GKD-Den) performs dense cross-modal alignment by guiding group-aware attention with activation-derived relation maps. Together, these modules enforce global semantic consistency and local structural coherence without requiring image-level correspondence. Extensive experiments on four clinical datasets demonstrate that PaGKD consistently and significantly outperforms state-of-the-art methods, achieving relative AUC improvements of 3.3%, 1.1%, 2.8%, and 3.2%, respectively, establishing a new direction for cross-modal learning from unpaired data.", "AI": {"tldr": "PaGKD is a novel framework for cross-modal knowledge distillation from NBI to WLI using unpaired endoscopic images, eliminating the need for costly paired data through group-level learning.", "motivation": "Current methods for transferring diagnostic knowledge from NBI to WLI require paired images of the same lesion, which is expensive and impractical, leaving most clinical data unused. There's a need for effective cross-modal learning without image-level pairing.", "method": "PaGKD uses group-level knowledge distillation with two modules: GKD-Pro distills modality-invariant semantic prototypes via shared lesion-aware queries, and GKD-Den performs dense cross-modal alignment using group-aware attention with activation-derived relation maps.", "result": "Extensive experiments on four clinical datasets show PaGKD consistently outperforms state-of-the-art methods with relative AUC improvements of 3.3%, 1.1%, 2.8%, and 3.2% respectively.", "conclusion": "PaGKD establishes a new direction for cross-modal learning from unpaired data by enabling effective knowledge transfer from NBI to WLI without requiring image-level correspondence, making better use of clinical data."}}
{"id": "2601.09233", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09233", "abs": "https://arxiv.org/abs/2601.09233", "authors": ["Zhengyang Zhao", "Lu Ma", "Yizhen Jiang", "Xiaochen Ma", "Zimo Meng", "Chengyu Shen", "Lexiang Tang", "Haoze Sun", "Peng Pei", "Wentao Zhang"], "title": "GIFT: Unlocking Global Optimality in Post-Training via Finite-Temperature Gibbs Initialization", "comment": null, "summary": "The prevailing post-training paradigm for Large Reasoning Models (LRMs)--Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL)--suffers from an intrinsic optimization mismatch: the rigid supervision inherent in SFT induces distributional collapse, thereby exhausting the exploration space necessary for subsequent RL. In this paper, we reformulate SFT within a unified post-training framework and propose Gibbs Initialization with Finite Temperature (GIFT). We characterize standard SFT as a degenerate zero-temperature limit that suppresses base priors. Conversely, GIFT incorporates supervision as a finite-temperature energy potential, establishing a distributional bridge that ensures objective consistency throughout the post-training pipeline. Our experiments demonstrate that GIFT significantly outperforms standard SFT and other competitive baselines when utilized for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training. Our code is available at https://github.com/zzy1127/GIFT.", "AI": {"tldr": "GIFT reformulates SFT with finite-temperature Gibbs initialization to address optimization mismatch between SFT and RL in post-training, preventing distributional collapse and enabling better RL exploration.", "motivation": "The standard post-training paradigm (SFT followed by RL) suffers from optimization mismatch where rigid SFT supervision causes distributional collapse, exhausting the exploration space needed for subsequent RL.", "method": "Reformulates SFT within a unified framework as Gibbs Initialization with Finite Temperature (GIFT), treating supervision as a finite-temperature energy potential rather than degenerate zero-temperature limit, establishing a distributional bridge for objective consistency.", "result": "GIFT significantly outperforms standard SFT and other competitive baselines when used for RL initialization, providing a mathematically principled pathway toward achieving global optimality in post-training.", "conclusion": "GIFT offers a principled solution to the optimization mismatch problem in LRM post-training by maintaining distributional diversity through finite-temperature initialization, enabling better RL performance."}}
{"id": "2601.09211", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09211", "abs": "https://arxiv.org/abs/2601.09211", "authors": ["Chunghyun Park", "Seunghyeon Lee", "Minsu Cho"], "title": "Affostruction: 3D Affordance Grounding with Generative Reconstruction", "comment": null, "summary": "This paper addresses the problem of affordance grounding from RGBD images of an object, which aims to localize surface regions corresponding to a text query that describes an action on the object. While existing methods predict affordance regions only on visible surfaces, we propose Affostruction, a generative framework that reconstructs complete geometry from partial observations and grounds affordances on the full shape including unobserved regions. We make three core contributions: generative multi-view reconstruction via sparse voxel fusion that extrapolates unseen geometry while maintaining constant token complexity, flow-based affordance grounding that captures inherent ambiguity in affordance distributions, and affordance-driven active view selection that leverages predicted affordances for intelligent viewpoint sampling. Affostruction achieves 19.1 aIoU on affordance grounding (40.4\\% improvement) and 32.67 IoU for 3D reconstruction (67.7\\% improvement), enabling accurate affordance prediction on complete shapes.", "AI": {"tldr": "Affostruction: A generative framework for affordance grounding on complete 3D shapes from partial RGBD observations, using multi-view reconstruction and flow-based affordance prediction with active view selection.", "motivation": "Existing affordance grounding methods only predict on visible surfaces, missing affordances on unobserved regions. The paper aims to localize affordance regions on complete object shapes including unseen parts.", "method": "Three core contributions: 1) Generative multi-view reconstruction via sparse voxel fusion for complete geometry reconstruction, 2) Flow-based affordance grounding to handle ambiguity in affordance distributions, 3) Affordance-driven active view selection for intelligent viewpoint sampling.", "result": "Achieves 19.1 aIoU on affordance grounding (40.4% improvement) and 32.67 IoU for 3D reconstruction (67.7% improvement), enabling accurate affordance prediction on complete shapes.", "conclusion": "Affostruction successfully addresses the limitation of existing methods by grounding affordances on complete shapes, significantly outperforming previous approaches in both affordance grounding and 3D reconstruction tasks."}}
{"id": "2601.09236", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09236", "abs": "https://arxiv.org/abs/2601.09236", "authors": ["Chaitanya Kharyal", "Calarina Muslimani", "Matthew E. Taylor"], "title": "Reward Learning through Ranking Mean Squared Error", "comment": null, "summary": "Reward design remains a significant bottleneck in applying reinforcement learning (RL) to real-world problems. A popular alternative is reward learning, where reward functions are inferred from human feedback rather than manually specified. Recent work has proposed learning reward functions from human feedback in the form of ratings, rather than traditional binary preferences, enabling richer and potentially less cognitively demanding supervision. Building on this paradigm, we introduce a new rating-based RL method, Ranked Return Regression for RL (R4). At its core, R4 employs a novel ranking mean squared error (rMSE) loss, which treats teacher-provided ratings as ordinal targets. Our approach learns from a dataset of trajectory-rating pairs, where each trajectory is labeled with a discrete rating (e.g., \"bad,\" \"neutral,\" \"good\"). At each training step, we sample a set of trajectories, predict their returns, and rank them using a differentiable sorting operator (soft ranks). We then optimize a mean squared error loss between the resulting soft ranks and the teacher's ratings. Unlike prior rating-based approaches, R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, we demonstrate that R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks from OpenAI Gym and the DeepMind Control Suite, while requiring significantly less feedback.", "AI": {"tldr": "R4 is a new RL method that learns reward functions from human ratings using a novel ranking MSE loss with formal guarantees, outperforming existing methods with less feedback.", "motivation": "Reward design is a bottleneck in RL applications, and reward learning from human feedback offers an alternative. While binary preferences are common, ratings provide richer supervision that's less cognitively demanding for humans.", "method": "R4 uses a novel ranking mean squared error (rMSE) loss that treats ratings as ordinal targets. It learns from trajectory-rating pairs, samples trajectories, predicts returns, ranks them using differentiable soft ranks, and optimizes MSE between soft ranks and teacher ratings.", "result": "R4 offers formal guarantees: its solution set is provably minimal and complete under mild assumptions. Empirically, using simulated human feedback, R4 consistently matches or outperforms existing rating and preference-based RL methods on robotic locomotion benchmarks while requiring significantly less feedback.", "conclusion": "R4 provides an effective rating-based RL approach with theoretical guarantees and practical advantages over existing methods, making reward learning from human feedback more efficient and reliable."}}
{"id": "2601.09212", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09212", "abs": "https://arxiv.org/abs/2601.09212", "authors": ["Xingyao Li", "Fengzhuo Zhang", "Cunxiao Du", "Hui Ji"], "title": "Annealed Relaxation of Speculative Decoding for Faster Autoregressive Image Generation", "comment": "Accepted to AAAI 2026", "summary": "Despite significant progress in autoregressive image generation, inference remains slow due to the sequential nature of AR models and the ambiguity of image tokens, even when using speculative decoding. Recent works attempt to address this with relaxed speculative decoding but lack theoretical grounding. In this paper, we establish the theoretical basis of relaxed SD and propose COOL-SD, an annealed relaxation of speculative decoding built on two key insights. The first analyzes the total variation (TV) distance between the target model and relaxed speculative decoding and yields an optimal resampling distribution that minimizes an upper bound of the distance. The second uses perturbation analysis to reveal an annealing behaviour in relaxed speculative decoding, motivating our annealed design. Together, these insights enable COOL-SD to generate images faster with comparable quality, or achieve better quality at similar latency. Experiments validate the effectiveness of COOL-SD, showing consistent improvements over prior methods in speed-quality trade-offs.", "AI": {"tldr": "COOL-SD: Annealed relaxed speculative decoding for faster autoregressive image generation with theoretical grounding and improved speed-quality trade-offs.", "motivation": "Autoregressive image generation suffers from slow inference due to sequential token generation and token ambiguity, even with speculative decoding. Existing relaxed speculative decoding approaches lack theoretical foundation.", "method": "COOL-SD uses annealed relaxation of speculative decoding based on two theoretical insights: 1) Optimal resampling distribution minimizing TV distance upper bound between target and relaxed models, and 2) Perturbation analysis revealing annealing behavior, leading to annealed design.", "result": "COOL-SD generates images faster with comparable quality, or achieves better quality at similar latency. Experiments show consistent improvements over prior methods in speed-quality trade-offs.", "conclusion": "The paper establishes theoretical basis for relaxed speculative decoding and proposes COOL-SD as an effective annealed approach that enables better speed-quality trade-offs for autoregressive image generation."}}
{"id": "2601.09237", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09237", "abs": "https://arxiv.org/abs/2601.09237", "authors": ["Xinyang Chen", "Huidong Jin", "Yu Huang", "Zaiwen Feng"], "title": "XLinear: A Lightweight and Accurate MLP-Based Model for Long-Term Time Series Forecasting with Exogenous Inputs", "comment": "Accepted by AAAI 2026", "summary": "Despite the prevalent assumption of uniform variable importance in long-term time series forecasting models, real world applications often exhibit asymmetric causal relationships and varying data acquisition costs. Specifically, cost-effective exogenous data (e.g., local weather) can unilaterally influence dynamics of endogenous variables, such as lake surface temperature. Exploiting these links enables more effective forecasts when exogenous inputs are readily available. Transformer-based models capture long-range dependencies but incur high computation and suffer from permutation invariance. Patch-based variants improve efficiency yet can miss local temporal patterns. To efficiently exploit informative signals across both the temporal dimension and relevant exogenous variables, this study proposes XLinear, a lightweight time series forecasting model built upon MultiLayer Perceptrons (MLPs). XLinear uses a global token derived from an endogenous variable as a pivotal hub for interacting with exogenous variables, and employs MLPs with sigmoid activation to extract both temporal patterns and variate-wise dependencies. Its prediction head then integrates these signals to forecast the endogenous series. We evaluate XLinear on seven standard benchmarks and five real-world datasets with exogenous inputs. Compared with state-of-the-art models, XLinear delivers superior accuracy and efficiency for both multivariate forecasts and univariate forecasts influenced by exogenous inputs.", "AI": {"tldr": "XLinear is a lightweight MLP-based model for time series forecasting that efficiently exploits asymmetric causal relationships between endogenous and exogenous variables using global tokens and sigmoid-activated MLPs.", "motivation": "Real-world time series forecasting often involves asymmetric causal relationships where cost-effective exogenous data (like weather) influences endogenous variables, but current models assume uniform variable importance. Transformer-based models are computationally expensive and permutation-invariant, while patch-based variants miss local patterns.", "method": "XLinear uses a global token from endogenous variables as a hub for interacting with exogenous variables. It employs MLPs with sigmoid activation to extract both temporal patterns and variate-wise dependencies, then integrates these signals in a prediction head for forecasting.", "result": "XLinear outperforms state-of-the-art models on seven standard benchmarks and five real-world datasets with exogenous inputs, delivering superior accuracy and efficiency for both multivariate and exogenous-influenced univariate forecasts.", "conclusion": "XLinear provides an effective lightweight solution for exploiting asymmetric causal relationships in time series forecasting, addressing limitations of transformer-based models while maintaining high accuracy and computational efficiency."}}
{"id": "2601.09213", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09213", "abs": "https://arxiv.org/abs/2601.09213", "authors": ["Jialu Li", "Taiyan Zhou"], "title": "SpikeVAEDiff: Neural Spike-based Natural Visual Scene Reconstruction via VD-VAE and Versatile Diffusion", "comment": "Preprint", "summary": "Reconstructing natural visual scenes from neural activity is a key challenge in neuroscience and computer vision. We present SpikeVAEDiff, a novel two-stage framework that combines a Very Deep Variational Autoencoder (VDVAE) and the Versatile Diffusion model to generate high-resolution and semantically meaningful image reconstructions from neural spike data. In the first stage, VDVAE produces low-resolution preliminary reconstructions by mapping neural spike signals to latent representations. In the second stage, regression models map neural spike signals to CLIP-Vision and CLIP-Text features, enabling Versatile Diffusion to refine the images via image-to-image generation.\n  We evaluate our approach on the Allen Visual Coding-Neuropixels dataset and analyze different brain regions. Our results show that the VISI region exhibits the most prominent activation and plays a key role in reconstruction quality. We present both successful and unsuccessful reconstruction examples, reflecting the challenges of decoding neural activity. Compared with fMRI-based approaches, spike data provides superior temporal and spatial resolution. We further validate the effectiveness of the VDVAE model and conduct ablation studies demonstrating that data from specific brain regions significantly enhances reconstruction performance.", "AI": {"tldr": "SpikeVAEDiff is a two-stage framework combining VDVAE and Versatile Diffusion to reconstruct high-resolution images from neural spike data, showing VISI brain region is most important for reconstruction quality.", "motivation": "Reconstructing natural visual scenes from neural activity is a fundamental challenge in neuroscience and computer vision. Current approaches often use fMRI data which has limited temporal and spatial resolution, while spike data offers superior resolution but presents decoding challenges.", "method": "Two-stage framework: 1) VDVAE produces low-resolution preliminary reconstructions from neural spike signals to latent representations; 2) Regression models map spike signals to CLIP-Vision and CLIP-Text features, enabling Versatile Diffusion to refine images via image-to-image generation.", "result": "Evaluation on Allen Visual Coding-Neuropixels dataset shows VISI region exhibits most prominent activation and plays key role in reconstruction quality. Spike data provides superior temporal/spatial resolution compared to fMRI. Ablation studies show specific brain regions significantly enhance reconstruction performance.", "conclusion": "SpikeVAEDiff successfully reconstructs high-resolution, semantically meaningful images from neural spike data, demonstrating the importance of specific brain regions (particularly VISI) for visual scene reconstruction and highlighting the advantages of spike data over fMRI for neural decoding tasks."}}
{"id": "2601.09251", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09251", "abs": "https://arxiv.org/abs/2601.09251", "authors": ["Qin-Yi Zhang", "Hong Wang", "Siyao Liu", "Haichuan Lin", "Linying Cao", "Xiao-Hu Zhou", "Chen Chen", "Shuangyi Wang", "Zeng-Guang Hou"], "title": "HGATSolver: A Heterogeneous Graph Attention Solver for Fluid-Structure Interaction", "comment": null, "summary": "Fluid-structure interaction (FSI) systems involve distinct physical domains, fluid and solid, governed by different partial differential equations and coupled at a dynamic interface. While learning-based solvers offer a promising alternative to costly numerical simulations, existing methods struggle to capture the heterogeneous dynamics of FSI within a unified framework. This challenge is further exacerbated by inconsistencies in response across domains due to interface coupling and by disparities in learning difficulty across fluid and solid regions, leading to instability during prediction. To address these challenges, we propose the Heterogeneous Graph Attention Solver (HGATSolver). HGATSolver encodes the system as a heterogeneous graph, embedding physical structure directly into the model via distinct node and edge types for fluid, solid, and interface regions. This enables specialized message-passing mechanisms tailored to each physical domain. To stabilize explicit time stepping, we introduce a novel physics-conditioned gating mechanism that serves as a learnable, adaptive relaxation factor. Furthermore, an Inter-domain Gradient-Balancing Loss dynamically balances the optimization objectives across domains based on predictive uncertainty. Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.", "AI": {"tldr": "HGATSolver: A heterogeneous graph attention solver for fluid-structure interaction systems that uses specialized message-passing for different physical domains, physics-conditioned gating for stability, and gradient-balancing loss for optimization.", "motivation": "Existing learning-based solvers struggle to capture heterogeneous dynamics in FSI systems within a unified framework, facing challenges with interface coupling inconsistencies and disparities in learning difficulty across fluid and solid regions, leading to instability during prediction.", "method": "HGATSolver encodes FSI systems as heterogeneous graphs with distinct node/edge types for fluid, solid, and interface regions, enabling specialized message-passing. It introduces physics-conditioned gating for stable explicit time stepping and an Inter-domain Gradient-Balancing Loss that dynamically balances optimization objectives based on predictive uncertainty.", "result": "Extensive experiments on two constructed FSI benchmarks and a public dataset demonstrate that HGATSolver achieves state-of-the-art performance, establishing an effective framework for surrogate modeling of coupled multi-physics systems.", "conclusion": "HGATSolver provides a novel approach to learning-based FSI simulation that effectively handles heterogeneous dynamics, interface coupling, and domain-specific learning challenges through graph-based representation, adaptive stabilization, and balanced optimization."}}
{"id": "2601.09228", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09228", "abs": "https://arxiv.org/abs/2601.09228", "authors": ["Fan Liu", "Ting Wu", "Chuanyi Zhang", "Liang Yao", "Xing Ma", "Yuhui Zheng"], "title": "Disentangle Object and Non-object Infrared Features via Language Guidance", "comment": null, "summary": "Infrared object detection focuses on identifying and locating objects in complex environments (\\eg, dark, snow, and rain) where visible imaging cameras are disabled by poor illumination. However, due to low contrast and weak edge information in infrared images, it is challenging to extract discriminative object features for robust detection. To deal with this issue, we propose a novel vision-language representation learning paradigm for infrared object detection. An additional textual supervision with rich semantic information is explored to guide the disentanglement of object and non-object features. Specifically, we propose a Semantic Feature Alignment (SFA) module to align the object features with the corresponding text features. Furthermore, we develop an Object Feature Disentanglement (OFD) module that disentangles text-aligned object features and non-object features by minimizing their correlation. Finally, the disentangled object features are entered into the detection head. In this manner, the detection performance can be remarkably enhanced via more discriminative and less noisy features. Extensive experimental results demonstrate that our approach achieves superior performance on two benchmarks: M\\textsuperscript{3}FD (83.7\\% mAP), FLIR (86.1\\% mAP). Our code will be publicly available once the paper is accepted.", "AI": {"tldr": "Vision-language representation learning for infrared object detection using textual supervision to guide feature disentanglement and improve discriminative object features.", "motivation": "Infrared object detection faces challenges due to low contrast and weak edge information in infrared images, making it difficult to extract discriminative features for robust detection in complex environments where visible imaging fails.", "method": "Proposes a vision-language representation learning paradigm with textual supervision. Includes: 1) Semantic Feature Alignment (SFA) module to align object features with text features, and 2) Object Feature Disentanglement (OFD) module that disentangles text-aligned object features from non-object features by minimizing their correlation.", "result": "Achieves superior performance on two benchmarks: 83.7% mAP on M\u00b3FD and 86.1% mAP on FLIR datasets.", "conclusion": "The proposed vision-language approach with textual supervision effectively enhances infrared object detection by learning more discriminative and less noisy features through semantic alignment and feature disentanglement."}}
{"id": "2601.09253", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09253", "abs": "https://arxiv.org/abs/2601.09253", "authors": ["Zehua Liu", "Shuqi Liu", "Tao Zhong", "Mingxuan Yuan"], "title": "RIFT: Repurposing Negative Samples via Reward-Informed Fine-Tuning", "comment": null, "summary": "While Supervised Fine-Tuning (SFT) and Rejection Sampling Fine-Tuning (RFT) are standard for LLM alignment, they either rely on costly expert data or discard valuable negative samples, leading to data inefficiency. To address this, we propose Reward Informed Fine-Tuning (RIFT), a simple yet effective framework that utilizes all self-generated samples. Unlike the hard thresholding of RFT, RIFT repurposes negative trajectories, reweighting the loss with scalar rewards to learn from both the positive and negative trajectories from the model outputs. To overcome the training collapse caused by naive reward integration, where direct multiplication yields an unbounded loss, we introduce a stabilized loss formulation that ensures numerical robustness and optimization efficiency. Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT. Our results demonstrate that RIFT is a robust and data-efficient alternative for alignment using mixed-quality, self-generated data.", "AI": {"tldr": "RIFT (Reward Informed Fine-Tuning) is a new alignment framework that efficiently uses all self-generated samples by reweighting loss with scalar rewards, outperforming standard RFT while avoiding data inefficiency.", "motivation": "Current LLM alignment methods like SFT and RFT are data-inefficient - SFT requires costly expert data, while RFT discards valuable negative samples. There's a need for a more efficient approach that can utilize all self-generated data.", "method": "RIFT repurposes negative trajectories by reweighting the loss with scalar rewards to learn from both positive and negative samples. It introduces a stabilized loss formulation to prevent training collapse from naive reward integration, ensuring numerical robustness and optimization efficiency.", "result": "Extensive experiments on mathematical benchmarks across various base models show that RIFT consistently outperforms RFT, demonstrating it as a robust and data-efficient alternative for alignment.", "conclusion": "RIFT provides a simple yet effective framework for LLM alignment that efficiently utilizes mixed-quality, self-generated data, offering a superior alternative to existing methods like RFT."}}
{"id": "2601.09229", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09229", "abs": "https://arxiv.org/abs/2601.09229", "authors": ["Ravi Shankar Prasad", "Dinesh Singh"], "title": "SPOT-Face: Forensic Face Identification using Attention Guided Optimal Transport", "comment": "14 pages, 5 figures, 3 tables (ICPR_2026)", "summary": "Person identification in forensic investigations becomes very challenging when common identification means for DNA (i.e., hair strands, soft tissue) are not available. Current methods utilize deep learning methods for face recognition. However, these methods lack effective mechanisms to model cross-domain structural correspondence between two different forensic modalities. In this paper, we introduce a SPOT-Face, a superpixel graph-based framework designed for cross-domain forensic face identification of victims using their skeleton and sketch images. Our unified framework involves constructing a superpixel-based graph from an image and then using different graph neural networks(GNNs) backbones to extract the embeddings of these graphs, while cross-domain correspondence is established through attention-guided optimal transport mechanism. We have evaluated our proposed framework on two publicly available dataset: IIT\\_Mandi\\_S2F (S2F) and CUFS. Extensive experiments were conducted to evaluate our proposed framework. The experimental results show significant improvement in identification metrics ( i.e., Recall, mAP) over existing graph-based baselines. Furthermore, our framework demonstrates to be highly effective for matching skulls and sketches to faces in forensic investigations.", "AI": {"tldr": "SPOT-Face: A superpixel graph-based framework for cross-domain forensic face identification using skeleton/sketch to face matching with attention-guided optimal transport.", "motivation": "Person identification in forensic investigations is challenging when traditional DNA sources are unavailable. Current deep learning face recognition methods lack effective mechanisms to model cross-domain structural correspondence between different forensic modalities like skeleton/sketch and face images.", "method": "SPOT-Face constructs superpixel-based graphs from images, uses GNN backbones to extract graph embeddings, and establishes cross-domain correspondence through attention-guided optimal transport mechanism.", "result": "Significant improvement in identification metrics (Recall, mAP) over existing graph-based baselines on IIT_Mandi_S2F and CUFS datasets. Highly effective for matching skulls and sketches to faces in forensic investigations.", "conclusion": "SPOT-Face provides an effective unified framework for cross-domain forensic face identification that addresses the structural correspondence challenge between different forensic modalities."}}
{"id": "2601.09261", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09261", "abs": "https://arxiv.org/abs/2601.09261", "authors": ["Zhipeng Zhang", "Zhenjie Yao", "Kai Li", "Lei Yang"], "title": "Learning to Trust Experience: A Monitor-Trust-Regulator Framework for Learning under Unobservable Feedback Reliability", "comment": "23 pages, 7 figures. Preprint", "summary": "Learning under unobservable feedback reliability poses a distinct challenge beyond optimization robustness: a system must decide whether to learn from an experience, not only how to learn stably. We study this setting as Epistemic Identifiability under Unobservable Reliability (EIUR), where each experience has a latent credibility, reliable and unreliable feedback can be locally indistinguishable, and data are generated in a closed loop by the learner's own evolving beliefs and actions. In EIUR, standard robust learning can converge stably yet form high-confidence, systematically wrong beliefs.\n  We propose metacognitive regulation as a practical response: a second, introspective control loop that infers experience credibility from endogenous evidence in the learner's internal dynamics. We formalize this as a modular Monitor-Trust-Regulator (MTR) decomposition and instantiate it with self-diagnosis, which maintains a slowly varying experience-trust variable that softly modulates learning updates, without exogenous reliability labels or an explicit corruption model.\n  Empirically, in the EIUR regimes studied here, self-diagnosis is associated with improved epistemic identifiability. In reinforcement learning, it enables calibrated skepticism and recovery under systematically corrupted rewards. In supervised learning, it exposes a critical dissociation: performance recovery does not imply epistemic recovery. Accuracy can rebound while internal belief dynamics remain locked-in by early misleading data, a failure detectable only through introspective diagnostics. Together, MTR and self-diagnosis provide an organizing abstraction and a concrete design template for intrinsic reliability assessment in autonomous learning under unobservable reliability.", "AI": {"tldr": "The paper introduces Epistemic Identifiability under Unobservable Reliability (EIUR) where feedback reliability is latent and unobservable, proposes metacognitive regulation via Monitor-Trust-Regulator (MTR) decomposition with self-diagnosis to infer experience credibility from internal dynamics.", "motivation": "Standard robust learning can converge stably yet form high-confidence, systematically wrong beliefs when feedback reliability is unobservable. There's a need for systems that can decide whether to learn from an experience, not just how to learn stably.", "method": "Proposes metacognitive regulation with Monitor-Trust-Regulator (MTR) decomposition and self-diagnosis instantiation. Self-diagnosis maintains a slowly varying experience-trust variable that softly modulates learning updates without needing exogenous reliability labels or explicit corruption models.", "result": "Self-diagnosis improves epistemic identifiability in EIUR regimes. In RL, enables calibrated skepticism and recovery under systematically corrupted rewards. In supervised learning, reveals critical dissociation: performance recovery doesn't imply epistemic recovery - accuracy can rebound while beliefs remain locked-in by early misleading data.", "conclusion": "MTR and self-diagnosis provide an organizing abstraction and concrete design template for intrinsic reliability assessment in autonomous learning under unobservable reliability, enabling systems to infer experience credibility from endogenous evidence in internal dynamics."}}
{"id": "2601.09230", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09230", "abs": "https://arxiv.org/abs/2601.09230", "authors": ["Haodi Yao", "Fenghua He", "Ning Hao", "Yao Su"], "title": "CLIDD: Cross-Layer Independent Deformable Description for Efficient and Discriminative Local Feature Representation", "comment": null, "summary": "Robust local feature representations are essential for spatial intelligence tasks such as robot navigation and augmented reality. Establishing reliable correspondences requires descriptors that provide both high discriminative power and computational efficiency. To address this, we introduce Cross-Layer Independent Deformable Description (CLIDD), a method that achieves superior distinctiveness by sampling directly from independent feature hierarchies. This approach utilizes learnable offsets to capture fine-grained structural details across scales while bypassing the computational burden of unified dense representations. To ensure real-time performance, we implement a hardware-aware kernel fusion strategy that maximizes inference throughput. Furthermore, we develop a scalable framework that integrates lightweight architectures with a training protocol leveraging both metric learning and knowledge distillation. This scheme generates a wide spectrum of model variants optimized for diverse deployment constraints. Extensive evaluations demonstrate that our approach achieves superior matching accuracy and exceptional computational efficiency simultaneously. Specifically, the ultra-compact variant matches the precision of SuperPoint while utilizing only 0.004M parameters, achieving a 99.7% reduction in model size. Furthermore, our high-performance configuration outperforms all current state-of-the-art methods, including high-capacity DINOv2-based frameworks, while exceeding 200 FPS on edge devices. These results demonstrate that CLIDD delivers high-precision local feature matching with minimal computational overhead, providing a robust and scalable solution for real-time spatial intelligence tasks.", "AI": {"tldr": "CLIDD is a novel local feature description method that achieves superior matching accuracy and computational efficiency through cross-layer independent sampling, hardware-aware optimization, and scalable model variants.", "motivation": "Robust local feature representations are essential for spatial intelligence tasks like robot navigation and AR, requiring descriptors with both high discriminative power and computational efficiency for real-time applications.", "method": "Cross-Layer Independent Deformable Description (CLIDD) samples directly from independent feature hierarchies using learnable offsets to capture fine-grained details. It implements hardware-aware kernel fusion for throughput optimization and integrates lightweight architectures with metric learning and knowledge distillation training.", "result": "Ultra-compact variant matches SuperPoint precision with only 0.004M parameters (99.7% size reduction). High-performance configuration outperforms all state-of-the-art methods including DINOv2-based frameworks while exceeding 200 FPS on edge devices.", "conclusion": "CLIDD delivers high-precision local feature matching with minimal computational overhead, providing a robust and scalable solution for real-time spatial intelligence tasks."}}
{"id": "2601.09285", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.09285", "abs": "https://arxiv.org/abs/2601.09285", "authors": ["Mianzhi Pan", "JianFei Li", "Peishuo Liu", "Botian Wang", "Yawen Ouyang", "Yiming Rong", "Hao Zhou", "Jianbing Zhang"], "title": "Enhancing Spatial Reasoning in Large Language Models for Metal-Organic Frameworks Structure Prediction", "comment": null, "summary": "Metal-organic frameworks (MOFs) are porous crystalline materials with broad applications such as carbon capture and drug delivery, yet accurately predicting their 3D structures remains a significant challenge. While Large Language Models (LLMs) have shown promise in generating crystals, their application to MOFs is hindered by MOFs' high atomic complexity. Inspired by the success of block-wise paradigms in deep generative models, we pioneer the use of LLMs in this domain by introducing MOF-LLM, the first LLM framework specifically adapted for block-level MOF structure prediction. To effectively harness LLMs for this modular assembly task, our training paradigm integrates spatial-aware continual pre-training (CPT), structural supervised fine-tuning (SFT), and matching-driven reinforcement learning (RL). By incorporating explicit spatial priors and optimizing structural stability via Soft Adaptive Policy Optimization (SAPO), our approach substantially enhances the spatial reasoning capability of a Qwen-3 8B model for accurate MOF structure prediction. Comprehensive experiments demonstrate that MOF-LLM outperforms state-of-the-art denoising-based and LLM-based methods while exhibiting superior sampling efficiency.", "AI": {"tldr": "MOF-LLM: First LLM framework for block-level metal-organic framework structure prediction using spatial-aware training and reinforcement learning to handle MOFs' high atomic complexity.", "motivation": "Predicting 3D structures of metal-organic frameworks (MOFs) is challenging due to their high atomic complexity, and existing LLM approaches struggle with this modular assembly task despite success with simpler crystals.", "method": "MOF-LLM adapts LLMs for block-level MOF prediction through spatial-aware continual pre-training (CPT), structural supervised fine-tuning (SFT), and matching-driven reinforcement learning with Soft Adaptive Policy Optimization (SAPO) to incorporate spatial priors and optimize structural stability.", "result": "MOF-LLM outperforms state-of-the-art denoising-based and LLM-based methods while demonstrating superior sampling efficiency in comprehensive experiments.", "conclusion": "The proposed framework successfully adapts LLMs to complex MOF structure prediction through a novel block-wise paradigm and specialized training approach, advancing the application of language models to challenging materials science problems."}}
{"id": "2601.09238", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09238", "abs": "https://arxiv.org/abs/2601.09238", "authors": ["Jackie Alex", "Justin Petter"], "title": "Knowledge-Embedded and Hypernetwork-Guided Few-Shot Substation Meter Defect Image Generation Method", "comment": null, "summary": "Substation meters play a critical role in monitoring and ensuring the stable operation of power grids, yet their detection of cracks and other physical defects is often hampered by a severe scarcity of annotated samples. To address this few-shot generation challenge, we propose a novel framework that integrates Knowledge Embedding and Hypernetwork-Guided Conditional Control into a Stable Diffusion pipeline, enabling realistic and controllable synthesis of defect images from limited data.\n  First, we bridge the substantial domain gap between natural-image pre-trained models and industrial equipment by fine-tuning a Stable Diffusion backbone using DreamBooth-style knowledge embedding. This process encodes the unique structural and textural priors of substation meters, ensuring generated images retain authentic meter characteristics.\n  Second, we introduce a geometric crack modeling module that parameterizes defect attributes--such as location, length, curvature, and branching pattern--to produce spatially constrained control maps. These maps provide precise, pixel-level guidance during generation.\n  Third, we design a lightweight hypernetwork that dynamically modulates the denoising process of the diffusion model in response to the control maps and high-level defect descriptors, achieving a flexible balance between generation fidelity and controllability.\n  Extensive experiments on a real-world substation meter dataset demonstrate that our method substantially outperforms existing augmentation and generation baselines. It reduces Frechet Inception Distance (FID) by 32.7%, increases diversity metrics, and--most importantly--boosts the mAP of a downstream defect detector by 15.3% when trained on augmented data. The framework offers a practical, high-quality data synthesis solution for industrial inspection systems where defect samples are rare.", "AI": {"tldr": "A novel framework combining knowledge embedding and hypernetwork-guided conditional control with Stable Diffusion for realistic few-shot defect image generation in substation meters.", "motivation": "Substation meters are critical for power grid monitoring but suffer from severe scarcity of annotated defect samples, creating a few-shot generation challenge for industrial inspection systems.", "method": "Three key components: 1) DreamBooth-style knowledge embedding to fine-tune Stable Diffusion for meter characteristics, 2) Geometric crack modeling for parameterized defect control maps, 3) Lightweight hypernetwork to dynamically modulate diffusion denoising based on control maps and defect descriptors.", "result": "Substantially outperforms existing methods: reduces FID by 32.7%, increases diversity metrics, and boosts downstream defect detector mAP by 15.3% when trained on augmented data.", "conclusion": "The framework offers a practical, high-quality data synthesis solution for industrial inspection systems where defect samples are rare, enabling realistic and controllable generation from limited data."}}
{"id": "2601.09304", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09304", "abs": "https://arxiv.org/abs/2601.09304", "authors": ["Sota Sugawara", "Yuji Kawamata", "Akihiro Toyoda", "Tomoru Nakayama", "Yukihiko Okada"], "title": "Single-Round Clustered Federated Learning via Data Collaboration Analysis for Non-IID Data", "comment": "9 pages, 3 figures", "summary": "Federated Learning (FL) enables distributed learning across multiple clients without sharing raw data. When statistical heterogeneity across clients is severe, Clustered Federated Learning (CFL) can improve performance by grouping similar clients and training cluster-wise models. However, most CFL approaches rely on multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight constraints on communication rounds. We propose Data Collaboration-based Clustered Federated Learning (DC-CFL), a single-round framework that completes both client clustering and cluster-wise learning, using only the information shared in DC analysis. DC-CFL quantifies inter-client similarity via total variation distance between label distributions, estimates clusters using hierarchical clustering, and performs cluster-wise learning via DC analysis. Experiments on multiple open datasets under representative non-IID conditions show that DC-CFL achieves accuracy comparable to multi-round baselines while requiring only one communication round. These results indicate that DC-CFL is a practical alternative for collaborative AI model development when multiple communication rounds are impractical.", "AI": {"tldr": "DC-CFL is a single-round federated learning framework that performs both client clustering and cluster-wise learning in one communication round, achieving comparable accuracy to multi-round methods.", "motivation": "Existing clustered federated learning (CFL) methods require multiple communication rounds for cluster estimation and model updates, which limits their practicality under tight communication constraints. There's a need for efficient CFL that can work with limited communication rounds.", "method": "DC-CFL uses Data Collaboration analysis to perform both client clustering and cluster-wise learning in a single round. It quantifies inter-client similarity via total variation distance between label distributions, estimates clusters using hierarchical clustering, and performs cluster-wise learning via DC analysis.", "result": "Experiments on multiple open datasets under representative non-IID conditions show that DC-CFL achieves accuracy comparable to multi-round baselines while requiring only one communication round.", "conclusion": "DC-CFL is a practical alternative for collaborative AI model development when multiple communication rounds are impractical, offering efficient clustered federated learning with minimal communication overhead."}}
{"id": "2601.09361", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09361", "abs": "https://arxiv.org/abs/2601.09361", "authors": ["Jiaying Zhang", "Lei Shi", "Jiguo Li", "Jun Xu", "Jiuchong Gao", "Jinghua Hao", "Renqing He"], "title": "GeoRA: Geometry-Aware Low-Rank Adaptation for RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is crucial for advancing large-scale reasoning models. However, existing parameter-efficient methods, such as PiSSA and MiLoRA, are designed for Supervised Fine-Tuning (SFT) and do not account for the distinct optimization dynamics and geometric structures of RLVR. Applying these methods directly leads to spectral collapse and optimization instability, which severely limit model performance. Meanwhile, alternative approaches that leverage update sparsity encounter significant efficiency bottlenecks on modern hardware due to unstructured computations. To address these challenges, we propose GeoRA (Geometry-Aware Low-Rank Adaptation), which exploits the anisotropic and compressible nature of RL update subspaces. GeoRA initializes adapters by extracting principal directions via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing the residual components. This method preserves the pre-trained geometric structure and enables efficient GPU computation through dense operators. Experiments on Qwen and Llama demonstrate that GeoRA mitigates optimization bottlenecks caused by geometric misalignment. It consistently outperforms established low-rank baselines on key mathematical benchmarks, achieving state-of-the-art (SOTA) results. Moreover, GeoRA shows superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.", "AI": {"tldr": "GeoRA is a geometry-aware low-rank adaptation method for RL with verifiable rewards that addresses optimization instability in existing parameter-efficient methods by preserving pre-trained geometric structure through SVD-based initialization in constrained subspaces.", "motivation": "Existing parameter-efficient methods (PiSSA, MiLoRA) designed for Supervised Fine-Tuning don't account for the distinct optimization dynamics and geometric structures of Reinforcement Learning with Verifiable Rewards (RLVR), leading to spectral collapse and optimization instability. Alternative sparse update approaches face efficiency bottlenecks on modern hardware due to unstructured computations.", "method": "GeoRA exploits the anisotropic and compressible nature of RL update subspaces by initializing adapters via Singular Value Decomposition (SVD) within a geometrically constrained subspace while freezing residual components. This preserves pre-trained geometric structure and enables efficient GPU computation through dense operators.", "result": "Experiments on Qwen and Llama show GeoRA mitigates optimization bottlenecks from geometric misalignment, consistently outperforms established low-rank baselines on key mathematical benchmarks achieving SOTA results, and demonstrates superior generalization and resilience to catastrophic forgetting in out-of-domain tasks.", "conclusion": "GeoRA provides an effective geometry-aware adaptation method for RLVR that addresses the limitations of existing parameter-efficient approaches by preserving geometric structure while maintaining computational efficiency on modern hardware."}}
{"id": "2601.09243", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09243", "abs": "https://arxiv.org/abs/2601.09243", "authors": ["Sheng-Chi Hsu", "Ting-Yu Yen", "Shih-Hsuan Hung", "Hung-Kuo Chu"], "title": "A$^2$TG: Adaptive Anisotropic Textured Gaussians for Efficient 3D Scene Representation", "comment": null, "summary": "Gaussian Splatting has emerged as a powerful representation for high-quality, real-time 3D scene rendering. While recent works extend Gaussians with learnable textures to enrich visual appearance, existing approaches allocate a fixed square texture per primitive, leading to inefficient memory usage and limited adaptability to scene variability. In this paper, we introduce adaptive anisotropic textured Gaussians (A$^2$TG), a novel representation that generalizes textured Gaussians by equipping each primitive with an anisotropic texture. Our method employs a gradient-guided adaptive rule to jointly determine texture resolution and aspect ratio, enabling non-uniform, detail-aware allocation that aligns with the anisotropic nature of Gaussian splats. This design significantly improves texture efficiency, reducing memory consumption while enhancing image quality. Experiments on multiple benchmark datasets demonstrate that A TG consistently outperforms fixed-texture Gaussian Splatting methods, achieving comparable rendering fidelity with substantially lower memory requirements.", "AI": {"tldr": "A\u00b2TG introduces anisotropic textures for Gaussian splats with adaptive resolution/aspect ratio allocation, reducing memory while improving quality over fixed-texture methods.", "motivation": "Existing textured Gaussian methods use fixed square textures per primitive, leading to inefficient memory usage and limited adaptability to scene variability. This wastes resources and doesn't align with the anisotropic nature of Gaussian splats.", "method": "Introduces adaptive anisotropic textured Gaussians (A\u00b2TG) that equip each primitive with anisotropic textures. Uses a gradient-guided adaptive rule to jointly determine texture resolution and aspect ratio, enabling non-uniform, detail-aware allocation aligned with Gaussian anisotropy.", "result": "A\u00b2TG consistently outperforms fixed-texture Gaussian Splatting methods across multiple benchmark datasets, achieving comparable rendering fidelity with substantially lower memory requirements.", "conclusion": "The adaptive anisotropic texture approach significantly improves texture efficiency for Gaussian splatting, reducing memory consumption while enhancing image quality through better alignment with scene variability and primitive anisotropy."}}
{"id": "2601.09400", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09400", "abs": "https://arxiv.org/abs/2601.09400", "authors": ["Olgierd Unold", "Stanis\u0142aw Franczyk"], "title": "Preliminary Tests of the Anticipatory Classifier System with Hindsight Experience Replay", "comment": null, "summary": "This paper introduces ACS2HER, a novel integration of the Anticipatory Classifier System (ACS2) with the Hindsight Experience Replay (HER) mechanism. While ACS2 is highly effective at building cognitive maps through latent learning, its performance often stagnates in environments characterized by sparse rewards. We propose a specific architectural variant that triggers hindsight learning when the agent fails to reach its primary goal, re-labeling visited states as virtual goals to densify the learning signal. The proposed model was evaluated on two benchmarks: the deterministic \\texttt{Maze 6} and the stochastic \\texttt{FrozenLake}. The results demonstrate that ACS2HER significantly accelerates knowledge acquisition and environmental mastery compared to the standard ACS2. However, this efficiency gain is accompanied by increased computational overhead and a substantial expansion in classifier numerosity. This work provides the first analysis of combining anticipatory mechanisms with retrospective goal-relabeling in Learning Classifier Systems.", "AI": {"tldr": "ACS2HER combines Anticipatory Classifier System (ACS2) with Hindsight Experience Replay (HER) to improve performance in sparse reward environments by re-labeling visited states as virtual goals when primary goals aren't reached.", "motivation": "ACS2 is effective at building cognitive maps through latent learning but struggles with performance stagnation in environments with sparse rewards. The authors aim to address this limitation by integrating HER to densify learning signals.", "method": "The paper introduces ACS2HER, which triggers hindsight learning when the agent fails to reach its primary goal. It re-labels visited states as virtual goals to create denser learning signals. The architecture was evaluated on deterministic Maze 6 and stochastic FrozenLake benchmarks.", "result": "ACS2HER significantly accelerates knowledge acquisition and environmental mastery compared to standard ACS2. However, this efficiency comes with increased computational overhead and substantial expansion in classifier numerosity.", "conclusion": "This work provides the first analysis of combining anticipatory mechanisms with retrospective goal-relabeling in Learning Classifier Systems, demonstrating improved performance in sparse reward environments at the cost of computational complexity."}}
{"id": "2601.09247", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09247", "abs": "https://arxiv.org/abs/2601.09247", "authors": ["Yiwei Zhang", "Jin Gao", "Hanshi Wang", "Fudong Ge", "Guan Luo", "Weiming Hu", "Zhipeng Zhang"], "title": "Integrating Diverse Assignment Strategies into DETRs", "comment": null, "summary": "Label assignment is a critical component in object detectors, particularly within DETR-style frameworks where the one-to-one matching strategy, despite its end-to-end elegance, suffers from slow convergence due to sparse supervision. While recent works have explored one-to-many assignments to enrich supervisory signals, they often introduce complex, architecture-specific modifications and typically focus on a single auxiliary strategy, lacking a unified and scalable design. In this paper, we first systematically investigate the effects of ``one-to-many'' supervision and reveal a surprising insight that performance gains are driven not by the sheer quantity of supervision, but by the diversity of the assignment strategies employed. This finding suggests that a more elegant, parameter-efficient approach is attainable. Building on this insight, we propose LoRA-DETR, a flexible and lightweight framework that seamlessly integrates diverse assignment strategies into any DETR-style detector. Our method augments the primary network with multiple Low-Rank Adaptation (LoRA) branches during training, each instantiating a different one-to-many assignment rule. These branches act as auxiliary modules that inject rich, varied supervisory gradients into the main model and are discarded during inference, thus incurring no additional computational cost. This design promotes robust joint optimization while maintaining the architectural simplicity of the original detector. Extensive experiments on different baselines validate the effectiveness of our approach. Our work presents a new paradigm for enhancing detectors, demonstrating that diverse ``one-to-many'' supervision can be integrated to achieve state-of-the-art results without compromising model elegance.", "AI": {"tldr": "LoRA-DETR enhances DETR-style detectors by using multiple LoRA branches with diverse one-to-many assignment strategies during training to provide rich supervision, improving convergence without inference cost.", "motivation": "One-to-one matching in DETR suffers from slow convergence due to sparse supervision. Existing one-to-many approaches are complex, architecture-specific, and lack unified design. The paper finds that diversity of assignment strategies, not just quantity of supervision, drives performance gains.", "method": "Proposes LoRA-DETR framework that adds multiple Low-Rank Adaptation (LoRA) branches during training, each implementing different one-to-many assignment rules. These auxiliary branches inject diverse supervisory gradients into the main model and are discarded during inference, maintaining original architecture.", "result": "Extensive experiments show effectiveness across different baselines. The approach achieves state-of-the-art results by integrating diverse one-to-many supervision without compromising model elegance or adding inference cost.", "conclusion": "Diverse one-to-many supervision can be elegantly integrated into DETR-style detectors using LoRA branches. This provides a new paradigm for enhancing detectors with rich, varied supervisory signals while maintaining architectural simplicity and zero inference overhead."}}
{"id": "2601.09428", "categories": ["cs.LG", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.09428", "abs": "https://arxiv.org/abs/2601.09428", "authors": ["Siyi Li", "Joseph G. Lambourne", "Longfei Zhang", "Pradeep Kumar Jayaraman", "Karl. D. D. Willis"], "title": "Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps", "comment": null, "summary": "We introduce a new method of generating Computer Aided Design (CAD) profiles via a sequence of simple geometric constructions including curve offsetting, rotations and intersections. These sequences start with geometry provided by a designer and build up the points and curves of the final profile step by step. We demonstrate that adding construction steps between the designer's input geometry and the final profile improves generation quality in a similar way to the introduction of a chain of thought in language models. Similar to the constraints in a parametric CAD model, the construction sequences reduce the degrees of freedom in the modeled shape to a small set of parameter values which can be adjusted by the designer, allowing parametric editing with the constructed geometry evaluated to floating point precision. In addition we show that applying reinforcement learning to the construction sequences gives further improvements over a wide range of metrics, including some which were not explicitly optimized.", "AI": {"tldr": "A new method for generating CAD profiles using geometric construction sequences that improves quality through intermediate steps, enables parametric editing, and benefits from reinforcement learning.", "motivation": "To improve CAD profile generation quality by introducing intermediate construction steps between designer input and final output, similar to chain-of-thought reasoning in language models, while enabling precise parametric editing.", "method": "Uses sequences of simple geometric constructions (curve offsetting, rotations, intersections) starting from designer-provided geometry, building up points and curves step-by-step. Applies reinforcement learning to optimize these construction sequences.", "result": "Construction steps improve generation quality similar to chain-of-thought in language models. Sequences reduce degrees of freedom to adjustable parameters for precise parametric editing. Reinforcement learning further improves performance across multiple metrics, including non-optimized ones.", "conclusion": "Geometric construction sequences provide an effective framework for CAD profile generation that combines quality improvement through intermediate reasoning steps, parametric editing capabilities, and reinforcement learning optimization for enhanced performance."}}
{"id": "2601.09248", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09248", "abs": "https://arxiv.org/abs/2601.09248", "authors": ["Ni Wang", "Zihan You", "Emre Neftci", "Thorben Schoepe"], "title": "Hybrid guided variational autoencoder for visual place recognition", "comment": null, "summary": "Autonomous agents such as cars, robots and drones need to precisely localize themselves in diverse environments, including in GPS-denied indoor environments. One approach for precise localization is visual place recognition (VPR), which estimates the place of an image based on previously seen places. State-of-the-art VPR models require high amounts of memory, making them unwieldy for mobile deployment, while more compact models lack robustness and generalization capabilities. This work overcomes these limitations for robotics using a combination of event-based vision sensors and an event-based novel guided variational autoencoder (VAE). The encoder part of our model is based on a spiking neural network model which is compatible with power-efficient low latency neuromorphic hardware. The VAE successfully disentangles the visual features of 16 distinct places in our new indoor VPR dataset with a classification performance comparable to other state-of-the-art approaches while, showing robust performance also under various illumination conditions. When tested with novel visual inputs from unknown scenes, our model can distinguish between these places, which demonstrates a high generalization capability by learning the essential features of location. Our compact and robust guided VAE with generalization capabilities poses a promising model for visual place recognition that can significantly enhance mobile robot navigation in known and unknown indoor environments.", "AI": {"tldr": "A compact visual place recognition model using event-based sensors and guided VAE with spiking neural networks for efficient mobile robot navigation in GPS-denied environments.", "motivation": "Current VPR models are either too memory-intensive for mobile deployment or lack robustness and generalization. There's a need for compact, efficient models that work well in diverse environments including GPS-denied indoor spaces.", "method": "Combines event-based vision sensors with a guided variational autoencoder (VAE) using spiking neural networks in the encoder, making it compatible with neuromorphic hardware for power efficiency.", "result": "Successfully disentangles visual features of 16 distinct places in a new indoor VPR dataset with classification performance comparable to state-of-the-art approaches. Shows robust performance under various illumination conditions and can distinguish novel visual inputs from unknown scenes.", "conclusion": "The compact, robust guided VAE with generalization capabilities is a promising model for visual place recognition that can significantly enhance mobile robot navigation in both known and unknown indoor environments."}}
{"id": "2601.09439", "categories": ["cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.09439", "abs": "https://arxiv.org/abs/2601.09439", "authors": ["Philipp Haim", "Vasilis Ntziachristos", "Torsten En\u00dflin", "Dominik J\u00fcstel"], "title": "DeepLight: A Sobolev-trained Image-to-Image Surrogate Model for Light Transport in Tissue", "comment": null, "summary": "In optoacoustic imaging, recovering the absorption coefficients of tissue by inverting the light transport remains a challenging problem. Improvements in solving this problem can greatly benefit the clinical value of optoacoustic imaging. Existing variational inversion methods require an accurate and differentiable model of this light transport. As neural surrogate models allow fast and differentiable simulations of complex physical processes, they are considered promising candidates to be used in solving such inverse problems. However, there are in general no guarantees that the derivatives of these surrogate models accurately match those of the underlying physical operator. As accurate derivatives are central to solving inverse problems, errors in the model derivative can considerably hinder high fidelity reconstructions. To overcome this limitation, we present a surrogate model for light transport in tissue that uses Sobolev training to improve the accuracy of the model derivatives. Additionally, the form of Sobolev training we used is suitable for high-dimensional models in general. Our results demonstrate that Sobolev training for a light transport surrogate model not only improves derivative accuracy but also reduces generalization error for in-distribution and out-of-distribution samples. These improvements promise to considerably enhance the utility of the surrogate model in downstream tasks, especially in solving inverse problems.", "AI": {"tldr": "Sobolev-trained neural surrogate model improves derivative accuracy for light transport simulation, enhancing optoacoustic imaging reconstruction.", "motivation": "Recovering tissue absorption coefficients in optoacoustic imaging requires accurate light transport models. Neural surrogates offer fast differentiable simulations but lack derivative accuracy guarantees, which is critical for solving inverse problems.", "method": "Developed a surrogate model for light transport in tissue using Sobolev training to improve derivative accuracy. The approach is suitable for high-dimensional models and focuses on matching both function values and derivatives to the underlying physical operator.", "result": "Sobolev training not only improves derivative accuracy but also reduces generalization error for both in-distribution and out-of-distribution samples. This enhances the surrogate model's utility for downstream inverse problems.", "conclusion": "Sobolev training significantly improves neural surrogate models for light transport simulation, promising better reconstructions in optoacoustic imaging by providing more accurate derivatives essential for solving inverse problems."}}
{"id": "2601.09255", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09255", "abs": "https://arxiv.org/abs/2601.09255", "authors": ["Yibo Zhao", "Hengjia Li", "Xiaofei He", "Boxi Wu"], "title": "PhyRPR: Training-Free Physics-Constrained Video Generation", "comment": null, "summary": "Recent diffusion-based video generation models can synthesize visually plausible videos, yet they often struggle to satisfy physical constraints. A key reason is that most existing approaches remain single-stage: they entangle high-level physical understanding with low-level visual synthesis, making it hard to generate content that require explicit physical reasoning. To address this limitation, we propose a training-free three-stage pipeline,\\textit{PhyRPR}:\\textit{Phy\\uline{R}eason}--\\textit{Phy\\uline{P}lan}--\\textit{Phy\\uline{R}efine}, which decouples physical understanding from visual synthesis. Specifically, \\textit{PhyReason} uses a large multimodal model for physical state reasoning and an image generator for keyframe synthesis; \\textit{PhyPlan} deterministically synthesizes a controllable coarse motion scaffold; and \\textit{PhyRefine} injects this scaffold into diffusion sampling via a latent fusion strategy to refine appearance while preserving the planned dynamics. This staged design enables explicit physical control during generation. Extensive experiments under physics constraints show that our method consistently improves physical plausibility and motion controllability.", "AI": {"tldr": "PhyRPR is a training-free three-stage pipeline that decouples physical reasoning from visual synthesis to improve physical plausibility in video generation.", "motivation": "Current diffusion-based video generation models often fail to satisfy physical constraints because they entangle physical understanding with visual synthesis in a single stage, making explicit physical reasoning difficult.", "method": "Three-stage pipeline: 1) PhyReason - uses large multimodal model for physical state reasoning and image generator for keyframe synthesis; 2) PhyPlan - deterministically synthesizes controllable coarse motion scaffold; 3) PhyRefine - injects scaffold into diffusion sampling via latent fusion to refine appearance while preserving planned dynamics.", "result": "Extensive experiments show the method consistently improves physical plausibility and motion controllability under physics constraints.", "conclusion": "The staged design enables explicit physical control during generation, addressing limitations of single-stage approaches that entangle physical understanding with visual synthesis."}}
{"id": "2601.09451", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.09451", "abs": "https://arxiv.org/abs/2601.09451", "authors": ["Yizhi Chen", "Ahmed Hemani"], "title": "Late Breaking Results: Quamba-SE: Soft-edge Quantizer for Activations in State Space Models", "comment": "Accepted to DATE Late Breaking Results 2026, Verona, Italy", "summary": "We propose Quamba-SE, a soft-edge quantizer for State Space Model (SSM) activation quantization. Unlike existing methods, using standard INT8 operation, Quamba-SE employs three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This preserves outlier information instead of hard clipping, while maintaining precision for other values. We evaluate on Mamba- 130M across 6 zero-shot benchmarks. Results show that Quamba- SE consistently outperforms Quamba, achieving up to +2.68% on individual benchmarks and up to +0.83% improvement in the average accuracy of 6 datasets.", "AI": {"tldr": "Quamba-SE is a soft-edge quantizer for SSM activation quantization that uses three adaptive scales instead of standard INT8, preserving outlier information while maintaining precision for normal values.", "motivation": "Existing quantization methods for State Space Models use standard INT8 operations which hard-clip outliers, losing important information. There's a need for quantization that preserves outlier information while maintaining precision for normal values.", "method": "Quamba-SE employs a soft-edge quantizer with three adaptive scales: high-precision for small values, standard scale for normal values, and low-precision for outliers. This approach avoids hard clipping of outliers while maintaining quantization efficiency.", "result": "Evaluated on Mamba-130M across 6 zero-shot benchmarks, Quamba-SE consistently outperforms Quamba, achieving up to +2.68% improvement on individual benchmarks and up to +0.83% average accuracy improvement across all 6 datasets.", "conclusion": "The soft-edge quantization approach with adaptive scales effectively preserves outlier information in SSM activation quantization, leading to improved performance over existing quantization methods while maintaining computational efficiency."}}
{"id": "2601.09262", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09262", "abs": "https://arxiv.org/abs/2601.09262", "authors": ["Maria Sdraka", "Dimitrios Michail", "Ioannis Papoutsis"], "title": "Magnifying change: Rapid burn scar mapping with multi-resolution, multi-source satellite imagery", "comment": null, "summary": "Delineating wildfire affected areas using satellite imagery remains challenging due to irregular and spatially heterogeneous spectral changes across the electromagnetic spectrum. While recent deep learning approaches achieve high accuracy when high-resolution multispectral data are available, their applicability in operational settings, where a quick delineation of the burn scar shortly after a wildfire incident is required, is limited by the trade-off between spatial resolution and temporal revisit frequency of current satellite systems. To address this limitation, we propose a novel deep learning model, namely BAM-MRCD, which employs multi-resolution, multi-source satellite imagery (MODIS and Sentinel-2) for the timely production of detailed burnt area maps with high spatial and temporal resolution. Our model manages to detect even small scale wildfires with high accuracy, surpassing similar change detection models as well as solid baselines. All data and code are available in the GitHub repository: https://github.com/Orion-AI-Lab/BAM-MRCD.", "AI": {"tldr": "BAM-MRCD is a deep learning model that uses multi-resolution satellite imagery (MODIS and Sentinel-2) to create detailed burnt area maps with both high spatial and temporal resolution for timely wildfire monitoring.", "motivation": "Current deep learning approaches for wildfire delineation face limitations in operational settings due to the trade-off between spatial resolution and temporal revisit frequency of satellite systems, making quick post-fire mapping challenging.", "method": "Proposes BAM-MRCD, a novel deep learning model that employs multi-resolution, multi-source satellite imagery from MODIS (for frequent temporal coverage) and Sentinel-2 (for high spatial resolution) to detect burnt areas.", "result": "The model successfully detects even small-scale wildfires with high accuracy, surpassing similar change detection models and solid baselines in performance.", "conclusion": "BAM-MRCD addresses the operational need for timely production of detailed burnt area maps by leveraging complementary satellite data sources, with all data and code made publicly available for reproducibility."}}
{"id": "2601.09455", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09455", "abs": "https://arxiv.org/abs/2601.09455", "authors": ["Andr\u00e9 Artelt", "Martin Olsen", "Kevin Tierney"], "title": "On the Hardness of Computing Counterfactual and Semifactual Explanations in XAI", "comment": "Accepted in Transactions on Machine Learning Research (TMLR), 2025 -- https://openreview.net/pdf?id=aELzBw0q1O", "summary": "Providing clear explanations to the choices of machine learning models is essential for these models to be deployed in crucial applications. Counterfactual and semi-factual explanations have emerged as two mechanisms for providing users with insights into the outputs of their models. We provide an overview of the computational complexity results in the literature for generating these explanations, finding that in many cases, generating explanations is computationally hard. We strengthen the argument for this considerably by further contributing our own inapproximability results showing that not only are explanations often hard to generate, but under certain assumptions, they are also hard to approximate. We discuss the implications of these complexity results for the XAI community and for policymakers seeking to regulate explanations in AI.", "AI": {"tldr": "Counterfactual and semi-factual explanations for ML models are often computationally hard to generate, with new inapproximability results showing they're also hard to approximate under certain assumptions.", "motivation": "Clear explanations of ML model decisions are crucial for deployment in critical applications. Counterfactual and semi-factual explanations provide user insights, but their computational complexity needs systematic analysis.", "method": "Literature review of computational complexity results for generating counterfactual and semi-factual explanations, plus new inapproximability results showing hardness of approximation under certain assumptions.", "result": "Generating explanations is computationally hard in many cases, and new results show they're also hard to approximate under certain assumptions, strengthening existing complexity arguments.", "conclusion": "Computational hardness of explanation generation has important implications for XAI research and AI regulation policies, highlighting practical limitations in providing certain types of explanations."}}
{"id": "2601.09263", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09263", "abs": "https://arxiv.org/abs/2601.09263", "authors": ["Yucheng Li", "Xiaofan Wang", "Junyi Wang", "Yijie Li", "Xi Zhu", "Mubai Du", "Dian Sheng", "Wei Zhang", "Fan Zhang"], "title": "BrainSegNet: A Novel Framework for Whole-Brain MRI Parcellation Enhanced by Large Models", "comment": null, "summary": "Whole-brain parcellation from MRI is a critical yet challenging task due to the complexity of subdividing the brain into numerous small, irregular shaped regions. Traditionally, template-registration methods were used, but recent advances have shifted to deep learning for faster workflows. While large models like the Segment Anything Model (SAM) offer transferable feature representations, they are not tailored for the high precision required in brain parcellation. To address this, we propose BrainSegNet, a novel framework that adapts SAM for accurate whole-brain parcellation into 95 regions. We enhance SAM by integrating U-Net skip connections and specialized modules into its encoder and decoder, enabling fine-grained anatomical precision. Key components include a hybrid encoder combining U-Net skip connections with SAM's transformer blocks, a multi-scale attention decoder with pyramid pooling for varying-sized structures, and a boundary refinement module to sharpen edges. Experimental results on the Human Connectome Project (HCP) dataset demonstrate that BrainSegNet outperforms several state-of-the-art methods, achieving higher accuracy and robustness in complex, multi-label parcellation.", "AI": {"tldr": "BrainSegNet adapts SAM for whole-brain parcellation into 95 regions using U-Net skip connections, multi-scale attention decoder, and boundary refinement, achieving state-of-the-art performance on HCP dataset.", "motivation": "Whole-brain parcellation is critical but challenging due to complex, irregular brain regions. Traditional template-registration methods are limited, and while large models like SAM offer transferable features, they lack the precision needed for brain parcellation.", "method": "BrainSegNet adapts SAM by integrating U-Net skip connections and specialized modules: 1) Hybrid encoder combining U-Net skip connections with SAM's transformer blocks, 2) Multi-scale attention decoder with pyramid pooling for varying-sized structures, 3) Boundary refinement module to sharpen edges.", "result": "Experimental results on the Human Connectome Project (HCP) dataset show BrainSegNet outperforms several state-of-the-art methods, achieving higher accuracy and robustness in complex, multi-label parcellation.", "conclusion": "BrainSegNet successfully adapts SAM for precise whole-brain parcellation, demonstrating superior performance through architectural enhancements that address the specific challenges of brain region segmentation."}}
{"id": "2601.09467", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.09467", "abs": "https://arxiv.org/abs/2601.09467", "authors": ["Tianye Li", "Qi Liu", "Hao Li", "Lei Chen", "Wencong Cheng", "Fei Zheng", "Xiangao Xia", "Ya Wang", "Gang Huang", "Weiwei Wang", "Xuan Tong", "Ziqing Zu", "Yi Fang", "Shenming Fu", "Jiang Jiang", "Haochen Li", "Mingxing Li", "Jiangjiang Xia"], "title": "Searth Transformer: A Transformer Architecture Incorporating Earth's Geospheric Physical Priors for Global Mid-Range Weather Forecasting", "comment": null, "summary": "Accurate global medium-range weather forecasting is fundamental to Earth system science. Most existing Transformer-based forecasting models adopt vision-centric architectures that neglect the Earth's spherical geometry and zonal periodicity. In addition, conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation. To address these challenges, we propose the Shifted Earth Transformer (Searth Transformer), a physics-informed architecture that incorporates zonal periodicity and meridional boundaries into window-based self-attention for physically consistent global information exchange. We further introduce a Relay Autoregressive (RAR) fine-tuning strategy that enables learning long-range atmospheric evolution under constrained memory and computational budgets. Based on these methods, we develop YanTian, a global medium-range weather forecasting model. YanTian achieves higher accuracy than the high-resolution forecast of the European Centre for Medium-Range Weather Forecasts and performs competitively with state-of-the-art AI models at one-degree resolution, while requiring roughly 200 times lower computational cost than standard autoregressive fine-tuning. Furthermore, YanTian attains a longer skillful forecast lead time for Z500 (10.3 days) than HRES (9 days). Beyond weather forecasting, this work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science.", "AI": {"tldr": "Searth Transformer introduces physics-informed architecture with zonal periodicity and meridional boundaries for global weather forecasting, plus Relay Autoregressive fine-tuning for long-range learning with low computational cost.", "motivation": "Existing Transformer-based weather models neglect Earth's spherical geometry and zonal periodicity, while conventional autoregressive training is computationally expensive and limits forecast horizons due to error accumulation.", "method": "Proposes Shifted Earth Transformer (Searth Transformer) incorporating zonal periodicity and meridional boundaries into window-based self-attention, plus Relay Autoregressive (RAR) fine-tuning strategy for learning long-range atmospheric evolution under constrained resources.", "result": "YanTian model achieves higher accuracy than ECMWF's high-resolution forecast, competitive with state-of-the-art AI models at 1-degree resolution with 200x lower computational cost than standard autoregressive fine-tuning, and attains longer skillful forecast lead time for Z500 (10.3 days vs 9 days).", "conclusion": "The work establishes a robust algorithmic foundation for predictive modeling of complex global-scale geophysical circulation systems, offering new pathways for Earth system science beyond weather forecasting."}}
{"id": "2601.09265", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09265", "abs": "https://arxiv.org/abs/2601.09265", "authors": ["Bei Huang", "Yixin Chen", "Ruijie Lu", "Gang Zeng", "Hongbin Zha", "Yuru Pei", "Siyuan Huang"], "title": "GaussianFluent: Gaussian Simulation for Dynamic Scenes with Mixed Materials", "comment": "16 pages", "summary": "3D Gaussian Splatting (3DGS) has emerged as a prominent 3D representation for high-fidelity and real-time rendering. Prior work has coupled physics simulation with Gaussians, but predominantly targets soft, deformable materials, leaving brittle fracture largely unresolved. This stems from two key obstacles: the lack of volumetric interiors with coherent textures in GS representation, and the absence of fracture-aware simulation methods for Gaussians. To address these challenges, we introduce GaussianFluent, a unified framework for realistic simulation and rendering of dynamic object states. First, it synthesizes photorealistic interiors by densifying internal Gaussians guided by generative models. Second, it integrates an optimized Continuum Damage Material Point Method (CD-MPM) to enable brittle fracture simulation at remarkably high speed. Our approach handles complex scenarios including mixed-material objects and multi-stage fracture propagation, achieving results infeasible with previous methods. Experiments clearly demonstrate GaussianFluent's capability for photo-realistic, real-time rendering with structurally consistent interiors, highlighting its potential for downstream application, such as VR and Robotics.", "AI": {"tldr": "GaussianFluent enables realistic brittle fracture simulation and rendering using 3D Gaussian Splatting by generating photorealistic interiors and integrating optimized fracture simulation.", "motivation": "Existing 3DGS-based physics simulation focuses on soft, deformable materials but lacks capability for brittle fracture due to two key obstacles: absence of volumetric interiors with coherent textures in GS representation, and lack of fracture-aware simulation methods for Gaussians.", "method": "1) Synthesizes photorealistic interiors by densifying internal Gaussians guided by generative models. 2) Integrates an optimized Continuum Damage Material Point Method (CD-MPM) to enable high-speed brittle fracture simulation. Handles mixed-material objects and multi-stage fracture propagation.", "result": "Achieves photo-realistic, real-time rendering with structurally consistent interiors. Handles complex scenarios including mixed-material objects and multi-stage fracture propagation that were infeasible with previous methods.", "conclusion": "GaussianFluent demonstrates capability for realistic simulation and rendering of dynamic object states with brittle fracture, highlighting potential for downstream applications like VR and Robotics."}}
{"id": "2601.09469", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09469", "abs": "https://arxiv.org/abs/2601.09469", "authors": ["Renqiang Luo", "Yongshuai Yang", "Huafei Huang", "Qing Qing", "Mingliang Hou", "Ziqi Xu", "Yi Yu", "Jingjing Zhou", "Feng Xia"], "title": "FairGU: Fairness-aware Graph Unlearning in Social Network", "comment": "9 pages, 2 figs, WWW 2026 accepted", "summary": "Graph unlearning has emerged as a critical mechanism for supporting sustainable and privacy-preserving social networks, enabling models to remove the influence of deleted nodes and thereby better safeguard user information. However, we observe that existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared with traditional graph learning methods. To address this gap, we introduce FairGU, a fairness-aware graph unlearning framework designed to preserve both utility and fairness during the unlearning process. FairGU integrates a dedicated fairness-aware module with effective data protection strategies, ensuring that sensitive attributes are neither inadvertently amplified nor structurally exposed when nodes are removed. Through extensive experiments on multiple real-world datasets, we demonstrate that FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in terms of both accuracy and fairness metrics. Our findings highlight a previously overlooked risk in current unlearning practices and establish FairGU as a robust and equitable solution for the next generation of socially sustainable networked systems. The codes are available at https://github.com/LuoRenqiang/FairGU.", "AI": {"tldr": "FairGU is a fairness-aware graph unlearning framework that preserves both utility and fairness when removing nodes, addressing the fairness degradation issue in existing graph unlearning methods.", "motivation": "Existing graph unlearning techniques insufficiently protect sensitive attributes, often leading to degraded algorithmic fairness compared to traditional graph learning methods, creating a gap in privacy-preserving social networks.", "method": "FairGU integrates a dedicated fairness-aware module with effective data protection strategies to ensure sensitive attributes are neither inadvertently amplified nor structurally exposed during node removal.", "result": "FairGU consistently outperforms state-of-the-art graph unlearning methods and fairness-enhanced graph learning baselines in both accuracy and fairness metrics across multiple real-world datasets.", "conclusion": "The research highlights a previously overlooked risk in current unlearning practices and establishes FairGU as a robust and equitable solution for socially sustainable networked systems."}}
{"id": "2601.09298", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09298", "abs": "https://arxiv.org/abs/2601.09298", "authors": ["Lianying Chao", "Haoran Cai", "Xubin Li", "Kai Zhang", "Sijie Wu", "Rui Xu"], "title": "Multi-Modal LLM based Image Captioning in ICT: Bridging the Gap Between General and Industry Domain", "comment": null, "summary": "In the information and communications technology (ICT) industry, training a domain-specific large language model (LLM) or constructing a retrieval-augmented generation system requires a substantial amount of high-value domain knowledge. However, the knowledge is not only hidden in the textual modality but also in the image modality. Traditional methods can parse text from domain documents but dont have image captioning ability. Multi-modal LLM (MLLM) can understand images, but they do not have sufficient domain knowledge. To address the above issues, this paper proposes a multi-stage progressive training strategy to train a Domain-specific Image Captioning Model (DICModel) in ICT, and constructs a standard evaluation system to validate the performance of DICModel. Specifically, this work first synthesizes about 7K image-text pairs by combining the Mermaid tool and LLMs, which are used for the first-stage supervised-fine-tuning (SFT) of DICModel. Then, ICT-domain experts manually annotate about 2K image-text pairs for the second-stage SFT of DICModel. Finally, experts and LLMs jointly synthesize about 1.5K visual question answering data for the instruction-based SFT. Experimental results indicate that our DICModel with only 7B parameters performs better than other state-of-the-art models with 32B parameters. Compared to the SOTA models with 7B and 32B parameters, our DICModel increases the BLEU metric by approximately 56.8% and 20.8%, respectively. On the objective questions constructed by ICT domain experts, our DICModel outperforms Qwen2.5-VL 32B by 1% in terms of accuracy rate. In summary, this work can efficiently and accurately extract the logical text from images, which is expected to promote the development of multimodal models in the ICT domain.", "AI": {"tldr": "A multi-stage training strategy creates a domain-specific image captioning model (DICModel) for ICT that outperforms larger SOTA models by efficiently extracting logical text from technical images.", "motivation": "Domain knowledge in ICT exists in both text and images, but current methods lack image captioning ability for domain-specific content, while multi-modal LLMs lack sufficient domain expertise.", "method": "Three-stage progressive training: 1) 7K synthetic image-text pairs (Mermaid+LLMs) for initial SFT, 2) 2K expert-annotated pairs for domain refinement, 3) 1.5K VQA data (expert+LLM) for instruction tuning.", "result": "7B DICModel outperforms 32B SOTA models: +56.8% BLEU vs 7B models, +20.8% vs 32B models, and beats Qwen2.5-VL 32B by 1% accuracy on ICT expert questions.", "conclusion": "The approach efficiently extracts logical text from ICT images, enabling better domain knowledge extraction and promoting multimodal development in specialized technical domains."}}
{"id": "2601.09473", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09473", "abs": "https://arxiv.org/abs/2601.09473", "authors": ["Oliver Bolton", "Aakanksha", "Arash Ahmadian", "Sara Hooker", "Marzieh Fadaee", "Beyza Ermis"], "title": "SimMerge: Learning to Select Merge Operators from Similarity Signals", "comment": null, "summary": "Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the best merge. In this work, we provide an alternative by introducing \\simmerge{}, \\emph{a predictive merge-selection method} that selects the best merge using inexpensive, task-agnostic similarity signals between models. From a small set of unlabeled probes, we compute functional and structural features and use them to predict the performance of a given 2-way merge. Using these predictions, \\simmerge{} selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. We demonstrate that we surpass standard merge-operator performance on 2-way merges of 7B-parameter LLMs, and that \\simmerge{} generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, we present a bandit variant that supports adding new tasks, models, and operators on the fly. Our results suggest that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.", "AI": {"tldr": "SimMerge is a predictive method that uses task-agnostic similarity signals to select optimal model merges without expensive evaluation loops, scaling to large models and multi-way merges.", "motivation": "Model merging is valuable for LLM development but becomes difficult at scale due to the need to choose merge operators, select models, and determine merge order, requiring expensive merge-and-evaluate searches.", "method": "SimMerge computes functional and structural features from unlabeled probes, uses these to predict 2-way merge performance, and selects optimal merge operators, model subsets, and merge orders without evaluation loops.", "result": "SimMerge surpasses standard merge-operator performance on 7B-parameter LLM merges, generalizes to multi-way merges and 111B-parameter merges without retraining, and supports dynamic addition of tasks/models/operators via a bandit variant.", "conclusion": "Learning how to merge via predictive methods like SimMerge provides a practical, scalable approach to model composition when dealing with large checkpoint catalogs and limited evaluation budgets."}}
{"id": "2601.09316", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09316", "abs": "https://arxiv.org/abs/2601.09316", "authors": ["Xinming Fang", "Chaoyan Huang", "Juncheng Li", "Jun Wang", "Jun Shi", "Guixu Zhang"], "title": "Frequency Error-Guided Under-sampling Optimization for Multi-Contrast MRI Reconstruction", "comment": "44 pages, 12 figures, 7 tables", "summary": "Magnetic resonance imaging (MRI) plays a vital role in clinical diagnostics, yet it remains hindered by long acquisition times and motion artifacts. Multi-contrast MRI reconstruction has emerged as a promising direction by leveraging complementary information from fully-sampled reference scans. However, existing approaches suffer from three major limitations: (1) superficial reference fusion strategies, such as simple concatenation, (2) insufficient utilization of the complementary information provided by the reference contrast, and (3) fixed under-sampling patterns. We propose an efficient and interpretable frequency error-guided reconstruction framework to tackle these issues. We first employ a conditional diffusion model to learn a Frequency Error Prior (FEP), which is then incorporated into a unified framework for jointly optimizing both the under-sampling pattern and the reconstruction network. The proposed reconstruction model employs a model-driven deep unfolding framework that jointly exploits frequency- and image-domain information. In addition, a spatial alignment module and a reference feature decomposition strategy are incorporated to improve reconstruction quality and bridge model-based optimization with data-driven learning for improved physical interpretability. Comprehensive validation across multiple imaging modalities, acceleration rates (4-30x), and sampling schemes demonstrates consistent superiority over state-of-the-art methods in both quantitative metrics and visual quality. All codes are available at https://github.com/fangxinming/JUF-MRI.", "AI": {"tldr": "Proposes JUF-MRI: a frequency error-guided reconstruction framework for multi-contrast MRI that jointly optimizes under-sampling patterns and reconstruction using diffusion models and deep unfolding.", "motivation": "MRI suffers from long acquisition times and motion artifacts. Existing multi-contrast reconstruction methods have limitations: superficial reference fusion, insufficient complementary information utilization, and fixed under-sampling patterns.", "method": "Uses conditional diffusion model to learn Frequency Error Prior (FEP), incorporates it into unified framework for joint optimization of under-sampling patterns and reconstruction. Employs model-driven deep unfolding with spatial alignment module and reference feature decomposition strategy.", "result": "Demonstrates consistent superiority over state-of-the-art methods across multiple imaging modalities, acceleration rates (4-30x), and sampling schemes in both quantitative metrics and visual quality.", "conclusion": "Proposed JUF-MRI framework effectively addresses limitations of existing multi-contrast MRI reconstruction methods, providing efficient and interpretable reconstruction with improved physical interpretability."}}
{"id": "2601.09474", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.09474", "abs": "https://arxiv.org/abs/2601.09474", "authors": ["Weiguo Gao", "Ming Li", "Qianxiao Li"], "title": "Terminally constrained flow-based generative models from an optimal control perspective", "comment": "59 pages, 9 figures", "summary": "We address the problem of sampling from terminally constrained distributions with pre-trained flow-based generative models through an optimal control formulation. Theoretically, we characterize the value function by a Hamilton-Jacobi-Bellman equation and derive the optimal feedback control as the minimizer of the associated Hamiltonian. We show that as the control penalty increases, the controlled process recovers the reference distribution, while as the penalty vanishes, the terminal law converges to a generalized Wasserstein projection onto the constraint manifold. Algorithmically, we introduce Terminal Optimal Control with Flow-based models (TOCFlow), a geometry-aware sampling-time guidance method for pre-trained flows. Solving the control problem in a terminal co-moving frame that tracks reference trajectories yields a closed-form scalar damping factor along the Riemannian gradient, capturing second-order curvature effects without matrix inversions. TOCFlow therefore matches the geometric consistency of Gauss-Newton updates at the computational cost of standard gradient guidance. We evaluate TOCFlow on three high-dimensional scientific tasks spanning equality, inequality, and global statistical constraints, namely Darcy flow, constrained trajectory planning, and turbulence snapshot generation with Kolmogorov spectral scaling. Across all settings, TOCFlow improves constraint satisfaction over Euclidean guidance and projection baselines while preserving the reference model's generative quality.", "AI": {"tldr": "TOCFlow: Optimal control method for sampling from terminally constrained distributions using pre-trained flow models, with geometry-aware guidance that matches Gauss-Newton updates at gradient guidance cost.", "motivation": "Need to sample from constrained distributions using pre-trained flow models while maintaining generative quality and satisfying terminal constraints (equality, inequality, statistical constraints).", "method": "Formulate as optimal control problem with Hamilton-Jacobi-Bellman equation. TOCFlow uses terminal co-moving frame tracking reference trajectories, yielding closed-form scalar damping factor along Riemannian gradient without matrix inversions.", "result": "Theoretical: As control penalty increases, recovers reference distribution; as penalty vanishes, converges to generalized Wasserstein projection. Empirical: TOCFlow improves constraint satisfaction over Euclidean guidance and projection baselines across Darcy flow, trajectory planning, and turbulence generation tasks.", "conclusion": "TOCFlow provides geometry-aware sampling-time guidance for pre-trained flows that matches Gauss-Newton geometric consistency at standard gradient guidance computational cost, effective for high-dimensional scientific tasks with various constraints."}}
{"id": "2601.09322", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09322", "abs": "https://arxiv.org/abs/2601.09322", "authors": ["Laure Ciernik", "Marco Morik", "Lukas Thede", "Luca Eyring", "Shinichi Nakajima", "Zeynep Akata", "Lukas Muttenthaler"], "title": "Beyond the final layer: Attentive multilayer fusion for vision transformers", "comment": null, "summary": "With the rise of large-scale foundation models, efficiently adapting them to downstream tasks remains a central challenge. Linear probing, which freezes the backbone and trains a lightweight head, is computationally efficient but often restricted to last-layer representations. We show that task-relevant information is distributed across the network hierarchy rather than solely encoded in any of the last layers. To leverage this distribution of information, we apply an attentive probing mechanism that dynamically fuses representations from all layers of a Vision Transformer. This mechanism learns to identify the most relevant layers for a target task and combines low-level structural cues with high-level semantic abstractions. Across 20 diverse datasets and multiple pretrained foundation models, our method achieves consistent, substantial gains over standard linear probes. Attention heatmaps further reveal that tasks different from the pre-training domain benefit most from intermediate representations. Overall, our findings underscore the value of intermediate layer information and demonstrate a principled, task aware approach for unlocking their potential in probing-based adaptation.", "AI": {"tldr": "Attentive probing mechanism that fuses representations from all ViT layers outperforms standard linear probing by leveraging distributed task-relevant information across network hierarchy.", "motivation": "Linear probing is computationally efficient but limited to last-layer representations, while task-relevant information is actually distributed across all network layers rather than concentrated in final layers.", "method": "Attentive probing mechanism that dynamically fuses representations from all layers of a Vision Transformer, learning to identify the most relevant layers for each target task and combining low-level structural cues with high-level semantic abstractions.", "result": "Across 20 diverse datasets and multiple pretrained foundation models, the method achieves consistent, substantial gains over standard linear probes. Attention heatmaps show tasks different from pre-training domain benefit most from intermediate representations.", "conclusion": "Intermediate layer information is valuable for probing-based adaptation, and the proposed attentive probing provides a principled, task-aware approach to unlock their potential."}}
{"id": "2601.09491", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09491", "abs": "https://arxiv.org/abs/2601.09491", "authors": ["Beatrice Ceccanti", "Mattia Galanti", "Ivo Roghair", "Martin van Sint Annaland"], "title": "Deep Operator Networks for Surrogate Modeling of Cyclic Adsorption Processes with Varying Initial Conditions", "comment": "36 pages, 11 figures", "summary": "Deep Operator Networks are emerging as fundamental tools among various neural network types to learn mappings between function spaces, and have recently gained attention due to their ability to approximate nonlinear operators. In particular, DeepONets offer a natural formulation for PDE solving, since the solution of a partial differential equation can be interpreted as an operator mapping an initial condition to its corresponding solution field. In this work, we applied DeepONets in the context of process modeling for adsorption technologies, to assess their feasibility as surrogates for cyclic adsorption process simulation and optimization. The goal is to accelerate convergence of cyclic processes such as Temperature-Vacuum Swing Adsorption (TVSA), which require repeated solution of transient PDEs, which are computationally expensive. Since each step of a cyclic adsorption process starts from the final state of the preceding step, effective surrogate modeling requires generalization across a wide range of initial conditions. The governing equations exhibit steep traveling fronts, providing a demanding benchmark for operator learning. To evaluate functional generalization under these conditions, we construct a mixed training dataset composed of heterogeneous initial conditions and train DeepONets to approximate the corresponding solution operators. The trained models are then tested on initial conditions outside the parameter ranges used during training, as well as on completely unseen functional forms. The results demonstrate accurate predictions both within and beyond the training distribution, highlighting DeepONets as potential efficient surrogates for accelerating cyclic adsorption simulations and optimization workflows.", "AI": {"tldr": "DeepONets are applied as efficient surrogates for cyclic adsorption process simulation and optimization, demonstrating accurate predictions even beyond training distributions for challenging PDEs with steep traveling fronts.", "motivation": "Cyclic adsorption processes like TVSA require repeated solution of computationally expensive transient PDEs. There's a need for efficient surrogate models to accelerate convergence and optimization workflows for these cyclic processes.", "method": "Applied DeepONets to learn solution operators for adsorption process PDEs. Constructed mixed training dataset with heterogeneous initial conditions to evaluate functional generalization. Trained models to approximate solution operators and tested on initial conditions outside training parameter ranges and unseen functional forms.", "result": "DeepONets demonstrated accurate predictions both within and beyond the training distribution. They successfully handled challenging PDEs with steep traveling fronts and showed potential as efficient surrogates for cyclic adsorption simulations.", "conclusion": "DeepONets are promising efficient surrogates for accelerating cyclic adsorption process simulation and optimization workflows, showing strong generalization capabilities even for demanding operator learning benchmarks."}}
{"id": "2601.09350", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09350", "abs": "https://arxiv.org/abs/2601.09350", "authors": ["Mingyu Jeon", "Sungjin Han", "Jinkwon Hwang", "Minchol Kwon", "Jonghee Kim", "Junyeong Kim"], "title": "See More, Store Less: Memory-Efficient Resolution for Video Moment Retrieval", "comment": null, "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have improved image recognition and reasoning, but video-related tasks remain challenging due to memory constraints from dense frame processing. Existing Video Moment Retrieval (VMR) methodologies rely on sparse frame sampling, risking potential information loss, especially in lengthy videos. We propose SMORE (See MORE, store less), a framework that enhances memory efficiency while maintaining high information resolution. SMORE (1) uses query-guided captions to encode semantics aligned with user intent, (2) applies query-aware importance modulation to highlight relevant segments, and (3) adaptively compresses frames to preserve key content while reducing redundancy. This enables efficient video understanding without exceeding memory budgets. Experimental validation reveals that SMORE achieves state-of-the-art performance on QVHighlights, Charades-STA, and ActivityNet-Captions benchmarks.", "AI": {"tldr": "SMORE is a memory-efficient video moment retrieval framework that uses query-guided captions, importance modulation, and adaptive frame compression to handle long videos without information loss.", "motivation": "Video Moment Retrieval faces memory constraints from dense frame processing, forcing existing methods to use sparse sampling which risks information loss, especially in long videos. There's a need for memory-efficient approaches that maintain high information resolution.", "method": "SMORE uses three key techniques: (1) query-guided captions to encode semantics aligned with user intent, (2) query-aware importance modulation to highlight relevant segments, and (3) adaptive frame compression to preserve key content while reducing redundancy.", "result": "SMORE achieves state-of-the-art performance on QVHighlights, Charades-STA, and ActivityNet-Captions benchmarks, demonstrating superior memory efficiency and retrieval accuracy.", "conclusion": "SMORE successfully addresses memory constraints in video moment retrieval by maintaining high information resolution through intelligent compression and query-aware processing, enabling efficient video understanding without exceeding memory budgets."}}
{"id": "2601.09495", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09495", "abs": "https://arxiv.org/abs/2601.09495", "authors": ["Florent De Geeter", "Gaspard Lambrechts", "Damien Ernst", "Guillaume Drion"], "title": "Parallelizable memory recurrent units", "comment": "19 pages, 12 figures. This work has been the subject of a patent application (Number: EP26151077). This work has been submitted to the IEEE for possible publication", "summary": "With the emergence of massively parallel processing units, parallelization has become a desirable property for new sequence models. The ability to parallelize the processing of sequences with respect to the sequence length during training is one of the main factors behind the uprising of the Transformer architecture. However, Transformers lack efficiency at sequence generation, as they need to reprocess all past timesteps at every generation step. Recently, state-space models (SSMs) emerged as a more efficient alternative. These new kinds of recurrent neural networks (RNNs) keep the efficient update of the RNNs while gaining parallelization by getting rid of nonlinear dynamics (or recurrence). SSMs can reach state-of-the art performance through the efficient training of potentially very large networks, but still suffer from limited representation capabilities. In particular, SSMs cannot exhibit persistent memory, or the capacity of retaining information for an infinite duration, because of their monostability. In this paper, we introduce a new family of RNNs, the memory recurrent units (MRUs), that combine the persistent memory capabilities of nonlinear RNNs with the parallelizable computations of SSMs. These units leverage multistability as a source of persistent memory, while getting rid of transient dynamics for efficient computations. We then derive a specific implementation as proof-of-concept: the bistable memory recurrent unit (BMRU). This new RNN is compatible with the parallel scan algorithm. We show that BMRU achieves good results in tasks with long-term dependencies, and can be combined with state-space models to create hybrid networks that are parallelizable and have transient dynamics as well as persistent memory.", "AI": {"tldr": "The paper introduces Memory Recurrent Units (MRUs), a new family of RNNs that combine persistent memory capabilities of nonlinear RNNs with parallelizable computations of state-space models, addressing limitations of both Transformers and SSMs.", "motivation": "Transformers are parallelizable during training but inefficient at sequence generation, while state-space models (SSMs) are efficient and parallelizable but lack persistent memory capabilities due to their monostability. There's a need for models that combine the best of both worlds: parallelizable computations with persistent memory.", "method": "Introduces Memory Recurrent Units (MRUs) that leverage multistability for persistent memory while eliminating transient dynamics for efficient computation. Specifically presents Bistable Memory Recurrent Unit (BMRU) as a proof-of-concept implementation that is compatible with the parallel scan algorithm.", "result": "BMRU achieves good results in tasks with long-term dependencies and can be combined with SSMs to create hybrid networks that are both parallelizable and have both transient dynamics and persistent memory capabilities.", "conclusion": "MRUs successfully bridge the gap between nonlinear RNNs with persistent memory and parallelizable state-space models, offering a new architecture that combines the strengths of both approaches for efficient sequence processing with long-term memory retention."}}
{"id": "2601.09352", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09352", "abs": "https://arxiv.org/abs/2601.09352", "authors": ["Wei Liu", "Xing Deng", "Haijian Shao", "Yingtao Jiang"], "title": "Spectral Complex Autoencoder Pruning: A Fidelity-Guided Criterion for Extreme Structured Channel Compression", "comment": "17 pages, 9 figures", "summary": "We propose Spectral Complex Autoencoder Pruning (SCAP), a reconstruction-based criterion that measures functional redundancy at the level of individual output channels. For each convolutional layer, we construct a complex interaction field by pairing the full multi-channel input activation as the real part with a single output-channel activation (spatially aligned and broadcast across input channels) as the imaginary part. We transform this complex field to the frequency domain and train a low-capacity autoencoder to reconstruct normalized spectra. Channels whose spectra are reconstructed with high fidelity are interpreted as lying close to a low-dimensional manifold captured by the autoencoder and are therefore more compressible; conversely, channels with low fidelity are retained as they encode information that cannot be compactly represented by the learned manifold. This yields an importance score (optionally fused with the filter L1 norm) that supports simple threshold-based pruning and produces a structurally consistent pruned network. On VGG16 trained on CIFAR-10, at a fixed threshold of 0.6, we obtain 90.11% FLOP reduction and 96.30% parameter reduction with an absolute Top-1 accuracy drop of 1.67% from a 93.44% baseline after fine-tuning, demonstrating that spectral reconstruction fidelity of complex interaction fields is an effective proxy for channel-level redundancy under aggressive compression.", "AI": {"tldr": "SCAP uses spectral reconstruction fidelity of complex interaction fields to measure channel redundancy for neural network pruning, achieving 90% FLOP reduction with minimal accuracy drop.", "motivation": "Existing pruning methods often use simple heuristics like weight magnitude, which may not capture functional redundancy at the channel level. There's a need for more sophisticated criteria that measure how much information each channel contributes to the network's overall function.", "method": "For each convolutional layer, create complex interaction fields pairing multi-channel input activations (real part) with single output-channel activations (imaginary part). Transform to frequency domain, train low-capacity autoencoder to reconstruct normalized spectra. Channels with high reconstruction fidelity are considered redundant and prunable.", "result": "On VGG16/CIFAR-10: 90.11% FLOP reduction, 96.30% parameter reduction with only 1.67% absolute Top-1 accuracy drop from 93.44% baseline after fine-tuning.", "conclusion": "Spectral reconstruction fidelity of complex interaction fields effectively measures channel-level redundancy, enabling aggressive compression while maintaining accuracy through structurally consistent pruning."}}
{"id": "2601.09522", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09522", "abs": "https://arxiv.org/abs/2601.09522", "authors": ["Badr-Eddine Marani", "Julio Silva-Rodriguez", "Ismail Ben Ayed", "Maria Vakalopoulou", "Stergios Christodoulidis", "Jose Dolz"], "title": "Class Adaptive Conformal Training", "comment": null, "summary": "Deep neural networks have achieved remarkable success across a variety of tasks, yet they often suffer from unreliable probability estimates. As a result, they can be overconfident in their predictions. Conformal Prediction (CP) offers a principled framework for uncertainty quantification, yielding prediction sets with rigorous coverage guarantees. Existing conformal training methods optimize for overall set size, but shaping the prediction sets in a class-conditional manner is not straightforward and typically requires prior knowledge of the data distribution. In this work, we introduce Class Adaptive Conformal Training (CaCT), which formulates conformal training as an augmented Lagrangian optimization problem that adaptively learns to shape prediction sets class-conditionally without making any distributional assumptions. Experiments on multiple benchmark datasets, including standard and long-tailed image recognition as well as text classification, demonstrate that CaCT consistently outperforms prior conformal training methods, producing significantly smaller and more informative prediction sets while maintaining the desired coverage guarantees.", "AI": {"tldr": "CaCT introduces class-adaptive conformal training that learns to shape prediction sets class-conditionally without distributional assumptions, outperforming prior methods with smaller, more informative sets while maintaining coverage guarantees.", "motivation": "Deep neural networks often provide unreliable probability estimates and can be overconfident. While Conformal Prediction offers principled uncertainty quantification with coverage guarantees, existing methods optimize for overall set size but struggle with class-conditional shaping, typically requiring prior knowledge of data distribution.", "method": "CaCT (Class Adaptive Conformal Training) formulates conformal training as an augmented Lagrangian optimization problem that adaptively learns to shape prediction sets class-conditionally without making any distributional assumptions.", "result": "Experiments on multiple benchmark datasets (standard and long-tailed image recognition, text classification) show CaCT consistently outperforms prior conformal training methods, producing significantly smaller and more informative prediction sets while maintaining desired coverage guarantees.", "conclusion": "CaCT provides an effective approach for class-adaptive conformal training that learns optimal prediction set shapes without distributional assumptions, offering improved uncertainty quantification for deep neural networks across diverse tasks."}}
{"id": "2601.09410", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09410", "abs": "https://arxiv.org/abs/2601.09410", "authors": ["Sangjun Han", "Youngmi Hur"], "title": "Detail Loss in Super-Resolution Models Based on the Laplacian Pyramid and Repeated Upscaling and Downscaling Process", "comment": "Accepted for publication in IET Image Processing. This is the authors' final accepted manuscript", "summary": "With advances in artificial intelligence, image processing has gained significant interest. Image super-resolution is a vital technology closely related to real-world applications, as it enhances the quality of existing images. Since enhancing fine details is crucial for the super-resolution task, pixels that contribute to high-frequency information should be emphasized. This paper proposes two methods to enhance high-frequency details in super-resolution images: a Laplacian pyramid-based detail loss and a repeated upscaling and downscaling process. Total loss with our detail loss guides a model by separately generating and controlling super-resolution and detail images. This approach allows the model to focus more effectively on high-frequency components, resulting in improved super-resolution images. Additionally, repeated upscaling and downscaling amplify the effectiveness of the detail loss by extracting diverse information from multiple low-resolution features. We conduct two types of experiments. First, we design a CNN-based model incorporating our methods. This model achieves state-of-the-art results, surpassing all currently available CNN-based and even some attention-based models. Second, we apply our methods to existing attention-based models on a small scale. In all our experiments, attention-based models adding our detail loss show improvements compared to the originals. These results demonstrate our approaches effectively enhance super-resolution images across different model structures.", "AI": {"tldr": "The paper proposes two novel methods for enhancing high-frequency details in image super-resolution: a Laplacian pyramid-based detail loss and a repeated upscaling/downscaling process, which together improve SR performance across both CNN-based and attention-based models.", "motivation": "Image super-resolution is crucial for real-world applications, and enhancing fine details (high-frequency information) is particularly important for improving image quality. Current methods need better mechanisms to emphasize pixels that contribute to high-frequency details.", "method": "Two main methods: 1) Laplacian pyramid-based detail loss that guides models by separately generating and controlling super-resolution and detail images, 2) repeated upscaling and downscaling process that amplifies detail loss effectiveness by extracting diverse information from multiple low-resolution features.", "result": "The CNN-based model incorporating these methods achieves state-of-the-art results, surpassing all available CNN-based and some attention-based models. When applied to existing attention-based models, the detail loss consistently improves performance compared to original models.", "conclusion": "The proposed approaches effectively enhance super-resolution images across different model structures, demonstrating that focusing on high-frequency components through specialized loss functions and processing techniques leads to significant improvements in SR quality."}}
{"id": "2601.09527", "categories": ["cs.LG", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.09527", "abs": "https://arxiv.org/abs/2601.09527", "authors": ["Jonathan Knoop", "Hendrik Holtmann"], "title": "Private LLM Inference on Consumer Blackwell GPUs: A Practical Guide for Cost-Effective Local Deployment in SMEs", "comment": "15 pages, 18 tables, 7 figures. Includes link to GitHub repository and Docker image for reproducibility", "summary": "SMEs increasingly seek alternatives to cloud LLM APIs, which raise data privacy concerns. Dedicated cloud GPU instances offer improved privacy but with limited guarantees and ongoing costs, while professional on-premise hardware (A100, H100) remains prohibitively expensive. We present a systematic evaluation of NVIDIA's Blackwell consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) for production LLM inference, benchmarking four open-weight models (Qwen3-8B, Gemma3-12B, Gemma3-27B, GPT-OSS-20B) across 79 configurations spanning quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs. The RTX 5090 delivers 3.5-4.6x higher throughput than the 5060 Ti with 21x lower latency for RAG, but budget GPUs achieve the highest throughput-per-dollar for API workloads with sub-second latency. NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss. Self-hosted inference costs $0.001-0.04 per million tokens (electricity only), which is 40-200x cheaper than budget-tier cloud APIs, with hardware breaking even in under four months at moderate volume (30M tokens/day). Our results show that consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG, where high-end GPUs remain essential. We provide deployment guidance and release all benchmark data for reproducible SME-scale deployments.", "AI": {"tldr": "Consumer GPUs (RTX 5060 Ti, 5070 Ti, 5090) offer cost-effective, privacy-preserving LLM inference for SMEs, with RTX 5090 providing 3.5-4.6x higher throughput than 5060 Ti and self-hosted costs 40-200x cheaper than cloud APIs.", "motivation": "SMEs need alternatives to cloud LLM APIs due to data privacy concerns, while dedicated cloud GPU instances offer limited privacy guarantees and ongoing costs, and professional on-premise hardware (A100, H100) is too expensive.", "method": "Systematic evaluation of NVIDIA Blackwell consumer GPUs for production LLM inference, benchmarking four open-weight models across 79 configurations including quantization formats (BF16, W4A16, NVFP4, MXFP4), context lengths (8k-64k), and three workloads: RAG, multi-LoRA agentic serving, and high-concurrency APIs.", "result": "RTX 5090 delivers 3.5-4.6x higher throughput than 5060 Ti with 21x lower latency for RAG; budget GPUs achieve highest throughput-per-dollar for API workloads; NVFP4 quantization provides 1.6x throughput over BF16 with 41% energy reduction and only 2-4% quality loss; self-hosted inference costs $0.001-0.04 per million tokens (electricity only), 40-200x cheaper than cloud APIs.", "conclusion": "Consumer GPUs can reliably replace cloud inference for most SME workloads, except latency-critical long-context RAG where high-end GPUs remain essential; hardware breaks even in under four months at moderate volume (30M tokens/day)."}}
{"id": "2601.09416", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09416", "abs": "https://arxiv.org/abs/2601.09416", "authors": ["Yaxi Chen", "Zi Ye", "Shaheer U. Saeed", "Oliver Yu", "Simin Ni", "Jie Huang", "Yipeng Hu"], "title": "Radiomics-Integrated Deep Learning with Hierarchical Loss for Osteosarcoma Histology Classification", "comment": null, "summary": "Osteosarcoma (OS) is an aggressive primary bone malignancy. Accurate histopathological assessment of viable versus non-viable tumor regions after neoadjuvant chemotherapy is critical for prognosis and treatment planning, yet manual evaluation remains labor-intensive, subjective, and prone to inter-observer variability. Recent advances in digital pathology have enabled automated necrosis quantification. Evaluating on test data, independently sampled on patient-level, revealed that the deep learning model performance dropped significantly from the tile-level generalization ability reported in previous studies. First, this work proposes the use of radiomic features as additional input in model training. We show that, despite that they are derived from the images, such a multimodal input effectively improved the classification performance, in addition to its added benefits in interpretability. Second, this work proposes to optimize two binary classification tasks with hierarchical classes (i.e. tumor-vs-non-tumor and viable-vs-non-viable), as opposed to the alternative ``flat'' three-class classification task (i.e. non-tumor, non-viable tumor, viable tumor), thereby enabling a hierarchical loss. We show that such a hierarchical loss, with trainable weightings between the two tasks, the per-class performance can be improved significantly. Using the TCIA OS Tumor Assessment dataset, we experimentally demonstrate the benefits from each of the proposed new approaches and their combination, setting a what we consider new state-of-the-art performance on this open dataset for this application. Code and trained models: https://github.com/YaxiiC/RadiomicsOS.git.", "AI": {"tldr": "Deep learning model for osteosarcoma necrosis quantification using radiomic features and hierarchical classification improves performance over previous methods.", "motivation": "Manual histopathological assessment of viable vs non-viable osteosarcoma tumor regions after chemotherapy is labor-intensive, subjective, and prone to variability. Previous deep learning models show significant performance drop when evaluated on patient-level test data compared to tile-level results.", "method": "Two main innovations: 1) Incorporation of radiomic features as multimodal input alongside images to improve classification and interpretability. 2) Hierarchical classification approach with two binary tasks (tumor-vs-non-tumor and viable-vs-non-viable) using trainable weighted hierarchical loss, instead of flat three-class classification.", "result": "The proposed approaches significantly improve classification performance, setting new state-of-the-art on the TCIA OS Tumor Assessment dataset. Radiomic features enhance both performance and interpretability, while hierarchical loss improves per-class performance.", "conclusion": "Combining radiomic features with hierarchical classification effectively addresses the patient-level generalization challenge in osteosarcoma necrosis quantification, providing more reliable automated assessment for prognosis and treatment planning."}}
{"id": "2601.09579", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.09579", "abs": "https://arxiv.org/abs/2601.09579", "authors": ["Fiona Murphy", "Alessio Benavoli"], "title": "Constraint- and Score-Based Nonlinear Granger Causality Discovery with Kernels", "comment": null, "summary": "Kernel-based methods are used in the context of Granger Causality to enable the identification of nonlinear causal relationships between time series variables. In this paper, we show that two state of the art kernel-based Granger Causality (GC) approaches can be theoretically unified under the framework of Kernel Principal Component Regression (KPCR), and introduce a method based on this unification, demonstrating that this approach can improve causal identification. Additionally, we introduce a Gaussian Process score-based model with Smooth Information Criterion penalisation on the marginal likelihood, and demonstrate improved performance over existing state of the art time-series nonlinear causal discovery methods. Furthermore, we propose a contemporaneous causal identification algorithm, fully based on GC, using the proposed score-based $GP_{SIC}$ method, and compare its performance to a state of the art contemporaneous time series causal discovery algorithm.", "AI": {"tldr": "Unifies kernel-based Granger Causality methods under KPCR framework, introduces Gaussian Process score-based model with SIC penalization, and proposes contemporaneous causal identification algorithm.", "motivation": "To improve nonlinear causal discovery in time series by unifying existing kernel-based Granger Causality approaches and developing more effective methods for identifying both lagged and contemporaneous causal relationships.", "method": "1) Theoretical unification of kernel-based GC methods under Kernel Principal Component Regression (KPCR) framework. 2) Introduction of Gaussian Process score-based model with Smooth Information Criterion (SIC) penalization on marginal likelihood. 3) Development of contemporaneous causal identification algorithm using the proposed GP_SIC method.", "result": "The unified KPCR-based approach improves causal identification compared to existing kernel-based GC methods. The GP_SIC method demonstrates improved performance over state-of-the-art nonlinear causal discovery methods. The contemporaneous causal identification algorithm performs comparably to state-of-the-art contemporaneous time series causal discovery algorithms.", "conclusion": "The paper successfully unifies kernel-based Granger Causality methods, introduces improved Gaussian Process-based approaches for nonlinear causal discovery, and extends Granger Causality to contemporaneous causal identification, advancing the field of time series causal analysis."}}
{"id": "2601.09430", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09430", "abs": "https://arxiv.org/abs/2601.09430", "authors": ["Rui Zhu", "Xin Shen", "Shuchen Wu", "Chenxi Miao", "Xin Yu", "Yang Li", "Weikang Li", "Deguo Xia", "Jizhou Huang"], "title": "Video-MSR: Benchmarking Multi-hop Spatial Reasoning Capabilities of MLLMs", "comment": null, "summary": "Spatial reasoning has emerged as a critical capability for Multimodal Large Language Models (MLLMs), drawing increasing attention and rapid advancement. However, existing benchmarks primarily focus on single-step perception-to-judgment tasks, leaving scenarios requiring complex visual-spatial logical chains significantly underexplored. To bridge this gap, we introduce Video-MSR, the first benchmark specifically designed to evaluate Multi-hop Spatial Reasoning (MSR) in dynamic video scenarios. Video-MSR systematically probes MSR capabilities through four distinct tasks: Constrained Localization, Chain-based Reference Retrieval, Route Planning, and Counterfactual Physical Deduction. Our benchmark comprises 3,052 high-quality video instances with 4,993 question-answer pairs, constructed via a scalable, visually-grounded pipeline combining advanced model generation with rigorous human verification. Through a comprehensive evaluation of 20 state-of-the-art MLLMs, we uncover significant limitations, revealing that while models demonstrate proficiency in surface-level perception, they exhibit distinct performance drops in MSR tasks, frequently suffering from spatial disorientation and hallucination during multi-step deductions. To mitigate these shortcomings and empower models with stronger MSR capabilities, we further curate MSR-9K, a specialized instruction-tuning dataset, and fine-tune Qwen-VL, achieving a +7.82% absolute improvement on Video-MSR. Our results underscore the efficacy of multi-hop spatial instruction data and establish Video-MSR as a vital foundation for future research. The code and data will be available at https://github.com/ruiz-nju/Video-MSR.", "AI": {"tldr": "Video-MSR is a new benchmark for evaluating multi-hop spatial reasoning in videos, revealing current MLLMs' limitations in complex spatial reasoning despite good surface perception.", "motivation": "Existing benchmarks focus on single-step perception-to-judgment tasks, leaving complex visual-spatial logical chains underexplored. There's a need to evaluate multi-hop spatial reasoning in dynamic video scenarios.", "method": "Created Video-MSR benchmark with 3,052 video instances and 4,993 QA pairs using scalable pipeline combining model generation with human verification. Evaluated 20 state-of-the-art MLLMs and created MSR-9K instruction-tuning dataset to improve Qwen-VL.", "result": "Models show proficiency in surface-level perception but significant performance drops in MSR tasks, suffering from spatial disorientation and hallucination. Fine-tuning with MSR-9K improved Qwen-VL by +7.82% on Video-MSR.", "conclusion": "Video-MSR establishes a vital foundation for evaluating multi-hop spatial reasoning, revealing current MLLM limitations and demonstrating that specialized instruction-tuning data can significantly improve spatial reasoning capabilities."}}
{"id": "2601.09588", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09588", "abs": "https://arxiv.org/abs/2601.09588", "authors": ["Wai-Lun Lam"], "title": "Energy-Entropy Regularization: The True Power of Minimal Looped Transformers", "comment": "19 pages, 2 figures", "summary": "Recent research suggests that looped Transformers have superior reasoning capabilities compared to standard deep architectures. Current approaches to training single-head looped architectures on benchmark tasks frequently fail or yield suboptimal performance due to a highly non-convex and irregular loss landscape. In these settings, optimization often stagnates in poor local minima and saddle points of the loss landscape, preventing the model from discovering the global minimum point. The internal mechanisms of these single-head looped transformer models remain poorly understood, and training them from scratch remains a significant challenge. In this paper, we propose a novel training framework that leverages Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape. By treating the parameter updates as a physical flow, we successfully trained a single-head looped Transformer with model dimension $d = 8$ to solve induction head task with input sequence length of 1000 tokens. This success reveals the internal mechanism behind the superior reasoning capability.", "AI": {"tldr": "A novel training framework using Tsallis entropy and Hamiltonian dynamics successfully trains single-head looped Transformers for reasoning tasks, overcoming optimization challenges in irregular loss landscapes.", "motivation": "Looped Transformers show superior reasoning capabilities but are difficult to train due to highly non-convex and irregular loss landscapes that cause optimization to stagnate in poor local minima and saddle points.", "method": "Proposes a training framework leveraging Tsallis entropy and Hamiltonian dynamics to transform the geometry of the loss landscape, treating parameter updates as a physical flow.", "result": "Successfully trained a single-head looped Transformer with model dimension d=8 to solve induction head task with input sequence length of 1000 tokens, revealing internal mechanisms behind superior reasoning capability.", "conclusion": "The proposed framework overcomes training challenges of looped Transformers and provides insights into their internal mechanisms for reasoning tasks."}}
{"id": "2601.09433", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09433", "abs": "https://arxiv.org/abs/2601.09433", "authors": ["David Reid", "Ognjen Arandjelovic"], "title": "Do Transformers Understand Ancient Roman Coin Motifs Better than CNNs?", "comment": null, "summary": "Automated analysis of ancient coins has the potential to help researchers extract more historical insights from large collections of coins and to help collectors understand what they are buying or selling. Recent research in this area has shown promise in focusing on identification of semantic elements as they are commonly depicted on ancient coins, by using convolutional neural networks (CNNs). This paper is the first to apply the recently proposed Vision Transformer (ViT) deep learning architecture to the task of identification of semantic elements on coins, using fully automatic learning from multi-modal data (images and unstructured text). This article summarises previous research in the area, discusses the training and implementation of ViT and CNN models for ancient coins analysis and provides an evaluation of their performance. The ViT models were found to outperform the newly trained CNN models in accuracy.", "AI": {"tldr": "Vision Transformers (ViT) outperform CNNs for identifying semantic elements on ancient coins using multi-modal learning from images and text.", "motivation": "Automated analysis of ancient coins can help researchers extract historical insights from large collections and assist collectors in understanding coin authenticity and value. Current CNN approaches show promise but need improvement.", "method": "Applied Vision Transformer (ViT) architecture to identify semantic elements on ancient coins using fully automatic learning from multi-modal data (images and unstructured text). Compared ViT performance against newly trained CNN models.", "result": "ViT models outperformed the newly trained CNN models in accuracy for identifying semantic elements on ancient coins.", "conclusion": "Vision Transformers represent a promising advancement over CNNs for automated ancient coin analysis, demonstrating superior performance in semantic element identification through multi-modal learning."}}
{"id": "2601.09624", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09624", "abs": "https://arxiv.org/abs/2601.09624", "authors": ["Jiali Cheng", "Ziheng Chen", "Chirag Agarwal", "Hadi Amiri"], "title": "Toward Understanding Unlearning Difficulty: A Mechanistic Perspective and Circuit-Guided Difficulty Metric", "comment": null, "summary": "Machine unlearning is becoming essential for building trustworthy and compliant language models. Yet unlearning success varies considerably across individual samples: some are reliably erased, while others persist despite the same procedure. We argue that this disparity is not only a data-side phenomenon, but also reflects model-internal mechanisms that encode and protect memorized information. We study this problem from a mechanistic perspective based on model circuits--structured interaction pathways that govern how predictions are formed. We propose Circuit-guided Unlearning Difficulty (CUD), a {\\em pre-unlearning} metric that assigns each sample a continuous difficulty score using circuit-level signals. Extensive experiments demonstrate that CUD reliably separates intrinsically easy and hard samples, and remains stable across unlearning methods. We identify key circuit-level patterns that reveal a mechanistic signature of difficulty: easy-to-unlearn samples are associated with shorter, shallower interactions concentrated in earlier-to-intermediate parts of the original model, whereas hard samples rely on longer and deeper pathways closer to late-stage computation. Compared to existing qualitative studies, CUD takes a first step toward a principled, fine-grained, and interpretable analysis of unlearning difficulty; and motivates the development of unlearning methods grounded in model mechanisms.", "AI": {"tldr": "The paper introduces Circuit-guided Unlearning Difficulty (CUD), a pre-unlearning metric that predicts sample difficulty for machine unlearning based on model circuit analysis, revealing mechanistic patterns behind why some samples are easy vs. hard to erase.", "motivation": "Machine unlearning success varies significantly across samples, with some reliably erased while others persist despite identical procedures. This disparity isn't just a data-side phenomenon but reflects model-internal mechanisms that encode and protect memorized information.", "method": "Proposes Circuit-guided Unlearning Difficulty (CUD), a pre-unlearning metric that assigns continuous difficulty scores using circuit-level signals. Analyzes model circuits\u2014structured interaction pathways that govern predictions\u2014to identify mechanistic patterns of unlearning difficulty.", "result": "CUD reliably separates intrinsically easy and hard samples and remains stable across unlearning methods. Key findings: easy-to-unlearn samples have shorter, shallower interactions concentrated in earlier-to-intermediate model parts, while hard samples rely on longer, deeper pathways closer to late-stage computation.", "conclusion": "CUD represents a first step toward principled, fine-grained, and interpretable analysis of unlearning difficulty, moving beyond qualitative studies. It motivates developing unlearning methods grounded in model mechanisms rather than just data characteristics."}}
{"id": "2601.09449", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09449", "abs": "https://arxiv.org/abs/2601.09449", "authors": ["Darya Baranouskaya", "Andrea Cavallaro"], "title": "PrivLEX: Detecting legal concepts in images through Vision-Language Models", "comment": null, "summary": "We present PrivLEX, a novel image privacy classifier that grounds its decisions in legally defined personal data concepts. PrivLEX is the first interpretable privacy classifier aligned with legal concepts that leverages the recognition capabilities of Vision-Language Models (VLMs). PrivLEX relies on zero-shot VLM concept detection to provide interpretable classification through a label-free Concept Bottleneck Model, without requiring explicit concept labels during training. We demonstrate PrivLEX's ability to identify personal data concepts that are present in images. We further analyse the sensitivity of such concepts as perceived by human annotators of image privacy datasets.", "AI": {"tldr": "PrivLEX is an interpretable image privacy classifier that grounds decisions in legally defined personal data concepts using Vision-Language Models without requiring explicit concept labels during training.", "motivation": "Current privacy classifiers lack interpretability and legal alignment. There's a need for privacy classification systems that can explain decisions using legally relevant personal data concepts rather than just providing black-box predictions.", "method": "Uses zero-shot Vision-Language Model concept detection with a label-free Concept Bottleneck Model. Leverages VLM recognition capabilities to identify personal data concepts without requiring explicit concept labels during training.", "result": "Demonstrates ability to identify personal data concepts in images. Analyzes sensitivity of these concepts as perceived by human annotators in image privacy datasets.", "conclusion": "PrivLEX represents the first interpretable privacy classifier aligned with legal concepts, providing transparent decision-making grounded in legally defined personal data concepts through zero-shot VLM capabilities."}}
{"id": "2601.09626", "categories": ["cs.LG", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09626", "abs": "https://arxiv.org/abs/2601.09626", "authors": ["Ge Lei", "Ferran Brosa Planella", "Sterling G. Baird", "Samuel J. Cooper"], "title": "From Prompt to Protocol: Fast Charging Batteries with Large Language Models", "comment": null, "summary": "Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.", "AI": {"tldr": "LLM-driven methods P2O and P2P outperform traditional optimization techniques for battery charging protocol design, achieving ~4.2% improvement in battery health metrics over state-of-the-art baselines.", "motivation": "Battery charging protocol optimization is challenging due to slow, costly, and non-differentiable evaluations. Existing approaches heavily constrain search spaces, limiting protocol diversity and preventing discovery of higher-performing solutions.", "method": "Two gradient-free, LLM-driven closed-loop methods: 1) Prompt-to-Optimizer (P2O) uses LLM to propose code for small neural-network-based protocols, which are then trained by an inner loop. 2) Prompt-to-Protocol (P2P) writes explicit functions for current and scalar parameters.", "result": "LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In realistic fast charging, both P2O and P2P yield ~4.2% improvement in state of health over multi-step constant current baseline, with P2P achieving this under matched evaluation budgets.", "conclusion": "LLMs can expand protocol functional form space, incorporate language-based constraints, and enable efficient optimization in high-cost experimental settings, demonstrating superior performance over traditional optimization methods."}}
{"id": "2601.09452", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09452", "abs": "https://arxiv.org/abs/2601.09452", "authors": ["Ahmad Rahimi", "Valentin Gerard", "Eloi Zablocki", "Matthieu Cord", "Alexandre Alahi"], "title": "MAD: Motion Appearance Decoupling for efficient Driving World Models", "comment": null, "summary": "Recent video diffusion models generate photorealistic, temporally coherent videos, yet they fall short as reliable world models for autonomous driving, where structured motion and physically consistent interactions are essential. Adapting these generalist video models to driving domains has shown promise but typically requires massive domain-specific data and costly fine-tuning. We propose an efficient adaptation framework that converts generalist video diffusion models into controllable driving world models with minimal supervision. The key idea is to decouple motion learning from appearance synthesis. First, the model is adapted to predict structured motion in a simplified form: videos of skeletonized agents and scene elements, focusing learning on physical and social plausibility. Then, the same backbone is reused to synthesize realistic RGB videos conditioned on these motion sequences, effectively \"dressing\" the motion with texture and lighting. This two-stage process mirrors a reasoning-rendering paradigm: first infer dynamics, then render appearance. Our experiments show this decoupled approach is exceptionally efficient: adapting SVD, we match prior SOTA models with less than 6% of their compute. Scaling to LTX, our MAD-LTX model outperforms all open-source competitors, and supports a comprehensive suite of text, ego, and object controls. Project page: https://vita-epfl.github.io/MAD-World-Model/", "AI": {"tldr": "MAD-World-Model efficiently adapts general video diffusion models into controllable driving world models using a two-stage motion-appearance decoupling approach with minimal supervision.", "motivation": "Existing video diffusion models generate realistic videos but lack structured motion and physical consistency needed for autonomous driving world models. Adapting these models typically requires massive domain data and expensive fine-tuning.", "method": "Two-stage adaptation: 1) Adapt model to predict structured motion using skeletonized agents/scene videos focusing on physical/social plausibility, 2) Reuse same backbone to synthesize realistic RGB videos conditioned on motion sequences (\"dressing\" motion with appearance). This follows a reasoning-rendering paradigm.", "result": "Achieves SOTA performance with <6% compute compared to prior methods when adapting SVD. MAD-LTX model outperforms all open-source competitors and supports comprehensive text, ego, and object controls.", "conclusion": "The decoupled motion-appearance approach enables efficient adaptation of general video diffusion models into controllable driving world models with minimal supervision, matching/exceeding SOTA with significantly reduced compute."}}
{"id": "2601.09654", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09654", "abs": "https://arxiv.org/abs/2601.09654", "authors": ["Aditya Tanna", "Pratinav Seth", "Mohamed Bouadi", "Vinay Kumar Sankarapu"], "title": "Exploring Fine-Tuning for Tabular Foundation Models", "comment": null, "summary": "Tabular Foundation Models (TFMs) have recently shown strong in-context learning capabilities on structured data, achieving zero-shot performance comparable to traditional machine learning methods. We find that zero-shot TFMs already achieve strong performance, while the benefits of fine-tuning are highly model and data-dependent. Meta-learning and PEFT provide moderate gains under specific conditions, whereas full supervised fine-tuning (SFT) often reduces accuracy or calibration quality. This work presents the first comprehensive study of fine-tuning in TFMs across benchmarks including TALENT, OpenML-CC18, and TabZilla. We compare Zero-Shot, Meta-Learning, Supervised (SFT), and parameter-efficient (PEFT) approaches, analyzing how dataset factors such as imbalance, size, and dimensionality affect outcomes. Our findings cover performance, calibration, and fairness, offering practical guidelines on when fine-tuning is most beneficial and its limitations.", "AI": {"tldr": "Zero-shot tabular foundation models already perform well, while fine-tuning benefits vary by model and data; meta-learning and PEFT help in specific cases, but full supervised fine-tuning often hurts accuracy or calibration.", "motivation": "To provide the first comprehensive study of fine-tuning in Tabular Foundation Models (TFMs) across multiple benchmarks, analyzing when fine-tuning is beneficial versus when zero-shot performance suffices.", "method": "Comparative study across TALENT, OpenML-CC18, and TabZilla benchmarks, evaluating Zero-Shot, Meta-Learning, Supervised Fine-Tuning (SFT), and Parameter-Efficient Fine-Tuning (PEFT) approaches while analyzing dataset factors like imbalance, size, and dimensionality.", "result": "Zero-shot TFMs already achieve strong performance comparable to traditional ML; fine-tuning benefits are model/data-dependent; meta-learning and PEFT provide moderate gains in specific conditions; full SFT often reduces accuracy or calibration quality.", "conclusion": "Provides practical guidelines on when fine-tuning is most beneficial and its limitations, covering performance, calibration, and fairness considerations for TFMs."}}
{"id": "2601.09497", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09497", "abs": "https://arxiv.org/abs/2601.09497", "authors": ["Ritabrata Chakraborty", "Hrishit Mitra", "Shivakumara Palaiahnakote", "Umapada Pal"], "title": "Towards Robust Cross-Dataset Object Detection Generalization under Domain Specificity", "comment": "15 pages, 4 figures, 6 tables", "summary": "Object detectors often perform well in-distribution, yet degrade sharply on a different benchmark. We study cross-dataset object detection (CD-OD) through a lens of setting specificity. We group benchmarks into setting-agnostic datasets with diverse everyday scenes and setting-specific datasets tied to a narrow environment, and evaluate a standard detector family across all train--test pairs. This reveals a clear structure in CD-OD: transfer within the same setting type is relatively stable, while transfer across setting types drops substantially and is often asymmetric. The most severe breakdowns occur when transferring from specific sources to agnostic targets, and persist after open-label alignment, indicating that domain shift dominates in the hardest regimes. To disentangle domain shift from label mismatch, we compare closed-label transfer with an open-label protocol that maps predicted classes to the nearest target label using CLIP similarity. Open-label evaluation yields consistent but bounded gains, and many corrected cases correspond to semantic near-misses supported by the image evidence. Overall, we provide a principled characterization of CD-OD under setting specificity and practical guidance for evaluating detectors under distribution shift. Code will be released at \\href{[https://github.com/Ritabrata04/cdod-icpr.git}{https://github.com/Ritabrata04/cdod-icpr}.", "AI": {"tldr": "The paper studies cross-dataset object detection (CD-OD) through setting specificity, revealing that transfer within same setting types is stable while cross-setting transfer drops significantly, with domain shift being the dominant factor in hardest regimes.", "motivation": "Object detectors perform well in-distribution but degrade sharply on different benchmarks. The paper aims to understand cross-dataset object detection through the lens of setting specificity to characterize performance patterns and identify key challenges.", "method": "Group benchmarks into setting-agnostic (diverse everyday scenes) and setting-specific (narrow environment) datasets. Evaluate standard detector family across all train-test pairs. Use open-label protocol with CLIP similarity to map predicted classes to nearest target labels, disentangling domain shift from label mismatch.", "result": "Reveals clear structure in CD-OD: transfer within same setting type is relatively stable, while transfer across setting types drops substantially and is often asymmetric. Most severe breakdowns occur when transferring from specific sources to agnostic targets. Open-label evaluation yields consistent but bounded gains, with many corrected cases corresponding to semantic near-misses.", "conclusion": "Provides principled characterization of CD-OD under setting specificity and practical guidance for evaluating detectors under distribution shift. Domain shift dominates in hardest regimes, and open-label alignment helps but has limited impact on the most challenging cross-setting transfers."}}
{"id": "2601.09684", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09684", "abs": "https://arxiv.org/abs/2601.09684", "authors": ["Ziyu Yang", "Guibin Chen", "Yuxin Yang", "Aoxiong Zeng", "Xiangquan Yang"], "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection", "comment": "preprint", "summary": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.", "AI": {"tldr": "Ortho-LoRA: A gradient projection method that mitigates negative transfer in multi-task LoRA by projecting conflicting task gradients onto orthogonal subspaces within the LoRA parameter space.", "motivation": "Multi-task learning with LoRA reduces storage overhead by sharing a single adapter across tasks, but suffers from negative transfer where conflicting gradient updates degrade individual task performance compared to single-task fine-tuning. This problem is exacerbated by LoRA's low-rank constraint limiting the optimization landscape's capacity for diverse tasks.", "method": "Ortho-LoRA is a gradient projection method tailored for LoRA's bipartite structure. It dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace, preventing interference while maintaining parameter efficiency.", "result": "Extensive experiments on GLUE benchmark show Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95% of the performance gap between multi-task and single-task baselines with negligible computational overhead.", "conclusion": "Ortho-LoRA provides an effective solution to negative transfer in multi-task LoRA, enabling parameter-efficient deployment of LLMs across multiple tasks without significant performance degradation, making it practical for real-world applications."}}
{"id": "2601.09499", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09499", "abs": "https://arxiv.org/abs/2601.09499", "authors": ["Edgar Sucar", "Eldar Insafutdinov", "Zihang Lai", "Andrea Vedaldi"], "title": "V-DPM: 4D Video Reconstruction with Dynamic Point Maps", "comment": "Project page: https://www.robots.ox.ac.uk/~vgg/research/vdpm/", "summary": "Powerful 3D representations such as DUSt3R invariant point maps, which encode 3D shape and camera parameters, have significantly advanced feed forward 3D reconstruction. While point maps assume static scenes, Dynamic Point Maps (DPMs) extend this concept to dynamic 3D content by additionally representing scene motion. However, existing DPMs are limited to image pairs and, like DUSt3R, require post processing via optimization when more than two views are involved. We argue that DPMs are more useful when applied to videos and introduce V-DPM to demonstrate this. First, we show how to formulate DPMs for video input in a way that maximizes representational power, facilitates neural prediction, and enables reuse of pretrained models. Second, we implement these ideas on top of VGGT, a recent and powerful 3D reconstructor. Although VGGT was trained on static scenes, we show that a modest amount of synthetic data is sufficient to adapt it into an effective V-DPM predictor. Our approach achieves state of the art performance in 3D and 4D reconstruction for dynamic scenes. In particular, unlike recent dynamic extensions of VGGT such as P3, DPMs recover not only dynamic depth but also the full 3D motion of every point in the scene.", "AI": {"tldr": "V-DPM extends Dynamic Point Maps to video input, achieving SOTA 3D/4D reconstruction by adapting VGGT with synthetic data to predict full 3D motion of every scene point.", "motivation": "Existing Dynamic Point Maps (DPMs) are limited to image pairs and require optimization for multiple views, while video-based dynamic 3D reconstruction would be more useful for real-world applications.", "method": "Formulates DPMs for video input to maximize representational power and neural prediction, then adapts VGGT (a static scene reconstructor) using synthetic data to create V-DPM predictor.", "result": "Achieves state-of-the-art performance in 3D and 4D reconstruction for dynamic scenes, recovering not only dynamic depth but also full 3D motion of every point in the scene.", "conclusion": "V-DPM successfully extends DPMs to video, demonstrating that modest synthetic data can adapt powerful static reconstructors for dynamic scene analysis with superior motion recovery capabilities."}}
{"id": "2601.09693", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.09693", "abs": "https://arxiv.org/abs/2601.09693", "authors": ["Lisa Schneckenreiter", "Sohvi Luukkonen", "Lukas Friedrich", "Daniel Kuhn", "G\u00fcnter Klambauer"], "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design", "comment": "ELLIS ML4Molecules Workshop 2025, ELLIS Unconference, Copenhagen 2025", "summary": "Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves state-of-the-art zero-shot virtual screening performance in settings where no binding pocket information is provided as input, substantially outperforms existing methods on a challenging target fishing task, and demonstrates competitive ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.", "AI": {"tldr": "ConGLUDe is a unified contrastive geometric model that combines structure-based and ligand-based drug design approaches, enabling joint training on both protein-ligand complexes and bioactivity data without requiring pre-defined binding pockets.", "motivation": "Traditional computational drug design methods use separate structure-based and ligand-based approaches with disjoint data sources and modeling assumptions, limiting their joint application at scale. There's a need to unify these approaches for more effective drug discovery.", "method": "ConGLUDe uses a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites, coupled with a fast ligand encoder. It aligns ligands with both global protein representations and multiple candidate binding sites through contrastive learning, enabling joint training on protein-ligand complexes and large-scale bioactivity data.", "result": "Achieves state-of-the-art zero-shot virtual screening performance without binding pocket information, substantially outperforms existing methods on target fishing, and demonstrates competitive ligand-conditioned pocket selection.", "conclusion": "ConGLUDe demonstrates the advantages of unified structure-ligand training and represents a step toward general-purpose foundation models for drug discovery by effectively combining both approaches in a single model."}}
{"id": "2601.09524", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.09524", "abs": "https://arxiv.org/abs/2601.09524", "authors": ["Lennart Eing", "Cristina Luna-Jim\u00e9nez", "Silvan Mertes", "Elisabeth Andr\u00e9"], "title": "Video Joint-Embedding Predictive Architectures for Facial Expression Recognition", "comment": "To appear in 2025 Proceedings of the 13th International Conference on Affective Computing and Intelligent Interaction (ACII), submitted to IEEE. \\c{opyright} 2025 IEEE", "summary": "This paper introduces a novel application of Video Joint-Embedding Predictive Architectures (V-JEPAs) for Facial Expression Recognition (FER). Departing from conventional pre-training methods for video understanding that rely on pixel-level reconstructions, V-JEPAs learn by predicting embeddings of masked regions from the embeddings of unmasked regions. This enables the trained encoder to not capture irrelevant information about a given video like the color of a region of pixels in the background. Using a pre-trained V-JEPA video encoder, we train shallow classifiers using the RAVDESS and CREMA-D datasets, achieving state-of-the-art performance on RAVDESS and outperforming all other vision-based methods on CREMA-D (+1.48 WAR). Furthermore, cross-dataset evaluations reveal strong generalization capabilities, demonstrating the potential of purely embedding-based pre-training approaches to advance FER. We release our code at https://github.com/lennarteingunia/vjepa-for-fer.", "AI": {"tldr": "V-JEPA pre-training for facial expression recognition achieves state-of-the-art performance on RAVDESS and outperforms vision-based methods on CREMA-D, showing strong generalization capabilities.", "motivation": "Traditional video understanding pre-training methods use pixel-level reconstructions which capture irrelevant information. The paper aims to leverage embedding-based pre-training (V-JEPA) that focuses on predicting masked region embeddings from unmasked ones, filtering out irrelevant details for better facial expression recognition.", "method": "Uses Video Joint-Embedding Predictive Architecture (V-JEPA) pre-training where the model learns by predicting embeddings of masked video regions from unmasked ones. Then trains shallow classifiers on top of the pre-trained V-JEPA encoder using RAVDESS and CREMA-D datasets for facial expression recognition.", "result": "Achieves state-of-the-art performance on RAVDESS and outperforms all other vision-based methods on CREMA-D with +1.48% WAR improvement. Cross-dataset evaluations demonstrate strong generalization capabilities.", "conclusion": "Embedding-based pre-training approaches like V-JEPA show significant potential for advancing facial expression recognition by learning more relevant representations and filtering out irrelevant information, with demonstrated state-of-the-art performance and strong generalization."}}
{"id": "2601.09528", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09528", "abs": "https://arxiv.org/abs/2601.09528", "authors": ["Alfio Spoto", "Rosario Leonardi", "Francesco Ragusa", "Giovanni Maria Farinella"], "title": "GlovEgo-HOI: Bridging the Synthetic-to-Real Gap for Industrial Egocentric Human-Object Interaction Detection", "comment": "8 pages, accepted as a Short Paper at VISAPP 2026", "summary": "Egocentric Human-Object Interaction (EHOI) analysis is crucial for industrial safety, yet the development of robust models is hindered by the scarcity of annotated domain-specific data. We address this challenge by introducing a data generation framework that combines synthetic data with a diffusion-based process to augment real-world images with realistic Personal Protective Equipment (PPE). We present GlovEgo-HOI, a new benchmark dataset for industrial EHOI, and GlovEgo-Net, a model integrating Glove-Head and Keypoint- Head modules to leverage hand pose information for enhanced interaction detection. Extensive experiments demonstrate the effectiveness of the proposed data generation framework and GlovEgo-Net. To foster further research, we release the GlovEgo-HOI dataset, augmentation pipeline, and pre-trained models at: GitHub project.", "AI": {"tldr": "A framework combining synthetic data and diffusion models to augment real images with PPE for industrial EHOI analysis, with new dataset and model.", "motivation": "Industrial safety requires robust EHOI analysis, but domain-specific annotated data is scarce, hindering model development.", "method": "Data generation framework using synthetic data and diffusion-based process to augment real images with realistic PPE; GlovEgo-Net model with Glove-Head and Keypoint-Head modules leveraging hand pose information.", "result": "Extensive experiments demonstrate effectiveness of both data generation framework and GlovEgo-Net model.", "conclusion": "The approach addresses data scarcity in industrial EHOI, with released dataset (GlovEgo-HOI), augmentation pipeline, and pre-trained models to foster further research."}}
{"id": "2601.09531", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09531", "abs": "https://arxiv.org/abs/2601.09531", "authors": ["Yue Yao", "Ruining Yang", "Tom Gedeon"], "title": "Bipartite Mode Matching for Vision Training Set Search from a Hierarchical Data Server", "comment": "Accepted to AAAI 2026", "summary": "We explore a situation in which the target domain is accessible, but real-time data annotation is not feasible. Instead, we would like to construct an alternative training set from a large-scale data server so that a competitive model can be obtained. For this problem, because the target domain usually exhibits distinct modes (i.e., semantic clusters representing data distribution), if the training set does not contain these target modes, the model performance would be compromised. While prior existing works improve algorithms iteratively, our research explores the often-overlooked potential of optimizing the structure of the data server. Inspired by the hierarchical nature of web search engines, we introduce a hierarchical data server, together with a bipartite mode matching algorithm (BMM) to align source and target modes. For each target mode, we look in the server data tree for the best mode match, which might be large or small in size. Through bipartite matching, we aim for all target modes to be optimally matched with source modes in a one-on-one fashion. Compared with existing training set search algorithms, we show that the matched server modes constitute training sets that have consistently smaller domain gaps with the target domain across object re-identification (re-ID) and detection tasks. Consequently, models trained on our searched training sets have higher accuracy than those trained otherwise. BMM allows data-centric unsupervised domain adaptation (UDA) orthogonal to existing model-centric UDA methods. By combining the BMM with existing UDA methods like pseudo-labeling, further improvement is observed.", "AI": {"tldr": "Proposes hierarchical data server with bipartite mode matching (BMM) to construct optimal training sets from unlabeled target domain by aligning source and target semantic modes, improving model performance in domain adaptation tasks.", "motivation": "Target domains are accessible but real-time annotation is infeasible. Need to construct training sets from large-scale data servers while ensuring target domain modes (semantic clusters) are represented to avoid performance compromise.", "method": "Introduces hierarchical data server inspired by web search engines, with bipartite mode matching (BMM) algorithm to align source and target modes. For each target mode, searches server data tree for best mode match, using bipartite matching for one-on-one optimal alignment between target and source modes.", "result": "Matched server modes create training sets with consistently smaller domain gaps across object re-identification and detection tasks. Models trained on BMM-searched sets achieve higher accuracy. BMM works orthogonally to existing UDA methods, and combining with pseudo-labeling yields further improvements.", "conclusion": "BMM enables data-centric unsupervised domain adaptation complementary to model-centric approaches. Optimizing data server structure through hierarchical organization and mode matching effectively reduces domain gap and improves model performance when target annotation is unavailable."}}
{"id": "2601.09566", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09566", "abs": "https://arxiv.org/abs/2601.09566", "authors": ["Shuyang Xiang", "Hao Guan"], "title": "Hot-Start from Pixels: Low-Resolution Visual Tokens for Chinese Language Modeling", "comment": "15 pages, 5 figures, submitted to ACL 2026", "summary": "Large language models typically represent Chinese characters as discrete index-based tokens, largely ignoring their visual form. For logographic scripts, visual structure carries semantic and phonetic information, which may aid prediction. We investigate whether low-resolution visual inputs can serve as an alternative for character-level modeling. Instead of token IDs, our decoder receives grayscale images of individual characters, with resolutions as low as $8 \\times 8$ pixels. Remarkably, these inputs achieve 39.2\\% accuracy, comparable to the index-based baseline of 39.1\\%. Such low-resource settings also exhibit a pronounced \\emph{hot-start} effect: by 0.4\\% of total training, accuracy reaches above 12\\%, while index-based models lag at below 6\\%. Overall, our results demonstrate that minimal visual structure can provide a robust and efficient signal for Chinese language modeling, offering an alternative perspective on character representation that complements traditional index-based approaches.", "AI": {"tldr": "Chinese character visual inputs (8\u00d78 grayscale images) achieve comparable accuracy to traditional token IDs in language modeling, with faster early learning.", "motivation": "Current LLMs treat Chinese characters as discrete tokens ignoring their visual form, which contains semantic and phonetic information that could aid prediction in logographic scripts.", "method": "Replace token IDs with low-resolution grayscale images of individual characters (as low as 8\u00d78 pixels) as input to a decoder for character-level modeling.", "result": "Visual inputs achieve 39.2% accuracy vs 39.1% for index-based baseline. Low-resource settings show \"hot-start\" effect: by 0.4% training, visual models reach >12% accuracy while index-based models lag at <6%.", "conclusion": "Minimal visual structure provides robust and efficient signal for Chinese language modeling, offering an alternative character representation that complements traditional index-based approaches."}}
{"id": "2601.09572", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09572", "abs": "https://arxiv.org/abs/2601.09572", "authors": ["Tianli Tao", "Ziyang Wang", "Delong Yang", "Han Zhang", "Le Zhang"], "title": "Trustworthy Longitudinal Brain MRI Completion: A Deformation-Based Approach with KAN-Enhanced Diffusion Model", "comment": null, "summary": "Longitudinal brain MRI is essential for lifespan study, yet high attrition rates often lead to missing data, complicating analysis. Deep generative models have been explored, but most rely solely on image intensity, leading to two key limitations: 1) the fidelity or trustworthiness of the generated brain images are limited, making downstream studies questionable; 2) the usage flexibility is restricted due to fixed guidance rooted in the model structure, restricting full ability to versatile application scenarios. To address these challenges, we introduce DF-DiffCom, a Kolmogorov-Arnold Networks (KAN)-enhanced diffusion model that smartly leverages deformation fields for trustworthy longitudinal brain image completion. Trained on OASIS-3, DF-DiffCom outperforms state-of-the-art methods, improving PSNR by 5.6% and SSIM by 0.12. More importantly, its modality-agnostic nature allows smooth extension to varied MRI modalities, even to attribute maps such as brain tissue segmentation results.", "AI": {"tldr": "DF-DiffCom is a KAN-enhanced diffusion model that uses deformation fields for trustworthy longitudinal brain MRI completion, outperforming SOTA methods and being modality-agnostic.", "motivation": "Longitudinal brain MRI studies suffer from high attrition rates leading to missing data. Existing deep generative models rely solely on image intensity, resulting in limited fidelity/trustworthiness and restricted usage flexibility due to fixed guidance in model structure.", "method": "DF-DiffCom is a Kolmogorov-Arnold Networks (KAN)-enhanced diffusion model that smartly leverages deformation fields for trustworthy longitudinal brain image completion. It's trained on OASIS-3 dataset.", "result": "Outperforms state-of-the-art methods, improving PSNR by 5.6% and SSIM by 0.12. The modality-agnostic nature allows smooth extension to varied MRI modalities and even to attribute maps like brain tissue segmentation results.", "conclusion": "DF-DiffCom addresses key limitations of existing methods by providing trustworthy longitudinal brain image completion with improved fidelity and greater flexibility for versatile application scenarios across different MRI modalities."}}
{"id": "2601.09575", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09575", "abs": "https://arxiv.org/abs/2601.09575", "authors": ["Sheng-Yu Huang", "Jaesung Choe", "Yu-Chiang Frank Wang", "Cheng Sun"], "title": "OpenVoxel: Training-Free Grouping and Captioning Voxels for Open-Vocabulary 3D Scene Understanding", "comment": "project page: https://peterjohnsonhuang.github.io/openvoxel-pages/", "summary": "We propose OpenVoxel, a training-free algorithm for grouping and captioning sparse voxels for the open-vocabulary 3D scene understanding tasks. Given the sparse voxel rasterization (SVR) model obtained from multi-view images of a 3D scene, our OpenVoxel is able to produce meaningful groups that describe different objects in the scene. Also, by leveraging powerful Vision Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), our OpenVoxel successfully build an informative scene map by captioning each group, enabling further 3D scene understanding tasks such as open-vocabulary segmentation (OVS) or referring expression segmentation (RES). Unlike previous methods, our method is training-free and does not introduce embeddings from a CLIP/BERT text encoder. Instead, we directly proceed with text-to-text search using MLLMs. Through extensive experiments, our method demonstrates superior performance compared to recent studies, particularly in complex referring expression segmentation (RES) tasks. The code will be open.", "AI": {"tldr": "OpenVoxel is a training-free algorithm for open-vocabulary 3D scene understanding that groups sparse voxels and generates captions using VLMs/MLLMs without CLIP/BERT embeddings.", "motivation": "To enable open-vocabulary 3D scene understanding without requiring training or dependency on CLIP/BERT text encoders, allowing for more flexible and efficient scene analysis.", "method": "Uses sparse voxel rasterization from multi-view images, groups voxels into meaningful object segments, then applies Vision Language Models and Multi-modal LLMs for captioning via text-to-text search instead of embedding-based approaches.", "result": "Demonstrates superior performance compared to recent methods, especially in complex referring expression segmentation tasks, while being training-free and avoiding CLIP/BERT dependencies.", "conclusion": "OpenVoxel provides an effective training-free approach for open-vocabulary 3D scene understanding that outperforms existing methods and will be open-sourced."}}
{"id": "2601.09586", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09586", "abs": "https://arxiv.org/abs/2601.09586", "authors": ["Said Yasin", "Torsten Zesch"], "title": "Show, don't tell -- Providing Visual Error Feedback for Handwritten Documents", "comment": null, "summary": "Handwriting remains an essential skill, particularly in education. Therefore, providing visual feedback on handwritten documents is an important but understudied area. We outline the many challenges when going from an image of handwritten input to correctly placed informative error feedback. We empirically compare modular and end-to-end systems and find that both approaches currently do not achieve acceptable overall quality. We identify the major challenges and outline an agenda for future research.", "AI": {"tldr": "Current handwriting feedback systems (both modular and end-to-end) fail to provide acceptable quality for educational applications, highlighting significant technical challenges that need future research.", "motivation": "Handwriting is a crucial educational skill, but providing visual feedback on handwritten documents is an important yet understudied problem that needs better solutions.", "method": "The paper empirically compares two approaches: modular systems (with separate components) and end-to-end systems, evaluating their ability to go from handwritten images to correctly placed informative error feedback.", "result": "Both modular and end-to-end approaches currently fail to achieve acceptable overall quality for providing handwriting feedback, revealing significant technical challenges in the pipeline.", "conclusion": "The research identifies major challenges in handwriting feedback systems and outlines a research agenda for future work to improve this important educational technology."}}
{"id": "2601.09613", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09613", "abs": "https://arxiv.org/abs/2601.09613", "authors": ["Yonglin Tian", "Qiyao Zhang", "Wei Xu", "Yutong Wang", "Yihao Wu", "Xinyi Li", "Xingyuan Dai", "Hui Zhang", "Zhiyong Cui", "Baoqing Guo", "Zujun Yu", "Yisheng Lv"], "title": "CogRail: Benchmarking VLMs in Cognitive Intrusion Perception for Intelligent Railway Transportation Systems", "comment": null, "summary": "Accurate and early perception of potential intrusion targets is essential for ensuring the safety of railway transportation systems. However, most existing systems focus narrowly on object classification within fixed visual scopes and apply rule-based heuristics to determine intrusion status, often overlooking targets that pose latent intrusion risks. Anticipating such risks requires the cognition of spatial context and temporal dynamics for the object of interest (OOI), which presents challenges for conventional visual models. To facilitate deep intrusion perception, we introduce a novel benchmark, CogRail, which integrates curated open-source datasets with cognitively driven question-answer annotations to support spatio-temporal reasoning and prediction. Building upon this benchmark, we conduct a systematic evaluation of state-of-the-art visual-language models (VLMs) using multimodal prompts to identify their strengths and limitations in this domain. Furthermore, we fine-tune VLMs for better performance and propose a joint fine-tuning framework that integrates three core tasks, position perception, movement prediction, and threat analysis, facilitating effective adaptation of general-purpose foundation models into specialized models tailored for cognitive intrusion perception. Extensive experiments reveal that current large-scale multimodal models struggle with the complex spatial-temporal reasoning required by the cognitive intrusion perception task, underscoring the limitations of existing foundation models in this safety-critical domain. In contrast, our proposed joint fine-tuning framework significantly enhances model performance by enabling targeted adaptation to domain-specific reasoning demands, highlighting the advantages of structured multi-task learning in improving both accuracy and interpretability. Code will be available at https://github.com/Hub-Tian/CogRail.", "AI": {"tldr": "CogRail benchmark introduces cognitive intrusion perception for railway safety, evaluating VLMs' spatial-temporal reasoning and proposing joint fine-tuning framework for improved performance.", "motivation": "Existing railway intrusion systems focus narrowly on object classification with rule-based heuristics, overlooking latent intrusion risks that require understanding spatial context and temporal dynamics of objects.", "method": "1) Introduce CogRail benchmark with curated datasets and cognitively-driven QA annotations for spatio-temporal reasoning; 2) Systematically evaluate state-of-the-art VLMs; 3) Propose joint fine-tuning framework integrating position perception, movement prediction, and threat analysis tasks.", "result": "Current large-scale multimodal models struggle with complex spatial-temporal reasoning for cognitive intrusion perception. The proposed joint fine-tuning framework significantly enhances model performance through targeted adaptation to domain-specific reasoning demands.", "conclusion": "Structured multi-task learning via joint fine-tuning enables effective adaptation of general foundation models into specialized models for cognitive intrusion perception, improving both accuracy and interpretability in safety-critical railway domains."}}
{"id": "2601.09601", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09601", "abs": "https://arxiv.org/abs/2601.09601", "authors": ["Emmanuele Barberi", "Felice Sfravara", "Filippo Cucinotta"], "title": "Iterative Differential Entropy Minimization (IDEM) method for fine rigid pairwise 3D Point Cloud Registration: A Focus on the Metric", "comment": null, "summary": "Point cloud registration is a central theme in computer vision, with alignment algorithms continuously improving for greater robustness. Commonly used methods evaluate Euclidean distances between point clouds and minimize an objective function, such as Root Mean Square Error (RMSE). However, these approaches are most effective when the point clouds are well-prealigned and issues such as differences in density, noise, holes, and limited overlap can compromise the results. Traditional methods, such as Iterative Closest Point (ICP), require choosing one point cloud as fixed, since Euclidean distances lack commutativity. When only one point cloud has issues, adjustments can be made, but in real scenarios, both point clouds may be affected, often necessitating preprocessing. The authors introduce a novel differential entropy-based metric, designed to serve as the objective function within an optimization framework for fine rigid pairwise 3D point cloud registration, denoted as Iterative Differential Entropy Minimization (IDEM). This metric does not depend on the choice of a fixed point cloud and, during transformations, reveals a clear minimum corresponding to the best alignment. Multiple case studies are conducted, and the results are compared with those obtained using RMSE, Chamfer distance, and Hausdorff distance. The proposed metric proves effective even with density differences, noise, holes, and partial overlap, where RMSE does not always yield optimal alignment.", "AI": {"tldr": "Proposes IDEM, a differential entropy-based metric for robust 3D point cloud registration that handles density differences, noise, holes, and partial overlap better than traditional Euclidean distance metrics.", "motivation": "Traditional point cloud registration methods (like ICP using RMSE) struggle with real-world challenges: density differences, noise, holes, limited overlap, and lack commutativity (require choosing fixed reference). These limitations necessitate preprocessing and compromise results when both point clouds have issues.", "method": "Introduces Iterative Differential Entropy Minimization (IDEM) - a novel differential entropy-based metric as objective function for fine rigid pairwise 3D point cloud registration. The metric is commutative (doesn't require choosing fixed point cloud) and shows clear minimum at optimal alignment during transformations.", "result": "IDEM outperforms traditional metrics (RMSE, Chamfer distance, Hausdorff distance) in multiple case studies. It remains effective with density differences, noise, holes, and partial overlap where RMSE fails to find optimal alignment.", "conclusion": "Differential entropy-based metric provides robust alternative to Euclidean distance metrics for point cloud registration, addressing key limitations of traditional methods in real-world scenarios with imperfect data."}}
{"id": "2601.09606", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09606", "abs": "https://arxiv.org/abs/2601.09606", "authors": ["Manning Gao", "Leheng Zhang", "Shiqin Han", "Haifeng Hu", "Yuncheng Jiang", "Sijie Mai"], "title": "GRCF: Two-Stage Groupwise Ranking and Calibration Framework for Multimodal Sentiment Analysis", "comment": null, "summary": "Most Multimodal Sentiment Analysis research has focused on point-wise regression. While straightforward, this approach is sensitive to label noise and neglects whether one sample is more positive than another, resulting in unstable predictions and poor correlation alignment. Pairwise ordinal learning frameworks emerged to address this gap, capturing relative order by learning from comparisons. Yet, they introduce two new trade-offs: First, they assign uniform importance to all comparisons, failing to adaptively focus on hard-to-rank samples. Second, they employ static ranking margins, which fail to reflect the varying semantic distances between sentiment groups. To address this, we propose a Two-Stage Group-wise Ranking and Calibration Framework (GRCF) that adapts the philosophy of Group Relative Policy Optimization (GRPO). Our framework resolves these trade-offs by simultaneously preserving relative ordinal structure, ensuring absolute score calibration, and adaptively focusing on difficult samples. Specifically, Stage 1 introduces a GRPO-inspired Advantage-Weighted Dynamic Margin Ranking Loss to build a fine-grained ordinal structure. Stage 2 then employs an MAE-driven objective to align prediction magnitudes. To validate its generalizability, we extend GRCF to classification tasks, including multimodal humor detection and sarcasm detection. GRCF achieves state-of-the-art performance on core regression benchmarks, while also showing strong generalizability in classification tasks.", "AI": {"tldr": "GRCF is a two-stage framework for multimodal sentiment analysis that improves upon pairwise ordinal learning by adaptively focusing on hard-to-rank samples and using dynamic margins, achieving SOTA performance in regression and strong results in classification tasks.", "motivation": "Traditional point-wise regression for multimodal sentiment analysis is sensitive to label noise and ignores relative ordering between samples. Pairwise ordinal learning addresses this but has limitations: uniform importance for all comparisons and static ranking margins that don't reflect varying semantic distances between sentiment groups.", "method": "Two-Stage Group-wise Ranking and Calibration Framework (GRCF) inspired by Group Relative Policy Optimization (GRPO). Stage 1: GRPO-inspired Advantage-Weighted Dynamic Margin Ranking Loss builds fine-grained ordinal structure. Stage 2: MAE-driven objective aligns prediction magnitudes. Framework is extended to classification tasks like humor and sarcasm detection.", "result": "GRCF achieves state-of-the-art performance on core regression benchmarks for multimodal sentiment analysis. It also demonstrates strong generalizability in classification tasks including multimodal humor detection and sarcasm detection.", "conclusion": "The proposed GRCF framework successfully addresses limitations of existing approaches by simultaneously preserving relative ordinal structure, ensuring absolute score calibration, and adaptively focusing on difficult samples, making it effective for both regression and classification tasks in multimodal sentiment analysis."}}
{"id": "2601.09647", "categories": ["cs.CV", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09647", "abs": "https://arxiv.org/abs/2601.09647", "authors": ["Ali Naseh", "Yuefeng Peng", "Anshuman Suri", "Harsh Chaudhari", "Alina Oprea", "Amir Houmansadr"], "title": "Identifying Models Behind Text-to-Image Leaderboards", "comment": null, "summary": "Text-to-image (T2I) models are increasingly popular, producing a large share of AI-generated images online. To compare model quality, voting-based leaderboards have become the standard, relying on anonymized model outputs for fairness. In this work, we show that such anonymity can be easily broken. We find that generations from each T2I model form distinctive clusters in the image embedding space, enabling accurate deanonymization without prompt control or training data. Using 22 models and 280 prompts (150K images), our centroid-based method achieves high accuracy and reveals systematic model-specific signatures. We further introduce a prompt-level distinguishability metric and conduct large-scale analyses showing how certain prompts can lead to near-perfect distinguishability. Our findings expose fundamental security flaws in T2I leaderboards and motivate stronger anonymization defenses.", "AI": {"tldr": "T2I model anonymity in leaderboards can be broken using centroid-based clustering in image embedding space, achieving high deanonymization accuracy without prompt control or training data.", "motivation": "To expose security flaws in text-to-image model leaderboards that rely on anonymized outputs for fair comparison, showing that model anonymity can be easily compromised.", "method": "Centroid-based clustering in image embedding space using 22 models and 280 prompts (150K images), with a prompt-level distinguishability metric to analyze model-specific signatures.", "result": "High deanonymization accuracy achieved, revealing systematic model-specific signatures and showing certain prompts lead to near-perfect distinguishability between models.", "conclusion": "Current T2I leaderboard anonymization is fundamentally flawed, requiring stronger defenses against deanonymization attacks that exploit model-specific signatures in generated images."}}
{"id": "2601.09652", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09652", "abs": "https://arxiv.org/abs/2601.09652", "authors": ["Emanuel da Costa Silva", "Tatiana Ta\u00eds Schein", "Jos\u00e9 David Garc\u00eda Ramos", "Eduardo Lawson da Silva", "Stephanie Loi Bri\u00e3o", "Felipe Gomes de Oliveira", "Paulo Lilles Jorge Drews-Jr"], "title": "AquaFeat+: an Underwater Vision Learning-based Enhancement Method for Object Detection, Classification, and Tracking", "comment": null, "summary": "Underwater video analysis is particularly challenging due to factors such as low lighting, color distortion, and turbidity, which compromise visual data quality and directly impact the performance of perception modules in robotic applications. This work proposes AquaFeat+, a plug-and-play pipeline designed to enhance features specifically for automated vision tasks, rather than for human perceptual quality. The architecture includes modules for color correction, hierarchical feature enhancement, and an adaptive residual output, which are trained end-to-end and guided directly by the loss function of the final application. Trained and evaluated in the FishTrack23 dataset, AquaFeat+ achieves significant improvements in object detection, classification, and tracking metrics, validating its effectiveness for enhancing perception tasks in underwater robotic applications.", "AI": {"tldr": "AquaFeat+ is a plug-and-play pipeline that enhances features for underwater video analysis tasks like object detection and tracking, addressing challenges like low lighting and color distortion.", "motivation": "Underwater video analysis faces severe challenges including low lighting, color distortion, and turbidity, which degrade visual data quality and negatively impact perception modules in robotic applications.", "method": "AquaFeat+ is an end-to-end trained architecture with modules for color correction, hierarchical feature enhancement, and adaptive residual output. It's guided directly by the loss function of the final application rather than human perceptual quality.", "result": "Trained and evaluated on the FishTrack23 dataset, AquaFeat+ achieves significant improvements in object detection, classification, and tracking metrics.", "conclusion": "AquaFeat+ effectively enhances perception tasks in underwater robotic applications by specifically targeting feature enhancement for automated vision tasks rather than human visual quality."}}
{"id": "2601.09658", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09658", "abs": "https://arxiv.org/abs/2601.09658", "authors": ["Selim Emir Can", "Jan Ackermann", "Kiyohiro Nakayama", "Ruofan Liu", "Tong Wu", "Yang Zheng", "Hugo Bertiche", "Menglei Chai", "Thabo Beeler", "Gordon Wetzstein"], "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image", "comment": null, "summary": "Estimating physically accurate, simulation-ready garments from a single image is challenging due to the absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either require multi-view capture and expensive differentiable simulation or predict only garment geometry without the material properties required for realistic simulation. We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a vision-language model to infer material composition and fabric attributes from real images, and then training a lightweight predictor that maps these attributes to the corresponding physical fabric parameters using a small dataset of material-physics measurements. Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a single image without iterative optimization. Experiments show that our estimator achieves superior accuracy in material composition estimation and fabric attribute prediction, and by passing them through our physics parameter estimator, we further achieve higher-fidelity simulations compared to state-of-the-art image-to-garment methods.", "AI": {"tldr": "Single-image garment estimation framework that predicts both geometry and physical material properties for simulation-ready garments using vision-language models and physics parameter mapping.", "motivation": "Current methods for estimating garments from images either require expensive multi-view capture with differentiable simulation or only predict geometry without material properties needed for realistic simulation. There's a lack of image-to-physics datasets and the problem is ill-posed.", "method": "Two-stage approach: 1) Fine-tune a vision-language model to infer material composition and fabric attributes from real images, 2) Train a lightweight predictor that maps these attributes to physical fabric parameters using a small dataset of material-physics measurements. Introduces two new datasets (FTAG and T2P).", "result": "Achieves superior accuracy in material composition estimation and fabric attribute prediction. When passed through the physics parameter estimator, produces higher-fidelity simulations compared to state-of-the-art image-to-garment methods. Enables simulation-ready garments from single images without iterative optimization.", "conclusion": "Proposed framework successfully addresses the challenge of estimating physically accurate, simulation-ready garments from single images by combining vision-language models with physics parameter mapping, overcoming limitations of prior methods that lacked material property prediction or required expensive multi-view capture."}}
{"id": "2601.09661", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09661", "abs": "https://arxiv.org/abs/2601.09661", "authors": ["Aishwarya Agarwal", "Srikrishna Karanam", "Vineet Gandhi"], "title": "LiteEmbed: Adapting CLIP to Rare Classes", "comment": "14 pages, 12 figures", "summary": "Large-scale vision-language models such as CLIP achieve strong zero-shot recognition but struggle with classes that are rarely seen during pretraining, including newly emerging entities and culturally specific categories. We introduce LiteEmbed, a lightweight framework for few-shot personalization of CLIP that enables new classes to be added without retraining its encoders. LiteEmbed performs subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based decomposition that disentangles coarse semantic directions from fine-grained variations. Two complementary objectives, coarse alignment and fine separation, jointly preserve global semantic consistency while enhancing discriminability among visually similar classes. Once optimized, the embeddings are plug-and-play, seamlessly substituting CLIP's original text features across classification, retrieval, segmentation, and detection tasks. Extensive experiments demonstrate substantial gains over prior methods, establishing LiteEmbed as an effective approach for adapting CLIP to underrepresented, rare, or unseen classes.", "AI": {"tldr": "LiteEmbed is a lightweight few-shot personalization framework for CLIP that adds new classes without retraining, using subspace-guided optimization of text embeddings with PCA decomposition for coarse semantic alignment and fine-grained separation.", "motivation": "CLIP struggles with rare, emerging, and culturally specific classes that were underrepresented during pretraining, creating a need for efficient adaptation without full retraining.", "method": "Uses subspace-guided optimization of text embeddings within CLIP's vocabulary via PCA decomposition to disentangle coarse semantic directions from fine variations. Employs two objectives: coarse alignment for global consistency and fine separation for discriminability among similar classes.", "result": "Substantial gains over prior methods, enabling effective adaptation of CLIP to underrepresented, rare, or unseen classes across classification, retrieval, segmentation, and detection tasks.", "conclusion": "LiteEmbed establishes an effective plug-and-play approach for few-shot personalization of CLIP, making it practical for real-world applications with diverse and evolving class requirements."}}
{"id": "2601.09663", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09663", "abs": "https://arxiv.org/abs/2601.09663", "authors": ["Xuyang Fang", "Sion Hannuna", "Edwin Simpson", "Neill Campbell"], "title": "Self-Supervised Animal Identification for Long Videos", "comment": "11 pages, 1 figure", "summary": "Identifying individual animals in long-duration videos is essential for behavioral ecology, wildlife monitoring, and livestock management. Traditional methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long sequences due to memory constraints and temporal error propagation. We introduce a highly efficient, self-supervised method that reframes animal identification as a global clustering task rather than a sequential tracking problem. Our approach assumes a known, fixed number of individuals within a single video -- a common scenario in practice -- and requires only bounding box detections and the total count. By sampling pairs of frames, using a frozen pre-trained backbone, and employing a self-bootstrapping mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns discriminative features without identity labels. We adapt a Binary Cross Entropy loss from vision-language models, enabling state-of-the-art accuracy ($>$97\\%) while consuming less than 1 GB of GPU memory per batch -- an order of magnitude less than standard contrastive methods. Evaluated on challenging real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or surpasses supervised baselines trained on over 1,000 labeled frames, effectively removing the manual annotation bottleneck. This work enables practical, high-accuracy animal identification on consumer-grade hardware, with broad applicability in resource-constrained research settings. All code written for this paper are \\href{https://huggingface.co/datasets/tonyFang04/8-calves}{here}.", "AI": {"tldr": "A highly efficient self-supervised method for animal identification that reframes the problem as global clustering rather than sequential tracking, achieving >97% accuracy with minimal GPU memory usage.", "motivation": "Traditional animal identification methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long video sequences due to memory constraints and temporal error propagation.", "method": "Reframes animal identification as a global clustering task assuming known, fixed number of individuals. Uses bounding box detections and total count, samples frame pairs, employs frozen pre-trained backbone with self-bootstrapping mechanism using Hungarian algorithm for pseudo-label assignment, and adapts Binary Cross Entropy loss from vision-language models.", "result": "Achieves state-of-the-art accuracy (>97%) while consuming less than 1 GB of GPU memory per batch (order of magnitude less than standard contrastive methods). Matches or surpasses supervised baselines trained on over 1,000 labeled frames on challenging datasets (3D-POP pigeons and 8-calves feeding videos).", "conclusion": "Enables practical, high-accuracy animal identification on consumer-grade hardware, effectively removing the manual annotation bottleneck with broad applicability in resource-constrained research settings."}}
{"id": "2601.09665", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09665", "abs": "https://arxiv.org/abs/2601.09665", "authors": ["Yuchen Wu", "Jiahe Li", "Xiaohan Yu", "Lina Yu", "Jin Zheng", "Xiao Bai"], "title": "SCE-SLAM: Scale-Consistent Monocular SLAM via Scene Coordinate Embeddings", "comment": null, "summary": "Monocular visual SLAM enables 3D reconstruction from internet video and autonomous navigation on resource-constrained platforms, yet suffers from scale drift, i.e., the gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance through local optimization but accumulate scale drift due to the lack of global constraints among independent windows. To address this, we propose SCE-SLAM, an end-to-end SLAM system that maintains scale consistency through scene coordinate embeddings, which are learned patch-level representations encoding 3D geometric relationships under a canonical scale reference. The framework consists of two key modules: geometry-guided aggregation that leverages 3D spatial proximity to propagate scale information from historical observations through geometry-modulated attention, and scene coordinate bundle adjustment that anchors current estimates to the reference scale through explicit 3D coordinate constraints decoded from the scene coordinate embeddings. Experiments on KITTI, Waymo, and vKITTI demonstrate substantial improvements: our method reduces absolute trajectory error by 8.36m on KITTI compared to the best prior approach, while maintaining 36 FPS and achieving scale consistency across large-scale scenes.", "AI": {"tldr": "SCE-SLAM: A monocular visual SLAM system that uses learned scene coordinate embeddings to maintain scale consistency and reduce scale drift in long sequences while maintaining real-time performance.", "motivation": "Monocular visual SLAM suffers from scale drift - gradual divergence of estimated scale over long sequences. Existing frame-to-frame methods achieve real-time performance but accumulate scale drift due to lack of global constraints among independent windows.", "method": "Proposes SCE-SLAM with two key modules: 1) Geometry-guided aggregation that uses 3D spatial proximity to propagate scale information through geometry-modulated attention, and 2) Scene coordinate bundle adjustment that anchors current estimates to reference scale through explicit 3D coordinate constraints decoded from learned scene coordinate embeddings.", "result": "Experiments on KITTI, Waymo, and vKITTI show substantial improvements: reduces absolute trajectory error by 8.36m on KITTI compared to best prior approach, while maintaining 36 FPS and achieving scale consistency across large-scale scenes.", "conclusion": "SCE-SLAM effectively addresses scale drift in monocular visual SLAM through learned scene coordinate embeddings, achieving both scale consistency and real-time performance across large-scale scenes."}}
{"id": "2601.09668", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09668", "abs": "https://arxiv.org/abs/2601.09668", "authors": ["Ailin Huang", "Chengyuan Yao", "Chunrui Han", "Fanqi Wan", "Hangyu Guo", "Haoran Lv", "Hongyu Zhou", "Jia Wang", "Jian Zhou", "Jianjian Sun", "Jingcheng Hu", "Kangheng Lin", "Liang Zhao", "Mitt Huang", "Song Yuan", "Wenwen Qu", "Xiangfeng Wang", "Yanlin Lai", "Yingxiu Zhao", "Yinmin Zhang", "Yukang Shi", "Yuyang Chen", "Zejia Weng", "Ziyang Meng", "Ang Li", "Aobo Kong", "Bo Dong", "Changyi Wan", "David Wang", "Di Qi", "Dingming Li", "En Yu", "Guopeng Li", "Haiquan Yin", "Han Zhou", "Hanshan Zhang", "Haolong Yan", "Hebin Zhou", "Hongbo Peng", "Jiaran Zhang", "Jiashu Lv", "Jiayi Fu", "Jie Cheng", "Jie Zhou", "Jisheng Yin", "Jingjing Xie", "Jingwei Wu", "Jun Zhang", "Junfeng Liu", "Kaijun Tan", "Kaiwen Yan", "Liangyu Chen", "Lina Chen", "Mingliang Li", "Qian Zhao", "Quan Sun", "Shaoliang Pang", "Shengjie Fan", "Shijie Shang", "Siyuan Zhang", "Tianhao You", "Wei Ji", "Wuxun Xie", "Xiaobo Yang", "Xiaojie Hou", "Xiaoran Jiao", "Xiaoxiao Ren", "Xiangwen Kong", "Xin Huang", "Xin Wu", "Xing Chen", "Xinran Wang", "Xuelin Zhang", "Yana Wei", "Yang Li", "Yanming Xu", "Yeqing Shen", "Yuang Peng", "Yue Peng", "Yu Zhou", "Yusheng Li", "Yuxiang Yang", "Yuyang Zhang", "Zhe Xie", "Zhewei Huang", "Zhenyi Lu", "Zhimin Fan", "Zihui Cheng", "Daxin Jiang", "Qi Han", "Xiangyu Zhang", "Yibo Zhu", "Zheng Ge"], "title": "STEP3-VL-10B Technical Report", "comment": "50 pages", "summary": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.", "AI": {"tldr": "STEP3-VL-10B is a 10B parameter open-source multimodal model that achieves state-of-the-art performance rivaling models 10-20x larger through unified pre-training on 1.2T tokens and innovative parallel reasoning techniques.", "motivation": "To redefine the trade-off between model compactness and multimodal intelligence, creating an efficient yet powerful open-source foundation model that can compete with much larger proprietary models.", "method": "Two strategic shifts: 1) Unified, fully unfrozen pre-training on 1.2T multimodal tokens using language-aligned Perception Encoder with Qwen3-8B decoder, 2) Scaled post-training with over 1k RL iterations, plus Parallel Coordinated Reasoning (PaCoRe) for test-time compute scaling.", "result": "Despite only 10B parameters, rivals/surpasses models 10-20x larger (GLM-4.6V-106B, Qwen3-VL-235B) and proprietary flagships (Gemini 2.5 Pro, Seed-1.5-VL). Achieves 92.2% on MMBench, 80.11% on MMMU, 94.43% on AIME2025, 75.95% on MathVision.", "conclusion": "STEP3-VL-10B delivers best-in-class performance in a compact 10B footprint, providing the community with a powerful, efficient, and reproducible baseline through full model release."}}
{"id": "2601.09697", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09697", "abs": "https://arxiv.org/abs/2601.09697", "authors": ["Jieying Chen", "Jeffrey Hu", "Joan Lasenby", "Ayush Tewari"], "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering", "comment": "Project page: https://ayushtewari.com/projects/srender/", "summary": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.", "AI": {"tldr": "SRENDER: A 3D reconstruction-based video generation method that uses diffusion models to generate sparse keyframes, then renders full videos through 3D reconstruction, achieving 40x speedup over diffusion baselines.", "motivation": "Current diffusion-based video generation models are computationally inefficient (minutes of GPU time for seconds of video), creating barriers for real-time applications like embodied AI and VR/AR that require interactive video synthesis.", "method": "Generate sparse keyframes using diffusion models, lift them into 3D representations, then render intermediate views through 3D reconstruction. Includes adaptive keyframe selection model that predicts optimal number of keyframes based on camera trajectory complexity.", "result": "40x faster than diffusion baselines for generating 20-second videos while maintaining high visual fidelity and temporal stability. Uses sparse keyframes for simple trajectories and denser ones for complex camera motion.", "conclusion": "SRENDER offers a practical path toward efficient and controllable video synthesis by amortizing generation costs across hundreds of frames through 3D reconstruction and adaptive computation allocation."}}
{"id": "2601.09698", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09698", "abs": "https://arxiv.org/abs/2601.09698", "authors": ["Tony Danjun Wang", "Tolga Birdal", "Nassir Navab", "Lennart Bastian"], "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation", "comment": null, "summary": "3D pose estimation from sparse multi-views is a critical task for numerous applications, including action recognition, sports analysis, and human-robot interaction. Optimization-based methods typically follow a two-stage pipeline, first detecting 2D keypoints in each view and then associating these detections across views to triangulate the 3D pose. Existing methods rely on mere pairwise associations to model this correspondence problem, treating global consistency between views (i.e., cycle consistency) as a soft constraint. Yet, reconciling these constraints for multiple views becomes brittle when spurious associations propagate errors. We thus propose COMPOSE, a novel framework that formulates multi-view pose correspondence matching as a hypergraph partitioning problem rather than through pairwise association. While the complexity of the resulting integer linear program grows exponentially in theory, we introduce an efficient geometric pruning strategy to substantially reduce the search space. COMPOSE achieves improvements of up to 23% in average precision over previous optimization-based methods and up to 11% over self-supervised end-to-end learned methods, offering a promising solution to a widely studied problem.", "AI": {"tldr": "COMPOSE formulates multi-view 3D pose estimation as hypergraph partitioning instead of pairwise associations, using geometric pruning for efficiency, achieving significant improvements over existing methods.", "motivation": "Existing multi-view 3D pose estimation methods rely on brittle pairwise associations that propagate errors when dealing with spurious correspondences across multiple views, treating global consistency as a soft constraint.", "method": "COMPOSE formulates the correspondence problem as hypergraph partitioning rather than pairwise association, solving it as an integer linear program with an efficient geometric pruning strategy to reduce exponential search space complexity.", "result": "COMPOSE achieves up to 23% improvement in average precision over previous optimization-based methods and up to 11% improvement over self-supervised end-to-end learned methods.", "conclusion": "Hypergraph partitioning with geometric pruning offers a promising solution to multi-view pose correspondence, significantly outperforming existing approaches by better handling global consistency constraints."}}
{"id": "2601.09699", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.09699", "abs": "https://arxiv.org/abs/2601.09699", "authors": ["Ruiqi Shen", "Chang Liu", "Henghui Ding"], "title": "SAM3-DMS: Decoupled Memory Selection for Multi-target Video Segmentation of SAM3", "comment": "Code: https://github.com/FudanCVL/SAM3-DMS", "summary": "Segment Anything 3 (SAM3) has established a powerful foundation that robustly detects, segments, and tracks specified targets in videos. However, in its original implementation, its group-level collective memory selection is suboptimal for complex multi-object scenarios, as it employs a synchronized decision across all concurrent targets conditioned on their average performance, often overlooking individual reliability. To this end, we propose SAM3-DMS, a training-free decoupled strategy that utilizes fine-grained memory selection on individual objects. Experiments demonstrate that our approach achieves robust identity preservation and tracking stability. Notably, our advantage becomes more pronounced with increased target density, establishing a solid foundation for simultaneous multi-target video segmentation in the wild.", "AI": {"tldr": "SAM3-DMS improves multi-object video segmentation by decoupling memory selection per object instead of using synchronized group decisions, enhancing tracking stability especially in dense scenarios.", "motivation": "Original SAM3's group-level collective memory selection is suboptimal for complex multi-object scenarios because it uses synchronized decisions across all targets based on average performance, often overlooking individual object reliability.", "method": "Proposes SAM3-DMS, a training-free decoupled strategy that utilizes fine-grained memory selection on individual objects rather than synchronized group decisions.", "result": "Achieves robust identity preservation and tracking stability, with advantages becoming more pronounced as target density increases.", "conclusion": "Establishes a solid foundation for simultaneous multi-target video segmentation in the wild by addressing individual object reliability in memory selection."}}
