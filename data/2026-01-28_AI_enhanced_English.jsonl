{"id": "2601.18821", "categories": ["eess.IV", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.18821", "abs": "https://arxiv.org/abs/2601.18821", "authors": ["Avinash Kadimisetty", "Oswald C", "Sivaselvan B", "Alekhya Kadimisetty"], "title": "Lossy Image Compression -- A Frequent Sequence Mining perspective employing efficient Clustering", "comment": null, "summary": "This work explores the scope of Frequent Sequence Mining in the domain of Lossy Image Compression. The proposed work is based on the idea of clustering pixels and using the cluster identifiers in the compression. The DCT phase in JPEG is replaced with a combination of closed frequent sequence mining and k-means clustering to handle the redundant data effectively. This method focuses mainly on applying k-means clustering in parallel to all blocks of each component of the image to reduce the compression time. Conventional GSP algorithm is refined to optimize the cardinality of patterns through a novel pruning strategy, thus achieving a good reduction in the code table size. Simulations of the proposed algorithm indicate significant gains in compression ratio and quality in relation to the existing alternatives.", "AI": {"tldr": "This paper proposes a novel lossy image compression method that replaces JPEG's DCT with frequent sequence mining and k-means clustering to improve compression ratio and quality.", "motivation": "The motivation is to explore the application of Frequent Sequence Mining in lossy image compression, aiming to handle redundant data more effectively than traditional DCT-based approaches like JPEG.", "method": "The method replaces JPEG's DCT phase with a combination of closed frequent sequence mining and k-means clustering. It applies k-means clustering in parallel to all blocks of each image component to reduce compression time, and refines the conventional GSP algorithm with a novel pruning strategy to optimize pattern cardinality and reduce code table size.", "result": "Simulations show significant gains in both compression ratio and quality compared to existing alternatives, demonstrating improved performance over traditional compression methods.", "conclusion": "The proposed approach successfully integrates frequent sequence mining and clustering techniques into image compression, achieving better compression efficiency and quality than conventional methods while reducing computational time through parallel processing."}}
{"id": "2601.18826", "categories": ["eess.IV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.18826", "abs": "https://arxiv.org/abs/2601.18826", "authors": ["MAria Simona Tivadar", "Ioana Damian", "Adrian Groza", "Simona Delia Nicoara"], "title": "OCTA-Based Biomarker Characterization in nAMD", "comment": null, "summary": "We aim to enhance ophthalmologists' decision-making when diagnosing the Neovascular Age-Related Macular Degeneration (nAMD). We developed three tools to analyze Optical Coherence Tomography Angiography images: (1) extracting biomarkers such as mCNV area and vessel density using image processing; (2) generating a 3D visualization of the neovascularization for a better view of the affected regions; and (3) applying an ensemble of three white box machine learning algorithms (decision tree, support vector machines and DL-Learner) for nAMD diagnosis. The learned expressions reached 100% accuracy for the training data and 68% accuracy in testing. The main advantage is that all the learned models white-box, which ensures explainability and transparency, allowing clinicians to better understand the decision-making process.", "AI": {"tldr": "Three tools for nAMD diagnosis: biomarker extraction, 3D visualization, and white-box ML ensemble achieving 68% test accuracy with full explainability.", "motivation": "To enhance ophthalmologists' decision-making in diagnosing Neovascular Age-Related Macular Degeneration (nAMD) by providing transparent, explainable tools that help clinicians understand the diagnostic process.", "method": "Developed three complementary tools: (1) Image processing for biomarker extraction (mCNV area, vessel density), (2) 3D visualization of neovascularization, and (3) Ensemble of white-box ML algorithms (decision tree, SVM, DL-Learner) for diagnosis.", "result": "The ensemble model achieved 100% accuracy on training data and 68% accuracy on test data. The key advantage is the white-box nature of all models, ensuring explainability and transparency for clinical use.", "conclusion": "The proposed tools provide ophthalmologists with transparent, explainable diagnostic support for nAMD, combining quantitative biomarkers, 3D visualization, and interpretable machine learning to enhance clinical decision-making."}}
{"id": "2601.18932", "categories": ["eess.IV", "cs.IT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18932", "abs": "https://arxiv.org/abs/2601.18932", "authors": ["Yibo Yang", "Stephan Mandt"], "title": "Advances in Diffusion-Based Generative Compression", "comment": "Preprint", "summary": "Popularized by their strong image generation performance, diffusion and related methods for generative modeling have found widespread success in visual media applications. In particular, diffusion methods have enabled new approaches to data compression, where realistic reconstructions can be generated at extremely low bit-rates. This article provides a unifying review of recent diffusion-based methods for generative lossy compression, with a focus on image compression. These methods generally encode the source into an embedding and employ a diffusion model to iteratively refine it in the decoding procedure, such that the final reconstruction approximately follows the ground truth data distribution. The embedding can take various forms and is typically transmitted via an auxiliary entropy model, and recent methods also explore the use of diffusion models themselves for information transmission via channel simulation. We review representative approaches through the lens of rate-distortion-perception theory, highlighting the role of common randomness and connections to inverse problems, and identify open challenges.", "AI": {"tldr": "Review of diffusion-based methods for generative lossy image compression, covering encoding into embeddings, iterative refinement via diffusion models, and transmission approaches including entropy models and channel simulation.", "motivation": "Diffusion models have shown strong image generation performance, enabling new approaches to data compression that can generate realistic reconstructions at extremely low bit-rates, bridging generative modeling and compression.", "method": "Methods encode source into embeddings, use diffusion models to iteratively refine them during decoding, with embeddings transmitted via auxiliary entropy models or through diffusion models themselves via channel simulation.", "result": "Diffusion-based compression methods achieve realistic reconstructions at very low bit-rates by ensuring final reconstructions approximately follow ground truth data distribution, enabling high-quality compression.", "conclusion": "Review provides unifying framework for diffusion-based generative compression, analyzes through rate-distortion-perception theory, highlights role of common randomness and connections to inverse problems, and identifies open challenges in the field."}}
{"id": "2601.18920", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.18920", "abs": "https://arxiv.org/abs/2601.18920", "authors": ["Aria Nouri"], "title": "Belief-Combining Framework for Multi-Trace Reconstruction over Channels with Insertions, Deletions, and Substitutions", "comment": "5 pages, 5 figures", "summary": "Optimal reconstruction of a source sequence from multiple noisy traces corrupted by random insertions, deletions, and substitutions typically requires joint processing of all traces, leading to computational complexity that grows exponentially with the number of traces. In this work, we propose an iterative belief-combining procedure that computes symbol-wise a posteriori probabilities by propagating trace-wise inferences via message passing. We prove that, upon convergence, our method achieves the same reconstruction performance as joint maximum a posteriori estimation, while reducing the complexity to quadratic in the number of traces. This performance equivalence is validated using a real-world dataset of clustered short-strand DNA reads.", "AI": {"tldr": "Iterative belief-combining method achieves same reconstruction performance as joint MAP estimation with quadratic complexity instead of exponential.", "motivation": "Optimal reconstruction from multiple noisy traces requires joint processing with exponential complexity, which is computationally prohibitive for many traces.", "method": "Proposed iterative belief-combining procedure that computes symbol-wise a posteriori probabilities by propagating trace-wise inferences via message passing.", "result": "Method achieves same reconstruction performance as joint MAP estimation while reducing complexity to quadratic in number of traces. Validated using real-world dataset of clustered short-strand DNA reads.", "conclusion": "The proposed message passing approach provides computationally efficient reconstruction with optimal performance, making it practical for applications like DNA sequencing with multiple noisy traces."}}
{"id": "2601.19117", "categories": ["eess.IV", "cs.CV", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.19117", "abs": "https://arxiv.org/abs/2601.19117", "authors": ["Ranjan Maitra"], "title": "Optimized $k$-means color quantization of digital images in machine-based and human perception-based colorspaces", "comment": "25 pages, 11 figures, 5 tables, accepted in the Journal of Electronic Imaging", "summary": "Color quantization represents an image using a fraction of its original number of colors while only minimally losing its visual quality. The $k$-means algorithm is commonly used in this context, but has mostly been applied in the machine-based RGB colorspace composed of the three primary colors. However, some recent studies have indicated its improved performance in human perception-based colorspaces. We investigated the performance of $k$-means color quantization at four quantization levels in the RGB, CIE-XYZ, and CIE-LUV/CIE-HCL colorspaces, on 148 varied digital images spanning a wide range of scenes, subjects and settings. The Visual Information Fidelity (VIF) measure numerically assessed the quality of the quantized images, and showed that in about half of the cases, $k$-means color quantization is best in the RGB space, while at other times, and especially for higher quantization levels ($k$), the CIE-XYZ colorspace is where it usually does better. There are also some cases, especially at lower $k$, where the best performance is obtained in the CIE-LUV colorspace. Further analysis of the performances in terms of the distributions of the hue, chromaticity and luminance in an image presents a nuanced perspective and characterization of the images for which each colorspace is better for $k$-means color quantization.", "AI": {"tldr": "The paper compares k-means color quantization performance across RGB, CIE-XYZ, and CIE-LUV/HCL colorspaces at four quantization levels on 148 diverse images, finding that RGB performs best in about half of cases, CIE-XYZ excels at higher quantization levels, and CIE-LUV works well at lower k values.", "motivation": "While k-means is commonly used for color quantization, it has mostly been applied in machine-based RGB colorspace. Recent studies suggest improved performance in human perception-based colorspaces, motivating a systematic comparison across different colorspaces to determine optimal conditions for each.", "method": "Applied k-means color quantization at four quantization levels (different k values) across three colorspace categories: RGB (machine-based), CIE-XYZ, and CIE-LUV/CIE-HCL (human perception-based). Tested on 148 diverse digital images covering various scenes, subjects, and settings. Used Visual Information Fidelity (VIF) measure to numerically assess quantized image quality.", "result": "RGB colorspace performed best in about half of cases overall. CIE-XYZ colorspace showed superior performance especially at higher quantization levels (larger k). CIE-LUV colorspace performed best at lower quantization levels (smaller k). Analysis of hue, chromaticity, and luminance distributions provided nuanced characterization of which images benefit from each colorspace.", "conclusion": "No single colorspace universally outperforms others for k-means color quantization. Performance depends on quantization level and image characteristics. RGB remains competitive, especially for general cases, while CIE-XYZ excels at higher quantization levels, and CIE-LUV performs well at lower k values. Image-specific characteristics influence optimal colorspace selection."}}
{"id": "2601.19126", "categories": ["cs.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.19126", "abs": "https://arxiv.org/abs/2601.19126", "authors": ["Xi Wang", "Parastoo Sadeghi", "Guodong Shi"], "title": "How Entanglement Reshapes the Geometry of Quantum Differential Privacy", "comment": "27 pages, 3 figures", "summary": "Quantum differential privacy provides a rigorous framework for quantifying privacy guarantees in quantum information processing. While classical correlations are typically regarded as adversarial to privacy, the role of their quantum analogue, entanglement, is not well understood. In this work, we investigate how quantum entanglement fundamentally shapes quantum local differential privacy (QLDP). We consider a bipartite quantum system whose input state has a prescribed level of entanglement, characterized by a lower bound on the entanglement entropy. Each subsystem is then processed by a local quantum mechanism and measured using local operations only, ensuring that no additional entanglement is generated during the process. Our main result reveals a sharp phase-transition phenomenon in the relation between entanglement and QLDP: below a mechanism-dependent entropy threshold, the optimal privacy leakage level mirrors that of unentangled inputs; beyond this threshold, the privacy leakage level decreases with the entropy, which strictly improves privacy guarantees and can even turn some non-private mechanisms into private ones. The phase-transition phenomenon gives rise to a nonlinear dependence of the privacy leakage level on the entanglement entropy, even though the underlying quantum mechanisms and measurements are linear. We show that the transition is governed by the intrinsic non-convex geometry of the set of entanglement-constrained quantum states, which we parametrize as a smooth manifold and analyze via Riemannian optimization. Our findings demonstrate that entanglement serves as a genuine privacy-enhancing resource, offering a geometric and operational foundation for designing robust privacy-preserving quantum protocols.", "AI": {"tldr": "Entanglement in quantum systems creates a phase transition in privacy leakage: below an entropy threshold, privacy matches unentangled inputs; above it, privacy improves with entanglement, turning some non-private mechanisms into private ones.", "motivation": "To understand how quantum entanglement fundamentally shapes quantum local differential privacy (QLDP), since classical correlations are adversarial to privacy but the role of quantum entanglement is not well understood.", "method": "Study bipartite quantum systems with prescribed entanglement levels (lower-bounded entanglement entropy), processed by local quantum mechanisms with local measurements only (no additional entanglement generation). Analyze via Riemannian optimization on the smooth manifold of entanglement-constrained quantum states.", "result": "Reveals sharp phase-transition phenomenon: below mechanism-dependent entropy threshold, optimal privacy leakage equals unentangled case; above threshold, privacy leakage decreases with entropy, improving privacy guarantees and enabling private mechanisms from non-private ones.", "conclusion": "Entanglement serves as a genuine privacy-enhancing resource, with phase transition governed by non-convex geometry of entanglement-constrained states, providing geometric/operational foundation for designing robust privacy-preserving quantum protocols."}}
{"id": "2601.18913", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.18913", "abs": "https://arxiv.org/abs/2601.18913", "authors": ["Mohammad Elayan", "Wissam Kontar"], "title": "Learning the Pareto Space of Multi-Objective Autonomous Driving: A Modular, Data-Driven Approach", "comment": "Accepted for presentation/publication at the The IEEE Intelligent Vehicles Symposium of 2026 (IEEE IV 2026)", "summary": "Balancing safety, efficiency, and interaction is fundamental to designing autonomous driving agents and to understanding autonomous vehicle (AV) behavior in real-world operation. This study introduces an empirical learning framework that derives these trade-offs directly from naturalistic trajectory data. A unified objective space represents each AV timestep through composite scores of safety, efficiency, and interaction. Pareto dominance is applied to identify non-dominated states, forming an empirical frontier that defines the attainable region of balanced performance.\n  The proposed framework was demonstrated using the Third Generation Simulation (TGSIM) datasets from Foggy Bottom and I-395. Results showed that only 0.23\\% of AV driving instances were Pareto-optimal, underscoring the rarity of simultaneous optimization across objectives. Pareto-optimal states showed notably higher mean scores for safety, efficiency, and interaction compared to non-optimal cases, with interaction showing the greatest potential for improvement.\n  This minimally invasive and modular framework, which requires only kinematic and positional data, can be directly applied beyond the scope of this study to derive and visualize multi-objective learning surfaces", "AI": {"tldr": "An empirical learning framework analyzes autonomous driving trade-offs using naturalistic trajectory data, revealing that only 0.23% of driving instances achieve Pareto-optimal balance across safety, efficiency, and interaction objectives.", "motivation": "To understand and design autonomous driving agents that balance the fundamental trade-offs between safety, efficiency, and interaction in real-world operation, which is crucial for AV development and evaluation.", "method": "An empirical learning framework that derives trade-offs from naturalistic trajectory data using a unified objective space with composite scores for safety, efficiency, and interaction, applying Pareto dominance to identify non-dominated states and form empirical performance frontiers.", "result": "Only 0.23% of AV driving instances were Pareto-optimal, showing these balanced states are rare. Pareto-optimal states had significantly higher mean scores across all objectives, with interaction showing the greatest potential for improvement.", "conclusion": "The framework provides a minimally invasive, modular approach using only kinematic and positional data to derive multi-objective learning surfaces, offering practical tools for AV development and evaluation beyond the current study scope."}}
{"id": "2601.18927", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18927", "abs": "https://arxiv.org/abs/2601.18927", "authors": ["Yuanwei Liu", "Hao Jiang", "Xu Gan", "Xiaoxia Xu", "Jia Guo", "Zhaolin Wang", "Chongjun Ouyang", "Xidong Mu", "Zhiguo Ding", "Arumugam Nallanathan", "Octavia A. Dobre", "George K. Karagiannidis", "Robert Schober"], "title": "A Survey of Pinching-Antenna Systems (PASS)", "comment": "Submitted to IEEE journal", "summary": "The pinching-antenna system (PASS), recently proposed as a flexible-antenna technology, has been regarded as a promising solution for several challenges in next-generation wireless networks. It provides large-scale antenna reconfiguration, establishes stable line-of-sight links, mitigates signal blockage, and exploits near-field advantages through its distinctive architecture. This article aims to present a comprehensive overview of the state of the art in PASS. The fundamental principles of PASS are first discussed, including its hardware architecture, circuit and physical models, and signal models. Several emerging PASS designs, such as segmented PASS (S-PASS), center-fed PASS (C-PASS), and multi-mode PASS (M-PASS), are subsequently introduced, and their design features are discussed. In addition, the properties and promising applications of PASS for wireless sensing are reviewed. On this basis, recent progress in the performance analysis of PASS for both communications and sensing is surveyed, and the performance gains achieved by PASS are highlighted. Existing research contributions in optimization and machine learning are also summarized, with the practical challenges of beamforming and resource allocation being identified in relation to the unique transmission structure and propagation characteristics of PASS. Finally, several variants of PASS are presented, and key implementation challenges that remain open for future study are discussed.", "AI": {"tldr": "Comprehensive survey of Pinching-Antenna System (PASS) technology covering fundamentals, designs, applications, performance analysis, and open challenges for next-generation wireless networks.", "motivation": "PASS addresses key challenges in next-generation wireless networks by providing large-scale antenna reconfiguration, stable LoS links, blockage mitigation, and near-field advantages through its unique flexible-antenna architecture.", "method": "The paper presents a comprehensive overview including: fundamental principles (hardware architecture, circuit/physical models, signal models), emerging designs (S-PASS, C-PASS, M-PASS), wireless sensing applications, performance analysis for communications/sensing, and optimization/ML approaches.", "result": "The survey highlights PASS's performance gains, summarizes existing research contributions in optimization and machine learning, identifies practical challenges in beamforming and resource allocation, and presents several PASS variants.", "conclusion": "PASS is a promising flexible-antenna technology for next-generation wireless networks, but key implementation challenges remain open for future research, including practical beamforming, resource allocation, and further system optimization."}}
{"id": "2601.18845", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18845", "abs": "https://arxiv.org/abs/2601.18845", "authors": ["Zeineb Dridi", "Jihen Bennaceur", "Amine Ben Hassouna"], "title": "Dynamic Mask-Based Backdoor Attack Against Vision AI Models: A Case Study on Mushroom Detection", "comment": null, "summary": "Deep learning has revolutionized numerous tasks within the computer vision field, including image classification, image segmentation, and object detection. However, the increasing deployment of deep learning models has exposed them to various adversarial attacks, including backdoor attacks. This paper presents a novel dynamic mask-based backdoor attack method, specifically designed for object detection models. We exploit a dataset poisoning technique to embed a malicious trigger, rendering any models trained on this compromised dataset vulnerable to our backdoor attack. We particularly focus on a mushroom detection dataset to demonstrate the practical risks posed by such attacks on critical real-life domains. Our work also emphasizes the importance of creating a detailed backdoor attack scenario to illustrate the significant risks associated with the outsourcing practice. Our approach leverages SAM, a recent and powerful image segmentation AI model, to create masks for dynamic trigger placement, introducing a new and stealthy attack method. Through extensive experimentation, we show that our sophisticated attack scenario maintains high accuracy on clean data with the YOLOv7 object detection model while achieving high attack success rates on poisoned samples. Our approach surpasses traditional methods for backdoor injection, which are based on static and consistent patterns. Our findings underscore the urgent need for robust countermeasures to protect deep learning models from these evolving adversarial threats.", "AI": {"tldr": "A novel dynamic mask-based backdoor attack method for object detection models using SAM segmentation for stealthy trigger placement, demonstrated on mushroom detection to highlight risks in outsourcing.", "motivation": "Deep learning models are increasingly vulnerable to adversarial attacks like backdoor attacks, especially in critical real-life domains. The paper aims to demonstrate practical risks of backdoor attacks on object detection models and highlight the dangers of outsourcing practices.", "method": "Uses dataset poisoning to embed malicious triggers, leverages SAM (Segment Anything Model) to create dynamic masks for trigger placement, and focuses on stealthy attacks that maintain clean data accuracy while achieving high attack success rates on poisoned samples.", "result": "The approach maintains high accuracy on clean data with YOLOv7 while achieving high attack success rates on poisoned samples, surpassing traditional static pattern-based backdoor injection methods.", "conclusion": "The research demonstrates the effectiveness of dynamic mask-based backdoor attacks, underscores the urgent need for robust countermeasures against evolving adversarial threats, and highlights the significant risks in outsourcing practices."}}
{"id": "2601.18800", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18800", "abs": "https://arxiv.org/abs/2601.18800", "authors": ["Yoontae Hwang", "Dongwoo Lee", "Minseok Choi", "Yong Sup Ihn", "Daham Kim", "Deok-Young Lee"], "title": "NavFormer: IGRF Forecasting in Moving Coordinate Frames", "comment": null, "summary": "Triad magnetometer components change with sensor attitude even when the IGRF total intensity target stays invariant. NavFormer forecasts this invariant target with rotation invariant scalar features and a Canonical SPD module that stabilizes the spectrum of window level second moments of the triads without sign discontinuities. The module builds a canonical frame from a Gram matrix per window and applies state dependent spectral scaling in the original coordinates. Experiments across five flights show lower error than strong baselines in standard training, few shot training, and zero shot transfer. The code is available at: https://anonymous.4open.science/r/NavFormer-Robust-IGRF-Forecasting-for-Autonomous-Navigators-0765", "AI": {"tldr": "NavFormer uses rotation-invariant features and a Canonical SPD module to forecast IGRF total intensity from triad magnetometer data, achieving better performance than baselines across various training scenarios.", "motivation": "Triad magnetometer readings change with sensor orientation even when the IGRF total intensity remains constant, creating challenges for accurate forecasting that needs to be invariant to rotation.", "method": "Uses rotation-invariant scalar features and a Canonical SPD module that stabilizes the spectrum of window-level second moments of triads without sign discontinuities. The module builds a canonical frame from a Gram matrix per window and applies state-dependent spectral scaling in original coordinates.", "result": "Experiments across five flights show lower error than strong baselines in standard training, few-shot training, and zero-shot transfer scenarios.", "conclusion": "NavFormer provides robust IGRF forecasting for autonomous navigation by effectively handling rotation invariance through novel architectural components, with code publicly available."}}
{"id": "2601.18833", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.18833", "abs": "https://arxiv.org/abs/2601.18833", "authors": ["Marlon Dumas", "Fredrik Milani", "David Chapela-Campa"], "title": "Agentic Business Process Management Systems", "comment": "Presented at the BPM'2025 conference on Artificial Intelligence for Business Process Management (AI4BPM)", "summary": "Since the early 90s, the evolution of the Business Process Management (BPM) discipline has been punctuated by successive waves of automation technologies. Some of these technologies enable the automation of individual tasks, while others focus on orchestrating the execution of end-to-end processes. The rise of Generative and Agentic Artificial Intelligence (AI) is opening the way for another such wave. However, this wave is poised to be different because it shifts the focus from automation to autonomy and from design-driven management of business processes to data-driven management, leveraging process mining techniques. This position paper, based on a keynote talk at the 2025 Workshop on AI for BPM, outlines how process mining has laid the foundations on top of which agents can sense process states, reason about improvement opportunities, and act to maintain and optimize performance. The paper proposes an architectural vision for Agentic Business Process Management Systems (A-BPMS): a new class of platforms that integrate autonomy, reasoning, and learning into process management and execution. The paper contends that such systems must support a continuum of processes, spanning from human-driven to fully autonomous, thus redefining the boundaries of process automation and governance.", "AI": {"tldr": "The paper proposes Agentic Business Process Management Systems (A-BPMS) that integrate AI agents with process mining to shift BPM from automation to autonomy and from design-driven to data-driven management.", "motivation": "The rise of Generative and Agentic AI presents an opportunity for a new wave in BPM evolution, shifting focus from automation to autonomy and from design-driven to data-driven process management using process mining techniques.", "method": "Proposes an architectural vision for A-BPMS that integrates autonomy, reasoning, and learning into process management, building on process mining foundations to enable agents to sense process states, reason about improvements, and act to optimize performance.", "result": "Outlines how process mining provides the foundation for AI agents in BPM and proposes a new class of platforms (A-BPMS) that support a continuum from human-driven to fully autonomous processes.", "conclusion": "A-BPMS will redefine process automation and governance boundaries by integrating AI agents with process mining, enabling autonomous, data-driven process management across the human-to-autonomous spectrum."}}
{"id": "2601.19169", "categories": ["eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19169", "abs": "https://arxiv.org/abs/2601.19169", "authors": ["Chenwei Wang", "Zhaoke Huang", "Zelin Li", "Wenqi Zhu"], "title": "Recover Cell Tensor: Diffusion-Equivalent Tensor Completion for Fluorescence Microscopy Imaging", "comment": null, "summary": "Fluorescence microscopy (FM) imaging is a fundamental technique for observing live cell division, one of the most essential processes in the cycle of life and death. Observing 3D live cells requires scanning through the cell volume while minimizing lethal phototoxicity. That limits acquisition time and results in sparsely sampled volumes with anisotropic resolution and high noise. Existing image restoration methods, primarily based on inverse problem modeling, assume known and stable degradation processes and struggle under such conditions, especially in the absence of high-quality reference volumes. In this paper, from a new perspective, we propose a novel tensor completion framework tailored to the nature of FM imaging, which inherently involves nonlinear signal degradation and incomplete observations. Specifically, FM imaging with equidistant Z-axis sampling is essentially a tensor completion task under a uniformly random sampling condition. On one hand, we derive the theoretical lower bound for exact cell tensor completion, validating the feasibility of accurately recovering 3D cell tensor. On the other hand, we reformulate the tensor completion problem as a mathematically equivalent score-based generative model. By incorporating structural consistency priors, the generative trajectory is effectively guided toward denoised and geometrically coherent reconstructions. Our method demonstrates state-of-the-art performance on SR-CACO-2 and three real \\textit{in vivo} cellular datasets, showing substantial improvements in both signal-to-noise ratio and structural fidelity.", "AI": {"tldr": "A tensor completion framework for 3D fluorescence microscopy imaging that treats sparse anisotropic sampling as a tensor completion problem and uses score-based generative modeling with structural priors for high-quality cell reconstruction.", "motivation": "Fluorescence microscopy imaging of live cells requires fast scanning to minimize phototoxicity, resulting in sparsely sampled volumes with anisotropic resolution and high noise. Existing inverse problem methods struggle with unknown degradation processes and lack of high-quality references.", "method": "Proposes a tensor completion framework tailored to FM imaging, treating equidistant Z-axis sampling as uniformly random tensor completion. Derives theoretical lower bound for exact completion, then reformulates it as a mathematically equivalent score-based generative model incorporating structural consistency priors to guide reconstructions.", "result": "Demonstrates state-of-the-art performance on SR-CACO-2 and three real in vivo cellular datasets, showing substantial improvements in both signal-to-noise ratio and structural fidelity compared to existing methods.", "conclusion": "The tensor completion approach with score-based generative modeling effectively addresses the challenges of sparse, noisy FM imaging, enabling accurate 3D cell reconstruction while overcoming limitations of traditional inverse problem methods."}}
{"id": "2601.19183", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19183", "abs": "https://arxiv.org/abs/2601.19183", "authors": ["Xiang Zhang", "Zhou Li", "Han Yu", "Kai Wan", "Hua Sun", "Mingyue Ji", "Giuseppe Caire"], "title": "Information-Theoretic Secure Aggregation over Regular Graphs", "comment": null, "summary": "Large-scale decentralized learning frameworks such as federated learning (FL), require both communication efficiency and strong data security, motivating the study of secure aggregation (SA). While information-theoretic SA is well understood in centralized and fully connected networks, its extension to decentralized networks with limited local connectivity remains largely unexplored. This paper introduces \\emph{topological secure aggregation} (TSA), which studies one-shot, information-theoretically secure aggregation of neighboring users' inputs over arbitrary network topologies. We develop a unified linear design framework that characterizes TSA achievability through the spectral properties of the communication graph, specifically the kernel of a diagonally modulated adjacency matrix. For several representative classes of $d$-regular graphs including ring, prism and complete topologies, we establish the optimal communication and secret key rate region. In particular, to securely compute one symbol of the neighborhood sum, each user must (i) store at least one key symbol, (ii) broadcast at least one message symbol, and (iii) collectively, all users must hold at least $d$ i.i.d. key symbols. Notably, this total key requirement depends only on the \\emph{neighborhood size} $d$, independent of the network size, revealing a fundamental limit of SA in decentralized networks with limited local connectivity.", "AI": {"tldr": "TSA enables secure aggregation in decentralized networks with limited connectivity, achieving optimal communication/key rates that depend only on neighborhood size, not network size.", "motivation": "Federated learning needs both communication efficiency and strong data security. While secure aggregation is well understood in centralized networks, it remains unexplored for decentralized networks with limited local connectivity.", "method": "Introduces topological secure aggregation (TSA) using a unified linear design framework that characterizes achievability through spectral properties of communication graphs, specifically the kernel of diagonally modulated adjacency matrices.", "result": "For d-regular graphs (ring, prism, complete topologies), establishes optimal communication and secret key rate region: each user must store \u22651 key symbol, broadcast \u22651 message symbol, and collectively all users must hold \u2265d i.i.d. key symbols.", "conclusion": "Total key requirement depends only on neighborhood size d, independent of network size, revealing a fundamental limit of secure aggregation in decentralized networks with limited local connectivity."}}
{"id": "2601.18923", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18923", "abs": "https://arxiv.org/abs/2601.18923", "authors": ["Manthan Patel", "Jonas Frey", "Mayank Mittal", "Fan Yang", "Alexander Hansson", "Amir Bar", "Cesar Cadena", "Marco Hutter"], "title": "DeFM: Learning Foundation Representations from Depth for Robotics", "comment": "Under review, 19 pages, 15 Figures, 9 Tables", "summary": "Depth sensors are widely deployed across robotic platforms, and advances in fast, high-fidelity depth simulation have enabled robotic policies trained on depth observations to achieve robust sim-to-real transfer for a wide range of tasks. Despite this, representation learning for depth modality remains underexplored compared to RGB, where large-scale foundation models now define the state of the art. To address this gap, we present DeFM, a self-supervised foundation model trained entirely on depth images for robotic applications. Using a DINO-style self-distillation objective on a curated dataset of 60M depth images, DeFM learns geometric and semantic representations that generalize to diverse environments, tasks, and sensors. To retain metric awareness across multiple scales, we introduce a novel input normalization strategy. We further distill DeFM into compact models suitable for resource-constrained robotic systems. When evaluated on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks, DeFM achieves state-of-the-art performance and demonstrates strong generalization from simulation to real-world environments. We release all our pretrained models, which can be adopted off-the-shelf for depth-based robotic learning without task-specific fine-tuning. Webpage: https://de-fm.github.io/", "AI": {"tldr": "DeFM is a self-supervised foundation model trained on 60M depth images for robotics, achieving SOTA on depth-based tasks with strong sim-to-real generalization.", "motivation": "Depth sensors are widely used in robotics, but representation learning for depth modality lags behind RGB, which has large-scale foundation models. There's a need for depth-specific foundation models for robotic applications.", "method": "Uses DINO-style self-distillation on 60M curated depth images with novel input normalization for metric awareness across scales. Also distills into compact models for resource-constrained systems.", "result": "Achieves state-of-the-art performance on depth-based classification, segmentation, navigation, locomotion, and manipulation benchmarks with strong sim-to-real generalization.", "conclusion": "DeFM provides effective depth representations for robotics, works off-the-shelf without fine-tuning, and bridges the gap between depth and RGB foundation models."}}
{"id": "2601.19173", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19173", "abs": "https://arxiv.org/abs/2601.19173", "authors": ["Yingzhe Mao", "Chao Zou", "Yanqun Tang"], "title": "SynthRM: A Synthetic Data Platform for Vision-Aided Mobile System Simulation", "comment": "conference", "summary": "Vision-aided wireless sensing is emerging as a cornerstone of 6G mobile computing. While data-driven approaches have advanced rapidly, establishing a precise geometric correspondence between ego-centric visual data and radio propagation remains a challenge. Existing paradigms typically either associate 2D topology maps and auxiliary information with radio maps, or provide 3D perspective views limited by sparse radio data. This spatial representation flattens the complex vertical interactions such as occlusion and diffraction that govern signal behavior in urban environments, rendering the task of cross-view signal inference mathematically ill-posed. To resolve this geometric ambiguity, we introduce SynthRM, a scalable synthetic data platform. SynthRM implements a Visible-Aligned-Surface simulation strategy: rather than probing a global volumetric grid, it performs ray-tracing directly onto the geometry exposed to the sensor. This approach ensures pixel-level consistency between visual semantics and electromagnetic response, transforming the learning objective into a physically well-posed problem. We demonstrate the platform's capabilities by presenting a diverse, city-scale dataset derived from procedurally generated environments. By combining efficient procedural synthesis with high-fidelity electromagnetic modeling, SynthRM provides a transparent, accessible foundation for developing next-generation mobile systems for environment-aware sensing and communication.", "AI": {"tldr": "SynthRM is a synthetic data platform that creates pixel-aligned visual and radio data to solve geometric ambiguity in vision-aided wireless sensing for 6G.", "motivation": "Existing approaches for vision-aided wireless sensing either use 2D topology maps with radio data or provide limited 3D views, which flatten complex vertical interactions like occlusion and diffraction. This makes cross-view signal inference mathematically ill-posed due to geometric ambiguity between visual data and radio propagation.", "method": "SynthRM implements a Visible-Aligned-Surface simulation strategy that performs ray-tracing directly onto the geometry exposed to sensors, rather than probing a global volumetric grid. This ensures pixel-level consistency between visual semantics and electromagnetic response, transforming the learning into a physically well-posed problem. The platform uses procedural generation to create diverse, city-scale datasets with high-fidelity electromagnetic modeling.", "result": "The paper demonstrates SynthRM's capabilities by presenting a diverse, city-scale dataset derived from procedurally generated environments. The platform provides a transparent, accessible foundation for developing next-generation mobile systems for environment-aware sensing and communication.", "conclusion": "SynthRM resolves the geometric ambiguity in vision-aided wireless sensing by creating pixel-aligned synthetic data, enabling physically well-posed learning problems for 6G mobile computing applications."}}
{"id": "2601.18849", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18849", "abs": "https://arxiv.org/abs/2601.18849", "authors": ["Yuhui Zhang", "Hui Yu", "Wei Liang", "Sunjie Zhang"], "title": "Audio-Driven Talking Face Generation with Blink Embedding and Hash Grid Landmarks Encoding", "comment": null, "summary": "Dynamic Neural Radiance Fields (NeRF) have demonstrated considerable success in generating high-fidelity 3D models of talking portraits. Despite significant advancements in the rendering speed and generation quality, challenges persist in accurately and efficiently capturing mouth movements in talking portraits. To tackle this challenge, we propose an automatic method based on blink embedding and hash grid landmarks encoding in this study, which can substantially enhance the fidelity of talking faces. Specifically, we leverage facial features encoded as conditional features and integrate audio features as residual terms into our model through a Dynamic Landmark Transformer. Furthermore, we employ neural radiance fields to model the entire face, resulting in a lifelike face representation. Experimental evaluations have validated the superiority of our approach to existing methods.", "AI": {"tldr": "Proposes an automatic method using blink embedding and hash grid landmarks encoding to enhance talking face fidelity in Dynamic Neural Radiance Fields (NeRF).", "motivation": "Existing Dynamic NeRF methods for talking portraits struggle with accurately and efficiently capturing mouth movements, despite advances in rendering speed and generation quality.", "method": "Uses blink embedding and hash grid landmarks encoding; integrates facial features as conditional features and audio features as residual terms via Dynamic Landmark Transformer; employs neural radiance fields for full face modeling.", "result": "Experimental evaluations show superiority over existing methods in generating lifelike talking face representations.", "conclusion": "The proposed approach effectively enhances talking face fidelity in Dynamic NeRF by better capturing mouth movements through novel blink embedding and landmark encoding techniques."}}
{"id": "2601.18803", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18803", "abs": "https://arxiv.org/abs/2601.18803", "authors": ["Olusegun Owoeye"], "title": "Latent Structural Similarity Networks for Unsupervised Discovery in Multivariate Time Series", "comment": null, "summary": "This paper proposes a task-agnostic discovery layer for multivariate time series that constructs a relational hypothesis graph over entities without assuming linearity, stationarity, or a downstream objective. The method learns window-level sequence representations using an unsupervised sequence-to-sequence autoencoder, aggregates these representations into entity-level embeddings, and induces a sparse similarity network by thresholding a latent-space similarity measure. This network is intended as an analyzable abstraction that compresses the pairwise search space and exposes candidate relationships for further investigation, rather than as a model optimized for prediction, trading, or any decision rule. The framework is demonstrated on a challenging real-world dataset of hourly cryptocurrency returns, illustrating how latent similarity induces coherent network structure; a classical econometric relation is also reported as an external diagnostic lens to contextualize discovered edges.", "AI": {"tldr": "Proposes a task-agnostic discovery layer for multivariate time series that builds relational hypothesis graphs without assumptions about linearity, stationarity, or downstream objectives.", "motivation": "To discover relationships in multivariate time series without making restrictive assumptions (linearity, stationarity) or being tied to specific prediction tasks, enabling exploratory analysis of entity relationships.", "method": "Uses unsupervised sequence-to-sequence autoencoder to learn window-level representations, aggregates into entity-level embeddings, then induces sparse similarity network by thresholding latent-space similarity measures.", "result": "Demonstrated on hourly cryptocurrency returns, showing latent similarity induces coherent network structure; classical econometric relation used as external diagnostic to contextualize discovered edges.", "conclusion": "The framework provides an analyzable abstraction that compresses pairwise search space and exposes candidate relationships for investigation, rather than being optimized for specific prediction or decision tasks."}}
{"id": "2601.18846", "categories": ["cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.18846", "abs": "https://arxiv.org/abs/2601.18846", "authors": ["Urban Skvorc", "Niki van Stein", "Moritz Seiler", "Britta Grimme", "Thomas B\u00e4ck", "Heike Trautmann"], "title": "LLM Driven Design of Continuous Optimization Problems with Controllable High-level Properties", "comment": "17 pages, accepted at EvoApplications 2026", "summary": "Benchmarking in continuous black-box optimisation is hindered by the limited structural diversity of existing test suites such as BBOB. We explore whether large language models embedded in an evolutionary loop can be used to design optimisation problems with clearly defined high-level landscape characteristics. Using the LLaMEA framework, we guide an LLM to generate problem code from natural-language descriptions of target properties, including multimodality, separability, basin-size homogeneity, search-space homogeneity and globallocal optima contrast. Inside the loop we score candidates through ELA-based property predictors. We introduce an ELA-space fitness-sharing mechanism that increases population diversity and steers the generator away from redundant landscapes. A complementary basin-of-attraction analysis, statistical testing and visual inspection, verifies that many of the generated functions indeed exhibit the intended structural traits. In addition, a t-SNE embedding shows that they expand the BBOB instance space rather than forming an unrelated cluster. The resulting library provides a broad, interpretable, and reproducible set of benchmark problems for landscape analysis and downstream tasks such as automated algorithm selection.", "AI": {"tldr": "LLMs can generate diverse optimization problems with specific landscape characteristics, expanding benchmark diversity beyond BBOB.", "motivation": "Existing benchmark suites like BBOB lack structural diversity, limiting comprehensive testing of optimization algorithms. Need for more diverse, interpretable benchmark problems.", "method": "Use LLaMEA framework with LLMs in evolutionary loop to generate problem code from natural-language descriptions of target properties (multimodality, separability, etc.). Score candidates using ELA-based property predictors with fitness-sharing mechanism for diversity.", "result": "Generated functions exhibit intended structural traits, expand BBOB instance space rather than forming unrelated clusters, and create a broad, interpretable benchmark library.", "conclusion": "LLMs can effectively generate diverse optimization benchmarks with specified characteristics, providing valuable resources for landscape analysis and algorithm selection."}}
{"id": "2601.19246", "categories": ["eess.IV", "cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2601.19246", "abs": "https://arxiv.org/abs/2601.19246", "authors": ["Hidenori Takeshima"], "title": "Magnetic Resonance Simulation of Effective Transverse Relaxation (T2*)", "comment": null, "summary": "Purpose: To simulate effective transverse relaxation ($T_2^*$) as a part of MR simulation. $T_2^*$ consists of reversible ($T_2^{\\prime}$) and irreversible ($T_2$) components. Whereas simulations of $T_2$ are easy, $T_2^{\\prime}$ is not easily simulated if only magnetizations of individual isochromats are simulated.\n  Theory and Methods: Efficient methods for simulating $T_2^{\\prime}$ were proposed. To approximate the Lorentzian function of $T_2^{\\prime}$ realistically, conventional simulators require 100+ isochromats. This approximation can be avoided by utilizing a linear phase model for simulating an entire Lorentzian function directly. To represent the linear phase model, the partial derivatives of the magnetizations with respect to the frequency axis were also simulated. To accelerate the simulations with these partial derivatives, the proposed methods introduced two techniques: analytic solutions, and combined transitions. For understanding the fundamental mechanism of the proposed method, a simple one-isochromat simulation was performed. For evaluating realistic cases, several pulse sequences were simulated using two phantoms with and without $T_2^{\\prime}$ simulations.\n  Results: The one-isochromat simulation demonstrated that $T_2^{\\prime}$ simulations were possible. In the realistic cases, $T_2^{\\prime}$ was recovered as expected without using 100+ isochromats for each point. The computational times with $T_2^{\\prime}$ simulations were only 2.0 to 2.7 times longer than those without $T_2^{\\prime}$ simulations. When the above-mentioned two techniques were utilized, the analytic solutions accelerated 19 times, and the combined transitions accelerated up to 17 times.\n  Conclusion: Both theory and results showed that the proposed methods simulated $T_2^{\\prime}$ efficiently by utilizing a linear model with a Lorentzian function, analytic solutions, and combined transitions.", "AI": {"tldr": "Proposed efficient methods for simulating T2' (reversible transverse relaxation) in MR simulations using linear phase model, analytic solutions, and combined transitions to avoid needing 100+ isochromats.", "motivation": "T2* relaxation in MRI consists of reversible (T2') and irreversible (T2) components. While T2 simulation is easy, T2' is difficult to simulate when only individual isochromat magnetizations are simulated, requiring 100+ isochromats for realistic Lorentzian function approximation.", "method": "Used linear phase model to simulate entire Lorentzian function directly, avoiding need for many isochromats. Simulated partial derivatives of magnetizations with respect to frequency axis. Introduced two acceleration techniques: analytic solutions and combined transitions. Tested with one-isochromat simulation for fundamental understanding and realistic pulse sequences with two phantoms.", "result": "One-isochromat simulation demonstrated T2' simulation capability. Realistic cases recovered T2' as expected without needing 100+ isochromats per point. Computational times with T2' simulations were only 2.0-2.7 times longer than without. Analytic solutions accelerated 19 times, combined transitions up to 17 times.", "conclusion": "Proposed methods efficiently simulate T2' using linear model with Lorentzian function, analytic solutions, and combined transitions, providing significant computational acceleration while maintaining accuracy."}}
{"id": "2601.19224", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19224", "abs": "https://arxiv.org/abs/2601.19224", "authors": ["Haohao Zhang", "Bowen Gu", "Xianhua Yu", "Hao Xie", "Liejun Wang", "Yongjun Xu", "Xiaoming Tao", "Haijun Zhang"], "title": "Movable-Antenna Empowered Backscatter ISAC: Toward Geometry-Adaptive, Low-Power Networks", "comment": "7 pages, 6 figures", "summary": "Backscatter-based integrated sensing and communication (B-ISAC) elevates passive tags into information-bearing scatterers, offering an ultra-low-power path toward dual-function wireless systems. However, this promise is fundamentally undermined by a cascaded backscattering link that suffers from severe double fading and is exquisitely sensitive to geometric misalignment. This article tackles this geometric bottleneck by integrating movable antenna systems (MAS) at the transceiver side. MAS provides real-time, controllable spatial degrees of freedom through sub-wavelength antenna repositioning, enabling active reconfiguration of the cascaded channel without modifying passive tags or consuming additional spectrum. We position this solution within a unified ISAC-backscatter communication-B-ISAC evolution, describe the resulting MAS-assisted B-ISAC architecture and operating principles, and demonstrate its system-level gains through comparative analysis and numerical results. Finally, we showcase the potential of this geometry-adaptive paradigm across key IoT application scenarios, pointing toward future motion-aware wireless networks.", "AI": {"tldr": "MAS-assisted B-ISAC uses movable antennas to overcome geometric limitations in backscatter-based integrated sensing and communication, enabling active channel reconfiguration without modifying passive tags.", "motivation": "Backscatter-based ISAC suffers from severe double fading and sensitivity to geometric misalignment due to cascaded backscattering links, fundamentally undermining its ultra-low-power promise for dual-function wireless systems.", "method": "Integrates Movable Antenna Systems (MAS) at transceiver side to provide real-time, controllable spatial degrees of freedom through sub-wavelength antenna repositioning, enabling active reconfiguration of cascaded channels without modifying passive tags or consuming additional spectrum.", "result": "Demonstrates system-level gains through comparative analysis and numerical results, showing improved performance in overcoming geometric bottlenecks and enabling geometry-adaptive wireless networks.", "conclusion": "MAS-assisted B-ISAC represents a geometry-adaptive paradigm with potential across key IoT applications, pointing toward future motion-aware wireless networks that overcome fundamental limitations of traditional backscatter systems."}}
{"id": "2601.18963", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18963", "abs": "https://arxiv.org/abs/2601.18963", "authors": ["Fauna Robotics", ":", "Diego Aldarondo", "Ana Pervan", "Daniel Corbalan", "Dave Petrillo", "Bolun Dai", "Aadhithya Iyer", "Nina Mortensen", "Erik Pearson", "Sridhar Pandian Arunachalam", "Emma Reznick", "David Weis", "Jacob Davison", "Samuel Patterson", "Tess Carella", "Michael Suguitan", "David Ye", "Oswaldo Ferro", "Nilesh Suriyarachchi", "Spencer Ling", "Erik Su", "Daniel Giebisch", "Peter Traver", "Sam Fonseca", "Mack Mor", "Rohan Singh", "Sertac Guven", "Kangni Liu", "Yaswanth Kumar Orru", "Ashiq Rahman Anwar Batcha", "Shruthi Ravindranath", "Silky Arora", "Hugo Ponte", "Dez Hernandez", "Utsav Chaudhary", "Zack Walker", "Michael Kelberman", "Ivan Veloz", "Christina Santa Lucia", "Kat Casale", "Helen Han", "Michael Gromis", "Michael Mignatti", "Jason Reisman", "Kelleher Guerin", "Dario Narvaez", "Christopher Anderson", "Anthony Moschella", "Robert Cochran", "Josh Merel"], "title": "Fauna Sprout: A lightweight, approachable, developer-ready humanoid robot", "comment": null, "summary": "Recent advances in learned control, large-scale simulation, and generative models have accelerated progress toward general-purpose robotic controllers, yet the field still lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or academic prototypes that are difficult to deploy and operate around people, limiting progress in robotics. We introduce Sprout, a developer platform designed to address these limitations through an emphasis on safety, expressivity, and developer accessibility. Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors to support safe operation in shared human spaces. The platform integrates whole-body control, manipulation with integrated grippers, and virtual-reality-based teleoperation within a unified hardware-software stack. An expressive head further enables social interaction -- a domain that remains underexplored on most utilitarian humanoids. By lowering physical and technical barriers to deployment, Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments.", "AI": {"tldr": "Sprout is a safe, expressive humanoid platform designed for long-term deployment in human environments, featuring compliant control, soft exteriors, and social interaction capabilities.", "motivation": "The field lacks platforms suitable for safe, expressive, long-term deployment in human environments. Most existing humanoids are either closed industrial systems or difficult academic prototypes that limit progress in robotics.", "method": "Sprout adopts a lightweight form factor with compliant control, limited joint torques, and soft exteriors for safety. It integrates whole-body control, manipulation with integrated grippers, VR-based teleoperation, and an expressive head for social interaction within a unified hardware-software stack.", "result": "Sprout provides a developer platform that lowers physical and technical barriers to deployment, enabling safe operation in shared human spaces and supporting social interaction capabilities.", "conclusion": "Sprout expands access to capable humanoid platforms and provides a practical basis for developing embodied intelligence in real human environments by emphasizing safety, expressivity, and developer accessibility."}}
{"id": "2601.19248", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19248", "abs": "https://arxiv.org/abs/2601.19248", "authors": ["Lina Zhu", "Lin Zhou"], "title": "Exponentially Consistent Low-Complexity Outlier Hypothesis Testing for Continuous Sequences", "comment": null, "summary": "In this work, we revisit outlier hypothesis testing and propose exponentially consistent, low-complexity fixed-length tests that achieve a better tradeoff between detection performance and computational complexity than existing exhaustive-search methods. In this setting, the goal is to identify outlying sequences from a set of observed sequences, where most sequences are i.i.d. from a nominal distribution and outliers are i.i.d. from a different anomalous distribution. While prior work has primarily focused on discrete-valued sequences, we extend the results of Bu et al. (TSP 2019) to continuous-valued sequences and develop a distribution-free test based on the MMD metric. Our framework handles both known and unknown numbers of outliers. In the unknown-count case, we bound the detection performance and characterize the tradeoff among the exponential decay rates of three types of error probabilities. Finally, we quantify the performance penalty incurred when the number of outliers is unknown.", "AI": {"tldr": "The paper proposes new fixed-length outlier detection tests that are exponentially consistent and computationally efficient, extending prior discrete methods to continuous sequences using MMD metrics, and handling both known and unknown outlier counts.", "motivation": "Existing outlier hypothesis testing methods face a tradeoff between detection performance and computational complexity, with exhaustive-search methods being computationally expensive. Prior work focused mainly on discrete-valued sequences, leaving a gap for continuous-valued sequences. There's also a need to handle scenarios where the number of outliers is unknown.", "method": "The authors extend Bu et al.'s results to continuous-valued sequences using Maximum Mean Discrepancy (MMD) metric to create distribution-free tests. They develop exponentially consistent, low-complexity fixed-length tests that work for both known and unknown numbers of outliers. For unknown outlier counts, they bound detection performance and characterize tradeoffs among error probability decay rates.", "result": "The proposed tests achieve better tradeoff between detection performance and computational complexity than existing exhaustive-search methods. The framework successfully handles continuous-valued sequences and both known/unknown outlier scenarios. The authors quantify the performance penalty when the number of outliers is unknown.", "conclusion": "The paper presents a significant advancement in outlier hypothesis testing by providing computationally efficient, exponentially consistent tests for continuous sequences that handle unknown outlier counts, with quantified performance tradeoffs."}}
{"id": "2601.18851", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18851", "abs": "https://arxiv.org/abs/2601.18851", "authors": ["Wei Liang", "Hui Yu", "Derui Ding", "Rachael E. Jack", "Philippe G. Schyns"], "title": "SelfieAvatar: Real-time Head Avatar reenactment from a Selfie Video", "comment": null, "summary": "Head avatar reenactment focuses on creating animatable personal avatars from monocular videos, serving as a foundational element for applications like social signal understanding, gaming, human-machine interaction, and computer vision. Recent advances in 3D Morphable Model (3DMM)-based facial reconstruction methods have achieved remarkable high-fidelity face estimation. However, on the one hand, they struggle to capture the entire head, including non-facial regions and background details in real time, which is an essential aspect for producing realistic, high-fidelity head avatars. On the other hand, recent approaches leveraging generative adversarial networks (GANs) for head avatar generation from videos can achieve high-quality reenactments but encounter limitations in reproducing fine-grained head details, such as wrinkles and hair textures. In addition, existing methods generally rely on a large amount of training data, and rarely focus on using only a simple selfie video to achieve avatar reenactment. To address these challenges, this study introduces a method for detailed head avatar reenactment using a selfie video. The approach combines 3DMMs with a StyleGAN-based generator. A detailed reconstruction model is proposed, incorporating mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details. Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks demonstrate that the proposed method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.", "AI": {"tldr": "This paper introduces a method for detailed head avatar reenactment using only a selfie video, combining 3DMMs with StyleGAN to achieve high-fidelity reconstruction with rich textures.", "motivation": "Current methods have limitations: 3DMM-based approaches struggle with capturing entire head regions and background in real-time, while GAN-based methods fail to reproduce fine-grained details like wrinkles and hair textures. Most methods require large training datasets and don't focus on using just a simple selfie video for avatar reenactment.", "method": "Proposes combining 3D Morphable Models (3DMMs) with a StyleGAN-based generator. Introduces a detailed reconstruction model with mixed loss functions for foreground reconstruction and avatar image generation during adversarial training to recover high-frequency details.", "result": "Qualitative and quantitative evaluations on self-reenactment and cross-reenactment tasks show the method achieves superior head avatar reconstruction with rich and intricate textures compared to existing approaches.", "conclusion": "The proposed approach successfully addresses the limitations of existing methods by enabling detailed head avatar reenactment from just a selfie video, achieving high-fidelity results with fine-grained details that previous methods couldn't capture."}}
{"id": "2601.18811", "categories": ["cs.LG", "q-fin.CP", "q-fin.PM", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18811", "abs": "https://arxiv.org/abs/2601.18811", "authors": ["Vincent Gurgul", "Ying Chen", "Stefan Lessmann"], "title": "Variational Quantum Circuit-Based Reinforcement Learning for Dynamic Portfolio Optimization", "comment": null, "summary": "This paper presents a Quantum Reinforcement Learning (QRL) solution to the dynamic portfolio optimization problem based on Variational Quantum Circuits. The implemented QRL approaches are quantum analogues of the classical neural-network-based Deep Deterministic Policy Gradient and Deep Q-Network algorithms. Through an empirical evaluation on real-world financial data, we show that our quantum agents achieve risk-adjusted performance comparable to, and in some cases exceeding, that of classical Deep RL models with several orders of magnitude more parameters. In addition to improved parameter efficiency, quantum agents exhibit reduced variability across market regimes, indicating robust behaviour under changing conditions. However, while quantum circuit execution is inherently fast at the hardware level, practical deployment on cloud-based quantum systems introduces substantial latency, making end-to-end runtime currently dominated by infrastructural overhead and limiting practical applicability. Taken together, our results suggest that QRL is theoretically competitive with state-of-the-art classical reinforcement learning and may become practically advantageous as deployment overheads diminish. This positions QRL as a promising paradigm for dynamic decision-making in complex, high-dimensional, and non-stationary environments such as financial markets. The complete codebase is released as open source at: https://github.com/VincentGurgul/qrl-dpo-public", "AI": {"tldr": "Quantum Reinforcement Learning (QRL) using Variational Quantum Circuits achieves comparable or better risk-adjusted performance than classical Deep RL models with far fewer parameters, though practical deployment faces latency challenges.", "motivation": "To develop quantum reinforcement learning solutions for dynamic portfolio optimization that can potentially outperform classical approaches with greater parameter efficiency and robustness in complex, non-stationary financial environments.", "method": "Implemented quantum analogues of Deep Deterministic Policy Gradient (DDPG) and Deep Q-Network (DQN) algorithms using Variational Quantum Circuits, evaluated on real-world financial data.", "result": "Quantum agents achieved risk-adjusted performance comparable to or exceeding classical Deep RL models with orders of magnitude more parameters, and exhibited reduced variability across market regimes indicating robust behavior.", "conclusion": "QRL is theoretically competitive with state-of-the-art classical reinforcement learning and may become practically advantageous as deployment overheads diminish, positioning it as a promising paradigm for dynamic decision-making in complex environments like financial markets."}}
{"id": "2601.18897", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18897", "abs": "https://arxiv.org/abs/2601.18897", "authors": ["Qusai Khaled", "Bahjat Mallak", "Uzay Kaymak", "Laura Genga"], "title": "Explainable Uncertainty Quantification for Wastewater Treatment Energy Prediction via Interval Type-2 Neuro-Fuzzy System", "comment": "Submitted to 21st International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2026)", "summary": "Wastewater treatment plants consume 1-3% of global electricity, making accurate energy forecasting critical for operational optimization and sustainability. While machine learning models provide point predictions, they lack explainable uncertainty quantification essential for risk-aware decision-making in safety-critical infrastructure. This study develops an Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Unlike black-box probabilistic methods, the proposed framework decomposes uncertainty across three levels: feature-level, footprint of uncertainty identify which variables introduce ambiguity, rule-level analysis reveals confidence in local models, and instance-level intervals quantify overall prediction uncertainty. Validated on Melbourne Water's Eastern Treatment Plant dataset, IT2-ANFIS achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs, while providing explainable uncertainty estimates that link prediction confidence directly to operational conditions and input variables.", "AI": {"tldr": "IT2-ANFIS model for wastewater treatment energy forecasting with explainable uncertainty quantification through fuzzy rule structures", "motivation": "Wastewater treatment consumes significant global energy (1-3% of electricity), requiring accurate energy forecasting for optimization. Current ML models lack explainable uncertainty quantification needed for risk-aware decisions in safety-critical infrastructure.", "method": "Develops Interval Type-2 Adaptive Neuro-Fuzzy Inference System (IT2-ANFIS) that generates interpretable prediction intervals through fuzzy rule structures. Decomposes uncertainty across three levels: feature-level (identifies ambiguous variables), rule-level (reveals confidence in local models), and instance-level (quantifies overall prediction uncertainty).", "result": "Validated on Melbourne Water's Eastern Treatment Plant dataset. Achieves comparable predictive performance to first order ANFIS with substantially reduced variance across training runs. Provides explainable uncertainty estimates linking prediction confidence directly to operational conditions and input variables.", "conclusion": "IT2-ANFIS offers a transparent uncertainty quantification framework for wastewater treatment energy forecasting, enabling risk-aware decision-making while maintaining predictive accuracy through interpretable fuzzy rule structures."}}
{"id": "2601.19293", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2601.19293", "abs": "https://arxiv.org/abs/2601.19293", "authors": ["Wuyang Cong", "Junqi Shi", "Lizhong Wang", "Weijing Shi", "Ming Lu", "Hao Chen", "Zhan Ma"], "title": "Reinforced Rate Control for Neural Video Compression via Inter-Frame Rate-Distortion Awareness", "comment": "Accepted by AAAI 2026", "summary": "Neural video compression (NVC) has demonstrated superior compression efficiency, yet effective rate control remains a significant challenge due to complex temporal dependencies. Existing rate control schemes typically leverage frame content to capture distortion interactions, overlooking inter-frame rate dependencies arising from shifts in per-frame coding parameters. This often leads to suboptimal bitrate allocation and cascading parameter decisions. To address this, we propose a reinforcement-learning (RL)-based rate control framework that formulates the task as a frame-by-frame sequential decision process. At each frame, an RL agent observes a spatiotemporal state and selects coding parameters to optimize a long-term reward that reflects rate-distortion (R-D) performance and bitrate adherence. Unlike prior methods, our approach jointly determines bitrate allocation and coding parameters in a single step, independent of group of pictures (GOP) structure. Extensive experiments across diverse NVC architectures show that our method reduces the average relative bitrate error to 1.20% and achieves up to 13.45% bitrate savings at typical GOP sizes, outperforming existing approaches. In addition, our framework demonstrates improved robustness to content variation and bandwidth fluctuations with lower coding overhead, making it highly suitable for practical deployment.", "AI": {"tldr": "RL-based rate control framework for neural video compression that jointly optimizes bitrate allocation and coding parameters frame-by-frame, achieving better rate-distortion performance and bitrate adherence than existing methods.", "motivation": "Existing rate control schemes for neural video compression overlook inter-frame rate dependencies, leading to suboptimal bitrate allocation and cascading parameter decisions. The complex temporal dependencies in NVC require a more sophisticated approach to rate control.", "method": "Proposes a reinforcement learning framework that formulates rate control as a sequential decision process. An RL agent observes spatiotemporal states at each frame and selects coding parameters to optimize long-term reward reflecting rate-distortion performance and bitrate adherence, independent of GOP structure.", "result": "Reduces average relative bitrate error to 1.20%, achieves up to 13.45% bitrate savings at typical GOP sizes, outperforms existing approaches. Demonstrates improved robustness to content variation and bandwidth fluctuations with lower coding overhead.", "conclusion": "The RL-based rate control framework effectively addresses inter-frame rate dependencies in neural video compression, providing superior performance, robustness, and practical deployability compared to existing methods."}}
{"id": "2601.19370", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19370", "abs": "https://arxiv.org/abs/2601.19370", "authors": ["Kaushlendra Pandey", "Harpreet S. Dhillon", "Abhishek K. Gupta"], "title": "On the Analysis of Platooned Vehicular Networks on Highways", "comment": null, "summary": "Vehicular platooning refers to coordinated and close movement of vehicular users (VUs) traveling together along a common route segment, offering strategic benefits such as reduced fuel costs, lower emissions, and improved traffic flow. {Highways offer a natural setting for platooning due to extended travel distances, yet their potential remains underexplored, particularly in terms of communication and connectivity. Given that effective platooning relies on robust vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) links, understanding connectivity dynamics on highways is essential.} In this paper, we analyze the dynamics of vehicular platooning on a highway and its impact on the performance of two forms of vehicular communications -- namely V2V and V2I communication -- compared to independent vehicle movement on a highway. The vehicular networks consists of road-side units (RSUs), modeled as a 1D Poisson point process (PPP), to provide the vehicular connectivity to the VUs. VUs are modeled as 1D PPP under the non-platooned traffic scenario (N-PTS) and as a 1D Matern cluster process (MCP) under the platooned traffic scenario (PTS). We evaluate the distribution on the per-RSU load, representing the number of VUs served, for the typical and tagged RSU. Additionally, we derive coverage probability (CP) and rate coverage (RC), which measures the probability of the signal-to-interference-plus-noise ratio (SINR) and achievable rate above a specified threshold at the typical VU along with their meta distribution (MD), providing a deeper understanding of the reliability and variability of these metrics across different spatial distributions of VUs and RSUs. Finally, we validate our theoretical findings through simulations and provide numerical insights into the impact of different traffic patterns on RSU load distribution, CP, and RC performance.", "AI": {"tldr": "This paper analyzes how vehicular platooning on highways affects V2V and V2I communication performance compared to independent vehicle movement, using stochastic geometry models to evaluate RSU load, coverage probability, and rate coverage.", "motivation": "Highways offer ideal conditions for vehicular platooning but its communication aspects remain underexplored. Since effective platooning depends on robust V2V and V2I connectivity, understanding these dynamics on highways is crucial for optimizing platooning systems.", "method": "Uses stochastic geometry: models RSUs as 1D Poisson point process, VUs as 1D PPP for non-platooned traffic and as 1D Matern cluster process for platooned traffic. Analyzes per-RSU load distribution, coverage probability, rate coverage, and their meta distributions for typical and tagged RSUs/VUs.", "result": "Theoretical analysis provides distributions for RSU load, coverage probability, and rate coverage metrics. Simulations validate theoretical findings and offer numerical insights into how different traffic patterns (platooned vs non-platooned) affect communication performance.", "conclusion": "The paper provides a comprehensive analytical framework for evaluating communication performance in vehicular platooning systems on highways, offering insights into connectivity dynamics that can inform the design and optimization of platooning technologies."}}
{"id": "2601.18971", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18971", "abs": "https://arxiv.org/abs/2601.18971", "authors": ["Ioannis G. Polyzos", "Konstantinos J. Kyriakopoulos"], "title": "A Switching Nonlinear Model Predictive Control Strategy for Safe Collision Handling by an Underwater Vehicle-Manipulator System", "comment": "This work has been submitted to the 2026 Mediterranean Conference on Control and Automation (MED) to be considered for publication. Figures and animations are available at https://zenodo.org/records/18357280", "summary": "For active intervention tasks in underwater environments, the use of autonomous vehicles is just now emerging as an active area of research. During operation, for various reasons, the robot might find itself on a collision course with an obstacle in its environment. In this paper, a switching Nonlinear Model Predictive Control (NMPC) strategy is proposed to safely handle collisions for an Underwater Vehicle-Manipulator System (UVMS). When avoiding the collision is impossible, the control algorithm takes advantage of the manipulator, using it to push against the obstacle, and deflect away from the collision. Virtual experiments are performed to demonstrate the algorithm's capability to successfully detect collisions and either avoid them, or use the manipulator to handle them appropriately without damaging sensitive areas of the vehicle.", "AI": {"tldr": "A switching NMPC strategy for underwater vehicles to handle collisions by either avoiding obstacles or using the manipulator to push against them when avoidance is impossible.", "motivation": "Underwater autonomous vehicles performing intervention tasks may encounter collision situations, and current approaches need better strategies to handle unavoidable collisions safely without damaging sensitive vehicle areas.", "method": "Proposes a switching Nonlinear Model Predictive Control (NMPC) strategy for Underwater Vehicle-Manipulator Systems that can either avoid collisions or use the manipulator to push against obstacles and deflect away when avoidance is impossible.", "result": "Virtual experiments demonstrate the algorithm successfully detects collisions and handles them appropriately - either avoiding them or using the manipulator to push against obstacles without damaging sensitive vehicle areas.", "conclusion": "The switching NMPC strategy provides an effective solution for safe collision handling in underwater intervention tasks, enabling autonomous vehicles to manage both avoidable and unavoidable collision scenarios using the manipulator as a protective tool."}}
{"id": "2601.19313", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19313", "abs": "https://arxiv.org/abs/2601.19313", "authors": ["Hetong Wang", "Yashuai Cao", "Tiejun Lv", "Jintao Wang", "Ni Wei", "Jiancheng An", "Chau Yuen"], "title": "Stacked Intelligent Metasurfaces-Based Electromagnetic Wave Domain Interference-Free Precoding", "comment": "16 pages, 13 figures, IEEE Transactions on Wirelesss Communications, Accepted", "summary": "This paper introduces an interference-free multi-stream transmission architecture leveraging stacked intelligent metasurfaces (SIMs), from a new perspective of interference exploitation. Unlike traditional interference exploitation precoding (IEP) which relies on computational hardware circuitry, we perform the precoding operations within the analog wave domain provided by SIMs. However, the benefits of SIM-enabled IEP are limited by the nonlinear distortion (NLD) caused by power amplifiers. A hardware-efficient interference-free transmitter architecture is developed to exploit SIM's high and flexible degree of freedom (DoF), where the NLD on modulated symbols can be directly compensated in the wave domain. Moreover, we design a frame-level SIM configuration scheme and formulate a maxmin problem on the safety margin function. With respect to the optimization of SIM phase shifts, we propose a recursive oblique manifold (ROM) algorithm to tackle the complex coupling among phase shifts across multiple layers. A flexible DoF-driven antenna selection (AS) scheme is explored in the SIM-enabled IEP system. Using an ROM-based alternating optimization (ROM-AO) framework, our approach jointly optimizes transmit AS, SIM phase shift design, and power allocation (PA), and develops a greedy safety margin-based AS algorithm. Simulations show that the proposed SIM-enabled frame-level IEP scheme significantly outperforms benchmarks. Specifically, the strategy with AS and PA can achieve a 20 dB performance gain compared to the case without any strategy under the 12 dB signal-to-noise ratio, which confirms the superiority of the NLD-aware IEP scheme and the effectiveness of the proposed algorithm.", "AI": {"tldr": "SIM-enabled interference exploitation precoding in wave domain with NLD compensation, using ROM algorithm for phase shift optimization and AS/PA strategies for 20dB performance gain.", "motivation": "Traditional IEP relies on computational hardware circuitry and suffers from nonlinear distortion from power amplifiers. SIMs offer analog wave domain precoding but need NLD compensation and efficient optimization methods.", "method": "Develop SIM-enabled IEP with wave domain NLD compensation, frame-level SIM configuration, maxmin safety margin optimization, ROM algorithm for multi-layer phase shifts, and ROM-AO framework for joint AS/SIM/PA optimization.", "result": "Proposed scheme achieves 20dB performance gain over no-strategy case at 12dB SNR, significantly outperforming benchmarks through effective NLD-aware IEP and optimization algorithms.", "conclusion": "SIM-enabled IEP with wave domain processing and NLD compensation, combined with ROM-AO optimization and AS/PA strategies, provides superior interference-free multi-stream transmission with substantial performance improvements."}}
{"id": "2601.18891", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18891", "abs": "https://arxiv.org/abs/2601.18891", "authors": ["Ghazaleh Serati", "Samuel Foucher", "Jerome Theau"], "title": "Weakly supervised framework for wildlife detection and counting in challenging Arctic environments: a case study on caribou (Rangifer tarandus)", "comment": "30 pages, 8 figures, submitted to Frontiers in Ecology and Evolution", "summary": "Caribou across the Arctic has declined in recent decades, motivating scalable and accurate monitoring approaches to guide evidence-based conservation actions and policy decisions. Manual interpretation from this imagery is labor-intensive and error-prone, underscoring the need for automatic and reliable detection across varying scenes. Yet, such automatic detection is challenging due to severe background heterogeneity, dominant empty terrain (class imbalance), small or occluded targets, and wide variation in density and scale. To make the detection model (HerdNet) more robust to these challenges, a weakly supervised patch-level pretraining based on a detection network's architecture is proposed. The detection dataset includes five caribou herds distributed across Alaska. By learning from empty vs. non-empty labels in this dataset, the approach produces early weakly supervised knowledge for enhanced detection compared to HerdNet, which is initialized from generic weights. Accordingly, the patch-based pretrain network attained high accuracy on multi-herd imagery (2017) and on an independent year's (2019) test sets (F1: 93.7%/92.6%, respectively), enabling reliable mapping of regions containing animals to facilitate manual counting on large aerial imagery. Transferred to detection, initialization from weakly supervised pretraining yielded consistent gains over ImageNet weights on both positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%), and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%). Remaining limitations are false positives from animal-like background clutter and false negatives related to low animal density occlusions. Overall, pretraining on coarse labels prior to detection makes it possible to rely on weakly-supervised pretrained weights even when labeled data are limited, achieving results comparable to generic-weight initialization.", "AI": {"tldr": "Weakly supervised patch-level pretraining improves caribou detection in aerial imagery by learning from empty vs. non-empty labels, outperforming generic ImageNet initialization and enabling reliable animal mapping for conservation monitoring.", "motivation": "Caribou populations are declining across the Arctic, requiring scalable and accurate monitoring methods. Manual interpretation of aerial imagery is labor-intensive and error-prone, necessitating automatic detection systems that can handle challenging conditions like background heterogeneity, class imbalance, small/occluded targets, and varying density/scale.", "method": "Proposed HerdNet with weakly supervised patch-level pretraining using a detection network architecture. The approach learns from empty vs. non-empty labels in a dataset of five caribou herds across Alaska, creating early weakly supervised knowledge for enhanced detection compared to initialization from generic ImageNet weights.", "result": "Patch-based pretraining achieved high accuracy on multi-herd imagery (2017: F1 93.7%) and independent 2019 test sets (F1 92.6%). When transferred to detection, weakly supervised pretraining outperformed ImageNet weights on positive patches (F1: 92.6%/93.5% vs. 89.3%/88.6%) and full-image counting (F1: 95.5%/93.3% vs. 91.5%/90.4%).", "conclusion": "Weakly supervised pretraining on coarse labels prior to detection enables reliable animal mapping even with limited labeled data, achieving results comparable to or better than generic-weight initialization. Remaining challenges include false positives from animal-like background clutter and false negatives from low-density occlusions."}}
{"id": "2601.18823", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18823", "abs": "https://arxiv.org/abs/2601.18823", "authors": ["Alejandro Ascarate", "Leo Lebrat", "Rodrigo Santa Cruz", "Clinton Fookes", "Olivier Salvado"], "title": "VAE with Hyperspherical Coordinates: Improving Anomaly Detection from Hypervolume-Compressed Latent Space", "comment": null, "summary": "Variational autoencoders (VAE) encode data into lower-dimensional latent vectors before decoding those vectors back to data. Once trained, one can hope to detect out-of-distribution (abnormal) latent vectors, but several issues arise when the latent space is high dimensional. This includes an exponential growth of the hypervolume with the dimension, which severely affects the generative capacity of the VAE. In this paper, we draw insights from high dimensional statistics: in these regimes, the latent vectors of a standard VAE are distributed on the `equators' of a hypersphere, challenging the detection of anomalies. We propose to formulate the latent variables of a VAE using hyperspherical coordinates, which allows compressing the latent vectors towards a given direction on the hypersphere, thereby allowing for a more expressive approximate posterior. We show that this improves both the fully unsupervised and OOD anomaly detection ability of the VAE, achieving the best performance on the datasets we considered, outperforming existing methods. For the unsupervised and OOD modalities, respectively, these are: i) detecting unusual landscape from the Mars Rover camera and unusual Galaxies from ground based imagery (complex, real world datasets); ii) standard benchmarks like Cifar10 and subsets of ImageNet as the in-distribution (ID) class.", "AI": {"tldr": "VAEs struggle with anomaly detection in high-dimensional latent spaces due to hyperspherical distribution patterns. The paper proposes using hyperspherical coordinates to compress latent vectors, improving anomaly detection performance on real-world and benchmark datasets.", "motivation": "Standard VAEs have limitations in detecting out-of-distribution anomalies in high-dimensional latent spaces. The latent vectors tend to distribute on hyperspherical \"equators,\" making anomaly detection challenging. There's a need to improve VAE's generative capacity and anomaly detection ability in high-dimensional regimes.", "method": "The paper proposes formulating VAE latent variables using hyperspherical coordinates. This approach allows compressing latent vectors towards specific directions on the hypersphere, creating a more expressive approximate posterior distribution. This modification addresses the hyperspherical distribution issue in high-dimensional latent spaces.", "result": "The proposed hyperspherical coordinate approach improves both fully unsupervised and out-of-distribution anomaly detection. It achieves best performance on considered datasets, outperforming existing methods. Tested on: 1) Mars Rover camera landscapes and galaxy imagery (real-world datasets), and 2) standard benchmarks like Cifar10 and ImageNet subsets as in-distribution classes.", "conclusion": "Using hyperspherical coordinates for VAE latent variables effectively addresses high-dimensional statistical challenges, enhancing anomaly detection capabilities. The method shows superior performance across diverse datasets, demonstrating practical value for real-world anomaly detection applications."}}
{"id": "2601.18924", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18924", "abs": "https://arxiv.org/abs/2601.18924", "authors": ["Andrew Jaffe", "Noah Reicin", "Jinho D. Choi"], "title": "RIFT: Reordered Instruction Following Testbed To Evaluate Instruction Following in Singular Multistep Prompt Structures", "comment": "13 pages, 5 figures, submitted to ACL ARR", "summary": "Large Language Models (LLMs) are increasingly relied upon for complex workflows, yet their ability to maintain flow of instructions remains underexplored. Existing benchmarks conflate task complexity with structural ordering, making it difficult to isolate the impact of prompt topology on performance. We introduce RIFT, Reordered Instruction Following Testbed, to assess instruction following by disentangling structure from content. Using rephrased Jeopardy! question-answer pairs, we test LLMs across two prompt structures: linear prompts, which progress sequentially, and jumping prompts, which preserve identical content but require non-sequential traversal. Across 10,000 evaluations spanning six state-of-the-art open-source LLMs, accuracy dropped by up to 72% under jumping conditions (compared to baseline), revealing a strong dependence on positional continuity. Error analysis shows that approximately 50% of failures stem from instruction-order violations and semantic drift, indicating that current architectures internalize instruction following as a sequential pattern rather than a reasoning skill. These results reveal structural sensitivity as a fundamental limitation in current architectures, with direct implications for applications requiring non-sequential control flow such as workflow automation and multi-agent systems.", "AI": {"tldr": "LLMs struggle with non-sequential instructions despite identical content, showing up to 72% accuracy drop when prompt structure changes from linear to jumping order.", "motivation": "Current benchmarks conflate task complexity with structural ordering, making it hard to isolate how prompt topology affects LLM performance. As LLMs are increasingly used for complex workflows, their ability to handle non-sequential instructions needs better assessment.", "method": "Introduces RIFT (Reordered Instruction Following Testbed) using rephrased Jeopardy! question-answer pairs. Tests LLMs across two prompt structures: linear (sequential) vs. jumping (non-sequential but identical content). Evaluates 10,000 cases across six state-of-the-art open-source LLMs.", "result": "Accuracy dropped by up to 72% under jumping conditions compared to baseline. Approximately 50% of failures stem from instruction-order violations and semantic drift. Shows LLMs strongly depend on positional continuity and internalize instruction following as sequential patterns rather than reasoning skills.", "conclusion": "Structural sensitivity is a fundamental limitation in current LLM architectures, with implications for applications requiring non-sequential control flow like workflow automation and multi-agent systems."}}
{"id": "2601.19349", "categories": ["eess.IV", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19349", "abs": "https://arxiv.org/abs/2601.19349", "authors": ["Chengxiang Guo", "Jian Wang", "Junhua Fei", "Xiao Li", "Chunling Chen", "Yun Jin"], "title": "AMGFormer: Adaptive Multi-Granular Transformer for Brain Tumor Segmentation with Missing Modalities", "comment": null, "summary": "Multimodal MRI is essential for brain tumor segmentation, yet missing modalities in clinical practice cause existing methods to exhibit >40% performance variance across modality combinations, rendering them clinically unreliable. We propose AMGFormer, achieving significantly improved stability through three synergistic modules: (1) QuadIntegrator Bridge (QIB) enabling spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences. On BraTS 2018, our method achieves 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations, solving the stability crisis. Single-modality ET segmentation shows 40-81% relative improvements over state-of-the-art methods. The method generalizes to BraTS 2020/2021, achieving up to 92.44% WT, 89.91% TC, 84.57% ET. The model demonstrates potential for clinical deployment with 1.2s inference. Code: https://github.com/guochengxiangives/AMGFormer.", "AI": {"tldr": "AMGFormer addresses the stability crisis in brain tumor segmentation when MRI modalities are missing, achieving consistent performance with <0.5% variance across 15 modality combinations through three synergistic modules.", "motivation": "Existing brain tumor segmentation methods suffer from >40% performance variance when MRI modalities are missing in clinical practice, making them clinically unreliable. The stability crisis needs to be solved for practical deployment.", "method": "Three synergistic modules: (1) QuadIntegrator Bridge (QIB) for spatially adaptive fusion maintaining consistent predictions regardless of available modalities, (2) Multi-Granular Attention Orchestrator (MGAO) focusing on pathological regions to reduce background sensitivity, and (3) Modality Quality-Aware Enhancement (MQAE) preventing error propagation from corrupted sequences.", "result": "On BraTS 2018: 89.33% WT, 82.70% TC, 67.23% ET Dice scores with <0.5% variance across 15 modality combinations. Single-modality ET segmentation shows 40-81% relative improvements over SOTA. Generalizes to BraTS 2020/2021 with up to 92.44% WT, 89.91% TC, 84.57% ET. Fast inference at 1.2s.", "conclusion": "AMGFormer solves the stability crisis in multimodal brain tumor segmentation, achieving consistent performance across missing modalities with minimal variance, demonstrating strong potential for clinical deployment with fast inference times."}}
{"id": "2601.19704", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19704", "abs": "https://arxiv.org/abs/2601.19704", "authors": ["Hao Feng", "Ming Zeng", "Xingwang Li", "Wenwu Xie", "Nian Xia", "Octavia A. Dobre"], "title": "Joint Power Allocation and Antenna Placement for Pinching-Antenna Systems under User Location Uncertainty", "comment": "submitted to IEEE journals; pinching antenna; user location uncertainty; imperfect CSI", "summary": "Pinching antenna systems have attracted much attention recently owing to its capability to maintain reliable line-of-sight (LoS) communication in high-frequency bands. By guiding signals through a waveguide and emitting them via a movable pinching antenna, these systems enable dynamic control of signal propagation and spatial adaptability. However, their performance heavily depends on effective resource allocation-encompassing power, bandwidth, and antenna positioning-which becomes challenging under imperfect channel state information (CSI) and user localization uncertainty. Existing studies largely assume perfect CSI or ideal user positioning, while our prior work considered uniform localization errors, an oversimplified assumption. In this paper, we develop a robust resource allocation framework for multiuser downlink pinching antenna systems under Gaussian-distributed localization uncertainty, which more accurately models real-world positioning errors. An energy efficiency (EE) maximization problem is formulated subject to probabilistic outage constraints, and an analytical power allocation strategy is derived under given antenna positions. On this basis, the heuristic particle swarm optimization (PSO) algorithm is employed to identify the antenna position that achieves the global EE configuration. Simulation results illustrate that the proposed scheme greatly enhances both EE and system reliability compared with fixed-antenna benchmark, validating its effectiveness for practical high-frequency wireless deployments.", "AI": {"tldr": "Robust resource allocation for multiuser pinching antenna systems under Gaussian localization uncertainty, using analytical power allocation and PSO optimization to maximize energy efficiency with outage constraints.", "motivation": "Pinching antenna systems enable dynamic signal control for high-frequency LoS communication, but performance depends on resource allocation (power, bandwidth, antenna positioning) which is challenging under imperfect CSI and user localization uncertainty. Existing work assumes perfect CSI or ideal positioning, while prior work considered uniform errors - an oversimplification.", "method": "Develop robust resource allocation framework for multiuser downlink pinching antenna systems under Gaussian-distributed localization uncertainty. Formulate energy efficiency maximization problem with probabilistic outage constraints, derive analytical power allocation strategy under given antenna positions, then use heuristic particle swarm optimization (PSO) to find optimal antenna position for global EE configuration.", "result": "Simulation results show the proposed scheme greatly enhances both energy efficiency and system reliability compared with fixed-antenna benchmark, validating effectiveness for practical high-frequency wireless deployments.", "conclusion": "The proposed robust resource allocation framework effectively addresses real-world localization uncertainty in pinching antenna systems, providing significant improvements in energy efficiency and reliability for high-frequency wireless communication deployments."}}
{"id": "2601.19079", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19079", "abs": "https://arxiv.org/abs/2601.19079", "authors": ["Naqash Afzal", "Niklas Funk", "Erik Helmut", "Jan Peters", "Benjamin Ward-Cherrier"], "title": "Neuromorphic BrailleNet: Accurate and Generalizable Braille Reading Beyond Single Characters through Event-Based Optical Tactile Sensing", "comment": null, "summary": "Conventional robotic Braille readers typically rely on discrete, character-by-character scanning, limiting reading speed and disrupting natural flow. Vision-based alternatives often require substantial computation, introduce latency, and degrade in real-world conditions. In this work, we present a high accuracy, real-time pipeline for continuous Braille recognition using Evetac, an open-source neuromorphic event-based tactile sensor. Unlike frame-based vision systems, the neuromorphic tactile modality directly encodes dynamic contact events during continuous sliding, closely emulating human finger-scanning strategies. Our approach combines spatiotemporal segmentation with a lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying indentation depths and scanning speeds. The proposed system achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, and maintains strong performance under fast scanning. On a physical Braille board containing daily-living vocabulary, the system attains over 90% word-level accuracy, demonstrating robustness to temporal compression effects that challenge conventional methods. These results position neuromorphic tactile sensing as a scalable, low latency solution for robotic Braille reading, with broader implications for tactile perception in assistive and robotic applications.", "AI": {"tldr": "Real-time continuous Braille reading using neuromorphic tactile sensor achieves high accuracy (>98%) by mimicking human finger scanning, outperforming conventional character-by-character methods.", "motivation": "Existing robotic Braille readers are slow due to discrete character-by-character scanning, while vision-based systems suffer from computational latency and degrade in real-world conditions. There's a need for a more natural, continuous reading approach.", "method": "Uses Evetac, an open-source neuromorphic event-based tactile sensor that encodes dynamic contact events during continuous sliding. Combines spatiotemporal segmentation with lightweight ResNet-based classifier to process sparse event streams, enabling robust character recognition across varying conditions.", "result": "Achieves near-perfect accuracy (>=98%) at standard depths, generalizes across multiple Braille board layouts, maintains strong performance under fast scanning, and attains over 90% word-level accuracy on physical Braille board with daily-living vocabulary.", "conclusion": "Neuromorphic tactile sensing provides a scalable, low-latency solution for robotic Braille reading that closely emulates human finger-scanning strategies, with broader implications for tactile perception in assistive and robotic applications."}}
{"id": "2601.19366", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19366", "abs": "https://arxiv.org/abs/2601.19366", "authors": ["Weijie Xiong", "Jingran Lin", "Di Jiang", "Yuhan Zhang", "Kai Zhong", "Qiang Li"], "title": "Cooperative Double IRS aided Secure Communication for MIMO-OFDM Systems", "comment": null, "summary": "Cooperative double intelligent reflecting surface (double-IRS) has emerged as a promising approach for enhancing physical layer security (PLS) in MIMO systems. However, existing studies are limited to narrowband scenarios and fail to address wideband MIMO-OFDM. In this regime, frequency-flat IRS phases and cascaded IRS links cause severe coupling, rendering narrowband designs inapplicable. To overcome this challenge, we introduce cooperative double-IRS-assisted wideband MIMO-OFDM and propose an efficient manifold-based solution. By regarding the power and constant modulus constraints as Riemannian manifolds, we reformulate the non-convex secrecy sum rate maximization as an unconstrained optimization on a product manifold. Building on this formulation, we further develop a product Riemannian gradient descent (PRGD) algorithm with guaranteed stationary convergence. Simulation results demonstrate that the proposed scheme effectively resolves the OFDM coupling issue and achieves significant secrecy rate gains, outperforming single-IRS and distributed multi-IRS benchmarks by 32.0% and 22.3%, respectively.", "AI": {"tldr": "Proposes cooperative double-IRS for wideband MIMO-OFDM security, addressing frequency-flat IRS phase coupling with manifold optimization, achieving 32% gains over single-IRS.", "motivation": "Existing double-IRS studies are limited to narrowband scenarios and fail to address wideband MIMO-OFDM, where frequency-flat IRS phases and cascaded links cause severe coupling problems.", "method": "Introduces cooperative double-IRS-assisted wideband MIMO-OFDM and proposes a manifold-based solution: reformulates secrecy sum rate maximization as unconstrained optimization on product manifold, then develops product Riemannian gradient descent (PRGD) algorithm.", "result": "Proposed scheme effectively resolves OFDM coupling issue and achieves significant secrecy rate gains: outperforms single-IRS by 32.0% and distributed multi-IRS by 22.3%.", "conclusion": "Cooperative double-IRS with manifold optimization successfully addresses wideband MIMO-OFDM security challenges, providing substantial performance improvements over existing approaches."}}
{"id": "2601.18900", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18900", "abs": "https://arxiv.org/abs/2601.18900", "authors": ["Haim Zisman", "Uri Shaham"], "title": "RealStats: A Rigorous Real-Only Statistical Framework for Fake Image Detection", "comment": "22 pages, 14 figures. Accepted to AISTATS 2026", "summary": "As generative models continue to evolve, detecting AI-generated images remains a critical challenge. While effective detection methods exist, they often lack formal interpretability and may rely on implicit assumptions about fake content, potentially limiting robustness to distributional shifts. In this work, we introduce a rigorous, statistically grounded framework for fake image detection that focuses on producing a probability score interpretable with respect to the real-image population. Our method leverages the strengths of multiple existing detectors by combining training-free statistics. We compute p-values over a range of test statistics and aggregate them using classical statistical ensembling to assess alignment with the unified real-image distribution. This framework is generic, flexible, and training-free, making it well-suited for robust fake image detection across diverse and evolving settings.", "AI": {"tldr": "A statistically grounded framework for fake image detection that produces interpretable probability scores by combining multiple existing detectors through training-free statistical ensembling.", "motivation": "Current AI-generated image detection methods lack formal interpretability and rely on implicit assumptions about fake content, limiting their robustness to distributional shifts. There's a need for a rigorous, statistically grounded approach.", "method": "Leverages multiple existing detectors by combining training-free statistics. Computes p-values over a range of test statistics and aggregates them using classical statistical ensembling to assess alignment with the unified real-image distribution.", "result": "The framework produces probability scores interpretable with respect to the real-image population, making it generic, flexible, and training-free for robust detection across diverse settings.", "conclusion": "The proposed statistically grounded framework addresses interpretability and robustness limitations of existing fake image detection methods through formal statistical ensembling of multiple detectors."}}
{"id": "2601.18828", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18828", "abs": "https://arxiv.org/abs/2601.18828", "authors": ["Mohammad Zare"], "title": "IPBC: An Interactive Projection-Based Framework for Human-in-the-Loop Semi-Supervised Clustering of High-Dimensional Data", "comment": null, "summary": "High-dimensional datasets are increasingly common across scientific and industrial domains, yet they remain difficult to cluster effectively due to the diminishing usefulness of distance metrics and the tendency of clusters to collapse or overlap when projected into lower dimensions. Traditional dimensionality reduction techniques generate static 2D or 3D embeddings that provide limited interpretability and do not offer a mechanism to leverage the analyst's intuition during exploration. To address this gap, we propose Interactive Project-Based Clustering (IPBC), a framework that reframes clustering as an iterative human-guided visual analysis process. IPBC integrates a nonlinear projection module with a feedback loop that allows users to modify the embedding by adjusting viewing angles and supplying simple constraints such as must-link or cannot-link relationships. These constraints reshape the objective of the projection model, gradually pulling semantically related points closer together and pushing unrelated points further apart. As the projection becomes more structured and expressive through user interaction, a conventional clustering algorithm operating on the optimized 2D layout can more reliably identify distinct groups. An additional explainability component then maps each discovered cluster back to the original feature space, producing interpretable rules or feature rankings that highlight what distinguishes each cluster. Experiments on various benchmark datasets show that only a small number of interactive refinement steps can substantially improve cluster quality. Overall, IPBC turns clustering into a collaborative discovery process in which machine representation and human insight reinforce one another.", "AI": {"tldr": "IPBC is an interactive clustering framework that combines human guidance with machine learning to improve high-dimensional data clustering through iterative visual feedback and constraint-based optimization.", "motivation": "High-dimensional data clustering is challenging due to distance metric limitations and cluster collapse in lower dimensions. Traditional dimensionality reduction produces static embeddings with limited interpretability and no mechanism for incorporating analyst intuition.", "method": "Interactive Project-Based Clustering (IPBC) integrates nonlinear projection with a feedback loop where users adjust viewing angles and provide must-link/cannot-link constraints. These constraints reshape the projection objective to pull related points closer and push unrelated points apart, enabling conventional clustering on the optimized 2D layout.", "result": "Experiments show that only a small number of interactive refinement steps can substantially improve cluster quality. The framework enables more reliable identification of distinct groups through human-guided optimization.", "conclusion": "IPBC transforms clustering into a collaborative discovery process where machine representation and human insight reinforce each other, creating a more effective and interpretable approach to high-dimensional data analysis."}}
{"id": "2601.18944", "categories": ["cs.AI", "cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.18944", "abs": "https://arxiv.org/abs/2601.18944", "authors": ["Qiyuan Xu", "Xiaokun Luan", "Renxi Wang", "Joshua Ong Jun Leang", "Peixin Wang", "Haonan Li", "Wenda Li", "Conrad Watt"], "title": "Neural Theorem Proving for Verification Conditions: A Real-World Benchmark", "comment": "Accepted in ICLR'26", "summary": "Theorem proving is fundamental to program verification, where the automated proof of Verification Conditions (VCs) remains a primary bottleneck. Real-world program verification frequently encounters hard VCs that existing Automated Theorem Provers (ATPs) cannot prove, leading to a critical need for extensive manual proofs that burden practical application. While Neural Theorem Proving (NTP) has achieved significant success in mathematical competitions, demonstrating the potential of machine learning approaches to formal reasoning, its application to program verification--particularly VC proving--remains largely unexplored. Despite existing work on annotation synthesis and verification-related theorem proving, no benchmark has specifically targeted this fundamental bottleneck: automated VC proving. This work introduces Neural Theorem Proving for Verification Conditions (NTP4VC), presenting the first real-world multi-language benchmark for this task. From real-world projects such as Linux and Contiki-OS kernel, our benchmark leverages industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages of Isabelle, Lean, and Rocq. We evaluate large language models (LLMs), both general-purpose and those fine-tuned for theorem proving, on NTP4VC. Results indicate that although LLMs show promise in VC proving, significant challenges remain for program verification, highlighting a large gap and opportunity for future research.", "AI": {"tldr": "NTP4VC introduces the first real-world multi-language benchmark for neural theorem proving of verification conditions from industrial codebases like Linux and Contiki-OS kernels, showing LLMs have promise but significant challenges remain for program verification.", "motivation": "Automated proof of Verification Conditions (VCs) is a major bottleneck in program verification, with hard VCs often requiring extensive manual proofs. While Neural Theorem Proving has succeeded in mathematical competitions, its application to program verification remains unexplored, and no benchmark exists for this fundamental task.", "method": "Created NTP4VC benchmark using real-world projects (Linux and Contiki-OS kernels) with industrial pipelines (Why3 and Frama-C) to generate semantically equivalent test cases across formal languages (Isabelle, Lean, Rocq). Evaluated both general-purpose and theorem-proving fine-tuned LLMs on this benchmark.", "result": "LLMs show promise in VC proving but significant challenges remain for program verification, highlighting a large gap between current capabilities and practical needs, indicating substantial opportunity for future research.", "conclusion": "NTP4VC establishes the first real-world benchmark for neural theorem proving of verification conditions, demonstrating both the potential of LLMs and the significant remaining challenges in applying neural theorem proving to practical program verification tasks."}}
{"id": "2601.19743", "categories": ["eess.IV", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19743", "abs": "https://arxiv.org/abs/2601.19743", "authors": ["Jyun-Ping Kao", "Jiaxing Yang", "C. -C. Jay Kuo", "Jonghye Woo"], "title": "Interpretable and backpropagation-free Green Learning for efficient multi-task echocardiographic segmentation and classification", "comment": "Jyun-Ping Kao and Jiaxing Yang contributed equally to this work. C.-C. Jay Kuo and Jonghye Woo are the senior authors", "summary": "Echocardiography is a cornerstone for managing heart failure (HF), with Left Ventricular Ejection Fraction (LVEF) being a critical metric for guiding therapy. However, manual LVEF assessment suffers from high inter-observer variability, while existing Deep Learning (DL) models are often computationally intensive and data-hungry \"black boxes\" that impede clinical trust and adoption. Here, we propose a backpropagation-free multi-task Green Learning (MTGL) framework that performs simultaneous Left Ventricle (LV) segmentation and LVEF classification. Our framework integrates an unsupervised VoxelHop encoder for hierarchical spatio-temporal feature extraction with a multi-level regression decoder and an XG-Boost classifier. On the EchoNet-Dynamic dataset, our MTGL model achieves state-of-the-art classification and segmentation performance, attaining a classification accuracy of 94.3% and a Dice Similarity Coefficient (DSC) of 0.912, significantly outperforming several advanced 3D DL models. Crucially, our model achieves this with over an order of magnitude fewer parameters, demonstrating exceptional computational efficiency. This work demonstrates that the GL paradigm can deliver highly accurate, efficient, and interpretable solutions for complex medical image analysis, paving the way for more sustainable and trustworthy artificial intelligence in clinical practice.", "AI": {"tldr": "A backpropagation-free multi-task Green Learning framework achieves state-of-the-art LV segmentation and LVEF classification with high accuracy and computational efficiency, outperforming complex 3D DL models.", "motivation": "Manual LVEF assessment has high inter-observer variability, while existing Deep Learning models are computationally intensive \"black boxes\" that lack clinical trust and adoption.", "method": "Proposes a multi-task Green Learning framework combining unsupervised VoxelHop encoder for hierarchical spatio-temporal feature extraction with multi-level regression decoder and XG-Boost classifier for simultaneous LV segmentation and LVEF classification.", "result": "Achieves 94.3% classification accuracy and 0.912 Dice Similarity Coefficient on EchoNet-Dynamic dataset, significantly outperforming advanced 3D DL models with over an order of magnitude fewer parameters.", "conclusion": "Green Learning paradigm delivers accurate, efficient, and interpretable solutions for medical image analysis, enabling more sustainable and trustworthy AI in clinical practice."}}
{"id": "2601.19098", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19098", "abs": "https://arxiv.org/abs/2601.19098", "authors": ["Kurt Enkera", "Josh Pinskier", "Marcus Gallagher", "David Howard"], "title": "SimTO: A simulation-based topology optimization framework for bespoke soft robotic grippers", "comment": "12 pages, 8 figures. Submitted to Structural and Multidisciplinary Optimization", "summary": "Soft robotic grippers are essential for grasping delicate, geometrically complex objects in manufacturing, healthcare and agriculture. However, existing grippers struggle to grasp feature-rich objects with high topological variability, including gears with sharp tooth profiles on automotive assembly lines, corals with fragile protrusions, or vegetables with irregular branching structures like broccoli. Unlike simple geometric primitives such as cubes or spheres, feature-rich objects lack a clear \"optimal\" contact surface, making them both difficult to grasp and susceptible to damage when grasped by existing gripper designs. Safe handling of such objects therefore requires specialized soft grippers whose morphology is tailored to the object's features. Topology optimization offers a promising approach for producing specialized grippers, but its utility is limited by the requirement for pre-defined load cases. For soft grippers interacting with feature-rich objects, these loads arise from hundreds of unpredictable gripper-object contact forces during grasping and are unknown a priori. To address this problem, we introduce SimTO, a framework that enables high-resolution topology optimization by automatically extracting load cases from a contact-based physics simulator, eliminating the need for manual load specification. Given an arbitrary feature-rich object, SimTO produces highly customized soft grippers with fine-grained morphological features tailored to the object geometry. Numerical results show our designs are not only highly specialized to feature-rich objects, but also generalize to unseen objects.", "AI": {"tldr": "SimTO is a framework that uses contact-based physics simulation to automatically extract load cases for topology optimization, enabling creation of highly customized soft grippers for feature-rich objects without manual load specification.", "motivation": "Existing soft robotic grippers struggle to grasp feature-rich objects with high topological variability (like gears, corals, broccoli) because these objects lack clear optimal contact surfaces and are susceptible to damage. Topology optimization could help but requires pre-defined load cases, which are unknown for unpredictable gripper-object contact forces during grasping.", "method": "SimTO framework automatically extracts load cases from a contact-based physics simulator, eliminating manual load specification. It enables high-resolution topology optimization to produce customized soft grippers with fine-grained morphological features tailored to specific object geometries.", "result": "The framework produces highly specialized soft grippers for feature-rich objects. Numerical results show these designs are not only specialized to target objects but also generalize to unseen objects.", "conclusion": "SimTO addresses the limitation of traditional topology optimization by automating load case extraction from physics simulation, enabling creation of effective soft grippers for complex, feature-rich objects without manual intervention."}}
{"id": "2601.19372", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19372", "abs": "https://arxiv.org/abs/2601.19372", "authors": ["Hao Fang", "Xiao Li", "Chongtao Guo", "Le Liang", "Shi Jin"], "title": "AoI-Driven Queue Management and Power Control in V2V Networks: A GNN-Enhanced MARL Approach", "comment": null, "summary": "Queue management and resource allocation play a critical role in enabling cooperative status awareness in vehicular networks. This paper investigates the problem of age of information (AoI)-aware status updates in vehicle-to-vehicle (V2V) communication, where each vehicle's status is represented by multiple interdependent packets. To enable fine-grained queue management at the packet level under resource constraints, we formulate a joint optimization problem that simultaneously learns active packet dropping and transmit power control strategies. A hybrid action space is designed to support both discrete dropping decisions and continuous power control. To exploit the graph-structured interference inherent in V2V topology, a graph neural network (GNN) is introduced to aggregate slowly varying large-scale fading, allowing agents to capture topological dependencies implicitly without frequent message exchange. The overall framework is built upon multi-agent proximal policy optimization (MAPPO), with centralized training and decentralized execution (CTDE). Simulations demonstrate that the proposed method significantly reduces average AoI across a wide range of network densities, channel conditions, and traffic loads, consistently outperforming several baselines.", "AI": {"tldr": "The paper proposes a GNN-enhanced MAPPO framework for AoI-aware status updates in V2V networks, jointly optimizing packet dropping and power control to minimize age of information for interdependent packets.", "motivation": "In vehicular networks, cooperative status awareness requires efficient queue management and resource allocation. Existing approaches need to handle multiple interdependent packets per vehicle's status while dealing with resource constraints and graph-structured interference in V2V topology.", "method": "The paper formulates a joint optimization problem for packet dropping and transmit power control with hybrid action space. It introduces a GNN to aggregate large-scale fading and capture topological dependencies, built upon MAPPO with CTDE (centralized training, decentralized execution).", "result": "Simulations show the proposed method significantly reduces average AoI across various network densities, channel conditions, and traffic loads, consistently outperforming several baseline approaches.", "conclusion": "The GNN-enhanced MAPPO framework effectively addresses AoI-aware status updates in V2V networks by enabling fine-grained queue management and resource allocation while handling graph-structured interference and interdependent packets."}}
{"id": "2601.18929", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18929", "abs": "https://arxiv.org/abs/2601.18929", "authors": ["John J. Han", "Adam Schmidt", "Muhammad Abdullah Jamal", "Chinedu Nwoye", "Anita Rau", "Jie Ying Wu", "Omid Mohareri"], "title": "On the Role of Depth in Surgical Vision Foundation Models: An Empirical Study of RGB-D Pre-training", "comment": null, "summary": "Vision foundation models (VFMs) have emerged as powerful tools for surgical scene understanding. However, current approaches predominantly rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. Although several architectures support multimodal or geometry-aware inputs in general computer vision, the benefits of incorporating depth information in surgical settings remain underexplored. We conduct a large-scale empirical study comparing eight ViT-based VFMs that differ in pre-training domain, learning objective, and input modality (RGB vs. RGB-D). For pre-training, we use a curated dataset of 1.4 million robotic surgical images paired with depth maps generated from an off-the-shelf network. We evaluate these models under both frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation. Our experiments yield several consistent findings. Models incorporating explicit geometric tokenization, such as MultiMAE, substantially outperform unimodal baselines across all tasks. Notably, geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on the full dataset. Importantly, these gains require no architectural or runtime changes at inference; depth is used only during pre-training, making adoption straightforward. These findings suggest that multimodal pre-training offers a viable path towards building more capable surgical vision systems.", "AI": {"tldr": "Multimodal RGB-D pre-training with geometric tokenization substantially outperforms RGB-only approaches across surgical vision tasks, enabling remarkable data efficiency with no inference overhead.", "motivation": "Current surgical vision foundation models rely on unimodal RGB pre-training, overlooking the complex 3D geometry inherent to surgical environments. The benefits of incorporating depth information in surgical settings remain underexplored despite available multimodal architectures.", "method": "Large-scale empirical study comparing eight ViT-based vision foundation models with different pre-training domains, learning objectives, and input modalities (RGB vs. RGB-D). Pre-training used 1.4 million robotic surgical images with depth maps generated from an off-the-shelf network. Evaluation under frozen-backbone and end-to-end fine-tuning protocols across eight surgical datasets spanning object detection, segmentation, depth estimation, and pose estimation.", "result": "Models with explicit geometric tokenization (like MultiMAE) substantially outperform unimodal baselines across all tasks. Geometric-aware pre-training enables remarkable data efficiency: models fine-tuned on just 25% of labeled data consistently surpass RGB-only models trained on full datasets. Gains require no architectural or runtime changes at inference since depth is only used during pre-training.", "conclusion": "Multimodal pre-training offers a viable path towards building more capable surgical vision systems by leveraging depth information during pre-training without increasing inference complexity."}}
{"id": "2601.18829", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18829", "abs": "https://arxiv.org/abs/2601.18829", "authors": ["Yaohua Zha", "Chunlin Fan", "Peiyuan Liu", "Yong Jiang", "Tao Dai", "Hai Wu", "Shu-Tao Xia"], "title": "CP Loss: Channel-wise Perceptual Loss for Time Series Forecasting", "comment": "Accepted to ICASSP 2026", "summary": "Multi-channel time-series data, prevalent across diverse applications, is characterized by significant heterogeneity in its different channels. However, existing forecasting models are typically guided by channel-agnostic loss functions like MSE, which apply a uniform metric across all channels. This often leads to fail to capture channel-specific dynamics such as sharp fluctuations or trend shifts. To address this, we propose a Channel-wise Perceptual Loss (CP Loss). Its core idea is to learn a unique perceptual space for each channel that is adapted to its characteristics, and to compute the loss within this space. Specifically, we first design a learnable channel-wise filter that decomposes the raw signal into disentangled multi-scale representations, which form the basis of our perceptual space. Crucially, the filter is optimized jointly with the main forecasting model, ensuring that the learned perceptual space is explicitly oriented towards the prediction task. Finally, losses are calculated within these perception spaces to optimize the model. Code is available at https://github.com/zyh16143998882/CP_Loss.", "AI": {"tldr": "Proposes Channel-wise Perceptual Loss (CP Loss) for multi-channel time-series forecasting, addressing channel heterogeneity by learning channel-specific perceptual spaces rather than using uniform MSE loss.", "motivation": "Multi-channel time-series data has significant heterogeneity across channels, but existing forecasting models use channel-agnostic loss functions like MSE that fail to capture channel-specific dynamics such as sharp fluctuations or trend shifts.", "method": "CP Loss learns unique perceptual spaces for each channel adapted to their characteristics. Uses learnable channel-wise filters to decompose raw signals into disentangled multi-scale representations, forming the perceptual space. Filters are optimized jointly with the main forecasting model to ensure perceptual spaces are explicitly oriented toward prediction tasks.", "result": "The method enables better capture of channel-specific dynamics in multi-channel time-series forecasting. Code is publicly available.", "conclusion": "Channel-wise Perceptual Loss addresses the limitations of uniform loss functions in multi-channel time-series forecasting by learning channel-specific perceptual spaces that better capture heterogeneous channel dynamics."}}
{"id": "2601.19082", "categories": ["cs.AI", "cs.CL", "cs.GT", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.19082", "abs": "https://arxiv.org/abs/2601.19082", "authors": ["Trung-Kiet Huynh", "Dao-Sy Duy-Minh", "Thanh-Bang Cao", "Phong-Hao Le", "Hong-Dan Nguyen", "Nguyen Lam Phu Quy", "Minh-Luan Nguyen-Vo", "Hong-Phat Pham", "Pham Phu Hoa", "Thien-Kim Than", "Chi-Nguyen Tran", "Huy Tran", "Gia-Thoai Tran-Le", "Alessio Buscemi", "Le Hong Trang", "The Anh Han"], "title": "More at Stake: How Payoff and Language Shape LLM Agent Strategies in Cooperation Dilemmas", "comment": "14 pages, 10 figures, 4 tables", "summary": "As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems. We investigate how payoff magnitude and linguistic context shape LLM strategies in repeated social dilemmas, using a payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength. Across models and languages, we observe consistent behavioral patterns, including incentive-sensitive conditional strategies and cross-linguistic divergence. To interpret these dynamics, we train supervised classifiers on canonical repeated-game strategies and apply them to LLM decisions, revealing systematic, model- and language-dependent behavioral intentions, with linguistic framing sometimes matching or exceeding architectural effects. Our results provide a unified framework for auditing LLMs as strategic agents and highlight cooperation biases with direct implications for AI governance and multi-agent system design.", "AI": {"tldr": "LLMs show consistent strategic patterns in repeated social dilemmas, with behavior influenced by payoff magnitude and linguistic context, revealing cooperation biases important for AI governance.", "motivation": "As LLMs increasingly act as autonomous agents in interactive and multi-agent settings, understanding their strategic behavior is critical for safety, coordination, and AI-driven social and economic systems.", "method": "Used payoff-scaled Prisoner's Dilemma to isolate sensitivity to incentive strength, trained supervised classifiers on canonical repeated-game strategies, and applied them to LLM decisions across models and languages.", "result": "Observed consistent behavioral patterns including incentive-sensitive conditional strategies and cross-linguistic divergence, with linguistic framing sometimes matching or exceeding architectural effects in influencing behavior.", "conclusion": "Provides a unified framework for auditing LLMs as strategic agents and highlights cooperation biases with direct implications for AI governance and multi-agent system design."}}
{"id": "2601.19461", "categories": ["cs.CV", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.19461", "abs": "https://arxiv.org/abs/2601.19461", "authors": ["Yida Lin", "Bing Xue", "Mengjie Zhang", "Sam Schofield", "Richard Green"], "title": "Towards Gold-Standard Depth Estimation for Tree Branches in UAV Forestry: Benchmarking Deep Stereo Matching Methods", "comment": null, "summary": "Autonomous UAV forestry operations require robust depth estimation with strong cross-domain generalization, yet existing evaluations focus on urban and indoor scenarios, leaving a critical gap for vegetation-dense environments. We present the first systematic zero-shot evaluation of eight stereo methods spanning iterative refinement, foundation model, diffusion-based, and 3D CNN paradigms. All methods use officially released pretrained weights (trained on Scene Flow) and are evaluated on four standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus a novel 5,313-pair Canterbury Tree Branches dataset ($1920 \\times 1080$). Results reveal scene-dependent patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), while iterative methods show variable cross-benchmark performance (IGEV++: 0.36 px on ETH3D but 6.77 px on Middlebury; IGEV: 0.33 px on ETH3D but 4.99 px on Middlebury). Qualitative evaluation on the Tree Branches dataset establishes DEFOM as the gold-standard baseline for vegetation depth estimation, with superior cross-domain consistency (consistently ranking 1st-2nd across benchmarks, average rank 1.75). DEFOM predictions will serve as pseudo-ground-truth for future benchmarking.", "AI": {"tldr": "First systematic zero-shot evaluation of 8 stereo depth estimation methods across urban/indoor benchmarks plus novel vegetation dataset, revealing DEFOM as best for cross-domain generalization in forestry applications.", "motivation": "Autonomous UAV forestry operations need robust depth estimation with cross-domain generalization, but existing evaluations focus on urban/indoor scenarios, leaving a critical gap for vegetation-dense environments.", "method": "Systematic zero-shot evaluation of 8 stereo methods (iterative refinement, foundation model, diffusion-based, 3D CNN) using officially released pretrained weights trained on Scene Flow. Evaluated on 4 standard benchmarks (ETH3D, KITTI 2012/2015, Middlebury) plus novel 5,313-pair Canterbury Tree Branches dataset (1920\u00d71080).", "result": "Scene-dependent performance patterns: foundation models excel on structured scenes (BridgeDepth: 0.23 px on ETH3D; DEFOM: 4.65 px on Middlebury), iterative methods show variable cross-benchmark performance. DEFOM established as gold-standard baseline for vegetation depth estimation with superior cross-domain consistency (average rank 1.75, consistently ranking 1st-2nd across benchmarks).", "conclusion": "DEFOM identified as best-performing method for cross-domain generalization in forestry applications, with its predictions to serve as pseudo-ground-truth for future benchmarking in vegetation-dense environments."}}
{"id": "2601.19523", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19523", "abs": "https://arxiv.org/abs/2601.19523", "authors": ["Sergi Liesegang", "Antonio Pascual-Iserte", "Olga Mu\u00f1oz", "Alessio Zappone"], "title": "Design of RIS-aided mMTC+ Networks for Rate Maximization under the Finite Blocklength Regime with Imperfect Channel Knowledge", "comment": "This work has been accepted for publication in IEEE Communications Letters. The final published version is available via IEEE Xplore", "summary": "Within the context of massive machine-type communications+, reconfigurable intelligent surfaces (RISs) represent a promising technology to boost system performance in scenarios with poor channel conditions. Considering single-antenna sensors transmitting short data packets to a multiple-antenna collector node, we introduce and design an RIS to maximize the weighted sum rate (WSR) of the system working in the finite blocklength regime. Due to the large number of reflecting elements and their passive nature, channel estimation errors may occur. In this letter, we then propose a robust RIS optimization to combat such a detrimental issue. Based on concave bounds and approximations, the nonconvex WSR problem for the RIS response is addressed via successive convex optimization (SCO). Numerical experiments validate the performance and complexity of the SCO solutions.", "AI": {"tldr": "Robust RIS optimization for massive IoT communications in finite blocklength regime with channel estimation errors, using successive convex optimization to maximize weighted sum rate.", "motivation": "RIS technology can boost system performance in poor channel conditions for massive machine-type communications, but channel estimation errors due to large number of passive reflecting elements degrade performance, requiring robust optimization.", "method": "Propose robust RIS optimization using concave bounds and approximations to address nonconvex weighted sum rate problem, solved via successive convex optimization (SCO).", "result": "Numerical experiments validate the performance and complexity of SCO solutions for RIS optimization in finite blocklength regime with channel estimation errors.", "conclusion": "Robust RIS optimization via SCO effectively combats channel estimation errors and maximizes weighted sum rate in massive IoT communications with short data packets."}}
{"id": "2601.19119", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19119", "abs": "https://arxiv.org/abs/2601.19119", "authors": ["Peter Travis Jardine", "Sidney Givigi"], "title": "Agree to Disagree: Consensus-Free Flocking under Constraints", "comment": "7 pages. This work has been accepted for publication in the Proceedings of IEEE SYSCON 2026", "summary": "Robots sometimes have to work together with a mixture of partially-aligned or conflicting goals. Flocking - coordinated motion through cohesion, alignment, and separation - traditionally assumes uniform desired inter-agent distances. Many practical applications demand greater flexibility, as the diversity of types and configurations grows with the popularity of multi-agent systems in society. Moreover, agents often operate without guarantees of trust or secure communication. Motivated by these challenges we update well-established frameworks by relaxing this assumption of shared inter-agent distances and constraints. Through a new form of constrained collective potential function, we introduce a solution that permits negotiation of these parameters. In the spirit of the traditional flocking control canon, this negotiation is achieved purely through local observations and does not require any global information or inter-agent communication. The approach is robust to semi-trust scenarios, where neighbouring agents pursue conflicting goals. We validate the effectiveness of the approach through a series of simulations.", "AI": {"tldr": "A flocking control framework that allows negotiation of inter-agent distances without communication, handling conflicting goals in semi-trust scenarios.", "motivation": "Traditional flocking assumes uniform desired inter-agent distances, but practical multi-agent systems need flexibility for diverse agent types and configurations. Agents often operate without trust guarantees or secure communication, requiring solutions for partially-aligned or conflicting goals.", "method": "Updates traditional flocking frameworks by relaxing shared inter-agent distance assumptions. Introduces a new constrained collective potential function that permits parameter negotiation purely through local observations without global information or inter-agent communication.", "result": "The approach is robust to semi-trust scenarios where neighboring agents pursue conflicting goals. Effectiveness is validated through a series of simulations.", "conclusion": "Proposes a flexible flocking control solution that enables negotiation of inter-agent parameters without communication, addressing practical challenges in diverse multi-agent systems with potentially conflicting objectives."}}
{"id": "2601.19457", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19457", "abs": "https://arxiv.org/abs/2601.19457", "authors": ["Dario Cellini", "Stella Civelli", "Marco Secondini"], "title": "ML-Enhanced Digital Backpropagation for Long-Reach Single-Span Systems", "comment": null, "summary": "We propose a digital backpropagation method that employs machine-learning-aided joint optimization of dispersion step lengths and nonlinear phase rotation filters within an FFT-based enhanced split-step Fourier structure, achieving improved accuracy at low computational complexity.", "AI": {"tldr": "ML-aided joint optimization of dispersion steps and nonlinear filters in digital backpropagation for improved accuracy with low complexity", "motivation": "Digital backpropagation (DBP) is computationally expensive for fiber nonlinearity compensation; existing methods trade off accuracy vs complexity. Need better accuracy at lower computational cost.", "method": "Machine-learning-aided joint optimization of dispersion step lengths and nonlinear phase rotation filters within an FFT-based enhanced split-step Fourier structure", "result": "Achieves improved accuracy at low computational complexity compared to conventional DBP methods", "conclusion": "Proposed ML-aided joint optimization approach enables more efficient digital backpropagation for fiber nonlinearity compensation with better performance-complexity trade-off"}}
{"id": "2601.18948", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18948", "abs": "https://arxiv.org/abs/2601.18948", "authors": ["Zahra Hafezi Kafshgari", "Ivan V. Bajic", "Parvaneh Saeedi"], "title": "Smart Split-Federated Learning over Noisy Channels for Embryo Image Segmentation", "comment": null, "summary": "Split-Federated (SplitFed) learning is an extension of federated learning that places minimal requirements on the clients computing infrastructure, since only a small portion of the overall model is deployed on the clients hardware. In SplitFed learning, feature values, gradient updates, and model updates are transferred across communication channels. In this paper, we study the effects of noise in the communication channels on the learning process and the quality of the final model. We propose a smart averaging strategy for SplitFed learning with the goal of improving resilience against channel noise. Experiments on a segmentation model for embryo images shows that the proposed smart averaging strategy is able to tolerate two orders of magnitude stronger noise in the communication channels compared to conventional averaging, while still maintaining the accuracy of the final model.", "AI": {"tldr": "SplitFed learning with smart averaging improves noise resilience in communication channels by two orders of magnitude compared to conventional averaging.", "motivation": "Split-Federated learning reduces client hardware requirements but faces vulnerability to communication channel noise affecting feature values, gradient updates, and model updates during transmission.", "method": "Proposed a smart averaging strategy for SplitFed learning to enhance resilience against channel noise, tested on a segmentation model for embryo images.", "result": "Smart averaging tolerates two orders of magnitude stronger noise in communication channels while maintaining final model accuracy compared to conventional averaging.", "conclusion": "Smart averaging strategy significantly improves SplitFed learning's robustness to communication channel noise without compromising model performance."}}
{"id": "2601.18830", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.18830", "abs": "https://arxiv.org/abs/2601.18830", "authors": ["Alireza Jafari", "Fatemeh Jafari"], "title": "How Much Temporal Modeling is Enough? A Systematic Study of Hybrid CNN-RNN Architectures for Multi-Label ECG Classification", "comment": "17 pages, 10 figures", "summary": "Accurate multi-label classification of electrocardiogram (ECG) signals remains challenging due to the coexistence of multiple cardiac conditions, pronounced class imbalance, and long-range temporal dependencies in multi-lead recordings. Although recent studies increasingly rely on deep and stacked recurrent architectures, the necessity and clinical justification of such architectural complexity have not been rigorously examined. In this work, we perform a systematic comparative evaluation of convolutional neural networks (CNNs) combined with multiple recurrent configurations, including LSTM, GRU, Bidirectional LSTM (BiLSTM), and their stacked variants, for multi-label ECG classification on the PTB-XL dataset comprising 23 diagnostic categories. The CNN component serves as a morphology-driven baseline, while recurrent layers are progressively integrated to assess their contribution to temporal modeling and generalization performance. Experimental results indicate that a CNN integrated with a single BiLSTM layer achieves the most favorable trade-off between predictive performance and model complexity. This configuration attains superior Hamming loss (0.0338), macro-AUPRC (0.4715), micro-F1 score (0.6979), and subset accuracy (0.5723) compared with deeper recurrent combinations. Although stacked recurrent models occasionally improve recall for specific rare classes, our results provide empirical evidence that increasing recurrent depth yields diminishing returns and may degrade generalization due to reduced precision and overfitting. These findings suggest that architectural alignment with the intrinsic temporal structure of ECG signals, rather than increased recurrent depth, is a key determinant of robust performance and clinically relevant deployment.", "AI": {"tldr": "CNN with single BiLSTM layer achieves best performance for multi-label ECG classification, showing diminishing returns with deeper recurrent architectures.", "motivation": "Multi-label ECG classification faces challenges from multiple coexisting cardiac conditions, class imbalance, and long-range temporal dependencies. Recent studies use complex deep recurrent architectures without rigorous justification of their necessity.", "method": "Systematic comparative evaluation of CNNs combined with multiple recurrent configurations (LSTM, GRU, BiLSTM, and stacked variants) for multi-label ECG classification on PTB-XL dataset with 23 diagnostic categories.", "result": "CNN with single BiLSTM layer achieves best trade-off: Hamming loss (0.0338), macro-AUPRC (0.4715), micro-F1 (0.6979), subset accuracy (0.5723). Deeper recurrent models show diminishing returns and may degrade generalization.", "conclusion": "Architectural alignment with ECG's intrinsic temporal structure (simple CNN-BiLSTM) is more important than increased recurrent depth for robust clinical deployment."}}
{"id": "2601.19112", "categories": ["cs.AI", "cs.MM", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.19112", "abs": "https://arxiv.org/abs/2601.19112", "authors": ["Nanhan Shen", "Zhilei Liu"], "title": "Uncertainty-Aware 3D Emotional Talking Face Synthesis with Emotion Prior Distillation", "comment": "Accepted by ICASSP 2026", "summary": "Emotional Talking Face synthesis is pivotal in multimedia and signal processing, yet existing 3D methods suffer from two critical challenges: poor audio-vision emotion alignment, manifested as difficult audio emotion extraction and inadequate control over emotional micro-expressions; and a one-size-fits-all multi-view fusion strategy that overlooks uncertainty and feature quality differences, undermining rendering quality. We propose UA-3DTalk, Uncertainty-Aware 3D Emotional Talking Face Synthesis with emotion prior distillation, which has three core modules: the Prior Extraction module disentangles audio into content-synchronized features for alignment and person-specific complementary features for individualization; the Emotion Distillation module introduces a multi-modal attention-weighted fusion mechanism and 4D Gaussian encoding with multi-resolution code-books, enabling fine-grained audio emotion extraction and precise control of emotional micro-expressions; the Uncertainty-based Deformation deploys uncertainty blocks to estimate view-specific aleatoric (input noise) and epistemic (model parameters) uncertainty, realizing adaptive multi-view fusion and incorporating a multi-head decoder for Gaussian primitive optimization to mitigate the limitations of uniform-weight fusion. Extensive experiments on regular and emotional datasets show UA-3DTalk outperforms state-of-the-art methods like DEGSTalk and EDTalk by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality. Project page: https://mrask999.github.io/UA-3DTalk", "AI": {"tldr": "UA-3DTalk is an uncertainty-aware 3D emotional talking face synthesis method that improves audio-vision emotion alignment and multi-view fusion through emotion prior distillation and adaptive uncertainty-based deformation.", "motivation": "Existing 3D emotional talking face synthesis methods suffer from poor audio-vision emotion alignment (difficult audio emotion extraction and inadequate control over emotional micro-expressions) and suboptimal multi-view fusion strategies that use uniform weighting, ignoring uncertainty and feature quality differences.", "method": "Three core modules: 1) Prior Extraction module disentangles audio into content-synchronized features and person-specific complementary features; 2) Emotion Distillation module uses multi-modal attention-weighted fusion and 4D Gaussian encoding with multi-resolution code-books for fine-grained emotion extraction; 3) Uncertainty-based Deformation uses uncertainty blocks to estimate view-specific aleatoric and epistemic uncertainty for adaptive multi-view fusion, with a multi-head decoder for Gaussian primitive optimization.", "result": "Outperforms state-of-the-art methods (DEGSTalk, EDTalk) by 5.2% in E-FID for emotion alignment, 3.1% in SyncC for lip synchronization, and 0.015 in LPIPS for rendering quality on regular and emotional datasets.", "conclusion": "UA-3DTalk effectively addresses the critical challenges in 3D emotional talking face synthesis by introducing uncertainty-aware mechanisms and emotion prior distillation, achieving superior performance in emotion alignment, lip synchronization, and rendering quality."}}
{"id": "2601.19539", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19539", "abs": "https://arxiv.org/abs/2601.19539", "authors": ["Heedong Do", "Angel Lozano"], "title": "Cramer-Rao Bound for Arbitrarily Constrained Sets", "comment": null, "summary": "This paper presents a Cramer-Rao bound (CRB) for the estimation of parameters confined to an arbitrary set. Unlike existing results that rely on equality or inequality constraints, manifold structures, or the nonsingularity of the Fisher information matrix, the derived CRB applies to any constrained set and holds for any estimation bias and any Fisher information matrix. The key geometric object governing the new CRB is the tangent cone to the constraint set, whose span determines how the constraints affect the estimation accuracy. This CRB subsumes, unifies, and generalizes known special cases, offering an intuitive and broadly applicable framework to characterize the minimum mean-square error of constrained estimators.", "AI": {"tldr": "Derives a general Cramer-Rao bound for parameter estimation with arbitrary constraints, using tangent cones to unify and generalize existing results.", "motivation": "Existing CRB results have limitations: they require specific constraint types (equality/inequality), manifold structures, or nonsingular Fisher information matrices. There's a need for a more general framework that applies to any constrained set regardless of bias or Fisher information properties.", "method": "Develops a CRB based on the geometric concept of tangent cones to the constraint set. The tangent cone's span determines how constraints affect estimation accuracy, providing a unified geometric framework that doesn't rely on specific constraint formulations or Fisher information properties.", "result": "The derived CRB applies to any constrained parameter set, holds for any estimation bias and any Fisher information matrix, and subsumes all known special cases. It provides an intuitive geometric interpretation through tangent cones.", "conclusion": "This work offers a comprehensive, unified framework for constrained parameter estimation that generalizes existing results and provides intuitive geometric insights through tangent cone analysis."}}
{"id": "2601.19144", "categories": ["cs.RO", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.19144", "abs": "https://arxiv.org/abs/2601.19144", "authors": ["Tzvika Geft", "William Zhang", "Jingjin Yu", "Kostas Bekris"], "title": "Robust Out-of-Order Retrieval for Grid-Based Storage at Maximum Capacity", "comment": "AAAI 2026", "summary": "This paper proposes a framework for improving the operational efficiency of automated storage systems under uncertainty. It considers a 2D grid-based storage for uniform-sized loads (e.g., containers, pallets, or totes), which are moved by a robot (or other manipulator) along a collision-free path in the grid. The loads are labeled (i.e., unique) and must be stored in a given sequence, and later be retrieved in a different sequence -- an operational pattern that arises in logistics applications, such as last-mile distribution centers and shipyards. The objective is to minimize the load relocations to ensure efficient retrieval. A previous result guarantees a zero-relocation solution for known storage and retrieval sequences, even for storage at full capacity, provided that the side of the grid through which loads are stored/retrieved is at least 3 cells wide. However, in practice, the retrieval sequence can change after the storage phase. To address such uncertainty, this work investigates \\emph{$k$-bounded perturbations} during retrieval, under which any two loads may depart out of order if they are originally at most $k$ positions apart. We prove that a $\u0398(k)$ grid width is necessary and sufficient for eliminating relocations at maximum capacity. We also provide an efficient solver for computing a storage arrangement that is robust to such perturbations. To address the higher-uncertainty case where perturbations exceed $k$, a strategy is introduced to effectively minimize relocations. Extensive experiments show that, for $k$ up to half the grid width, the proposed storage-retrieval framework essentially eliminates relocations. For $k$ values up to the full grid width, relocations are reduced by $50\\%+$.", "AI": {"tldr": "A framework for optimizing automated storage systems under retrieval sequence uncertainty using k-bounded perturbations and grid width optimization to minimize load relocations.", "motivation": "In practice, retrieval sequences can change after storage phase due to uncertainty, unlike previous work that assumed known sequences. This uncertainty causes inefficient load relocations in automated storage systems.", "method": "Proposes k-bounded perturbations model where loads may depart out of order if originally at most k positions apart. Analyzes necessary grid width (\u0398(k)) for zero relocations at max capacity. Provides efficient solver for robust storage arrangement and strategy for higher-uncertainty cases.", "result": "For k up to half grid width, framework essentially eliminates relocations. For k up to full grid width, relocations reduced by 50%+. Proves \u0398(k) grid width is necessary and sufficient for eliminating relocations at maximum capacity.", "conclusion": "The proposed framework effectively handles retrieval sequence uncertainty in automated storage systems, significantly reducing relocations through strategic grid width design and robust storage arrangements."}}
{"id": "2601.19518", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19518", "abs": "https://arxiv.org/abs/2601.19518", "authors": ["Andreas Angelou", "Pourya Behmandpoor", "Marc Moonen"], "title": "Master-Assisted Distributed Uplink Operation for Cell-Free Massive MIMO Networks", "comment": "This paper has been accepted for publication in the IEEE ICASSP 2026", "summary": "Cell-free massive multiple-input-multiple-output is considered a promising technology for the next generation of wireless communication networks. The main idea is to distribute a large number of access points (APs) in a geographical region to serve the user equipments (UEs) cooperatively. In the uplink, one of two types of operations is often adopted: centralized or distributed. In centralized operation, channel estimation and data decoding are performed at the central processing unit (CPU), whereas in distributed operation, channel estimation occurs at the APs and data detection at the CPU. In this paper, we propose a novel uplink operation, termed Master-Assisted Distributed Uplink Operation (MADUO), where each UE is assigned a master AP, which receives soft data estimates from the other APs and decodes the data using its local signals and the received data estimates. Numerical experiments demonstrate that the proposed operation performs comparably to the centralized operation and balances fronthaul signaling and computational complexity.", "AI": {"tldr": "Proposes Master-Assisted Distributed Uplink Operation (MADUO) for cell-free massive MIMO, where each UE has a master AP that collects soft data estimates from other APs and performs decoding, achieving performance comparable to centralized operation with balanced fronthaul signaling and computational complexity.", "motivation": "Current cell-free massive MIMO systems use either centralized operation (channel estimation and decoding at CPU) or distributed operation (channel estimation at APs, detection at CPU). Both approaches have trade-offs in fronthaul signaling and computational complexity. The paper aims to develop a novel uplink operation that achieves performance comparable to centralized operation while balancing these trade-offs.", "method": "Proposes Master-Assisted Distributed Uplink Operation (MADUO) where each user equipment (UE) is assigned a master access point (AP). The master AP receives soft data estimates from other APs and uses both these received estimates and its own local signals to decode the data. This creates a hybrid approach between centralized and distributed operations.", "result": "Numerical experiments show that MADUO performs comparably to centralized operation in terms of performance metrics. The proposed operation effectively balances fronthaul signaling requirements and computational complexity between the two traditional approaches.", "conclusion": "MADUO offers a promising alternative to existing uplink operations in cell-free massive MIMO systems, providing performance similar to centralized operation while maintaining a favorable balance between fronthaul signaling and computational complexity."}}
{"id": "2601.18970", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.18970", "abs": "https://arxiv.org/abs/2601.18970", "authors": ["Alex Beriand", "JhihYang Wu", "Daniel Brignac", "Natnael Daba", "Abhijit Mahalanobis"], "title": "Pay Attention to Where You Look", "comment": "ICIP 2025 Workshop on Generative AI for World Simulations and Communications", "summary": "Novel view synthesis (NVS) has advanced with generative modeling, enabling photorealistic image generation. In few-shot NVS, where only a few input views are available, existing methods often assume equal importance for all input views relative to the target, leading to suboptimal results.\n  We address this limitation by introducing a camera-weighting mechanism that adjusts the importance of source views based on their relevance to the target. We propose two approaches: a deterministic weighting scheme leveraging geometric properties like Euclidean distance and angular differences, and a cross-attention-based learning scheme that optimizes view weighting. Additionally, models can be further trained with our camera-weighting scheme to refine their understanding of view relevance and enhance synthesis quality. This mechanism is adaptable and can be integrated into various NVS algorithms, improving their ability to synthesize high-quality novel views. Our results demonstrate that adaptive view weighting enhances accuracy and realism, offering a promising direction for improving NVS.", "AI": {"tldr": "The paper introduces a camera-weighting mechanism for few-shot novel view synthesis that adaptively weights input views based on their relevance to the target view, improving synthesis quality.", "motivation": "Existing few-shot NVS methods treat all input views as equally important relative to the target view, which leads to suboptimal results. The authors aim to address this limitation by developing a mechanism that recognizes and weights views based on their actual relevance to the target view.", "method": "Two camera-weighting approaches: 1) deterministic weighting using geometric properties (Euclidean distance and angular differences), and 2) cross-attention-based learning scheme that optimizes view weighting. The mechanism can be integrated into various NVS algorithms and further trained to refine view relevance understanding.", "result": "The adaptive view weighting mechanism improves accuracy and realism in novel view synthesis. It's adaptable and can enhance various existing NVS algorithms by helping them better understand view relevance.", "conclusion": "Adaptive camera-weighting offers a promising direction for improving few-shot novel view synthesis by enabling models to intelligently weight input views based on their relevance to the target, leading to higher quality synthesized views."}}
{"id": "2601.18832", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18832", "abs": "https://arxiv.org/abs/2601.18832", "authors": ["Ren Zhuang", "Ben Wang", "Shuifa Sun"], "title": "The Geometric Reasoner: Manifold-Informed Latent Foresight Search for Long-Context Reasoning", "comment": "11 pages, 5 figures", "summary": "Scaling test-time compute enhances long chain-of-thought (CoT) reasoning, yet existing approaches face a fundamental trade-off between computational cost and coverage quality: either incurring high training expense or yielding redundant trajectories. We introduce The Geometric Reasoner (TGR), a training-free framework that performs manifold-informed latent foresight search under strict memory bounds. At each chunk boundary, TGR scores candidate latent anchors via a lightweight look-ahead estimate combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length. On challenging math and code benchmarks, TGR improves robust trajectory coverage, measured by the area under the Pass@$k$ curve (AUC), by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1--1.3 times.", "AI": {"tldr": "TGR is a training-free framework that improves long chain-of-thought reasoning through manifold-informed latent foresight search with geometric regularizers, achieving better coverage with minimal computational overhead.", "motivation": "Existing approaches for scaling test-time compute in chain-of-thought reasoning face a fundamental trade-off between computational cost and coverage quality - either requiring high training expense or producing redundant trajectories.", "method": "TGR performs manifold-informed latent foresight search under strict memory bounds. It scores candidate latent anchors using lightweight look-ahead estimates combined with soft geometric regularizers that encourage smooth trajectories and diverse exploration. Chunk-wise KV cache resets keep memory linear in chunk length.", "result": "On challenging math and code benchmarks, TGR improves robust trajectory coverage (measured by area under Pass@k curve) by up to 13 points on Qwen3-8B, with negligible overhead of about 1.1-1.3 times.", "conclusion": "TGR provides an effective training-free solution that enhances long chain-of-thought reasoning coverage while maintaining computational efficiency through geometric regularization and memory-efficient search."}}
{"id": "2601.19122", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19122", "abs": "https://arxiv.org/abs/2601.19122", "authors": ["Weiran Guo", "Bing Bo", "Shaoxiang Wu", "Jingsheng Yang"], "title": "Exploring Weaknesses in Function Call Models via Reinforcement Learning: An Adversarial Data Augmentation Approach", "comment": null, "summary": "Function call capabilities have become crucial for Large Language Models (LLMs), enabling them to interact more effectively with external tools and APIs. Existing methods for improving the function call capabilities of LLMs rely on data obtained either through manual annotation or automated generation by models, and use this data to finetune the LLMs. However, these methods often lack targeted design and are constrained by fixed patterns and data distributions, which limits their effectiveness in enhancing the generalization and robustness of function call LLMs. To address this limitation, we propose a novel adversarial data augmentation method that employs reinforcement learning to systematically identify and target the weaknesses of function call LLMs. Our training framework introduces a query model trained with reinforcement learning (RL) to generate adversarial queries that are specifically designed to challenge function call (FC) models. This approach adopts a zero sum game formulation, where the query model and the FC model engage in iterative alternating training. Overall, our method advances the development of more robust FC models and provides a systematic way to identify and correct weaknesses in the ability of LLMs to interact with external tools.", "AI": {"tldr": "Proposes adversarial data augmentation using reinforcement learning to systematically identify and target weaknesses in LLM function calling capabilities, improving robustness through iterative training.", "motivation": "Existing methods for improving LLM function call capabilities rely on manual annotation or automated generation, which lack targeted design and are constrained by fixed patterns, limiting generalization and robustness.", "method": "Adversarial data augmentation using reinforcement learning with a query model trained via RL to generate challenging adversarial queries. Uses zero-sum game formulation with iterative alternating training between query model and function call model.", "result": "The method advances development of more robust function call models and provides systematic way to identify and correct weaknesses in LLMs' ability to interact with external tools.", "conclusion": "Proposed adversarial RL-based approach effectively addresses limitations of existing methods by systematically targeting weaknesses in function call LLMs, leading to improved robustness and generalization."}}
{"id": "2601.19590", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.19590", "abs": "https://arxiv.org/abs/2601.19590", "authors": ["Sergi Liesegang", "Antonio Pascual-Iserte", "Olga Mu\u00f1oz"], "title": "Robust Design of Reconfigurable Intelligent Surfaces for Parameter Estimation in MTC", "comment": "This work has been accepted for publication in EURASIP Journal on Wireless Communications and Networking. The final published version is available via Springer Nature Link", "summary": "This paper introduces a reconfigurable intelligent surface (RIS) to support parameter estimation in machine-type communications (MTC). We focus on a network where single-antenna sensors transmit spatially correlated measurements to a multiple-antenna collector node (CN) via non-orthogonal multiple access. We propose an estimation scheme based on the minimum mean square error (MMSE) criterion. We also integrate successive interference cancelation (SIC) at the receiver to mitigate communication failures in noisy and interference-prone channels under the finite blocklength (FBL) regime. Moreover, recognizing the importance of channel state information (CSI), we explore various methodologies for its acquisition at the CN. We statistically design the RIS configuration and SIC decoding order to minimize estimation error while accounting for channel temporal variations and short packet lengths. To mirror practical systems, we incorporate the detrimental effects of FBL communication and imperfect CSI errors in our analysis. Simulations demonstrate that larger reflecting surfaces lead to smaller MSEs and underscore the importance of selecting an appropriate decoding order for accuracy and ultimate performance.", "AI": {"tldr": "RIS-assisted parameter estimation for MTC using MMSE with SIC under FBL regime, addressing CSI acquisition and imperfect channel knowledge.", "motivation": "To improve parameter estimation accuracy in machine-type communications where sensors transmit correlated measurements over noisy, interference-prone channels with short packet lengths and limited channel state information.", "method": "Proposes RIS-assisted MMSE estimation with SIC for interference mitigation, statistical RIS configuration design, SIC decoding order optimization, and incorporates FBL communication effects and imperfect CSI errors in analysis.", "result": "Larger RIS surfaces reduce MSE, appropriate decoding order selection is crucial for accuracy, and the proposed scheme effectively handles channel variations and short packets.", "conclusion": "RIS can significantly enhance parameter estimation in MTC under practical constraints of FBL and imperfect CSI, with surface size and decoding order being key design factors."}}
{"id": "2601.19234", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19234", "abs": "https://arxiv.org/abs/2601.19234", "authors": ["Youndo Do", "Chad Meece", "Marc Zebrowitz", "Spencer Banks", "Myeongjun Choi", "Xiaoxu Diao", "Kai Tan", "Michael Doran", "Jason Reed", "Fan Zhang"], "title": "iFAN Ecosystem: A Unified AI, Digital Twin, Cyber-Physical Security, and Robotics Environment for Advanced Nuclear Simulation and Operations", "comment": null, "summary": "As nuclear facilities experience digital transformation and advanced reactor development, AI integration, cyber-physical security, and other emerging technologies such as autonomous robot operations are increasingly developed. However, evaluation and deployment is challenged by the lack of dedicated virtual testbeds. The Immersive Framework for Advanced Nuclear (iFAN) ecosystem is developed, a comprehensive digital twin framework with a realistic 3D environment with physics-based simulations. The iFAN ecosystem serves as a high-fidelity virtual testbed for plant operation, cybersecurity, physical security, and robotic operation, as it provides real-time data exchange for pre-deployment verification. Core features include virtual reality, reinforcement learning, radiation simulation, and cyber-physical security. In addition, the paper investigates various applications through potential operational scenarios. The iFAN ecosystem provides a versatile and secure architecture for validating the next generation of autonomous and cyber-resilient nuclear operations.", "AI": {"tldr": "iFAN is a digital twin framework for nuclear facilities providing a high-fidelity virtual testbed for AI integration, cybersecurity, physical security, and robotic operations through realistic 3D environments with physics-based simulations.", "motivation": "Nuclear facilities lack dedicated virtual testbeds for evaluating emerging technologies like AI integration, cyber-physical security, and autonomous robot operations during digital transformation and advanced reactor development.", "method": "Developed the Immersive Framework for Advanced Nuclear (iFAN) ecosystem - a comprehensive digital twin framework with realistic 3D environment and physics-based simulations that enables real-time data exchange for pre-deployment verification.", "result": "iFAN provides core features including virtual reality, reinforcement learning, radiation simulation, and cyber-physical security capabilities, serving as a versatile high-fidelity virtual testbed for various operational scenarios.", "conclusion": "The iFAN ecosystem offers a secure architecture for validating next-generation autonomous and cyber-resilient nuclear operations, addressing the critical need for virtual testbeds in nuclear facility digital transformation."}}
{"id": "2601.18993", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.18993", "abs": "https://arxiv.org/abs/2601.18993", "authors": ["Wei Cao", "Hao Zhang", "Fengrui Tian", "Yulun Wu", "Yingying Li", "Shenlong Wang", "Ning Yu", "Yaoyao Liu"], "title": "FreeOrbit4D: Training-Free Arbitrary Camera Redirection for Monocular Videos via Geometry-Complete 4D Reconstruction", "comment": "14 pages, 10 figures", "summary": "Camera redirection aims to replay a dynamic scene from a single monocular video under a user-specified camera trajectory. However, large-angle redirection is inherently ill-posed: a monocular video captures only a narrow spatio-temporal view of a dynamic 3D scene, providing highly partial observations of the underlying 4D world. The key challenge is therefore to recover a complete and coherent representation from this limited input, with consistent geometry and motion. While recent diffusion-based methods achieve impressive results, they often break down under large-angle viewpoint changes far from the original trajectory, where missing visual grounding leads to severe geometric ambiguity and temporal inconsistency. To address this, we present FreeOrbit4D, an effective training-free framework that tackles this geometric ambiguity by recovering a geometry-complete 4D proxy as structural grounding for video generation. We obtain this proxy by decoupling foreground and background reconstructions: we unproject the monocular video into a static background and geometry-incomplete foreground point clouds in a unified global space, then leverage an object-centric multi-view diffusion model to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical object space. By aligning the canonical foreground point cloud to the global scene space via dense pixel-synchronized 3D--3D correspondences and projecting the geometry-complete 4D proxy onto target camera viewpoints, we provide geometric scaffolds that guide a conditional video diffusion model. Extensive experiments show that FreeOrbit4D produces more faithful redirected videos under challenging large-angle trajectories, and our geometry-complete 4D proxy further opens a potential avenue for practical applications such as edit propagation and 4D data generation. Project page and code will be released soon.", "AI": {"tldr": "FreeOrbit4D is a training-free framework for camera redirection that recovers a geometry-complete 4D proxy from monocular video to enable faithful large-angle viewpoint changes.", "motivation": "Large-angle camera redirection from monocular video is ill-posed due to limited spatio-temporal observations, causing geometric ambiguity and temporal inconsistency in existing methods when viewpoints deviate significantly from the original trajectory.", "method": "Decouples foreground/background reconstruction, unprojects video into static background and geometry-incomplete foreground point clouds, uses object-centric multi-view diffusion to synthesize multi-view images and reconstruct geometry-complete foreground point clouds in canonical space, aligns them via dense 3D-3D correspondences, and projects the 4D proxy to guide a conditional video diffusion model.", "result": "Produces more faithful redirected videos under challenging large-angle trajectories compared to existing methods, and enables practical applications like edit propagation and 4D data generation.", "conclusion": "FreeOrbit4D effectively addresses geometric ambiguity in large-angle camera redirection by recovering a geometry-complete 4D proxy, providing structural grounding that enables faithful viewpoint changes and opens avenues for practical 4D applications."}}
{"id": "2601.18837", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18837", "abs": "https://arxiv.org/abs/2601.18837", "authors": ["Md Zahidul Hasan", "A. Ben Hamza", "Nizar Bouguila"], "title": "Time series forecasting with Hahn Kolmogorov-Arnold networks", "comment": null, "summary": "Recent Transformer- and MLP-based models have demonstrated strong performance in long-term time series forecasting, yet Transformers remain limited by their quadratic complexity and permutation-equivariant attention, while MLPs exhibit spectral bias. We propose HaKAN, a versatile model based on Kolmogorov-Arnold Networks (KANs), leveraging Hahn polynomial-based learnable activation functions and providing a lightweight and interpretable alternative for multivariate time series forecasting. Our model integrates channel independence, patching, a stack of Hahn-KAN blocks with residual connections, and a bottleneck structure comprised of two fully connected layers. The Hahn-KAN block consists of inter- and intra-patch KAN layers to effectively capture both global and local temporal patterns. Extensive experiments on various forecasting benchmarks demonstrate that our model consistently outperforms recent state-of-the-art methods, with ablation studies validating the effectiveness of its core components.", "AI": {"tldr": "HaKAN: A lightweight, interpretable model using Hahn polynomial-based Kolmogorov-Arnold Networks for multivariate time series forecasting, outperforming recent Transformer and MLP methods.", "motivation": "Transformers have quadratic complexity and permutation-equivariant attention limitations, while MLPs suffer from spectral bias. There's a need for more efficient, interpretable alternatives for long-term time series forecasting.", "method": "HaKAN integrates channel independence, patching, Hahn-KAN blocks with residual connections, and bottleneck structure. Hahn-KAN blocks use inter- and intra-patch KAN layers with Hahn polynomial-based activation functions to capture global and local patterns.", "result": "Extensive experiments show HaKAN consistently outperforms recent state-of-the-art methods on various forecasting benchmarks, with ablation studies validating core component effectiveness.", "conclusion": "HaKAN provides a versatile, lightweight, and interpretable alternative to Transformers and MLPs for multivariate time series forecasting, addressing their computational and representational limitations."}}
{"id": "2601.19142", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19142", "abs": "https://arxiv.org/abs/2601.19142", "authors": ["Zhicheng Zhang", "Zhaocheng Du", "Jieming Zhu", "Jiwei Tang", "Fengyuan Lu", "Wang Jiaheng", "Song-Li Wu", "Qianhui Zhu", "Jingyu Li", "Hai-Tao Zheng", "Zhenhua Dong"], "title": "Length-Adaptive Interest Network for Balancing Long and Short Sequence Modeling in CTR Prediction", "comment": "Accepted at AAAI 2026", "summary": "User behavior sequences in modern recommendation systems exhibit significant length heterogeneity, ranging from sparse short-term interactions to rich long-term histories. While longer sequences provide more context, we observe that increasing the maximum input sequence length in existing CTR models paradoxically degrades performance for short-sequence users due to attention polarization and length imbalance in training data. To address this, we propose LAIN(Length-Adaptive Interest Network), a plug-and-play framework that explicitly incorporates sequence length as a conditioning signal to balance long- and short-sequence modeling. LAIN consists of three lightweight components: a Spectral Length Encoder that maps length into continuous representations, Length-Conditioned Prompting that injects global contextual cues into both long- and short-term behavior branches, and Length-Modulated Attention that adaptively adjusts attention sharpness based on sequence length. Extensive experiments on three real-world benchmarks across five strong CTR backbones show that LAIN consistently improves overall performance, achieving up to 1.15% AUC gain and 2.25% log loss reduction. Notably, our method significantly improves accuracy for short-sequence users without sacrificing longsequence effectiveness. Our work offers a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation.", "AI": {"tldr": "LAIN is a plug-and-play framework that uses sequence length as a conditioning signal to balance long- and short-sequence modeling in CTR prediction, addressing performance degradation for short-sequence users in existing models.", "motivation": "Existing CTR models suffer from performance degradation for short-sequence users when increasing maximum input sequence length due to attention polarization and training data length imbalance, creating a need for length-adaptive solutions.", "method": "LAIN framework with three components: Spectral Length Encoder (maps length to continuous representations), Length-Conditioned Prompting (injects global contextual cues), and Length-Modulated Attention (adaptively adjusts attention sharpness based on sequence length).", "result": "Consistent improvements across three real-world benchmarks and five CTR backbones, achieving up to 1.15% AUC gain and 2.25% log loss reduction, with significant accuracy improvements for short-sequence users without sacrificing long-sequence effectiveness.", "conclusion": "LAIN provides a general, efficient, and deployable solution to mitigate length-induced bias in sequential recommendation by explicitly incorporating sequence length as a conditioning signal."}}
{"id": "2601.19275", "categories": ["cs.RO", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19275", "abs": "https://arxiv.org/abs/2601.19275", "authors": ["Tatsuya Kamijo", "Mai Nishimura", "Cristian C. Beltran-Hernandez", "Nodoka Shibasaki", "Masashi Hamaya"], "title": "Tactile Memory with Soft Robot: Robust Object Insertion via Masked Encoding and Soft Wrist", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Tactile memory, the ability to store and retrieve touch-based experience, is critical for contact-rich tasks such as key insertion under uncertainty. To replicate this capability, we introduce Tactile Memory with Soft Robot (TaMeSo-bot), a system that integrates a soft wrist with tactile retrieval-based control to enable safe and robust manipulation. The soft wrist allows safe contact exploration during data collection, while tactile memory reuses past demonstrations via retrieval for flexible adaptation to unseen scenarios. The core of this system is the Masked Tactile Trajectory Transformer (MAT$^\\text{3}$), which jointly models spatiotemporal interactions between robot actions, distributed tactile feedback, force-torque measurements, and proprioceptive signals. Through masked-token prediction, MAT$^\\text{3}$ learns rich spatiotemporal representations by inferring missing sensory information from context, autonomously extracting task-relevant features without explicit subtask segmentation. We validate our approach on peg-in-hole tasks with diverse pegs and conditions in real-robot experiments. Our extensive evaluation demonstrates that MAT$^\\text{3}$ achieves higher success rates than the baselines over all conditions and shows remarkable capability to adapt to unseen pegs and conditions.", "AI": {"tldr": "TaMeSo-bot integrates a soft wrist with tactile retrieval-based control for safe manipulation, using MAT\u00b3 transformer to model spatiotemporal interactions and achieve robust peg-in-hole performance.", "motivation": "To replicate tactile memory capabilities for contact-rich tasks like key insertion under uncertainty, enabling safe exploration and flexible adaptation to unseen scenarios.", "method": "TaMeSo-bot system with soft wrist for safe contact exploration, and Masked Tactile Trajectory Transformer (MAT\u00b3) that jointly models robot actions, tactile feedback, force-torque measurements, and proprioceptive signals through masked-token prediction.", "result": "MAT\u00b3 achieves higher success rates than baselines in peg-in-hole tasks with diverse pegs and conditions, showing remarkable capability to adapt to unseen pegs and conditions.", "conclusion": "The system successfully replicates tactile memory capabilities, enabling safe and robust manipulation through tactile retrieval-based control and learned spatiotemporal representations without explicit subtask segmentation."}}
{"id": "2601.18997", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18997", "abs": "https://arxiv.org/abs/2601.18997", "authors": ["M\u00e9lanie Gaillochet", "Christian Desrosiers", "Herv\u00e9 Lombaert"], "title": "Anatomically-aware conformal prediction for medical image segmentation with random walks", "comment": "13 pages", "summary": "The reliable deployment of deep learning in medical imaging requires uncertainty quantification that provides rigorous error guarantees while remaining anatomically meaningful. Conformal prediction (CP) is a powerful distribution-free framework for constructing statistically valid prediction intervals. However, standard applications in segmentation often ignore anatomical context, resulting in fragmented, spatially incoherent, and over-segmented prediction sets that limit clinical utility. To bridge this gap, this paper proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework which can be added on top of any segmentation method. RW-CP enforces spatial coherence to generate anatomically valid sets. Our method constructs a k-nearest neighbour graph from pre-trained vision foundation model features and applies a random walk to diffuse uncertainty. The random walk diffusion regularizes the non-conformity scores, making the prediction sets less sensitive to the conformal calibration parameter $\u03bb$, ensuring more stable and continuous anatomical boundaries. RW-CP maintains rigorous marginal coverage while significantly improving segmentation quality. Evaluations on multi-modal public datasets show improvements of up to $35.4\\%$ compared to standard CP baselines, given an allowable error rate of $\u03b1=0.1$.", "AI": {"tldr": "RW-CP improves medical segmentation uncertainty quantification by enforcing spatial coherence through random walk diffusion on vision foundation model features, maintaining statistical validity while producing anatomically meaningful prediction sets.", "motivation": "Standard conformal prediction for medical segmentation produces fragmented, spatially incoherent prediction sets that lack anatomical validity and limit clinical utility, despite providing statistical error guarantees.", "method": "Proposes Random-Walk Conformal Prediction (RW-CP), a model-agnostic framework that constructs k-nearest neighbor graphs from pre-trained vision foundation model features and applies random walk diffusion to regularize non-conformity scores, enforcing spatial coherence.", "result": "RW-CP maintains rigorous marginal coverage while improving segmentation quality by up to 35.4% compared to standard CP baselines on multi-modal public datasets, with more stable and continuous anatomical boundaries.", "conclusion": "RW-CP bridges the gap between statistical validity and anatomical meaningfulness in medical segmentation uncertainty quantification, providing clinically useful prediction sets while maintaining rigorous error guarantees."}}
{"id": "2601.18840", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.18840", "abs": "https://arxiv.org/abs/2601.18840", "authors": ["Donghwan Lee", "Hyukjun Yang"], "title": "Analysis of Control Bellman Residual Minimization for Markov Decision Problem", "comment": null, "summary": "Markov decision problems are most commonly solved via dynamic programming. Another approach is Bellman residual minimization, which directly minimizes the squared Bellman residual objective function. However, compared to dynamic programming, this approach has received relatively less attention, mainly because it is often less efficient in practice and can be more difficult to extend to model-free settings such as reinforcement learning. Nonetheless, Bellman residual minimization has several advantages that make it worth investigating, such as more stable convergence with function approximation for value functions. While Bellman residual methods for policy evaluation have been widely studied, methods for policy optimization (control tasks) have been scarcely explored. In this paper, we establish foundational results for the control Bellman residual minimization for policy optimization.", "AI": {"tldr": "This paper establishes foundational results for Bellman residual minimization for policy optimization in control tasks, addressing a gap where previous work focused mainly on policy evaluation.", "motivation": "While Bellman residual minimization has advantages like more stable convergence with function approximation, it has received less attention than dynamic programming due to practical inefficiency and difficulty extending to model-free settings. Methods for policy optimization (control tasks) have been scarcely explored compared to policy evaluation.", "method": "The paper focuses on Bellman residual minimization for policy optimization, establishing foundational results for control tasks. This involves directly minimizing the squared Bellman residual objective function rather than using dynamic programming approaches.", "result": "The paper establishes foundational theoretical results for Bellman residual minimization in policy optimization/control settings, addressing a significant gap in the literature.", "conclusion": "Bellman residual minimization for policy optimization is worth investigating despite practical challenges, and this paper provides the foundational results needed to advance this approach for control tasks."}}
{"id": "2601.19151", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.19151", "abs": "https://arxiv.org/abs/2601.19151", "authors": ["Patara Trirat", "Jin Myung Kwak", "Jay Heo", "Heejun Lee", "Sung Ju Hwang"], "title": "TS-Debate: Multimodal Collaborative Debate for Zero-Shot Time Series Reasoning", "comment": "Code will be available at https://github.com/DeepAuto-AI/TS-Debate", "summary": "Recent progress at the intersection of large language models (LLMs) and time series (TS) analysis has revealed both promise and fragility. While LLMs can reason over temporal structure given carefully engineered context, they often struggle with numeric fidelity, modality interference, and principled cross-modal integration. We present TS-Debate, a modality-specialized, collaborative multi-agent debate framework for zero-shot time series reasoning. TS-Debate assigns dedicated expert agents to textual context, visual patterns, and numerical signals, preceded by explicit domain knowledge elicitation, and coordinates their interaction via a structured debate protocol. Reviewer agents evaluate agent claims using a verification-conflict-calibration mechanism, supported by lightweight code execution and numerical lookup for programmatic verification. This architecture preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning. Across 20 tasks spanning three public benchmarks, TS-Debate achieves consistent and significant performance improvements over strong baselines, including standard multimodal debate in which all agents observe all inputs.", "AI": {"tldr": "TS-Debate: A multi-agent debate framework with modality-specialized experts for zero-shot time series reasoning, improving performance over standard multimodal approaches.", "motivation": "LLMs show promise for time series analysis but struggle with numeric fidelity, modality interference, and principled cross-modal integration, requiring better approaches for zero-shot reasoning.", "method": "A collaborative multi-agent debate framework with dedicated experts for textual context, visual patterns, and numerical signals, using explicit domain knowledge elicitation, structured debate protocol, and reviewer agents with verification-conflict-calibration mechanism supported by code execution and numerical lookup.", "result": "Achieves consistent and significant performance improvements over strong baselines across 20 tasks spanning three public benchmarks, outperforming standard multimodal debate where all agents observe all inputs.", "conclusion": "TS-Debate effectively preserves modality fidelity, exposes conflicting evidence, and mitigates numeric hallucinations without task-specific fine-tuning, demonstrating the value of modality-specialized collaborative reasoning for time series analysis."}}
{"id": "2601.19318", "categories": ["cs.RO", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19318", "abs": "https://arxiv.org/abs/2601.19318", "authors": ["Venkatakrishna Reddy Oruganti"], "title": "Perception-to-Pursuit: Track-Centric Temporal Reasoning for Open-World Drone Detection and Autonomous Chasing", "comment": "7 pages, 2 figures, 3 tables, 15 references. Intended for submission to ICCV 2027", "summary": "Autonomous drone pursuit requires not only detecting drones but also predicting their trajectories in a manner that enables kinematically feasible interception. Existing tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. We propose Perception-to-Pursuit (P2P), a track-centric temporal reasoning framework that bridges detection and actionable pursuit planning. Our method represents drone motion as compact 8-dimensional tokens capturing velocity, acceleration, scale, and smoothness, enabling a 12-frame causal transformer to reason about future behavior. We introduce the Intercept Success Rate (ISR) metric to measure pursuit feasibility under realistic interceptor constraints. Evaluated on the Anti-UAV-RGBT dataset with 226 real drone sequences, P2P achieves 28.12 pixel average displacement error and 0.597 ISR, representing a 77% improvement in trajectory prediction and 597x improvement in pursuit feasibility over tracking-only baselines, while maintaining perfect drone classification accuracy (100%). Our work demonstrates that temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning.", "AI": {"tldr": "P2P is a track-centric temporal reasoning framework that bridges drone detection with actionable pursuit planning by representing drone motion as 8D tokens and using a causal transformer to predict kinematically feasible interception trajectories.", "motivation": "Existing drone tracking methods optimize for prediction accuracy but ignore pursuit feasibility, resulting in trajectories that are physically impossible to intercept 99.9% of the time. There's a need to bridge detection with actionable pursuit planning for autonomous drone interception.", "method": "Proposes Perception-to-Pursuit (P2P) framework representing drone motion as compact 8-dimensional tokens (velocity, acceleration, scale, smoothness) and using a 12-frame causal transformer to reason about future behavior for pursuit planning.", "result": "On Anti-UAV-RGBT dataset with 226 real drone sequences: 28.12 pixel average displacement error, 0.597 Intercept Success Rate (77% improvement in trajectory prediction, 597x improvement in pursuit feasibility over baselines), while maintaining 100% drone classification accuracy.", "conclusion": "Temporal reasoning over motion patterns enables both accurate prediction and actionable pursuit planning, demonstrating that bridging perception with pursuit constraints is crucial for effective autonomous drone interception."}}
{"id": "2601.19587", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19587", "abs": "https://arxiv.org/abs/2601.19587", "authors": ["Zihan Zhou", "Ang Chen", "Yunfei Chen", "Weidong Wang", "Li Chen"], "title": "Exposure-Aware Beamforming for mmWave Systems: From EM Theory to Thermal Compliance", "comment": "13 pages, 8 figures", "summary": "Electromagnetic (EM) exposure compliance has long been recognized as a crucial aspect of communications terminal designs. However, accurately assessing the impact of EM exposure for proper design strategies remains challenging. In this paper, we develop a long-term thermal EM exposure constraint model and propose a novel adaptive exposure-aware beamforming design for an mmWave uplink system. Specifically, we first establish an equivalent channel model based on Maxwell's radiation equations, which accurately captures the EM physical effects. Then, we derive a closed-form thermal impulse response model from the Pennes bioheat transfer equation (BHTE), characterizing the thermal inertia of tissue. Inspired by this model, we formulate a beamforming optimization problem that translates rigid instantaneous exposure limits into a flexible long-term thermal budget constraint. Furthermore, we develop a low-complexity online beamforming algorithm based on Lyapunov optimization theory, obtaining a closed-form near-optimal solution. Simulation results demonstrate that the proposed algorithm effectively stabilizes tissue temperature near a predefined safety threshold and significantly outperforms the conventional scheme with instantaneous exposure constraints.", "AI": {"tldr": "Proposes an adaptive exposure-aware beamforming design for mmWave uplink systems that converts rigid instantaneous EM exposure limits into flexible long-term thermal budget constraints using thermal impulse response modeling.", "motivation": "EM exposure compliance is crucial for communications terminal designs, but accurately assessing EM exposure impact for proper design strategies remains challenging. Current approaches use rigid instantaneous exposure limits that may be overly conservative.", "method": "1) Establish equivalent channel model based on Maxwell's radiation equations; 2) Derive closed-form thermal impulse response model from Pennes bioheat transfer equation; 3) Formulate beamforming optimization problem with long-term thermal budget constraint; 4) Develop low-complexity online beamforming algorithm using Lyapunov optimization theory.", "result": "Simulation results show the proposed algorithm effectively stabilizes tissue temperature near a predefined safety threshold and significantly outperforms conventional schemes with instantaneous exposure constraints.", "conclusion": "The proposed adaptive exposure-aware beamforming design successfully addresses EM exposure compliance by converting rigid instantaneous limits into flexible long-term thermal constraints, enabling more efficient mmWave uplink system operation while maintaining safety."}}
{"id": "2601.19014", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19014", "abs": "https://arxiv.org/abs/2601.19014", "authors": ["Lena Hark\u00e4mper", "Leo Lebrat", "David Ahmedt-Aristizabal", "Olivier Salvado", "Mattias Heinrich", "Rodrigo Santa Cruz"], "title": "Non-Invasive 3D Wound Measurement with RGB-D Imaging", "comment": null, "summary": "Chronic wound monitoring and management require accurate and efficient wound measurement methods. This paper presents a fast, non-invasive 3D wound measurement algorithm based on RGB-D imaging. The method combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes, enabling automatic computation of clinically relevant wound measurements such as perimeter, surface area, and dimensions. We evaluated our system on realistic silicone wound phantoms and measured sub-millimetre 3D reconstruction accuracy compared with high-resolution ground-truth scans. The extracted measurements demonstrated low variability across repeated captures and strong agreement with manual assessments. The proposed pipeline also outperformed a state-of-the-art object-centric RGB-D reconstruction method while maintaining runtimes suitable for real-time clinical deployment. Our approach offers a promising tool for automated wound assessment in both clinical and remote healthcare settings.", "AI": {"tldr": "A fast, non-invasive 3D wound measurement algorithm using RGB-D imaging that combines odometry with B-spline surface reconstruction for automated clinical wound assessment.", "motivation": "Chronic wound monitoring requires accurate and efficient measurement methods for clinical assessment. Current approaches need improvement in speed, accuracy, and automation for both clinical and remote healthcare settings.", "method": "Combines RGB-D odometry with B-spline surface reconstruction to generate detailed 3D wound meshes. Enables automatic computation of clinically relevant measurements (perimeter, surface area, dimensions) from RGB-D imaging.", "result": "Achieved sub-millimeter 3D reconstruction accuracy compared to high-resolution ground-truth scans. Demonstrated low variability across repeated captures and strong agreement with manual assessments. Outperformed state-of-the-art object-centric RGB-D reconstruction methods while maintaining real-time runtime capabilities.", "conclusion": "The proposed pipeline offers a promising tool for automated wound assessment suitable for real-time clinical deployment in both clinical and remote healthcare settings."}}
{"id": "2601.18858", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18858", "abs": "https://arxiv.org/abs/2601.18858", "authors": ["Zhiyu An", "Wan Du"], "title": "Representational Homomorphism Predicts and Improves Compositional Generalization In Transformer Language Model", "comment": null, "summary": "Compositional generalization-the ability to interpret novel combinations of familiar components-remains a persistent challenge for neural networks. Behavioral evaluations reveal when models fail but offer limited insight into why failures arise at the representational level. We introduce Homomorphism Error (HE), a structural metric that quantifies deviations from approximate homomorphisms between the expression algebra and a model's hidden-state space. We instantiate HE for two compositional operators in SCAN-style tasks: modifier HE for unary composition and sequence HE for binary composition, measured by learning representation-level operators that predict composed representations from their parts. Across controlled experiments with small decoder-only Transformers, HE predicts out-of-distribution (OOD) compositional generalization under noise injection, achieving R^2 = 0.73 correlation between modifier HE and OOD accuracy. Ablations show that model depth has minimal effect on either HE or OOD accuracy, training data coverage exhibits threshold effects (insufficient coverage sharply increases HE and degrades OOD performance), and randomly inserted noise tokens systematically increase HE. Finally, we test if HE-regularized training improves OOD accuracy. Experiment shows that explicitly enforcing low modifier HE during training significantly reduces modifier HE (p = 1.1x10-4) and sequence HE (p = 0.001) and yields a statistically significant improvement in OOD accuracy (p = 0.023). Together, these results indicate the potential of HE to be both a diagnostic and an actionable training signal for improving compositional generalization. Code to reproduce our experiments is open-sourced.", "AI": {"tldr": "The paper introduces Homomorphism Error (HE), a structural metric that quantifies deviations from approximate homomorphisms between expression algebra and model representations, showing it predicts compositional generalization and can be used as a training signal.", "motivation": "Compositional generalization remains challenging for neural networks, and behavioral evaluations offer limited insight into why failures occur at the representational level. There's a need for structural metrics that can diagnose and potentially improve compositional generalization.", "method": "Introduces Homomorphism Error (HE) metric that measures deviations from approximate homomorphisms between expression algebra and model hidden-state space. Instantiates HE for two compositional operators in SCAN-style tasks: modifier HE for unary composition and sequence HE for binary composition. Tests HE across controlled experiments with small decoder-only Transformers under various conditions including noise injection, model depth variations, and training data coverage.", "result": "HE strongly predicts out-of-distribution compositional generalization (R^2 = 0.73 correlation between modifier HE and OOD accuracy). Model depth has minimal effect on HE or OOD accuracy, insufficient training data coverage sharply increases HE and degrades performance, and noise tokens systematically increase HE. HE-regularized training significantly reduces both modifier HE (p = 1.1x10-4) and sequence HE (p = 0.001) and yields statistically significant improvement in OOD accuracy (p = 0.023).", "conclusion": "Homomorphism Error shows potential as both a diagnostic tool and actionable training signal for improving compositional generalization in neural networks, moving beyond behavioral evaluations to structural representational analysis."}}
{"id": "2601.19155", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19155", "abs": "https://arxiv.org/abs/2601.19155", "authors": ["Qiujun Li", "Zijin Xiao", "Xulin Wang", "Zhidan Ma", "Cheng Yang", "Haifeng Li"], "title": "LocationAgent: A Hierarchical Agent for Image Geolocation via Decoupling Strategy and Evidence from Parametric Knowledge", "comment": "9 pages, 5 figures, 3 tables", "summary": "Image geolocation aims to infer capture locations based on visual content. Fundamentally, this constitutes a reasoning process composed of \\textit{hypothesis-verification cycles}, requiring models to possess both geospatial reasoning capabilities and the ability to verify evidence against geographic facts. Existing methods typically internalize location knowledge and reasoning patterns into static memory via supervised training or trajectory-based reinforcement fine-tuning. Consequently, these methods are prone to factual hallucinations and generalization bottlenecks in open-world settings or scenarios requiring dynamic knowledge. To address these challenges, we propose a Hierarchical Localization Agent, called LocationAgent. Our core philosophy is to retain hierarchical reasoning logic within the model while offloading the verification of geographic evidence to external tools. To implement hierarchical reasoning, we design the RER architecture (Reasoner-Executor-Recorder), which employs role separation and context compression to prevent the drifting problem in multi-step reasoning. For evidence verification, we construct a suite of clue exploration tools that provide diverse evidence to support location reasoning. Furthermore, to address data leakage and the scarcity of Chinese data in existing datasets, we introduce CCL-Bench (China City Location Bench), an image geolocation benchmark encompassing various scene granularities and difficulty levels. Extensive experiments demonstrate that LocationAgent significantly outperforms existing methods by at least 30\\% in zero-shot settings.", "AI": {"tldr": "LocationAgent is a hierarchical localization agent that separates reasoning logic from geographic evidence verification using external tools, achieving 30%+ improvement in zero-shot geolocation.", "motivation": "Existing image geolocation methods internalize location knowledge via supervised training or reinforcement fine-tuning, making them prone to factual hallucinations and generalization issues in open-world settings requiring dynamic knowledge.", "method": "Proposes LocationAgent with RER architecture (Reasoner-Executor-Recorder) for hierarchical reasoning, and external clue exploration tools for evidence verification. Also introduces CCL-Bench benchmark for Chinese city location evaluation.", "result": "LocationAgent significantly outperforms existing methods by at least 30% in zero-shot settings, demonstrating superior geospatial reasoning capabilities.", "conclusion": "Separating reasoning logic from evidence verification using external tools effectively addresses hallucination and generalization problems in image geolocation, with the proposed hierarchical approach showing strong performance."}}
{"id": "2601.19354", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.19354", "abs": "https://arxiv.org/abs/2601.19354", "authors": ["Ziqian Wang", "Chenxi Fang", "Zhen Zhang"], "title": "Self-Supervised Path Planning in Unstructured Environments via Global-Guided Differentiable Hard Constraint Projection", "comment": null, "summary": "Deploying deep learning agents for autonomous navigation in unstructured environments faces critical challenges regarding safety, data scarcity, and limited computational resources. Traditional solvers often suffer from high latency, while emerging learning-based approaches struggle to ensure deterministic feasibility. To bridge the gap from embodied to embedded intelligence, we propose a self-supervised framework incorporating a differentiable hard constraint projection layer for runtime assurance. To mitigate data scarcity, we construct a Global-Guided Artificial Potential Field (G-APF), which provides dense supervision signals without manual labeling. To enforce actuator limitations and geometric constraints efficiently, we employ an adaptive neural projection layer, which iteratively rectifies the coarse network output onto the feasible manifold. Extensive benchmarks on a test set of 20,000 scenarios demonstrate an 88.75\\% success rate, substantiating the enhanced operational safety. Closed-loop experiments in CARLA further validate the physical realizability of the planned paths under dynamic constraints. Furthermore, deployment verification on an NVIDIA Jetson Orin NX confirms an inference latency of 94 ms, showing real-time feasibility on resource-constrained embedded hardware. This framework offers a generalized paradigm for embedding physical laws into neural architectures, providing a viable direction for solving constrained optimization in mechatronics. Source code is available at: https://github.com/wzq-13/SSHC.git.", "AI": {"tldr": "A self-supervised framework with differentiable hard constraint projection for autonomous navigation that ensures safety, handles data scarcity via Global-Guided Artificial Potential Fields, and achieves real-time performance on embedded hardware.", "motivation": "Addressing critical challenges in deploying deep learning agents for autonomous navigation in unstructured environments: safety concerns, data scarcity, and limited computational resources. Traditional solvers have high latency, while learning-based approaches struggle with deterministic feasibility.", "method": "Proposes a self-supervised framework with: 1) Global-Guided Artificial Potential Field (G-APF) for dense supervision without manual labeling, and 2) Adaptive neural projection layer that iteratively rectifies network outputs onto feasible manifold to enforce actuator limitations and geometric constraints.", "result": "Achieved 88.75% success rate on 20,000 scenario test set, validated physical realizability in CARLA simulations under dynamic constraints, and demonstrated 94 ms inference latency on NVIDIA Jetson Orin NX, showing real-time feasibility on resource-constrained hardware.", "conclusion": "The framework offers a generalized paradigm for embedding physical laws into neural architectures, providing a viable direction for solving constrained optimization in mechatronics, bridging the gap from embodied to embedded intelligence with runtime safety assurance."}}
{"id": "2601.19042", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19042", "abs": "https://arxiv.org/abs/2601.19042", "authors": ["Ines Vati", "Pierrick Bourgeat", "Rodrigo Santa Cruz", "Vincent Dore", "Olivier Salvado", "Clinton Fookes", "L\u00e9o Lebrat"], "title": "NC-Reg : Neural Cortical Maps for Rigid Registration", "comment": "ISBI 2026", "summary": "We introduce neural cortical maps, a continuous and compact neural representation for cortical feature maps, as an alternative to traditional discrete structures such as grids and meshes. It can learn from meshes of arbitrary size and provide learnt features at any resolution. Neural cortical maps enable efficient optimization on the sphere and achieve runtimes up to 30 times faster than classic barycentric interpolation (for the same number of iterations). As a proof of concept, we investigate rigid registration of cortical surfaces and propose NC-Reg, a novel iterative algorithm that involves the use of neural cortical feature maps, gradient descent optimization and a simulated annealing strategy. Through ablation studies and subject-to-template experiments, our method demonstrates sub-degree accuracy ($<1^\\circ$ from the global optimum), and serves as a promising robust pre-alignment strategy, which is critical in clinical settings.", "AI": {"tldr": "Neural cortical maps provide continuous neural representations for cortical feature maps, enabling faster optimization on spheres and achieving sub-degree accuracy in cortical surface registration.", "motivation": "Traditional discrete structures like grids and meshes for cortical feature maps have limitations in flexibility and efficiency. The paper aims to create a more continuous, compact neural representation that can learn from arbitrary mesh sizes and provide features at any resolution.", "method": "Introduces neural cortical maps as continuous neural representations for cortical features. Proposes NC-Reg, an iterative algorithm combining neural cortical feature maps, gradient descent optimization, and simulated annealing for rigid registration of cortical surfaces.", "result": "Neural cortical maps achieve runtimes up to 30 times faster than classic barycentric interpolation. NC-Reg demonstrates sub-degree accuracy (<1\u00b0 from global optimum) in subject-to-template experiments, serving as a robust pre-alignment strategy for clinical applications.", "conclusion": "Neural cortical maps offer an efficient alternative to traditional discrete representations for cortical feature mapping, enabling faster optimization and accurate cortical surface registration with promising clinical applications."}}
{"id": "2601.18909", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18909", "abs": "https://arxiv.org/abs/2601.18909", "authors": ["Ziyao Cui", "Jian Pei"], "title": "How Is Uncertainty Propagated in Knowledge Distillation?", "comment": null, "summary": "Knowledge distillation transfers behavior from a teacher to a student model, but the process is inherently stochastic: teacher outputs, student training, and student inference can all be random. Collapsing these uncertainties to a single point estimate can distort what is learned. We systematically study how uncertainty propagates through knowledge distillation across three representative model classes--linear regression, feed-forward neural networks, and large language models (LLMs)--and propose simple corrections. We distinguish inter-student uncertainty (variance across independently distilled students) from intra-student uncertainty (variance of a single student's predictive distribution), showing that standard single-response knowledge distillation suppresses intra-student variance while leaving substantial inter-student variability. To address these mismatches, we introduce two variance-aware strategies: averaging multiple teacher responses, which reduces noise at rate $O(1/k)$, and variance-weighting, which combines teacher and student estimates via inverse-variance weighting to yield a minimum-variance estimator. We provide formal guarantees in linear regression, validate the methods in neural networks, and demonstrate empirical gains in LLM distillation, including reduced systematic noise and hallucination. These results reframe knowledge distillation as an uncertainty transformation and show that variance-aware distillation produces more stable students that better reflect teacher uncertainty.", "AI": {"tldr": "Knowledge distillation is stochastic but standard methods ignore uncertainty. The paper studies uncertainty propagation in distillation across model classes, distinguishes inter- vs intra-student variance, and proposes variance-aware strategies (response averaging and inverse-variance weighting) to produce more stable students.", "motivation": "Knowledge distillation is inherently stochastic with randomness in teacher outputs, student training, and student inference. Standard approaches collapse these uncertainties to point estimates, which distorts what is learned. The paper aims to systematically study how uncertainty propagates through knowledge distillation and propose corrections.", "method": "1. Systematically study uncertainty propagation across three model classes: linear regression, feed-forward neural networks, and LLMs. 2. Distinguish inter-student uncertainty (variance across independently distilled students) from intra-student uncertainty (variance of a single student's predictive distribution). 3. Propose two variance-aware strategies: averaging multiple teacher responses (reduces noise at O(1/k)) and variance-weighting (combines teacher and student estimates via inverse-variance weighting to yield minimum-variance estimator). 4. Provide formal guarantees in linear regression and validate in neural networks.", "result": "Standard single-response knowledge distillation suppresses intra-student variance but leaves substantial inter-student variability. The proposed variance-aware strategies demonstrate empirical gains in LLM distillation, including reduced systematic noise and hallucination. Formal guarantees are provided for linear regression case.", "conclusion": "The paper reframes knowledge distillation as an uncertainty transformation and shows that variance-aware distillation produces more stable students that better reflect teacher uncertainty. The methods address mismatches in uncertainty propagation and yield improved distillation outcomes."}}
{"id": "2601.19170", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19170", "abs": "https://arxiv.org/abs/2601.19170", "authors": ["Wangyang Ying", "Yanchi Liu", "Xujiang Zhao", "Wei Cheng", "Zhengzhang Chen", "Wenchao Yu", "Yanjie Fu", "Haifeng Chen"], "title": "Multi-Agent Procedural Graph Extraction with Structural and Logical Refinement", "comment": null, "summary": "Automatically extracting workflows as procedural graphs from natural language is promising yet underexplored, demanding both structural validity and logical alignment. While recent large language models (LLMs) show potential for procedural graph extraction, they often produce ill-formed structures or misinterpret logical flows. We present \\model{}, a multi-agent framework that formulates procedural graph extraction as a multi-round reasoning process with dedicated structural and logical refinement. The framework iterates through three stages: (1) a graph extraction phase with the graph builder agent, (2) a structural feedback phase in which a simulation agent diagnoses and explains structural defects, and (3) a logical feedback phase in which a semantic agent aligns semantics between flow logic and linguistic cues in the source text. Important feedback is prioritized and expressed in natural language, which is injected into subsequent prompts, enabling interpretable and controllable refinement. This modular design allows agents to target distinct error types without supervision or parameter updates. Experiments demonstrate that \\model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.", "AI": {"tldr": "Procedural graph extraction from text using multi-agent LLM framework with iterative structural and logical refinement", "motivation": "Automatically extracting workflows as procedural graphs from natural language is promising but challenging, requiring both structural validity and logical alignment. Current LLMs often produce ill-formed structures or misinterpret logical flows.", "method": "Proposed \\model{}, a multi-agent framework that formulates procedural graph extraction as multi-round reasoning with dedicated structural and logical refinement. Three iterative stages: (1) graph extraction with graph builder agent, (2) structural feedback phase with simulation agent diagnosing structural defects, (3) logical feedback phase with semantic agent aligning semantics between flow logic and linguistic cues. Uses natural language feedback prioritized and injected into subsequent prompts.", "result": "Experiments demonstrate that \\model{} achieves substantial improvements in both structural correctness and logical consistency over strong baselines.", "conclusion": "The modular multi-agent design allows agents to target distinct error types without supervision or parameter updates, enabling interpretable and controllable refinement for procedural graph extraction from natural language."}}
{"id": "2601.19376", "categories": ["cs.RO", "cs.AI", "cs.CY", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19376", "abs": "https://arxiv.org/abs/2601.19376", "authors": ["Viacheslav Sydora", "Guner Dilsad Er", "Michael Muehlebach"], "title": "Teaching Machine Learning Fundamentals with LEGO Robotics", "comment": "10 pages, 8 figures", "summary": "This paper presents the web-based platform Machine Learning with Bricks and an accompanying two-day course designed to teach machine learning concepts to students aged 12 to 17 through programming-free robotics activities. Machine Learning with Bricks is an open source platform and combines interactive visualizations with LEGO robotics to teach three core algorithms: KNN, linear regression, and Q-learning. Students learn by collecting data, training models, and interacting with robots via a web-based interface. Pre- and post-surveys with 14 students demonstrate significant improvements in conceptual understanding of machine learning algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning. This work demonstrates that tangible, visualization-based approaches can make machine learning concepts accessible and engaging for young learners while maintaining technical depth. The platform is freely available at https://learning-and-dynamics.github.io/ml-with-bricks/, with video tutorials guiding students through the experiments at https://youtube.com/playlist?list=PLx1grFu4zAcwfKKJZ1Ux4LwRqaePCOA2J.", "AI": {"tldr": "Web-based platform teaches ML to teens (12-17) using LEGO robotics without coding, covering KNN, linear regression, and Q-learning through interactive visualizations.", "motivation": "Make machine learning concepts accessible and engaging for young learners (12-17 years old) through tangible, visualization-based approaches while maintaining technical depth.", "method": "Developed open-source web platform combining interactive visualizations with LEGO robotics. Students learn by collecting data, training models, and interacting with robots via web interface without programming. Two-day course teaches three core algorithms: KNN, linear regression, and Q-learning.", "result": "Pre- and post-surveys with 14 students showed: significant improvements in conceptual understanding of ML algorithms, positive shifts in AI perception, high platform usability, and increased motivation for continued learning.", "conclusion": "Tangible, visualization-based approaches can effectively teach machine learning to young learners while maintaining technical depth. The platform successfully makes ML accessible and engaging for students aged 12-17 through programming-free robotics activities."}}
{"id": "2601.19602", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19602", "abs": "https://arxiv.org/abs/2601.19602", "authors": ["Sergio Mic\u00f3-Rosa", "Concepcion Garcia-Pardo", "Matteo Frasson", "Narcis Cardona", "Vicente Pons-Beltr\u00e1n", "Pedro L\u00f3pez-Mu\u00f1oz"], "title": "Initial Characterization of Healthy and Malignant in vivo and ex vivo Human Colon Tissues under Surgery Procedures", "comment": "6 pages, 8 figures, 3 tables. Published at the 2024 IEEE 35th International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC)", "summary": "The dielectric characterization of human tissues can play a crucial role in the development of new medical diagnostic tools. In particular, the characterization of healthy and pathological tissues can provide vital information for diagnosis. In this paper, preliminary results from a small-scale measurement campaign conducted in 0.5-26.5GHz during real surgeries on healthy and malignant human colon tissues are presented. Those measurements were carried out externally to the colon, without direct contact to the tumor growing inside the colon. Furthermore, different tumor stages are taken into account. Initial findings reveal that advanced tumor stages are related with increased higher values of dielectric properties in malignant tumor tissues compared to the healthy ones.", "AI": {"tldr": "Preliminary dielectric measurements of healthy vs. malignant colon tissues (0.5-26.5GHz) show advanced tumor stages have higher dielectric properties than healthy tissues.", "motivation": "Dielectric characterization of human tissues can enable new medical diagnostic tools, especially distinguishing healthy from pathological tissues for diagnosis.", "method": "Small-scale measurement campaign during real surgeries on healthy and malignant human colon tissues in 0.5-26.5GHz range, conducted externally to colon without direct tumor contact, considering different tumor stages.", "result": "Initial findings reveal advanced tumor stages are related with increased higher values of dielectric properties in malignant tumor tissues compared to healthy ones.", "conclusion": "Dielectric measurements show promise for distinguishing tumor stages, with advanced malignancies exhibiting higher dielectric properties than healthy tissues."}}
{"id": "2601.19048", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19048", "abs": "https://arxiv.org/abs/2601.19048", "authors": ["Han-Hung Lee", "Cheng-Yu Yang", "Yu-Lun Liu", "Angel X. Chang"], "title": "NuiWorld: Exploring a Scalable Framework for End-to-End Controllable World Generation", "comment": null, "summary": "World generation is a fundamental capability for applications like video games, simulation, and robotics. However, existing approaches face three main obstacles: controllability, scalability, and efficiency. End-to-end scene generation models have been limited by data scarcity. While object-centric generation approaches rely on fixed resolution representations, degrading fidelity for larger scenes. Training-free approaches, while flexible, are often slow and computationally expensive at inference time. We present NuiWorld, a framework that attempts to address these challenges. To overcome data scarcity, we propose a generative bootstrapping strategy that starts from a few input images. Leveraging recent 3D reconstruction and expandable scene generation techniques, we synthesize scenes of varying sizes and layouts, producing enough data to train an end-to-end model. Furthermore, our framework enables controllability through pseudo sketch labels, and demonstrates a degree of generalization to previously unseen sketches. Our approach represents scenes as a collection of variable scene chunks, which are compressed into a flattened vector-set representation. This significantly reduces the token length for large scenes, enabling consistent geometric fidelity across scenes sizes while improving training and inference efficiency.", "AI": {"tldr": "NuiWorld is a framework for world generation that addresses controllability, scalability, and efficiency challenges through generative bootstrapping, variable scene chunks, and pseudo sketch labels.", "motivation": "Existing world generation approaches face three main obstacles: controllability (difficulty in controlling generated content), scalability (degrading fidelity for larger scenes), and efficiency (slow and computationally expensive inference). End-to-end models suffer from data scarcity, object-centric approaches use fixed resolution representations, and training-free methods are inefficient.", "method": "1) Generative bootstrapping: Starts from few input images and uses 3D reconstruction/expandable scene generation to synthesize varied scenes for training data. 2) Variable scene chunks: Represents scenes as collections of chunks compressed into flattened vector-set representation to reduce token length. 3) Pseudo sketch labels: Enables controllability and generalization to unseen sketches.", "result": "The framework produces enough training data from limited inputs, maintains consistent geometric fidelity across scene sizes, improves training/inference efficiency, and enables controllable generation through sketch-based guidance with generalization to unseen sketches.", "conclusion": "NuiWorld addresses key challenges in world generation by combining generative bootstrapping for data scarcity, variable scene chunk representation for scalability, and pseudo sketch labels for controllability, offering a comprehensive solution for applications like video games, simulation, and robotics."}}
{"id": "2601.18912", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18912", "abs": "https://arxiv.org/abs/2601.18912", "authors": ["Shalima Binta Manir", "Tim Oates"], "title": "ASEHybrid: When Geometry Matters Beyond Homophily in Graph Neural Networks", "comment": "16 pages, 1 figure, 2 tables", "summary": "Standard message-passing graph neural networks (GNNs) often struggle on graphs with low homophily, yet homophily alone does not explain this behavior, as graphs with similar homophily levels can exhibit markedly different performance and some heterophilous graphs remain easy for vanilla GCNs. Recent work suggests that label informativeness (LI), the mutual information between labels of adjacent nodes, provides a more faithful characterization of when graph structure is useful. In this work, we develop a unified theoretical framework that connects curvature-guided rewiring and positional geometry through the lens of label informativeness, and instantiate it in a practical geometry-aware architecture, ASEHybrid. Our analysis provides a necessary-and-sufficient characterization of when geometry-aware GNNs can improve over feature-only baselines: such gains are possible if and only if graph structure carries label-relevant information beyond node features. Theoretically, we relate adjusted homophily and label informativeness to the spectral behavior of label signals under Laplacian smoothing, show that degree-based Forman curvature does not increase expressivity beyond the one-dimensional Weisfeiler--Lehman test but instead reshapes information flow, and establish convergence and Lipschitz stability guarantees for a curvature-guided rewiring process. Empirically, we instantiate ASEHybrid using Forman curvature and Laplacian positional encodings and conduct controlled ablations on Chameleon, Squirrel, Texas, Tolokers, and Minesweeper, observing gains precisely on label-informative heterophilous benchmarks where graph structure provides label-relevant information beyond node features, and no meaningful improvement in high-baseline regimes.", "AI": {"tldr": "The paper introduces ASEHybrid, a geometry-aware GNN architecture that uses curvature-guided rewiring and positional encodings to improve performance on heterophilous graphs where graph structure provides label-relevant information beyond node features.", "motivation": "Standard GNNs struggle on low-homophily graphs, but homophily alone doesn't explain performance variations. Recent work suggests label informativeness (mutual information between adjacent node labels) better characterizes when graph structure is useful. The authors aim to understand when geometry-aware GNNs can improve over feature-only baselines.", "method": "Developed a unified theoretical framework connecting curvature-guided rewiring and positional geometry through label informativeness. Instantiated ASEHybrid architecture using Forman curvature for rewiring and Laplacian positional encodings. Theoretically analyzed adjusted homophily, label informativeness, spectral behavior of label signals, and established convergence/stability guarantees for curvature-guided rewiring.", "result": "Theoretical analysis shows geometry-aware GNNs improve over feature-only baselines if and only if graph structure carries label-relevant information beyond node features. Empirically, ASEHybrid shows gains precisely on label-informative heterophilous benchmarks (Chameleon, Squirrel, Texas, Tolokers, Minesweeper) where graph structure provides additional label information, but no meaningful improvement in high-baseline regimes.", "conclusion": "Label informativeness provides a more accurate characterization of when graph structure is useful than homophily alone. Geometry-aware architectures like ASEHybrid can effectively leverage graph structure when it contains label-relevant information beyond node features, with theoretical guarantees on performance improvements."}}
{"id": "2601.19178", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19178", "abs": "https://arxiv.org/abs/2601.19178", "authors": ["Jingyu Li", "Zhaocheng Du", "Qianhui Zhu", "kaiyuan Li", "Zhicheng Zhang", "Song-Li Wu", "Chaolang Li", "Pengwen Dai"], "title": "CollectiveKV: Decoupling and Sharing Collaborative Information in Sequential Recommendation", "comment": "Accepted by ICLR 2026", "summary": "Sequential recommendation models are widely used in applications, yet they face stringent latency requirements. Mainstream models leverage the Transformer attention mechanism to improve performance, but its computational complexity grows with the sequence length, leading to a latency challenge for long sequences. Consequently, KV cache technology has recently been explored in sequential recommendation systems to reduce inference latency. However, KV cache introduces substantial storage overhead in sequential recommendation systems, which often have a large user base with potentially very long user history sequences. In this work, we observe that KV sequences across different users exhibit significant similarities, indicating the existence of collaborative signals in KV. Furthermore, we analyze the KV using singular value decomposition (SVD) and find that the information in KV can be divided into two parts: the majority of the information is shareable across users, while a small portion is user-specific. Motivated by this, we propose CollectiveKV, a cross-user KV sharing mechanism. It captures the information shared across users through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain the final KV. Experiments on five sequential recommendation models and three datasets show that our method can compress the KV cache to only 0.8% of its original size, while maintaining or even enhancing model performance.", "AI": {"tldr": "CollectiveKV is a cross-user KV sharing mechanism that compresses KV cache to 0.8% of original size while maintaining or improving performance in sequential recommendation systems.", "motivation": "KV cache reduces inference latency in sequential recommendation systems but introduces substantial storage overhead due to large user base and long history sequences. The authors observed that KV sequences across users show significant similarities, indicating collaborative signals in KV.", "method": "Proposes CollectiveKV, a cross-user KV sharing mechanism that captures shared information through a learnable global KV pool. During inference, each user retrieves high-dimensional shared KV from the pool and concatenates them with low-dimensional user-specific KV to obtain final KV.", "result": "Experiments on five sequential recommendation models and three datasets show the method can compress KV cache to only 0.8% of its original size while maintaining or even enhancing model performance.", "conclusion": "CollectiveKV effectively addresses the storage overhead problem of KV cache in sequential recommendation systems by leveraging collaborative signals in KV sequences, achieving significant compression without performance degradation."}}
{"id": "2601.19388", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19388", "abs": "https://arxiv.org/abs/2601.19388", "authors": ["Yimin Tang", "Sven Koenig", "Erdem B\u0131y\u0131k"], "title": "Judgelight: Trajectory-Level Post-Optimization for Multi-Agent Path Finding via Closed-Subwalk Collapsing", "comment": null, "summary": "Multi-Agent Path Finding (MAPF) is an NP-hard problem with applications in warehouse automation and multi-robot coordination. Learning-based MAPF solvers offer fast and scalable planning but often produce feasible trajectories that contain unnecessary or oscillatory movements. We propose Judgelight, a post-optimization method that improves trajectory quality after a MAPF solver generates a feasible schedule. Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements while preserving all feasibility constraints. We formalize this process as MAPF-Collapse, prove that it is NP-hard, and present an exact optimization approach by formulating it as integer linear programming (ILP) problem. Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly for learning-based solvers, producing trajectories that are better suited for real-world deployment.", "AI": {"tldr": "Judgelight is a post-optimization method that improves trajectory quality in Multi-Agent Path Finding by collapsing redundant movements while preserving feasibility constraints.", "motivation": "Learning-based MAPF solvers produce fast but often suboptimal trajectories with unnecessary or oscillatory movements, making them less suitable for real-world deployment despite their scalability.", "method": "Judgelight collapses closed subwalks in agents' trajectories to remove redundant movements, formalized as MAPF-Collapse problem. The authors prove it's NP-hard and solve it exactly using integer linear programming (ILP).", "result": "Experimental results show Judgelight consistently reduces solution cost by around 20%, particularly benefiting learning-based solvers, producing trajectories better suited for real-world applications.", "conclusion": "Judgelight effectively improves trajectory quality as a post-optimization step, making learning-based MAPF solvers more practical for real-world deployment by removing redundant movements while maintaining feasibility."}}
{"id": "2601.19623", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19623", "abs": "https://arxiv.org/abs/2601.19623", "authors": ["Chenyang Yan", "Geert Leus", "Mats Bengtsson"], "title": "Robust Covariance-Based DoA Estimation under Weather-Induced Distortion", "comment": null, "summary": "We investigate robust direction-of-arrival (DoA) estimation for sensor arrays operating in adverse weather conditions, where weather-induced distortions degrade estimation accuracy. Building on a physics-based $S$-matrix model established in prior work, we adopt a statistical characterization of random phase and amplitude distortions caused by multiple scattering in rain. Based on this model, we develop a measurement framework for uniform linear arrays (ULAs) that explicitly incorporates such distortions. To mitigate their impact, we exploit the Hermitian Toeplitz (HT) structure of the covariance matrix to reduce the number of parameters to be estimated. We then apply a generalized least squares (GLS) approach for calibration. Simulation results show that the proposed method effectively suppresses rain-induced distortions, improves DoA estimation accuracy, and enhances radar sensing performance in challenging weather conditions.", "AI": {"tldr": "Robust DoA estimation method for sensor arrays in adverse weather using physics-based distortion modeling and Hermitian Toeplitz covariance structure with GLS calibration.", "motivation": "Weather-induced distortions (particularly rain) degrade direction-of-arrival estimation accuracy for sensor arrays, necessitating robust methods that can operate effectively in adverse weather conditions.", "method": "1) Use physics-based S-matrix model with statistical characterization of random phase/amplitude distortions from multiple scattering in rain. 2) Develop measurement framework for ULAs incorporating distortions. 3) Exploit Hermitian Toeplitz structure of covariance matrix to reduce parameter estimation. 4) Apply generalized least squares approach for calibration.", "result": "Simulation results show the method effectively suppresses rain-induced distortions, improves DoA estimation accuracy, and enhances radar sensing performance in challenging weather conditions.", "conclusion": "The proposed approach successfully addresses weather-induced distortion problems in DoA estimation by combining physics-based modeling with statistical characterization and efficient parameter reduction techniques, enabling reliable sensor array operation in adverse weather."}}
{"id": "2601.19060", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19060", "abs": "https://arxiv.org/abs/2601.19060", "authors": ["Jeonghwan Kim", "Renjie Tao", "Sanat Sharma", "Jiaqi Wang", "Kai Sun", "Zhaojiang Lin", "Seungwhan Moon", "Lambert Mathias", "Anuj Kumar", "Heng Ji", "Xin Luna Dong"], "title": "Pixel-Grounded Retrieval for Knowledgeable Large Multimodal Models", "comment": "Preprint", "summary": "Visual Question Answering (VQA) often requires coupling fine-grained perception with factual knowledge beyond the input image. Prior multimodal Retrieval-Augmented Generation (MM-RAG) systems improve factual grounding but lack an internal policy for when and how to retrieve. We propose PixSearch, the first end-to-end Segmenting Large Multimodal Model (LMM) that unifies region-level perception and retrieval-augmented reasoning. During encoding, PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text, image, or region), and generates pixel-level masks that directly serve as visual queries, eliminating the reliance on modular pipelines (detectors, segmenters, captioners, etc.). A two-stage supervised fine-tuning regimen with search-interleaved supervision teaches retrieval timing and query selection while preserving segmentation ability. On egocentric and entity-centric VQA benchmarks, PixSearch substantially improves factual consistency and generalization, yielding a 19.7% relative gain in accuracy on CRAG-MM compared to whole image retrieval, while retaining competitive reasoning performance on various VQA and text-only QA tasks.", "AI": {"tldr": "PixSearch is an end-to-end Segmenting Large Multimodal Model that unifies region-level perception with retrieval-augmented reasoning, using pixel-level masks as visual queries and learning when/what to retrieve through supervised fine-tuning.", "motivation": "Visual Question Answering requires both fine-grained perception and external factual knowledge. Existing multimodal RAG systems lack internal policies for when and how to retrieve information, relying on modular pipelines that are not end-to-end optimized.", "method": "PixSearch emits <search> tokens to trigger retrieval, selects query modalities (text/image/region), and generates pixel-level masks as visual queries. It uses two-stage supervised fine-tuning with search-interleaved supervision to teach retrieval timing and query selection while preserving segmentation ability.", "result": "PixSearch achieves 19.7% relative accuracy gain on CRAG-MM compared to whole image retrieval, improves factual consistency and generalization on egocentric and entity-centric VQA benchmarks, while maintaining competitive performance on various VQA and text-only QA tasks.", "conclusion": "PixSearch successfully unifies region-level perception with retrieval-augmented reasoning in an end-to-end model, eliminating reliance on modular pipelines and demonstrating significant improvements in factual grounding for VQA tasks."}}
{"id": "2601.18917", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18917", "abs": "https://arxiv.org/abs/2601.18917", "authors": ["Semih Cant\u00fcrk", "Andrei Manolache", "Arman Mielke", "Chendi Qian", "Antoine Siraudin", "Christopher Morris", "Mathias Niepert", "Guy Wolf"], "title": "GraIP: A Benchmarking Framework For Neural Graph Inverse Problems", "comment": null, "summary": "A wide range of graph learning tasks, such as structure discovery, temporal graph analysis, and combinatorial optimization, focus on inferring graph structures from data, rather than making predictions on given graphs. However, the respective methods to solve such problems are often developed in an isolated, task-specific manner and thus lack a unifying theoretical foundation. Here, we provide a stepping stone towards the formation of such a foundation and further development by introducing the Neural Graph Inverse Problem (GraIP) conceptual framework, which formalizes and reframes a broad class of graph learning tasks as inverse problems. Unlike discriminative approaches that directly predict target variables from given graph inputs, the GraIP paradigm addresses inverse problems, i.e., it relies on observational data and aims to recover the underlying graph structure by reversing the forward process, such as message passing or network dynamics, that produced the observed outputs. We demonstrate the versatility of GraIP across various graph learning tasks, including rewiring, causal discovery, and neural relational inference. We also propose benchmark datasets and metrics for each GraIP domain considered, and characterize and empirically evaluate existing baseline methods used to solve them. Overall, our unifying perspective bridges seemingly disparate applications and provides a principled approach to structural learning in constrained and combinatorial settings while encouraging cross-pollination of existing methods across graph inverse problems.", "AI": {"tldr": "The paper introduces Neural Graph Inverse Problem (GraIP), a unifying framework that reframes diverse graph learning tasks as inverse problems to recover underlying graph structures from observational data.", "motivation": "Current graph learning methods for structure inference tasks are developed in isolated, task-specific ways without a unifying theoretical foundation. The authors aim to provide a common framework to bridge disparate applications and enable cross-pollination of methods.", "method": "Proposes the Neural Graph Inverse Problem (GraIP) conceptual framework that formalizes graph learning tasks as inverse problems. Unlike discriminative approaches, GraIP aims to recover underlying graph structures by reversing forward processes (like message passing or network dynamics) that produced observed outputs.", "result": "Demonstrates GraIP's versatility across various graph learning tasks including rewiring, causal discovery, and neural relational inference. Provides benchmark datasets and metrics for each GraIP domain and empirically evaluates existing baseline methods.", "conclusion": "GraIP offers a unifying perspective that bridges seemingly disparate applications, provides principled approaches to structural learning in constrained/combinatorial settings, and encourages cross-pollination of methods across graph inverse problems."}}
{"id": "2601.19193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19193", "abs": "https://arxiv.org/abs/2601.19193", "authors": ["Van-Quang Nguyen", "Takayuki Okatani"], "title": "CoReTab: Improving Multimodal Table Understanding with Code-driven Reasoning", "comment": "accepted to EACL'26 (main conference)", "summary": "Existing datasets for multimodal table understanding, such as MMTab, primarily provide short factual answers without explicit multi-step reasoning supervision. Models trained on these datasets often generate brief responses that offers insufficient accuracy and limited interpretability into how these models arrive at the final answer. We introduce CoReTab, a code-driven reasoning framework that produces scalable, interpretable, and automatically verifiable annotations by coupling multi-step reasoning with executable Python code. Using the CoReTab framework, we curate a dataset of 115K verified samples averaging 529 tokens per response and fine-tune open-source MLLMs through a three-stage pipeline. We evaluate the resulting model trained on CoReTab across 17 MMTab benchmarks spanning table question answering, fact verification, and table structure understanding. Our model achieves significant gains of +6.2%, +5.7%, and +25.6%, respectively, over MMTab-trained baselines, while producing transparent and verifiable reasoning traces. These results establish CoReTab as a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding.", "AI": {"tldr": "CoReTab introduces a code-driven reasoning framework for multimodal table understanding that generates interpretable, verifiable multi-step reasoning with executable Python code, achieving significant performance gains over existing methods.", "motivation": "Existing multimodal table understanding datasets provide only short factual answers without explicit reasoning supervision, leading to models that produce brief, uninterpretable responses with insufficient accuracy.", "method": "Developed CoReTab framework that couples multi-step reasoning with executable Python code to create scalable, interpretable, and automatically verifiable annotations. Curated 115K verified samples and fine-tuned open-source MLLMs through a three-stage pipeline.", "result": "Model trained on CoReTab achieved significant gains: +6.2% on table question answering, +5.7% on fact verification, and +25.6% on table structure understanding across 17 MMTab benchmarks, while producing transparent reasoning traces.", "conclusion": "CoReTab establishes a robust and generalizable supervision framework for improving multi-step reasoning in multimodal table understanding, offering interpretable and verifiable reasoning capabilities."}}
{"id": "2601.19406", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19406", "abs": "https://arxiv.org/abs/2601.19406", "authors": ["Kaipeng Fang", "Weiqing Liang", "Yuyang Li", "Ji Zhang", "Pengpeng Zeng", "Lianli Gao", "Jingkuan Song", "Heng Tao Shen"], "title": "Sim-and-Human Co-training for Data-Efficient and Generalizable Robotic Manipulation", "comment": null, "summary": "Synthetic simulation data and real-world human data provide scalable alternatives to circumvent the prohibitive costs of robot data collection. However, these sources suffer from the sim-to-real visual gap and the human-to-robot embodiment gap, respectively, which limits the policy's generalization to real-world scenarios. In this work, we identify a natural yet underexplored complementarity between these sources: simulation offers the robot action that human data lacks, while human data provides the real-world observation that simulation struggles to render. Motivated by this insight, we present SimHum, a co-training framework to simultaneously extract kinematic prior from simulated robot actions and visual prior from real-world human observations. Based on the two complementary priors, we achieve data-efficient and generalizable robotic manipulation in real-world tasks. Empirically, SimHum outperforms the baseline by up to $\\mathbf{40\\%}$ under the same data collection budget, and achieves a $\\mathbf{62.5\\%}$ OOD success with only 80 real data, outperforming the real only baseline by $7.1\\times$. Videos and additional information can be found at \\href{https://kaipengfang.github.io/sim-and-human}{project website}.", "AI": {"tldr": "SimHum: A co-training framework that leverages complementary strengths of simulation data (robot actions) and human data (real-world observations) for data-efficient and generalizable robotic manipulation.", "motivation": "Both synthetic simulation data and real-world human data have limitations: simulation suffers from sim-to-real visual gap, while human data lacks robot-specific actions. The paper identifies their natural complementarity - simulation provides robot actions that human data lacks, while human data provides real-world observations that simulation struggles to render.", "method": "SimHum is a co-training framework that simultaneously extracts kinematic prior from simulated robot actions and visual prior from real-world human observations. It combines these two complementary priors to achieve better generalization.", "result": "SimHum outperforms baselines by up to 40% under the same data collection budget, and achieves 62.5% OOD success with only 80 real data, outperforming real-only baseline by 7.1\u00d7.", "conclusion": "The complementary nature of simulation and human data can be effectively leveraged through co-training to achieve data-efficient and generalizable robotic manipulation in real-world tasks."}}
{"id": "2601.19656", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19656", "abs": "https://arxiv.org/abs/2601.19656", "authors": ["Parisa Ramezani", "Emil Bj\u00f6rnson"], "title": "Cell-Free MIMO in Space: Cooperative Satellite Transmission with Multi-Antenna Ground Users", "comment": null, "summary": "This paper develops a multi-user downlink communication framework for distributed low Earth orbit satellite networks serving ground users equipped with multiple antennas. Building upon the concept of cell-free multiple-input multiple-output in terrestrial networks, we propose a coordinated transmission scheme where multiple satellites jointly transmit spatially multiplexed data streams to each user. Using a new approximate achievable rate expression, we formulate a sum rate maximization problem under per-satellite and per-antenna power constraints and use the classical equivalence between sum rate maximization and mean square error minimization to optimize the satellites' precoding matrices using statistical channel state information. We numerically examine the performance of the proposed scheme in different settings and validate its effectiveness by comparing it against traditional precoding designs.", "AI": {"tldr": "Proposes cell-free MIMO for LEO satellite networks with multi-antenna ground users, using coordinated satellite transmission and statistical CSI-based precoding optimization.", "motivation": "Extend terrestrial cell-free MIMO concepts to distributed LEO satellite networks to improve multi-user downlink communication performance for ground users with multiple antennas.", "method": "Coordinated transmission scheme where multiple satellites jointly transmit spatially multiplexed data streams; uses approximate achievable rate expression, formulates sum rate maximization under power constraints, and optimizes precoding matrices using statistical CSI via MSE minimization equivalence.", "result": "Numerically examines performance in different settings and validates effectiveness against traditional precoding designs.", "conclusion": "Proposed cell-free MIMO framework for LEO satellite networks with coordinated transmission and statistical CSI-based precoding optimization shows improved performance over traditional approaches."}}
{"id": "2601.19099", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19099", "abs": "https://arxiv.org/abs/2601.19099", "authors": ["Yosub Shin", "Michael Buriek", "Igor Molybog"], "title": "m2sv: A Scalable Benchmark for Map-to-Street-View Spatial Reasoning", "comment": null, "summary": "Vision--language models (VLMs) achieve strong performance on many multimodal benchmarks but remain brittle on spatial reasoning tasks that require aligning abstract overhead representations with egocentric views. We introduce m2sv, a scalable benchmark for map-to-street-view spatial reasoning that asks models to infer camera viewing direction by aligning a north-up overhead map with a Street View image captured at the same real-world intersection. We release m2sv-20k, a geographically diverse benchmark with controlled ambiguity, along with m2sv-sft-11k, a curated set of structured reasoning traces for supervised fine-tuning.\n  Despite strong performance on existing multimodal benchmarks, the best evaluated VLM achieves only 65.2% accuracy on m2sv, far below the human baseline of 95%. While supervised fine-tuning and reinforcement learning yield consistent gains, cross-benchmark evaluations reveal limited transfer. Beyond aggregate accuracy, we systematically analyze difficulty in map-to-street-view reasoning using both structural signals and human effort, and conduct an extensive failure analysis of adapted open models. Our findings highlight persistent gaps in geometric alignment, evidence aggregation, and reasoning consistency, motivating future work on grounded spatial reasoning across viewpoints.", "AI": {"tldr": "m2sv benchmark tests VLMs on spatial reasoning by aligning overhead maps with Street View images to infer camera direction, revealing significant performance gaps vs humans.", "motivation": "Vision-language models perform well on many multimodal tasks but struggle with spatial reasoning requiring alignment between abstract overhead representations and egocentric views.", "method": "Introduces m2sv benchmark with m2sv-20k (geographically diverse dataset) and m2sv-sft-11k (curated reasoning traces for fine-tuning). Evaluates VLMs on map-to-street-view alignment tasks.", "result": "Best VLM achieves only 65.2% accuracy vs human baseline of 95%. Fine-tuning and RL yield gains but limited cross-benchmark transfer. Analysis reveals gaps in geometric alignment, evidence aggregation, and reasoning consistency.", "conclusion": "Persistent gaps in spatial reasoning highlight need for future work on grounded spatial reasoning across viewpoints, particularly in geometric alignment and evidence aggregation."}}
{"id": "2601.18919", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18919", "abs": "https://arxiv.org/abs/2601.18919", "authors": ["Bartosz Szab\u0142owski"], "title": "One Global Model, Many Behaviors: Stockout-Aware Feature Engineering and Dynamic Scaling for Multi-Horizon Retail Demand Forecasting with a Cost-Aware Ordering Policy (VN2 Winner Report)", "comment": "13 pages, 5 figures. Technical report/winner report for the VN2 Inventory Planning Challenge (2025)", "summary": "Inventory planning for retail chains requires translating demand forecasts into ordering decisions, including asymmetric shortages and holding costs. The VN2 Inventory Planning Challenge formalizes this setting as a weekly decision-making cycle with a two-week product delivery lead time, where the total cost is defined as the shortage cost plus the holding cost. This report presents the winning VN2 solution: a two-stage predict-then-optimize pipeline that combines a single global multi-horizon forecasting model with a cost-aware ordering policy. The forecasting model is trained in a global paradigm, jointly using all available time series. A gradient-boosted decision tree (GBDT) model implemented in CatBoost is used as the base learner. The model incorporates stockout-aware feature engineering to address censored demand during out-of-stock periods, per-series scaling to focus learning on time-series patterns rather than absolute levels, and time-based observation weights to reflect shifts in demand patterns. In the decision stage, inventory is projected to the start of the delivery week, and a target stock level is calculated that explicitly trades off shortage and holding costs. Evaluated by the official competition simulation in six rounds, the solution achieved first place by combining a strong global forecasting model with a lightweight cost-aware policy. Although developed for the VN2 setting, the proposed approach can be extended to real-world applications and additional operational constraints.", "AI": {"tldr": "Winning VN2 Inventory Planning Challenge solution uses a two-stage predict-then-optimize pipeline with global multi-horizon forecasting and cost-aware ordering policy.", "motivation": "Retail inventory planning requires translating demand forecasts into ordering decisions while balancing asymmetric shortage and holding costs, formalized in the VN2 Inventory Planning Challenge with weekly decisions and two-week lead times.", "method": "Two-stage approach: 1) Global multi-horizon forecasting using CatBoost GBDT with stockout-aware feature engineering, per-series scaling, and time-based weights; 2) Cost-aware ordering policy that projects inventory and calculates target stock levels trading off shortage vs holding costs.", "result": "Achieved first place in official competition simulation across six rounds by combining strong global forecasting with lightweight cost-aware policy.", "conclusion": "The solution demonstrates effective inventory planning through global forecasting and cost-aware optimization, with potential for extension to real-world applications and additional operational constraints."}}
{"id": "2601.19199", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19199", "abs": "https://arxiv.org/abs/2601.19199", "authors": ["Libo Sun", "Jiwen Zhang", "Siyuan Wang", "Zhongyu Wei"], "title": "MAGNET: Towards Adaptive GUI Agents with Memory-Driven Knowledge Evolution", "comment": null, "summary": "Mobile GUI agents powered by large foundation models enable autonomous task execution, but frequent updates altering UI appearance and reorganizing workflows cause agents trained on historical data to fail. Despite surface changes, functional semantics and task intents remain fundamentally stable. Building on this insight, we introduce MAGNET, a memory-driven adaptive agent framework with dual-level memory: stationary memory linking diverse visual features to stable functional semantics for robust action grounding and procedural memory capturing stable task intents across varying workflows. We propose a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge. Online benchmark AndroidWorld evaluations show substantial improvements over baselines, while offline benchmarks confirm consistent gains under distribution shifts. These results validate that leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments.", "AI": {"tldr": "MAGNET is a memory-driven adaptive agent framework with dual-level memory that improves GUI agent robustness to UI changes by leveraging stable functional semantics and task intents.", "motivation": "Mobile GUI agents fail when UI appearance changes or workflows are reorganized, even though functional semantics and task intents remain fundamentally stable across updates.", "method": "MAGNET uses dual-level memory: stationary memory links visual features to stable functional semantics for action grounding, and procedural memory captures stable task intents across varying workflows. It includes a dynamic memory evolution mechanism that continuously refines both memories by prioritizing frequently accessed knowledge.", "result": "Online benchmark AndroidWorld evaluations show substantial improvements over baselines, and offline benchmarks confirm consistent gains under distribution shifts.", "conclusion": "Leveraging stable structures across interface changes improves agent performance and generalization in evolving software environments."}}
{"id": "2601.19411", "categories": ["cs.RO", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19411", "abs": "https://arxiv.org/abs/2601.19411", "authors": ["Ziang Zheng", "Kai Feng", "Yi Nie", "Shentao Qin"], "title": "Task-Centric Policy Optimization from Misaligned Motion Priors", "comment": null, "summary": "Humanoid control often leverages motion priors from human demonstrations to encourage natural behaviors. However, such demonstrations are frequently suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations, causing na\u00efve imitation to degrade task performance. Conversely, task-only reinforcement learning admits many task-optimal solutions, often resulting in unnatural or unstable motions. This exposes a fundamental limitation of linear reward mixing in adversarial imitation learning. We propose \\emph{Task-Centric Motion Priors} (TCMP), a task-priority adversarial imitation framework that treats imitation as a conditional regularizer rather than a co-equal objective. TCMP maximizes task improvement while incorporating imitation signals only when they are compatible with task progress, yielding an adaptive, geometry-aware update that preserves task-feasible descent and suppresses harmful imitation under misalignment. We provide theoretical analysis of gradient conflict and task-priority stationary points, and validate our claims through humanoid control experiments demonstrating robust task performance with consistent motion style under noisy demonstrations.", "AI": {"tldr": "TCMP is a task-priority adversarial imitation framework that treats imitation as conditional regularizer, not co-equal objective, to maintain task performance while preserving natural motion style from noisy demonstrations.", "motivation": "Human demonstrations used as motion priors are often suboptimal or misaligned with robotic tasks due to embodiment differences, retargeting errors, and task-irrelevant variations. Na\u00efve imitation degrades task performance, while task-only RL produces unnatural motions. Linear reward mixing in adversarial imitation learning has fundamental limitations.", "method": "Task-Centric Motion Priors (TCMP) - a task-priority adversarial imitation framework that treats imitation as conditional regularizer rather than co-equal objective. It maximizes task improvement while incorporating imitation signals only when compatible with task progress, using adaptive, geometry-aware updates that preserve task-feasible descent and suppress harmful imitation under misalignment.", "result": "Theoretical analysis of gradient conflict and task-priority stationary points. Humanoid control experiments demonstrate robust task performance with consistent motion style under noisy demonstrations.", "conclusion": "TCMP effectively addresses the limitations of linear reward mixing in adversarial imitation learning by prioritizing task objectives while conditionally incorporating imitation signals, enabling robust task performance with natural motion styles even with imperfect demonstrations."}}
{"id": "2601.19660", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19660", "abs": "https://arxiv.org/abs/2601.19660", "authors": ["Parisa Ramezani", "Alva Kosasih", "Emil Bj\u00f6rnson"], "title": "Maximum A Posteriori Probability Channel Tracking with an Intelligent Transmitting Surface", "comment": null, "summary": "This paper considers an intelligent transmitting surface (ITS) integrated into a base station and develops a low-overhead maximum a posteriori (MAP) probability channel tracking method for the dominant line-of-sight link between the ITS and the user equipment. We cast the per-block channel as a three-parameter model consisting of the channel amplitude, channel phase, and angle-of-arrival at the ITS. We exploit temporal correlation by updating the priors using the estimates from the previous block. Using only two pilots per coherence block alongside a targeted beam alignment strategy, the proposed method achieves precise channel tracking and attains spectral efficiency close to that achievable under perfect channel knowledge.", "AI": {"tldr": "Low-overhead MAP channel tracking for ITS using only 2 pilots per coherence block achieves near-perfect channel knowledge performance.", "motivation": "Need efficient channel tracking for intelligent transmitting surface (ITS) integrated base stations with minimal pilot overhead while maintaining accurate channel estimation.", "method": "Proposes MAP probability channel tracking using three-parameter model (amplitude, phase, AoA) with temporal correlation via prior updates from previous blocks, using only two pilots per coherence block with targeted beam alignment.", "result": "Achieves precise channel tracking and attains spectral efficiency close to that achievable under perfect channel knowledge with minimal pilot overhead.", "conclusion": "The proposed low-overhead MAP channel tracking method effectively maintains channel accuracy for ITS systems while minimizing pilot resources."}}
{"id": "2601.19103", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19103", "abs": "https://arxiv.org/abs/2601.19103", "authors": ["Linshan Wu", "Jiaxin Zhuang", "Hao Chen"], "title": "Glance and Focus Reinforcement for Pan-cancer Screening", "comment": "Accepted by ICLR 2026. Code is available at https://github.com/Luffy03/GF-Screen", "summary": "Pan-cancer screening in large-scale CT scans remains challenging for existing AI methods, primarily due to the difficulty of localizing diverse types of tiny lesions in large CT volumes. The extreme foreground-background imbalance significantly hinders models from focusing on diseased regions, while redundant focus on healthy regions not only decreases the efficiency but also increases false positives. Inspired by radiologists' glance and focus diagnostic strategy, we introduce GF-Screen, a Glance and Focus reinforcement learning framework for pan-cancer screening. GF-Screen employs a Glance model to localize the diseased regions and a Focus model to precisely segment the lesions, where segmentation results of the Focus model are leveraged to reward the Glance model via Reinforcement Learning (RL). Specifically, the Glance model crops a group of sub-volumes from the entire CT volume and learns to select the sub-volumes with lesions for the Focus model to segment. Given that the selecting operation is non-differentiable for segmentation training, we propose to employ the segmentation results to reward the Glance model. To optimize the Glance model, we introduce a novel group relative learning paradigm, which employs group relative comparison to prioritize high-advantage predictions and discard low-advantage predictions within sub-volume groups, not only improving efficiency but also reducing false positives. In this way, for the first time, we effectively extend cutting-edge RL techniques to tackle the specific challenges in pan-cancer screening. Extensive experiments on 16 internal and 7 external datasets across 9 lesion types demonstrated the effectiveness of GF-Screen. Notably, GF-Screen leads the public validation leaderboard of MICCAI FLARE25 pan-cancer challenge, surpassing the FLARE24 champion solution by a large margin (+25.6% DSC and +28.2% NSD).", "AI": {"tldr": "GF-Screen is a reinforcement learning framework for pan-cancer CT screening that uses a two-stage \"glance and focus\" approach to efficiently localize and segment diverse tiny lesions in large volumes.", "motivation": "Pan-cancer screening in large CT volumes is challenging due to difficulty localizing diverse tiny lesions, extreme foreground-background imbalance, and inefficient focus on healthy regions that increases false positives.", "method": "Two-stage RL framework: Glance model localizes diseased regions by cropping and selecting sub-volumes, Focus model precisely segments lesions. Segmentation results reward Glance model via RL with novel group relative learning paradigm for optimization.", "result": "Extensive experiments on 16 internal and 7 external datasets across 9 lesion types show effectiveness. Leads MICCAI FLARE25 pan-cancer challenge leaderboard, surpassing FLARE24 champion by +25.6% DSC and +28.2% NSD.", "conclusion": "GF-Screen successfully extends RL techniques to pan-cancer screening challenges, achieving state-of-the-art performance through efficient glance-focus strategy that reduces false positives and improves lesion detection."}}
{"id": "2601.18930", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.18930", "abs": "https://arxiv.org/abs/2601.18930", "authors": ["Seiji Shaw", "Travis Manderson", "Chad Kessens", "Nicholas Roy"], "title": "Toward Learning POMDPs Beyond Full-Rank Actions and State Observability", "comment": null, "summary": "We are interested in enabling autonomous agents to learn and reason about systems with hidden states, such as furniture with hidden locking mechanisms. We cast this problem as learning the parameters of a discrete Partially Observable Markov Decision Process (POMDP). The agent begins with knowledge of the POMDP's actions and observation spaces, but not its state space, transitions, or observation models. These properties must be constructed from action-observation sequences. Spectral approaches to learning models of partially observable domains, such as learning Predictive State Representations (PSRs), are known to directly estimate the number of hidden states. These methods cannot, however, yield direct estimates of transition and observation likelihoods, which are important for many downstream reasoning tasks. Other approaches leverage tensor decompositions to estimate transition and observation likelihoods but often assume full state observability and full-rank transition matrices for all actions. To relax these assumptions, we study how PSRs learn transition and observation matrices up to a similarity transform, which may be estimated via tensor methods. Our method learns observation matrices and transition matrices up to a partition of states, where the states in a single partition have the same observation distributions corresponding to actions whose transition matrices are full-rank. Our experiments suggest that these partition-level transition models learned by our method, with a sufficient amount of data, meets the performance of PSRs as models to be used by standard sampling-based POMDP solvers. Furthermore, the explicit observation and transition likelihoods can be leveraged to specify planner behavior after the model has been learned.", "AI": {"tldr": "The paper proposes a method to learn POMDP parameters (transition and observation likelihoods) from action-observation sequences using tensor decompositions and Predictive State Representations, relaxing assumptions of full observability and full-rank transition matrices.", "motivation": "Enable autonomous agents to learn and reason about systems with hidden states (like furniture with hidden locking mechanisms) by learning POMDP parameters from action-observation sequences, addressing limitations of existing spectral methods that can't estimate transition/observation likelihoods needed for downstream reasoning tasks.", "method": "Combines Predictive State Representations (PSRs) with tensor decompositions to learn observation matrices and transition matrices up to a partition of states. States within a partition share the same observation distributions for actions with full-rank transition matrices. The method learns models up to a similarity transform via tensor methods.", "result": "Experiments show that partition-level transition models learned by the method, with sufficient data, achieve performance comparable to PSRs when used by standard sampling-based POMDP solvers. The explicit observation and transition likelihoods can be leveraged to specify planner behavior after model learning.", "conclusion": "The proposed approach successfully learns POMDP parameters (transition and observation matrices) from action-observation sequences, relaxing restrictive assumptions of existing methods while maintaining performance comparable to PSRs and enabling downstream planning applications."}}
{"id": "2601.19204", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19204", "abs": "https://arxiv.org/abs/2601.19204", "authors": ["Zhixi Cai", "Fucai Ke", "Kevin Leo", "Sukai Huang", "Maria Garcia de la Banda", "Peter J. Stuckey", "Hamid Rezatofighi"], "title": "MATA: A Trainable Hierarchical Automaton System for Multi-Agent Visual Reasoning", "comment": "ICLR 2026", "summary": "Recent vision-language models have strong perceptual ability but their implicit reasoning is hard to explain and easily generates hallucinations on complex queries. Compositional methods improve interpretability, but most rely on a single agent or hand-crafted pipeline and cannot decide when to collaborate across complementary agents or compete among overlapping ones. We introduce MATA (Multi-Agent hierarchical Trainable Automaton), a multi-agent system presented as a hierarchical finite-state automaton for visual reasoning whose top-level transitions are chosen by a trainable hyper agent. Each agent corresponds to a state in the hyper automaton, and runs a small rule-based sub-automaton for reliable micro-control. All agents read and write a shared memory, yielding transparent execution history. To supervise the hyper agent's transition policy, we build transition-trajectory trees and transform to memory-to-next-state pairs, forming the MATA-SFT-90K dataset for supervised finetuning (SFT). The finetuned LLM as the transition policy understands the query and the capacity of agents, and it can efficiently choose the optimal agent to solve the task. Across multiple visual reasoning benchmarks, MATA achieves the state-of-the-art results compared with monolithic and compositional baselines. The code and dataset are available at https://github.com/ControlNet/MATA.", "AI": {"tldr": "MATA is a multi-agent hierarchical trainable automaton for visual reasoning that uses a trainable hyper agent to coordinate specialized agents, achieving state-of-the-art results while improving interpretability.", "motivation": "Vision-language models have strong perceptual abilities but suffer from hallucinations and lack interpretability on complex queries. Existing compositional methods are limited by single-agent approaches or rigid hand-crafted pipelines that cannot dynamically decide when agents should collaborate or compete.", "method": "MATA uses a hierarchical finite-state automaton where a trainable hyper agent controls transitions between specialized agents. Each agent runs a small rule-based sub-automaton for reliable micro-control, and all agents share a common memory for transparent execution history. The system is trained using the MATA-SFT-90K dataset created from transition-trajectory trees.", "result": "MATA achieves state-of-the-art results across multiple visual reasoning benchmarks compared to both monolithic and compositional baselines. The finetuned LLM as transition policy effectively understands queries and agent capabilities to choose optimal agents.", "conclusion": "MATA provides an interpretable, multi-agent approach to visual reasoning that dynamically coordinates specialized agents through a trainable hyper agent, addressing hallucinations and improving performance while maintaining transparency through shared memory."}}
{"id": "2601.19496", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19496", "abs": "https://arxiv.org/abs/2601.19496", "authors": ["Jie Gu", "Hongrun Gao", "Zhihao Xia", "Yirun Sun", "Chunxu Tian", "Dan Zhang"], "title": "Self-Reconfiguration Planning for Deformable Quadrilateral Modular Robots", "comment": null, "summary": "For lattice modular self-reconfigurable robots (MSRRs), maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability. This letter presents a novel self-reconfiguration planning algorithm for deformable quadrilateral MSRRs that guarantees stable connection. The method first constructs feasible connect/disconnect actions using a virtual graph representation, and then organizes these actions into a valid execution sequence through a Dependence-based Reverse Tree (DRTree) that resolves interdependencies. We also prove that reconfiguration sequences satisfying motion characteristics exist for any pair of configurations with seven or more modules (excluding linear topologies). Finally, comparisons with a modified BiRRT algorithm highlight the superior efficiency and stability of our approach, while deployment on a physical robotic platform confirms its practical feasibility.", "AI": {"tldr": "Novel self-reconfiguration planning algorithm for deformable quadrilateral modular robots that guarantees stable connections during reconfiguration.", "motivation": "For lattice modular self-reconfigurable robots, maintaining stable connections during reconfiguration is crucial for physical feasibility and deployability.", "method": "Constructs feasible connect/disconnect actions using virtual graph representation, then organizes actions into valid execution sequence through Dependence-based Reverse Tree (DRTree) to resolve interdependencies.", "result": "Proves reconfiguration sequences exist for any pair of configurations with seven or more modules (excluding linear topologies). Comparisons with modified BiRRT show superior efficiency and stability. Physical deployment confirms practical feasibility.", "conclusion": "The algorithm provides an efficient and stable solution for self-reconfiguration planning in deformable quadrilateral MSRRs with guaranteed connection stability."}}
{"id": "2601.19784", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19784", "abs": "https://arxiv.org/abs/2601.19784", "authors": ["Danilo Lelin Li", "Ramtin Rabiee", "Arman Farhang"], "title": "Channel Estimation using 5G Sounding Reference Signals: A Delay-Doppler Domain Approach", "comment": null, "summary": "Delay-Doppler multicarrier modulation (DDMC) techniques have been among the central topics of research for high-Doppler channels. However, a complete transition to DDMC-based waveforms is not yet practically feasible. This is because 5G NR based waveforms, orthogonal frequency division multiplexing (OFDM) and discrete Fourier transform-spread OFDM (DFT-s-OFDM), remain as the modulation schemes for the sixth-generation radio (6GR). Hence, in this paper, we demonstrate how we can still benefit from DD-domain processing in high-mobility scenarios using 5G NR sounding reference signals (SRSs). By considering a DFT-s-OFDM receiver, we transform each received OFDM symbol into the delay-Doppler (DD) domain, where the channel is then estimated. With this approach, we estimate the DD channel parameters, allowing us to predict the aged channel over OFDM symbols without pilots. To improve channel prediction, we propose a linear joint channel estimation and equalization technique, where we use the detected data in each OFDM symbol to sequentially update our channel estimates. Our simulation results show that the proposed technique significantly outperforms the conventional frequency-domain estimation technique in terms of bit error rate (BER) and normalized mean squared error (NMSE). Furthermore, we show that using only two slots with SRS for initial channel estimation, our method supports pilot-free detection for more than 25 subsequent OFDM symbols.", "AI": {"tldr": "The paper proposes using delay-Doppler domain processing with existing 5G NR waveforms to improve channel estimation and prediction in high-mobility scenarios, enabling pilot-free detection for many subsequent symbols.", "motivation": "While DDMC techniques are promising for high-Doppler channels, 5G NR waveforms (OFDM/DFT-s-OFDM) remain standard for 6G. The paper aims to leverage DD-domain processing benefits within existing 5G NR frameworks using SRS signals.", "method": "Transform received OFDM symbols to delay-Doppler domain for channel estimation, estimate DD channel parameters to predict aged channels, and propose linear joint channel estimation/equalization using detected data to sequentially update channel estimates.", "result": "The proposed technique significantly outperforms conventional frequency-domain estimation in BER and NMSE. Using only two SRS slots for initial estimation, it supports pilot-free detection for over 25 subsequent OFDM symbols.", "conclusion": "DD-domain processing can be effectively applied within existing 5G NR frameworks to improve high-mobility channel performance without requiring full transition to DDMC waveforms, enabling practical benefits in current systems."}}
{"id": "2601.19114", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19114", "abs": "https://arxiv.org/abs/2601.19114", "authors": ["Lin Chen", "Yue He", "Fengting Zhang", "Yaonan Wang", "Fengming Lin", "Xiang Chen", "Min Liu"], "title": "Reg-TTR, Test-Time Refinement for Fast, Robust and Accurate Image Registration", "comment": null, "summary": "Traditional image registration methods are robust but slow due to their iterative nature. While deep learning has accelerated inference, it often struggles with domain shifts. Emerging registration foundation models offer a balance of speed and robustness, yet typically cannot match the peak accuracy of specialized models trained on specific datasets. To mitigate this limitation, we propose Reg-TTR, a test-time refinement framework that synergizes the complementary strengths of both deep learning and conventional registration techniques. By refining the predictions of pre-trained models at inference, our method delivers significantly improved registration accuracy at a modest computational cost, requiring only 21% additional inference time (0.56s). We evaluate Reg-TTR on two distinct tasks and show that it achieves state-of-the-art (SOTA) performance while maintaining inference speeds close to previous deep learning methods. As foundation models continue to emerge, our framework offers an efficient strategy to narrow the performance gap between registration foundation models and SOTA methods trained on specialized datasets. The source code will be publicly available following the acceptance of this work.", "AI": {"tldr": "Reg-TTR is a test-time refinement framework that combines deep learning speed with traditional registration accuracy by refining pre-trained model predictions at inference, achieving SOTA performance with only 21% additional time.", "motivation": "Traditional registration methods are robust but slow, while deep learning is fast but struggles with domain shifts. Registration foundation models offer a balance but can't match specialized model accuracy on specific datasets.", "method": "Proposes Reg-TTR, a test-time refinement framework that synergizes deep learning and conventional techniques by refining pre-trained model predictions during inference to improve accuracy with minimal computational overhead.", "result": "Achieves state-of-the-art performance on two distinct tasks with only 21% additional inference time (0.56s), maintaining speeds close to previous deep learning methods while significantly improving accuracy.", "conclusion": "Reg-TTR offers an efficient strategy to narrow the performance gap between registration foundation models and specialized SOTA methods, providing a practical solution as foundation models continue to emerge."}}
{"id": "2601.18936", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18936", "abs": "https://arxiv.org/abs/2601.18936", "authors": ["Jialei Liu", "C. Emre Koksal", "Ming Shi"], "title": "Bi-Level Online Provisioning and Scheduling with Switching Costs and Cross-Level Constraints", "comment": null, "summary": "We study a bi-level online provisioning and scheduling problem motivated by network resource allocation, where provisioning decisions are made at a slow time scale while queue-/state-dependent scheduling is performed at a fast time scale. We model this two-time-scale interaction using an upper-level online convex optimization (OCO) problem and a lower-level constrained Markov decision process (CMDP). Existing OCO typically assumes stateless decisions and thus cannot capture MDP network dynamics such as queue evolution. Meanwhile, CMDP algorithms typically assume a fixed constraint threshold, whereas in provisioning-and-scheduling systems, the threshold varies with online budget decisions. To address these gaps, we study bi-level OCO-CMDP learning under switching costs (budget reprovisioning/system reconfiguration) and cross-level constraints that couple budgets to scheduling decisions. Our new algorithm solves this learning problem via several non-trivial developments, including a carefully designed dual feedback that returns the budget multiplier as sensitivity information for the upper-level update and a lower level that solves a budget-adaptive safe exploration problem via an extended occupancy-measure linear program. We establish near-optimal regret and high-probability satisfaction of the cross-level constraints.", "AI": {"tldr": "Bi-level online learning algorithm for network resource allocation with provisioning at slow time scale and queue-dependent scheduling at fast time scale, combining OCO with CMDP under switching costs and cross-level constraints.", "motivation": "Existing OCO methods don't capture MDP network dynamics like queue evolution, while CMDP algorithms assume fixed constraint thresholds, but in provisioning-scheduling systems the threshold varies with online budget decisions.", "method": "Bi-level OCO-CMDP learning algorithm with dual feedback (returns budget multiplier as sensitivity for upper-level update) and lower level solving budget-adaptive safe exploration via extended occupancy-measure linear program.", "result": "Establishes near-optimal regret and high-probability satisfaction of cross-level constraints that couple budgets to scheduling decisions.", "conclusion": "Novel bi-level learning framework successfully addresses gaps in existing methods for two-time-scale network resource allocation with switching costs and cross-level constraints."}}
{"id": "2601.19245", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19245", "abs": "https://arxiv.org/abs/2601.19245", "authors": ["Yongxin Deng", "Zhen Fang", "Yixuan Li", "Ling Chen"], "title": "Beyond In-Domain Detection: SpikeScore for Cross-Domain Hallucination Detection", "comment": null, "summary": "Hallucination detection is critical for deploying large language models (LLMs) in real-world applications. Existing hallucination detection methods achieve strong performance when the training and test data come from the same domain, but they suffer from poor cross-domain generalization. In this paper, we study an important yet overlooked problem, termed generalizable hallucination detection (GHD), which aims to train hallucination detectors on data from a single domain while ensuring robust performance across diverse related domains. In studying GHD, we simulate multi-turn dialogues following LLMs initial response and observe an interesting phenomenon: hallucination-initiated multi-turn dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. Based on the phenomenon, we propose a new score SpikeScore, which quantifies abrupt fluctuations in multi-turn dialogues. Through both theoretical analysis and empirical validation, we demonstrate that SpikeScore achieves strong cross-domain separability between hallucinated and non-hallucinated responses. Experiments across multiple LLMs and benchmarks demonstrate that the SpikeScore-based detection method outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods, verifying the effectiveness of our method in cross-domain hallucination detection.", "AI": {"tldr": "The paper introduces SpikeScore, a novel metric for generalizable hallucination detection in LLMs that quantifies uncertainty fluctuations in multi-turn dialogues to achieve robust cross-domain performance.", "motivation": "Current hallucination detection methods perform well within the same domain but fail to generalize across different domains, limiting their real-world applicability. The authors identify the need for generalizable hallucination detection (GHD) that works robustly across diverse related domains.", "method": "The authors propose SpikeScore, which quantifies abrupt uncertainty fluctuations in multi-turn dialogues. They discovered that hallucination-initiated dialogues universally exhibit larger uncertainty fluctuations than factual ones across different domains. SpikeScore measures these fluctuations to distinguish hallucinated from non-hallucinated responses.", "result": "Experiments across multiple LLMs and benchmarks show that SpikeScore-based detection outperforms representative baselines in cross-domain generalization and surpasses advanced generalization-oriented methods. Both theoretical analysis and empirical validation demonstrate strong cross-domain separability between hallucinated and non-hallucinated responses.", "conclusion": "SpikeScore provides an effective solution for generalizable hallucination detection by leveraging the universal property of uncertainty fluctuations in multi-turn dialogues, enabling robust cross-domain performance that addresses a critical limitation of existing methods."}}
{"id": "2601.19499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19499", "abs": "https://arxiv.org/abs/2601.19499", "authors": ["Mehdi Heydari Shahna", "Seyed Adel Alizadeh Kolagar", "Jouni Mattila"], "title": "Reinforcement Learning Goal-Reaching Control with Guaranteed Lyapunov-Like Stabilizer for Mobile Robots", "comment": null, "summary": "Reinforcement learning (RL) can be highly effective at learning goal-reaching policies, but it typically does not provide formal guarantees that the goal will always be reached. A common approach to provide formal goal-reaching guarantees is to introduce a shielding mechanism that restricts the agent to actions that satisfy predefined safety constraints. The main challenge here is integrating this mechanism with RL so that learning and exploration remain effective without becoming overly conservative. Hence, this paper proposes an RL-based control framework that provides formal goal-reaching guarantees for wheeled mobile robots operating in unstructured environments. We first design a real-time RL policy with a set of 15 carefully defined reward terms. These rewards encourage the robot to reach both static and dynamic goals while generating sufficiently smooth command signals that comply with predefined safety specifications, which is critical in practice. Second, a Lyapunov-like stabilizer layer is integrated into the benchmark RL framework as a policy supervisor to formally strengthen the goal-reaching control while preserving meaningful exploration of the state action space. The proposed framework is suitable for real-time deployment in challenging environments, as it provides a formal guarantee of convergence to the intended goal states and compensates for uncertainties by generating real-time control signals based on the current state, while respecting real-world motion constraints. The experimental results show that the proposed Lyapunov-like stabilizer consistently improves the benchmark RL policies, boosting the goal-reaching rate from 84.6% to 99.0%, sharply reducing failures, and improving efficiency.", "AI": {"tldr": "RL framework with Lyapunov-like stabilizer for wheeled mobile robots provides formal goal-reaching guarantees while maintaining effective exploration.", "motivation": "Standard RL lacks formal guarantees for goal-reaching, while traditional shielding methods can be overly conservative and hinder exploration. Need a framework that provides formal guarantees without sacrificing learning effectiveness for wheeled mobile robots in unstructured environments.", "method": "1) Design RL policy with 15 carefully defined reward terms for smooth, safe control; 2) Integrate Lyapunov-like stabilizer as policy supervisor to strengthen goal-reaching guarantees while preserving exploration.", "result": "The framework boosts goal-reaching rate from 84.6% to 99.0%, sharply reduces failures, improves efficiency, and provides formal convergence guarantees while respecting real-world motion constraints.", "conclusion": "The proposed RL-based control framework with Lyapunov-like stabilizer successfully provides formal goal-reaching guarantees for wheeled mobile robots while maintaining effective exploration and real-time performance in challenging environments."}}
{"id": "2601.19853", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19853", "abs": "https://arxiv.org/abs/2601.19853", "authors": ["Huy Trinh"], "title": "Generative Latent Alignment for Interpretable Radar Based Occupancy Detection in Ambient Assisted Living", "comment": null, "summary": "In this work, we study how to make mmWave radar presence detection more interpretable for Ambient Assisted Living (AAL) settings, where camera-based sensing raises privacy concerns. We propose a Generative Latent Alignment (GLA) framework that combines a lightweight convolutional variational autoencoder with a frozen CLIP text encoder to learn a low-dimensional latent representation of radar Range-Angle (RA) heatmaps. The latent space is softly aligned with two semantic anchors corresponding to \"empty room\" and \"person present\", and Grad-CAM is applied in this aligned latent space to visualize which spatial regions support each presence decision. On our mmWave radar dataset, we qualitatively observe that the \"person present\" class produces compact Grad-CAM blobs that coincide with strong RA returns, whereas \"empty room\" samples yield diffuse or no evidence. We also conduct an ablation study using unrelated text prompts, which degrades both reconstruction and localization, suggesting that radar-specific anchors are important for meaningful explanations in this setting.", "AI": {"tldr": "Proposes GLA framework combining VAE with CLIP to make mmWave radar presence detection interpretable for privacy-sensitive AAL settings, using semantic text anchors and Grad-CAM visualization.", "motivation": "Address privacy concerns in Ambient Assisted Living by making mmWave radar presence detection more interpretable, as camera-based sensing raises privacy issues but radar provides privacy-preserving alternative.", "method": "Generative Latent Alignment (GLA) framework: lightweight convolutional VAE + frozen CLIP text encoder learns low-dimensional latent representation of radar Range-Angle heatmaps; latent space aligned with semantic anchors (\"empty room\", \"person present\"); Grad-CAM applied in aligned latent space to visualize spatial evidence.", "result": "Qualitative observations: \"person present\" class produces compact Grad-CAM blobs coinciding with strong RA returns; \"empty room\" yields diffuse/no evidence. Ablation study shows unrelated text prompts degrade both reconstruction and localization, indicating radar-specific anchors are important.", "conclusion": "GLA framework successfully makes mmWave radar presence detection interpretable for AAL settings, with semantic text anchors enabling meaningful explanations through Grad-CAM visualization in aligned latent space."}}
{"id": "2601.19115", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19115", "abs": "https://arxiv.org/abs/2601.19115", "authors": ["Xiang Gao", "Yunpeng Jia"], "title": "FBSDiff++: Improved Frequency Band Substitution of Diffusion Features for Efficient and Highly Controllable Text-Driven Image-to-Image Translation", "comment": null, "summary": "With large-scale text-to-image (T2I) diffusion models achieving significant advancements in open-domain image creation, increasing attention has been focused on their natural extension to the realm of text-driven image-to-image (I2I) translation, where a source image acts as visual guidance to the generated image in addition to the textual guidance provided by the text prompt. We propose FBSDiff, a novel framework adapting off-the-shelf T2I diffusion model into the I2I paradigm from a fresh frequency-domain perspective. Through dynamic frequency band substitution of diffusion features, FBSDiff realizes versatile and highly controllable text-driven I2I in a plug-and-play manner (without need for model training, fine-tuning, or online optimization), allowing appearance-guided, layout-guided, and contour-guided I2I translation by progressively substituting low-frequency band, mid-frequency band, and high-frequency band of latent diffusion features, respectively. In addition, FBSDiff flexibly enables continuous control over I2I correlation intensity simply by tuning the bandwidth of the substituted frequency band. To further promote image translation efficiency, flexibility, and functionality, we propose FBSDiff++ which improves upon FBSDiff mainly in three aspects: (1) accelerate inference speed by a large margin (8.9$\\times$ speedup in inference) with refined model architecture; (2) improve the Frequency Band Substitution module to allow for input source images of arbitrary resolution and aspect ratio; (3) extend model functionality to enable localized image manipulation and style-specific content creation with only subtle adjustments to the core method. Extensive qualitative and quantitative experiments verify superiority of FBSDiff++ in I2I translation visual quality, efficiency, versatility, and controllability compared to related advanced approaches.", "AI": {"tldr": "FBSDiff/FBSDiff++: A plug-and-play framework adapting T2I diffusion models for I2I translation via frequency band substitution, enabling appearance/layout/contour-guided manipulation without training.", "motivation": "Existing text-to-image diffusion models lack effective image-to-image translation capabilities. Current approaches require training/fine-tuning, limiting flexibility and control over different aspects of image translation (appearance, layout, contour).", "method": "Adapts off-the-shelf T2I diffusion models using dynamic frequency band substitution of diffusion features. Low/mid/high-frequency band substitution enables appearance/layout/contour-guided translation respectively. FBSDiff++ adds architectural improvements for speed, arbitrary resolution support, and localized manipulation capabilities.", "result": "Achieves versatile I2I translation without training/fine-tuning. FBSDiff++ provides 8.9\u00d7 speedup, supports arbitrary resolutions, enables localized manipulation, and outperforms advanced approaches in visual quality, efficiency, versatility, and controllability.", "conclusion": "Frequency-domain perspective offers effective plug-and-play solution for text-driven I2I translation. The framework enables fine-grained control over different image aspects while maintaining high quality and efficiency."}}
{"id": "2601.18938", "categories": ["cs.LG", "cs.SI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18938", "abs": "https://arxiv.org/abs/2601.18938", "authors": ["Xin Qiao", "Shijie Sun", "Anqi Dong", "Cong Hua", "Xia Zhao", "Longfei Zhang", "Guangming Zhu", "Liang Zhang"], "title": "FSD-CAP: Fractional Subgraph Diffusion with Class-Aware Propagation for Graph Feature Imputation", "comment": "31 pages, 12 figures", "summary": "Imputing missing node features in graphs is challenging, particularly under high missing rates. Existing methods based on latent representations or global diffusion often fail to produce reliable estimates, and may propagate errors across the graph. We propose FSD-CAP, a two-stage framework designed to improve imputation quality under extreme sparsity. In the first stage, a graph-distance-guided subgraph expansion localizes the diffusion process. A fractional diffusion operator adjusts propagation sharpness based on local structure. In the second stage, imputed features are refined using class-aware propagation, which incorporates pseudo-labels and neighborhood entropy to promote consistency. We evaluated FSD-CAP on multiple datasets. With $99.5\\%$ of features missing across five benchmark datasets, FSD-CAP achieves average accuracies of $80.06\\%$ (structural) and $81.01\\%$ (uniform) in node classification, close to the $81.31\\%$ achieved by a standard GCN with full features. For link prediction under the same setting, it reaches AUC scores of $91.65\\%$ (structural) and $92.41\\%$ (uniform), compared to $95.06\\%$ for the fully observed case. Furthermore, FSD-CAP demonstrates superior performance on both large-scale and heterophily datasets when compared to other models.", "AI": {"tldr": "FSD-CAP is a two-stage graph feature imputation method that handles extreme missing rates (up to 99.5%) using localized diffusion and class-aware refinement.", "motivation": "Existing graph feature imputation methods struggle with high missing rates, often producing unreliable estimates and propagating errors across the graph structure.", "method": "Two-stage framework: 1) Graph-distance-guided subgraph expansion with fractional diffusion operator for localized propagation, 2) Class-aware propagation refinement using pseudo-labels and neighborhood entropy for consistency.", "result": "With 99.5% missing features, achieves 80.06% (structural) and 81.01% (uniform) node classification accuracy (close to 81.31% with full features), and 91.65%-92.41% AUC for link prediction (vs 95.06% full features). Outperforms other models on large-scale and heterophily datasets.", "conclusion": "FSD-CAP effectively handles extreme feature sparsity in graphs through localized diffusion and class-aware refinement, achieving performance close to fully observed cases and demonstrating robustness across diverse graph types."}}
{"id": "2601.19249", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19249", "abs": "https://arxiv.org/abs/2601.19249", "authors": ["Xingkun Yin", "Hongyang Du"], "title": "GLOVE: Global Verifier for LLM Memory-Environment Realignment", "comment": null, "summary": "Most existing memory-enhanced Large Language Model (LLM) approaches implicitly assume that memory validity can be established either through external evaluators that provide task-specific success signals or through internal model cognition, such as reflection, for editing memory entries. However, these assumptions often break down in practical environments with dynamic drifts. We propose the Global Verifier (GLOVE), a framework that introduces a new design dimension for LLM memory systems by establishing a relative notion of truth. Through active probing to detect inconsistencies between retrieved memories and fresh observations, GLOVE enables memory-environment realignment by verifying and updating memory without access to ground-truth supervision or strong reliance on model introspection. We evaluate GLOVE on diverse benchmarks spanning web navigation, planning, and control, augmented with controlled environmental drifts that introduce non-stationarity beyond the original benchmark settings. Our results show that GLOVE substantially improves agent success rates, suggesting a robust pathway to cognitive agents capable of self-evolving.", "AI": {"tldr": "GLOVE framework introduces relative truth verification for LLM memory systems, enabling memory-environment realignment through inconsistency detection without ground-truth supervision.", "motivation": "Existing LLM memory approaches rely on external evaluators or internal model cognition, which fail in dynamic environments with drifts. Need a more robust memory verification method.", "method": "Proposes Global Verifier (GLOVE) framework that establishes relative notion of truth through active probing to detect inconsistencies between retrieved memories and fresh observations, enabling memory verification and updating without ground-truth supervision.", "result": "GLOVE substantially improves agent success rates on diverse benchmarks (web navigation, planning, control) with controlled environmental drifts, showing robustness in non-stationary settings.", "conclusion": "GLOVE provides a robust pathway to cognitive agents capable of self-evolving by enabling memory-environment realignment through relative truth verification without external supervision."}}
{"id": "2601.19509", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19509", "abs": "https://arxiv.org/abs/2601.19509", "authors": ["Jin Huang", "Zichen Liu", "Haoda Li", "Zhikun Wang", "Ying Chen"], "title": "A DVL Aided Loosely Coupled Inertial Navigation Strategy for AUVs with Attitude Error Modeling and Variance Propagation", "comment": null, "summary": "In underwater navigation systems, strap-down inertial navigation system/Doppler velocity log (SINS/DVL)-based loosely coupled architectures are widely adopted. Conventional approaches project DVL velocities from the body coordinate system to the navigation coordinate system using SINS-derived attitude; however, accumulated attitude estimation errors introduce biases into velocity projection and degrade navigation performance during long-term operation. To address this issue, two complementary improvements are introduced. First, a vehicle attitude error-aware DVL velocity transformation model is formulated by incorporating attitude error terms into the observation equation to reduce projection-induced velocity bias. Second, a covariance matrix-based variance propagation method is developed to transform DVL measurement uncertainty across coordinate systems, introducing an expectation-based attitude error compensation term to achieve statistically consistent noise modeling. Simulation and field experiment results demonstrate that both improvements individually enhance navigation accuracy and confirm that accumulated attitude errors affect both projected velocity measurements and their associated uncertainty. When jointly applied, long-term error divergence is effectively suppressed. Field experimental results show that the proposed approach achieves a 78.3% improvement in 3D position RMSE and a 71.8% reduction in the maximum component-wise position error compared with the baseline IMU+DVL method, providing a robust solution for improving long-term SINS/DVL navigation performance.", "AI": {"tldr": "The paper proposes improvements to SINS/DVL underwater navigation by addressing attitude error-induced velocity projection biases and inconsistent noise modeling, achieving significant accuracy improvements over baseline methods.", "motivation": "Conventional SINS/DVL systems suffer from accumulated attitude estimation errors that introduce biases into DVL velocity projection from body to navigation coordinates, degrading long-term navigation performance.", "method": "Two complementary improvements: 1) Vehicle attitude error-aware DVL velocity transformation model incorporating attitude error terms into observation equation; 2) Covariance matrix-based variance propagation method with expectation-based attitude error compensation for statistically consistent noise modeling.", "result": "Simulation and field experiments show both improvements individually enhance navigation accuracy. When jointly applied, long-term error divergence is effectively suppressed with 78.3% improvement in 3D position RMSE and 71.8% reduction in maximum component-wise position error compared to baseline IMU+DVL method.", "conclusion": "The proposed approach provides a robust solution for improving long-term SINS/DVL navigation performance by addressing both projection-induced velocity bias and inconsistent noise modeling due to accumulated attitude errors."}}
{"id": "2601.19127", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19127", "abs": "https://arxiv.org/abs/2601.19127", "authors": ["Zhilong Zhang", "Lei Zhang", "Qing He", "Shuyin Xia", "Guoyin Wang", "Fuxiang Huang"], "title": "Implicit Non-Causal Factors are Out via Dataset Splitting for Domain Generalization Object Detection", "comment": "To appear in IJCV", "summary": "Open world object detection faces a significant challenge in domain-invariant representation, i.e., implicit non-causal factors. Most domain generalization (DG) methods based on domain adversarial learning (DAL) pay much attention to learn domain-invariant information, but often overlook the potential non-causal factors. We unveil two critical causes: 1) The domain discriminator-based DAL method is subject to the extremely sparse domain label, i.e., assigning only one domain label to each dataset, thus can only associate explicit non-causal factor, which is incredibly limited. 2) The non-causal factors, induced by unidentified data bias, are excessively implicit and cannot be solely discerned by conventional DAL paradigm. Based on these key findings, inspired by the Granular-Ball perspective, we propose an improved DAL method, i.e., GB-DAL. The proposed GB-DAL utilizes Prototype-based Granular Ball Splitting (PGBS) module to generate more dense domains from limited datasets, akin to more fine-grained granular balls, indicating more potential non-causal factors. Inspired by adversarial perturbations akin to non-causal factors, we propose a Simulated Non-causal Factors (SNF) module as a means of data augmentation to reduce the implicitness of non-causal factors, and facilitate the training of GB-DAL. Comparative experiments on numerous benchmarks demonstrate that our method achieves better generalization performance in novel circumstances.", "AI": {"tldr": "GB-DAL improves domain generalization for open-world object detection by addressing implicit non-causal factors through granular-ball splitting and simulated non-causal factor augmentation.", "motivation": "Existing domain adversarial learning methods for domain generalization focus on domain-invariant information but overlook implicit non-causal factors caused by data bias. Two key issues: 1) sparse domain labels limit identification of explicit non-causal factors, and 2) conventional DAL cannot handle excessively implicit non-causal factors.", "method": "Proposes GB-DAL with two modules: 1) Prototype-based Granular Ball Splitting (PGBS) generates dense domains from limited datasets to reveal more potential non-causal factors, and 2) Simulated Non-causal Factors (SNF) module uses adversarial perturbations as data augmentation to reduce implicitness of non-causal factors and improve training.", "result": "Comparative experiments on multiple benchmarks show the method achieves better generalization performance in novel circumstances compared to existing approaches.", "conclusion": "GB-DAL effectively addresses implicit non-causal factors in domain generalization for open-world object detection through granular-ball perspective and simulated non-causal factor augmentation, leading to improved generalization to new domains."}}
{"id": "2601.18939", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.18939", "abs": "https://arxiv.org/abs/2601.18939", "authors": ["Claire O'Brien", "Jessica Seto", "Dristi Roy", "Aditya Dwivedi", "Sunishchal Dev", "Kevin Zhu", "Sean O'Brien", "Ashwinee Panda", "Ryan Lagasse"], "title": "A Few Bad Neurons: Isolating and Surgically Correcting Sycophancy", "comment": "Accepted to NeurIPS Workshop on CogInterp and NeurIPS Workshop on Reliable ML 2025", "summary": "Behavioral alignment in large language models (LLMs) is often achieved through broad fine-tuning, which can result in undesired side effects like distributional shift and low interpretability. We propose a method for alignment that identifies and updates only the neurons most responsible for a given behavior, a targeted approach that allows for fine-tuning with significantly less data. Using sparse autoencoders (SAEs) and linear probes, we isolate the 3% of MLP neurons most predictive of a target behavior, decode them into residual space, and fine-tune only those neurons using gradient masking. We demonstrate this approach on the task of reducing sycophantic behavior, where our method matches or exceeds state-of-the-art performance on four benchmarks (Syco-Bench, NLP, POLI, PHIL) using Gemma-2-2B and 9B models. Our results show that sparse, neuron-level updates offer a scalable and precise alternative to full-model fine-tuning, remaining effective even in situations when little data is available", "AI": {"tldr": "Targeted neuron-level alignment method using sparse autoencoders and linear probes to update only 3% of MLP neurons responsible for specific behaviors, achieving state-of-the-art sycophancy reduction with less data.", "motivation": "Broad fine-tuning for LLM alignment causes distributional shift and low interpretability; need more precise, data-efficient methods that target specific behaviors without affecting the entire model.", "method": "Use sparse autoencoders (SAEs) and linear probes to identify 3% of MLP neurons most predictive of target behavior, decode them into residual space, and fine-tune only those neurons using gradient masking.", "result": "Matches or exceeds SOTA performance on four sycophancy benchmarks (Syco-Bench, NLP, POLI, PHIL) using Gemma-2-2B and 9B models, showing effectiveness even with limited data.", "conclusion": "Sparse, neuron-level updates provide scalable, precise alternative to full-model fine-tuning, enabling targeted behavior alignment with minimal data and better interpretability."}}
{"id": "2601.19306", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19306", "abs": "https://arxiv.org/abs/2601.19306", "authors": ["Sijia Li", "Xiaoyu Tan", "Shahir Ali", "Niels Schmidt", "Gengchen Ma", "Xihe Qiu"], "title": "Curiosity Driven Knowledge Retrieval for Mobile Agents", "comment": null, "summary": "Mobile agents have made progress toward reliable smartphone automation, yet performance in complex applications remains limited by incomplete knowledge and weak generalization to unseen environments. We introduce a curiosity driven knowledge retrieval framework that formalizes uncertainty during execution as a curiosity score. When this score exceeds a threshold, the system retrieves external information from documentation, code repositories, and historical trajectories. Retrieved content is organized into structured AppCards, which encode functional semantics, parameter conventions, interface mappings, and interaction patterns. During execution, an enhanced agent selectively integrates relevant AppCards into its reasoning process, thereby compensating for knowledge blind spots and improving planning reliability. Evaluation on the AndroidWorld benchmark shows consistent improvements across backbones, with an average gain of six percentage points and a new state of the art success rate of 88.8\\% when combined with GPT-5. Analysis indicates that AppCards are particularly effective for multi step and cross application tasks, while improvements depend on the backbone model. Case studies further confirm that AppCards reduce ambiguity, shorten exploration, and support stable execution trajectories. Task trajectories are publicly available at https://lisalsj.github.io/Droidrun-appcard/.", "AI": {"tldr": "A curiosity-driven knowledge retrieval framework for mobile agents that uses AppCards to encode structured app information, improving performance on complex smartphone automation tasks.", "motivation": "Mobile agents struggle with complex smartphone automation due to incomplete knowledge and poor generalization to unseen environments, limiting their reliability in real-world applications.", "method": "Introduces a curiosity-driven framework that formalizes execution uncertainty as a curiosity score. When thresholds are exceeded, the system retrieves external information from documentation, code repositories, and historical trajectories, organizing it into structured AppCards that encode functional semantics, parameter conventions, interface mappings, and interaction patterns. An enhanced agent selectively integrates relevant AppCards during reasoning.", "result": "Evaluation on AndroidWorld benchmark shows consistent improvements across backbones with average 6 percentage point gain and new SOTA success rate of 88.8% with GPT-5. AppCards are particularly effective for multi-step and cross-application tasks, reducing ambiguity, shortening exploration, and supporting stable execution trajectories.", "conclusion": "The curiosity-driven knowledge retrieval framework with structured AppCards significantly improves mobile agent performance by compensating for knowledge blind spots and enhancing planning reliability, especially for complex automation tasks."}}
{"id": "2601.19510", "categories": ["cs.RO", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19510", "abs": "https://arxiv.org/abs/2601.19510", "authors": ["Vitor Gaboardi dos Santos", "Ibrahim Khadraoui", "Ibrahim Farhat", "Hamza Yous", "Samy Teffahi", "Hakim Hacid"], "title": "ALRM: Agentic LLM for Robotic Manipulation", "comment": null, "summary": "Large Language Models (LLMs) have recently empowered agentic frameworks to exhibit advanced reasoning and planning capabilities. However, their integration in robotic control pipelines remains limited in two aspects: (1) prior \\ac{llm}-based approaches often lack modular, agentic execution mechanisms, limiting their ability to plan, reflect on outcomes, and revise actions in a closed-loop manner; and (2) existing benchmarks for manipulation tasks focus on low-level control and do not systematically evaluate multistep reasoning and linguistic variation. In this paper, we propose Agentic LLM for Robot Manipulation (ALRM), an LLM-driven agentic framework for robotic manipulation. ALRM integrates policy generation with agentic execution through a ReAct-style reasoning loop, supporting two complementary modes: Code-asPolicy (CaP) for direct executable control code generation, and Tool-as-Policy (TaP) for iterative planning and tool-based action execution. To enable systematic evaluation, we also introduce a novel simulation benchmark comprising 56 tasks across multiple environments, capturing linguistically diverse instructions. Experiments with ten LLMs demonstrate that ALRM provides a scalable, interpretable, and modular approach for bridging natural language reasoning with reliable robotic execution. Results reveal Claude-4.1-Opus as the top closed-source model and Falcon-H1-7B as the top open-source model under CaP.", "AI": {"tldr": "ALRM is an LLM-driven agentic framework for robotic manipulation that integrates policy generation with agentic execution through ReAct-style reasoning, supporting Code-asPolicy and Tool-as-Policy modes, with a new benchmark for systematic evaluation.", "motivation": "Current LLM-based robotic approaches lack modular agentic execution mechanisms for closed-loop planning and reflection, and existing benchmarks don't adequately evaluate multistep reasoning and linguistic variation in manipulation tasks.", "method": "ALRM integrates policy generation with agentic execution through a ReAct-style reasoning loop, supporting two complementary modes: Code-asPolicy (CaP) for direct executable control code generation, and Tool-as-Policy (TaP) for iterative planning and tool-based action execution.", "result": "Experiments with ten LLMs show ALRM provides scalable, interpretable, and modular approach for bridging natural language reasoning with robotic execution. Claude-4.1-Opus is top closed-source model and Falcon-H1-7B is top open-source model under CaP mode.", "conclusion": "ALRM successfully addresses limitations in current LLM-based robotic frameworks by providing an agentic execution mechanism with systematic evaluation capabilities, demonstrating effective integration of natural language reasoning with reliable robotic control."}}
{"id": "2601.19007", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.19007", "abs": "https://arxiv.org/abs/2601.19007", "authors": ["Emily C. Ehrhardt", "Felipe Tobar"], "title": "Accelerated training of Gaussian processes using banded square exponential covariances", "comment": "Accepted at IEEE ICASSP 2026", "summary": "We propose a novel approach to computationally efficient GP training based on the observation that square-exponential (SE) covariance matrices contain several off-diagonal entries extremely close to zero. We construct a principled procedure to eliminate those entries to produce a \\emph{banded}-matrix approximation to the original covariance, whose inverse and determinant can be computed at a reduced computational cost, thus contributing to an efficient approximation to the likelihood function. We provide a theoretical analysis of the proposed method to preserve the structure of the original covariance in the 1D setting with SE kernel, and validate its computational efficiency against the variational free energy approach to sparse GPs.", "AI": {"tldr": "A banded-matrix approximation method for efficient Gaussian Process training by removing near-zero off-diagonal entries in SE covariance matrices.", "motivation": "To achieve computational efficiency in GP training by exploiting the observation that square-exponential covariance matrices contain many off-diagonal entries extremely close to zero, enabling approximation without significant loss of accuracy.", "method": "Construct a principled procedure to eliminate near-zero off-diagonal entries to produce a banded-matrix approximation to the original covariance matrix, allowing reduced computational cost for inverse and determinant calculations.", "result": "Provides theoretical analysis showing the method preserves covariance structure in 1D setting with SE kernel, and demonstrates computational efficiency compared to variational free energy approach for sparse GPs.", "conclusion": "The banded-matrix approximation offers an efficient alternative to traditional GP training methods by leveraging the sparse structure of SE covariance matrices while maintaining accuracy."}}
{"id": "2601.19128", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19128", "abs": "https://arxiv.org/abs/2601.19128", "authors": ["Chao Yin", "Qing Han", "Zhiwei Hou", "Yue Liu", "Anjin Dai", "Hongda Hu", "Ji Yang", "Wei Yao"], "title": "Resolving Primitive-Sharing Ambiguity in Long-Tailed Industrial Point Cloud Segmentation via Spatial Context Constraints", "comment": null, "summary": "Industrial point cloud segmentation for Digital Twin construction faces a persistent challenge: safety-critical components such as reducers and valves are systematically misclassified. These failures stem from two compounding factors: such components are rare in training data, yet they share identical local geometry with dominant structures like pipes. This work identifies a dual crisis unique to industrial 3D data extreme class imbalance 215:1 ratio compounded by geometric ambiguity where most tail classes share cylindrical primitives with head classes. Existing frequency-based re-weighting methods address statistical imbalance but cannot resolve geometric ambiguity. We propose spatial context constraints that leverage neighborhood prediction consistency to disambiguate locally similar structures. Our approach extends the Class-Balanced (CB) Loss framework with two architecture-agnostic mechanisms: (1) Boundary-CB, an entropy-based constraint that emphasizes ambiguous boundaries, and (2) Density-CB, a density-based constraint that compensates for scan-dependent variations. Both integrate as plug-and-play modules without network modifications, requiring only loss function replacement. On the Industrial3D dataset (610M points from water treatment facilities), our method achieves 55.74% mIoU with 21.7% relative improvement on tail-class performance (29.59% vs. 24.32% baseline) while preserving head-class accuracy (88.14%). Components with primitive-sharing ambiguity show dramatic gains: reducer improves from 0% to 21.12% IoU; valve improves by 24.3% relative. This resolves geometric ambiguity without the typical head-tail trade-off, enabling reliable identification of safety-critical components for automated knowledge extraction in Digital Twin applications.", "AI": {"tldr": "Proposes spatial context constraints to address both class imbalance and geometric ambiguity in industrial point cloud segmentation, achieving significant improvements in tail-class performance without sacrificing head-class accuracy.", "motivation": "Industrial point cloud segmentation for Digital Twins faces persistent misclassification of safety-critical components (reducers, valves) due to extreme class imbalance (215:1 ratio) compounded by geometric ambiguity where tail classes share identical local geometry (cylindrical primitives) with dominant structures like pipes.", "method": "Extends Class-Balanced (CB) Loss framework with two architecture-agnostic spatial context constraints: (1) Boundary-CB (entropy-based constraint emphasizing ambiguous boundaries) and (2) Density-CB (density-based constraint compensating for scan-dependent variations). Both integrate as plug-and-play modules requiring only loss function replacement.", "result": "On Industrial3D dataset (610M points from water treatment facilities): 55.74% mIoU with 21.7% relative improvement on tail-class performance (29.59% vs. 24.32% baseline) while preserving head-class accuracy (88.14%). Components with primitive-sharing ambiguity show dramatic gains: reducer improves from 0% to 21.12% IoU; valve improves by 24.3% relative.", "conclusion": "Resolves geometric ambiguity without typical head-tail trade-off, enabling reliable identification of safety-critical components for automated knowledge extraction in Digital Twin applications. The spatial context constraints effectively address both statistical imbalance and geometric ambiguity in industrial 3D data."}}
{"id": "2601.18952", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.18952", "abs": "https://arxiv.org/abs/2601.18952", "authors": ["Mehrdad Mohammadi", "Qi Zheng", "Ruoqing Zhu"], "title": "Vector-Valued Distributional Reinforcement Learning Policy Evaluation: A Hilbert Space Embedding Approach", "comment": null, "summary": "We propose an (offline) multi-dimensional distributional reinforcement learning framework (KE-DRL) that leverages Hilbert space mappings to estimate the kernel mean embedding of the multi-dimensional value distribution under a proposed target policy. In our setting, the state-action variables are multi-dimensional and continuous. By mapping probability measures into a reproducing kernel Hilbert space via kernel mean embeddings, our method replaces Wasserstein metrics with an integral probability metric. This enables efficient estimation in multi-dimensional state-action spaces and reward settings, where direct computation of Wasserstein distances is computationally challenging. Theoretically, we establish contraction properties of the distributional Bellman operator under our proposed metric involving the Matern family of kernels and provide uniform convergence guarantees. Simulations and empirical results demonstrate robust off-policy evaluation and recovery of the kernel mean embedding under mild assumptions, namely, Lipschitz continuity and boundedness of the kernels, highlighting the potential of embedding-based approaches in complex real-world decision-making scenarios and risk evaluation.", "AI": {"tldr": "KE-DRL: Offline multi-dimensional distributional RL using kernel mean embeddings to estimate value distributions, replacing Wasserstein metrics with integral probability metrics for computational efficiency in continuous spaces.", "motivation": "Direct computation of Wasserstein distances in multi-dimensional continuous state-action spaces is computationally challenging. Need efficient methods for distributional RL in complex real-world scenarios with multi-dimensional variables.", "method": "Leverages Hilbert space mappings and kernel mean embeddings to estimate multi-dimensional value distributions. Uses reproducing kernel Hilbert spaces to replace Wasserstein metrics with integral probability metrics. Employs Matern family kernels and establishes theoretical guarantees for the distributional Bellman operator.", "result": "Theoretical contraction properties and uniform convergence guarantees established. Simulations demonstrate robust off-policy evaluation and recovery of kernel mean embeddings under mild assumptions (Lipschitz continuity and boundedness of kernels).", "conclusion": "Kernel mean embedding approaches show potential for complex real-world decision-making and risk evaluation by enabling efficient distributional RL in multi-dimensional continuous spaces where Wasserstein metrics are computationally prohibitive."}}
{"id": "2601.19311", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19311", "abs": "https://arxiv.org/abs/2601.19311", "authors": ["Anh Khoa Ngo Ho", "Martin Chauvin", "Simon Gosset", "Philippe Cordier", "Boris Gamazaychikov"], "title": "Balancing Sustainability And Performance: The Role Of Small-Scale Llms In Agentic Artificial Intelligence Systems", "comment": null, "summary": "As large language models become integral to agentic artificial intelligence systems, their energy demands during inference may pose significant sustainability challenges. This study investigates whether deploying smaller-scale language models can reduce energy consumption without compromising responsiveness and output quality in a multi-agent, real-world environments. We conduct a comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance. Results show that smaller open-weights models can lower energy usage while preserving task quality. Building on these findings, we propose practical guidelines for sustainable artificial intelligence design, including optimal batch size configuration and computation resource allocation. These insights offer actionable strategies for developing scalable, environmentally responsible artificial intelligence systems.", "AI": {"tldr": "Smaller open-weight language models can reduce energy consumption in multi-agent AI systems while maintaining task performance, offering sustainable AI design strategies.", "motivation": "As LLMs become integral to agentic AI systems, their energy demands during inference pose sustainability challenges. The study investigates whether smaller-scale models can reduce energy consumption without compromising performance in real-world multi-agent environments.", "method": "Conducted comparative analysis across language models of varying scales to quantify trade-offs between efficiency and performance in multi-agent, real-world environments.", "result": "Smaller open-weights models can lower energy usage while preserving task quality. The study also identified practical optimization strategies including optimal batch size configuration and computation resource allocation.", "conclusion": "The findings provide actionable strategies for developing scalable, environmentally responsible AI systems through sustainable design guidelines that balance energy efficiency with performance requirements."}}
{"id": "2601.19514", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19514", "abs": "https://arxiv.org/abs/2601.19514", "authors": ["Ruiyu Wang", "Zheyu Zhuang", "Danica Kragic", "Florian T. Pokorny"], "title": "PALM: Enhanced Generalizability for Local Visuomotor Policies via Perception Alignment", "comment": null, "summary": "Generalizing beyond the training domain in image-based behavior cloning remains challenging. Existing methods address individual axes of generalization, workspace shifts, viewpoint changes, and cross-embodiment transfer, yet they are typically developed in isolation and often rely on complex pipelines. We introduce PALM (Perception Alignment for Local Manipulation), which leverages the invariance of local action distributions between out-of-distribution (OOD) and demonstrated domains to address these OOD shifts concurrently, without additional input modalities, model changes, or data collection. PALM modularizes the manipulation policy into coarse global components and a local policy for fine-grained actions. We reduce the discrepancy between in-domain and OOD inputs at the local policy level by enforcing local visual focus and consistent proprioceptive representation, allowing the policy to retrieve invariant local actions under OOD conditions. Experiments show that PALM limits OOD performance drops to 8% in simulation and 24% in the real world, compared to 45% and 77% for baselines.", "AI": {"tldr": "PALM addresses generalization challenges in image-based behavior cloning by leveraging invariant local action distributions to handle workspace shifts, viewpoint changes, and cross-embodiment transfer without additional modalities or data.", "motivation": "Existing methods for generalization in image-based behavior cloning address individual axes (workspace shifts, viewpoint changes, cross-embodiment transfer) in isolation with complex pipelines, lacking a unified approach.", "method": "PALM modularizes manipulation policy into coarse global components and fine-grained local policy. It reduces discrepancy between in-domain and OOD inputs by enforcing local visual focus and consistent proprioceptive representation to retrieve invariant local actions.", "result": "PALM limits OOD performance drops to 8% in simulation and 24% in real world, compared to 45% and 77% for baseline methods.", "conclusion": "PALM effectively addresses multiple OOD shifts concurrently by leveraging invariant local action distributions, achieving significantly better generalization than existing approaches without requiring additional modalities or data collection."}}
{"id": "2601.19129", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19129", "abs": "https://arxiv.org/abs/2601.19129", "authors": ["Puzhen Wu", "Han Weng", "Quan Zheng", "Yi Zhan", "Hewei Wang", "Yiming Li", "Jiahui Han", "Rui Xu"], "title": "CLIP-Guided Unsupervised Semantic-Aware Exposure Correction", "comment": null, "summary": "Improper exposure often leads to severe loss of details, color distortion, and reduced contrast. Exposure correction still faces two critical challenges: (1) the ignorance of object-wise regional semantic information causes the color shift artifacts; (2) real-world exposure images generally have no ground-truth labels, and its labeling entails massive manual editing. To tackle the challenges, we propose a new unsupervised semantic-aware exposure correction network. It contains an adaptive semantic-aware fusion module, which effectively fuses the semantic information extracted from a pre-trained Fast Segment Anything Model into a shared image feature space. Then the fused features are used by our multi-scale residual spatial mamba group to restore the details and adjust the exposure. To avoid manual editing, we propose a pseudo-ground truth generator guided by CLIP, which is fine-tuned to automatically identify exposure situations and instruct the tailored corrections. Also, we leverage the rich priors from the FastSAM and CLIP to develop a semantic-prompt consistency loss to enforce semantic consistency and image-prompt alignment for unsupervised training. Comprehensive experimental results illustrate the effectiveness of our method in correcting real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.", "AI": {"tldr": "Unsupervised semantic-aware exposure correction network using FastSAM for semantic fusion and CLIP-guided pseudo-ground truth generation, outperforming SOTA methods.", "motivation": "Exposure correction faces two main challenges: (1) ignoring object-wise regional semantic information causes color shift artifacts, and (2) real-world exposure images lack ground-truth labels and manual labeling is labor-intensive.", "method": "Proposes an unsupervised semantic-aware exposure correction network with: (1) adaptive semantic-aware fusion module integrating FastSAM semantic information, (2) multi-scale residual spatial mamba group for detail restoration, (3) CLIP-guided pseudo-ground truth generator for automatic exposure identification and correction, and (4) semantic-prompt consistency loss leveraging FastSAM and CLIP priors.", "result": "Comprehensive experiments show the method effectively corrects real-world exposure images and outperforms state-of-the-art unsupervised methods both numerically and visually.", "conclusion": "The proposed unsupervised approach successfully addresses exposure correction challenges by leveraging semantic information from FastSAM and CLIP guidance, achieving superior performance without requiring manual ground-truth labeling."}}
{"id": "2601.18972", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.18972", "abs": "https://arxiv.org/abs/2601.18972", "authors": ["Utkarsh Pratiush", "Austin Houston", "Richard Liu", "Gerd Duscher", "Sergei Kalinin"], "title": "Towards Self-Optimizing Electron Microscope: Robust Tuning of Aberration Coefficients via Physics-Aware Multi-Objective Bayesian Optimization", "comment": null, "summary": "Realizing high-throughput aberration-corrected Scanning Transmission Electron Microscopy (STEM) exploration of atomic structures requires rapid tuning of multipole probe correctors while compensating for the inevitable drift of the optical column. While automated alignment routines exist, conventional approaches rely on serial, gradient-free searches (e.g., Nelder-Mead) that are sample-inefficient and struggle to correct multiple interacting parameters simultaneously. Conversely, emerging deep learning methods offer speed but often lack the flexibility to adapt to varying sample conditions without extensive retraining. Here, we introduce a Multi-Objective Bayesian Optimization (MOBO) framework for rapid, data-efficient aberration correction. Importantly, this framework does not prescribe a single notion of image quality; instead, it enables user-defined, physically motivated reward formulations (e.g., symmetry-induced objectives) and uses Pareto fronts to expose the resulting trade-offs between competing experimental priorities. By using Gaussian Process regression to model the aberration landscape probabilistically, our workflow actively selects the most informative lens settings to evaluate next, rather than performing an exhaustive blind search. We demonstrate that this active learning loop is more robust than traditional optimization algorithms and effectively tunes focus, astigmatism, and higher-order aberrations. By balancing competing objectives, this approach enables \"self-optimizing\" microscopy by dynamically sustaining optimal performance during experiments.", "AI": {"tldr": "MOBO framework for rapid, data-efficient aberration correction in STEM using Bayesian optimization with user-defined objectives and Pareto fronts.", "motivation": "Current automated alignment routines for STEM aberration correction use inefficient serial searches that struggle with multiple interacting parameters, while deep learning methods lack flexibility for varying conditions without extensive retraining.", "method": "Multi-Objective Bayesian Optimization (MOBO) framework using Gaussian Process regression to model aberration landscape probabilistically, with active learning to select informative lens settings and Pareto fronts to expose trade-offs between competing experimental priorities.", "result": "The framework demonstrates robust tuning of focus, astigmatism, and higher-order aberrations, outperforming traditional optimization algorithms and enabling dynamic \"self-optimizing\" microscopy.", "conclusion": "MOBO provides a flexible, data-efficient approach for aberration correction that balances competing objectives and sustains optimal performance during experiments without requiring extensive retraining."}}
{"id": "2601.19337", "categories": ["cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19337", "abs": "https://arxiv.org/abs/2601.19337", "authors": ["Sayak Chowdhury", "Meenakshi D'Souza"], "title": "SETA: Statistical Fault Attribution for Compound AI Systems", "comment": "Accepted to CAIN 2026 co-hosted with ICSE 2026", "summary": "Modern AI systems increasingly comprise multiple interconnected neural networks to tackle complex inference tasks. Testing such systems for robustness and safety entails significant challenges. Current state-of-the-art robustness testing techniques, whether black-box or white-box, have been proposed and implemented for single-network models and do not scale well to multi-network pipelines. We propose a modular robustness testing framework that applies a given set of perturbations to test data. Our testing framework supports (1) a component-wise system analysis to isolate errors and (2) reasoning about error propagation across the neural network modules. The testing framework is architecture and modality agnostic and can be applied across domains. We apply the framework to a real-world autonomous rail inspection system composed of multiple deep networks and successfully demonstrate how our approach enables fine-grained robustness analysis beyond conventional end-to-end metrics.", "AI": {"tldr": "A modular robustness testing framework for multi-network AI systems that enables component-wise analysis and error propagation reasoning across interconnected neural networks.", "motivation": "Modern AI systems increasingly use multiple interconnected neural networks for complex tasks, but existing robustness testing techniques designed for single networks don't scale well to multi-network pipelines, creating challenges for testing system robustness and safety.", "method": "Proposed a modular robustness testing framework that applies perturbations to test data, supports component-wise system analysis to isolate errors, and enables reasoning about error propagation across neural network modules. The framework is architecture and modality agnostic.", "result": "Successfully applied the framework to a real-world autonomous rail inspection system composed of multiple deep networks, demonstrating fine-grained robustness analysis beyond conventional end-to-end metrics.", "conclusion": "The modular testing framework enables effective robustness analysis of complex multi-network AI systems by providing component-level insights and understanding error propagation, addressing limitations of single-network testing approaches."}}
{"id": "2601.19529", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19529", "abs": "https://arxiv.org/abs/2601.19529", "authors": ["Jie Gu", "Yirui Sun", "Zhihao Xia", "Tin Lun Lam", "Chunxu Tian", "Dan Zhang"], "title": "Rhombot: Rhombus-shaped Modular Robots for Stable, Medium-Independent Reconfiguration Motion", "comment": null, "summary": "In this paper, we present Rhombot, a novel deformable planar lattice modular self-reconfigurable robot (MSRR) with a rhombus shaped module. Each module consists of a parallelogram skeleton with a single centrally mounted actuator that enables folding and unfolding along its diagonal. The core design philosophy is to achieve essential MSRR functionalities such as morphing, docking, and locomotion with minimal control complexity. This enables a continuous and stable reconfiguration process that is independent of the surrounding medium, allowing the system to reliably form various configurations in diverse environments. To leverage the unique kinematics of Rhombot, we introduce morphpivoting, a novel motion primitive for reconfiguration that differs from advanced MSRR systems, and propose a strategy for its continuous execution. Finally, a series of physical experiments validate the module's stable reconfiguration ability, as well as its positional and docking accuracy.", "AI": {"tldr": "Rhombot is a novel deformable planar lattice modular self-reconfigurable robot with rhombus-shaped modules that uses minimal control complexity for morphing, docking, and locomotion.", "motivation": "To create a modular self-reconfigurable robot system that achieves essential functionalities (morphing, docking, locomotion) with minimal control complexity, enabling stable reconfiguration independent of the surrounding medium for reliable operation in diverse environments.", "method": "Design of rhombus-shaped modules with parallelogram skeleton and single centrally mounted actuator for folding/unfolding along diagonal. Introduction of \"morphpivoting\" motion primitive for reconfiguration and strategy for its continuous execution.", "result": "Physical experiments validate the module's stable reconfiguration ability, positional accuracy, and docking accuracy, demonstrating reliable formation of various configurations in diverse environments.", "conclusion": "Rhombot successfully achieves essential MSRR functionalities with minimal control complexity through its novel deformable planar lattice design and morphpivoting motion primitive, enabling continuous and stable reconfiguration across diverse environments."}}
{"id": "2601.19133", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19133", "abs": "https://arxiv.org/abs/2601.19133", "authors": ["Yuxiang Wang", "Kunming Jiang", "Tianxiang Zhang", "Ke Tian", "Gaozhe Jiang"], "title": "QA-ReID: Quality-Aware Query-Adaptive Convolution Leveraging Fused Global and Structural Cues for Clothes-Changing ReID", "comment": null, "summary": "Unlike conventional person re-identification (ReID), clothes-changing ReID (CC-ReID) presents severe challenges due to substantial appearance variations introduced by clothing changes. In this work, we propose the Quality-Aware Dual-Branch Matching (QA-ReID), which jointly leverages RGB-based features and parsing-based representations to model both global appearance and clothing-invariant structural cues. These heterogeneous features are adaptively fused through a multi-modal attention module. At the matching stage, we further design the Quality-Aware Query Adaptive Convolution (QAConv-QA), which incorporates pixel-level importance weighting and bidirectional consistency constraints to enhance robustness against clothing variations. Extensive experiments demonstrate that QA-ReID achieves state-of-the-art performance on multiple benchmarks, including PRCC, LTCC, and VC-Clothes, and significantly outperforms existing approaches under cross-clothing scenarios.", "AI": {"tldr": "QA-ReID: A quality-aware dual-branch matching framework for clothes-changing person re-identification that combines RGB and parsing features with adaptive fusion and quality-aware matching.", "motivation": "Clothes-changing ReID presents severe challenges due to substantial appearance variations from clothing changes, requiring methods that can handle these variations while maintaining identity recognition.", "method": "Proposes Quality-Aware Dual-Branch Matching (QA-ReID) with: 1) RGB-based features and parsing-based representations for global appearance and clothing-invariant structural cues, 2) Multi-modal attention module for adaptive fusion, 3) Quality-Aware Query Adaptive Convolution (QAConv-QA) with pixel-level importance weighting and bidirectional consistency constraints.", "result": "Achieves state-of-the-art performance on multiple benchmarks (PRCC, LTCC, VC-Clothes) and significantly outperforms existing approaches under cross-clothing scenarios.", "conclusion": "QA-ReID effectively addresses clothes-changing ReID challenges through dual-branch feature extraction, adaptive fusion, and quality-aware matching, demonstrating superior performance in handling clothing variations."}}
{"id": "2601.18973", "categories": ["cs.LG", "cs.AI", "eess.SY", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.18973", "abs": "https://arxiv.org/abs/2601.18973", "authors": ["Nima Leclerc", "Chris Miller", "Nicholas Brawand"], "title": "When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control", "comment": "28 pages, 11 figures", "summary": "Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $>40\\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.", "AI": {"tldr": "Meta-learning scaling law shows adaptation benefits saturate exponentially with gradient steps and scale linearly with task variance, validated on quantum gate calibration and classical control.", "motivation": "Quantum hardware suffers from device heterogeneity and environmental drift, forcing a choice between suboptimal non-adaptive controllers or costly per-device recalibration. Need to understand when adaptation justifies its overhead.", "method": "Derived a scaling law lower bound for meta-learning showing adaptation gain saturates exponentially with gradient steps and scales linearly with task variance. Validated on quantum gate calibration and classical linear-quadratic control.", "result": "Validation shows negligible benefits for low-variance tasks but >40% fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10\u00d7 training noise). Classical control validation confirms laws emerge from general optimization geometry.", "conclusion": "Provides quantitative criterion for when adaptation justifies overhead. Offers transferable framework for decision-making in adaptive control with implications for reducing per-device calibration time on cloud quantum processors."}}
{"id": "2601.19402", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19402", "abs": "https://arxiv.org/abs/2601.19402", "authors": ["Amit Singh Bhatti", "Vishal Vaddina", "Dagnachew Birru"], "title": "PROTEUS: SLA-Aware Routing via Lagrangian RL for Multi-LLM Serving Systems", "comment": null, "summary": "Production LLM deployments serve diverse workloads where cost and quality requirements vary by customer tier, time of day, and query criticality. Model serving systems accept latency SLOs directly. LLM routers do not. They force operators to tune parameters offline and guess what accuracy might result. The relationship between parameters and outcomes is indirect, non-monotonic, and dataset-dependent. Operators need to specify accuracy targets, not infer them from opaque settings. We present PROTEUS (Polymorphic Router for Operational Target Enforcement with Unified SLA), a router that accepts accuracy targets tau as runtime input. PROTEUS uses Lagrangian dual control. A learned dual variable lambda tracks constraint violations during training and conditions the policy network. This lets the router translate specified tau values into routing decisions that satisfy them. A single trained model serves the full accuracy spectrum without retraining.We evaluate on RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries). PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau. The target-response correlation reaches 0.97 to 0.98. The closest baseline, OmniRouter, meets floors only 22% of the time despite also using Lagrangian optimization. PROTEUS operates across tau in [0.85, 0.95] from a single model. On RouterBench it achieves 90.1% accuracy, within 1.3% of oracle. On SPROUT it achieves 94.0% accuracy, within 4.6% of oracle. Cost savings reach 89.8% versus the best fixed model.", "AI": {"tldr": "PROTEUS is an LLM router that accepts accuracy targets as runtime input and uses Lagrangian dual control to translate specified accuracy requirements into routing decisions that satisfy them, achieving consistent floor compliance and high cost savings.", "motivation": "Current LLM routers force operators to tune parameters offline and guess accuracy outcomes, with indirect, non-monotonic relationships between parameters and results. Operators need to specify accuracy targets directly rather than inferring them from opaque settings.", "method": "PROTEUS uses Lagrangian dual control where a learned dual variable lambda tracks constraint violations during training and conditions the policy network. This allows the router to translate specified accuracy targets (tau) into routing decisions that satisfy them, with a single trained model serving the full accuracy spectrum without retraining.", "result": "On RouterBench (11 models, 405K queries) and SPROUT (14 models, 45K queries), PROTEUS achieves consistent floor compliance where accuracy meets or exceeds tau, with target-response correlation of 0.97-0.98. It meets accuracy floors 78% more often than the closest baseline (OmniRouter). It achieves 90.1% accuracy on RouterBench (within 1.3% of oracle) and 94.0% on SPROUT (within 4.6% of oracle), with cost savings reaching 89.8% versus the best fixed model.", "conclusion": "PROTEUS enables operators to directly specify accuracy targets as runtime input rather than tuning opaque parameters, providing consistent floor compliance across the accuracy spectrum from a single trained model while achieving near-oracle accuracy and significant cost savings."}}
{"id": "2601.19536", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19536", "abs": "https://arxiv.org/abs/2601.19536", "authors": ["Hongji Liu", "Linwei Zheng", "Yongjian Li", "Mingkai Tang", "Xiaoyang Yan", "Ming Liu", "Jun Ma"], "title": "Enhancing Inverse Perspective Mapping for Automatic Vectorized Road Map Generation", "comment": null, "summary": "In this study, we present a low-cost and unified framework for vectorized road mapping leveraging enhanced inverse perspective mapping (IPM). In this framework, Catmull-Rom splines are utilized to characterize lane lines, and all the other ground markings are depicted using polygons uniformly. The results from instance segmentation serve as references to refine the three-dimensional position of spline control points and polygon corner points. In conjunction with this process, the homography matrix of IPM and vehicle poses are optimized simultaneously. Our proposed framework significantly reduces the mapping errors associated with IPM. It also improves the accuracy of the initial IPM homography matrix and the predicted vehicle poses. Furthermore, it addresses the limitations imposed by the coplanarity assumption in IPM. These enhancements enable IPM to be effectively applied to vectorized road mapping, which serves a cost-effective solution with enhanced accuracy. In addition, our framework generalizes road map elements to include all common ground markings and lane lines. The proposed framework is evaluated in two different practical scenarios, and the test results show that our method can automatically generate high-precision maps with near-centimeter-level accuracy. Importantly, the optimized IPM matrix achieves an accuracy comparable to that of manual calibration, while the accuracy of vehicle poses is also significantly improved.", "AI": {"tldr": "A low-cost framework for vectorized road mapping using enhanced inverse perspective mapping (IPM) with Catmull-Rom splines for lane lines and polygons for ground markings, achieving near-centimeter-level accuracy.", "motivation": "To address mapping errors in IPM, limitations of coplanarity assumption, and provide a cost-effective solution for high-precision vectorized road mapping that includes all common ground markings and lane lines.", "method": "Enhanced IPM framework using Catmull-Rom splines for lane lines and polygons for ground markings, with instance segmentation results refining 3D positions of control points while simultaneously optimizing IPM homography matrix and vehicle poses.", "result": "Significantly reduces IPM mapping errors, improves IPM homography matrix accuracy (comparable to manual calibration), enhances vehicle pose accuracy, and achieves near-centimeter-level precision in two practical scenarios.", "conclusion": "The framework enables effective application of IPM to vectorized road mapping with enhanced accuracy, generalizes to all common road elements, and provides a cost-effective solution for automatic high-precision map generation."}}
{"id": "2601.19136", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19136", "abs": "https://arxiv.org/abs/2601.19136", "authors": ["Iftekhar Ahmed", "Shakib Absar", "Aftar Ahmad Sami", "Shadman Sakib", "Debojyoti Biswas", "Seraj Al Mahmud Mostafa"], "title": "TFFM: Topology-Aware Feature Fusion Module via Latent Graph Reasoning for Retinal Vessel Segmentation", "comment": "Accepted in WACV 2026 @ P2P-workshop as a full paper and selected for oral presentation", "summary": "Precise segmentation of retinal arteries and veins carries the diagnosis of systemic cardiovascular conditions. However, standard convolutional architectures often yield topologically disjointed segmentations, characterized by gaps and discontinuities that render reliable graph-based clinical analysis impossible despite high pixel-level accuracy. To address this, we introduce a topology-aware framework engineered to maintain vascular connectivity. Our architecture fuses a Topological Feature Fusion Module (TFFM) that maps local feature representations into a latent graph space, deploying Graph Attention Networks to capture global structural dependencies often missed by fixed receptive fields. Furthermore, we drive the learning process with a hybrid objective function, coupling Tversky loss for class imbalance with soft clDice loss to explicitly penalize topological disconnects. Evaluation on the Fundus-AVSeg dataset reveals state-of-the-art performance, achieving a combined Dice score of 90.97% and a 95% Hausdorff Distance of 3.50 pixels. Notably, our method decreases vessel fragmentation by approximately 38% relative to baselines, yielding topologically coherent vascular trees viable for automated biomarker quantification. We open-source our code at https://tffm-module.github.io/.", "AI": {"tldr": "A topology-aware framework for retinal vessel segmentation that maintains vascular connectivity using graph attention networks and hybrid loss functions, reducing fragmentation by 38%.", "motivation": "Standard convolutional architectures produce topologically disjointed segmentations with gaps and discontinuities, making reliable graph-based clinical analysis impossible despite high pixel-level accuracy.", "method": "Introduces a topology-aware framework with Topological Feature Fusion Module (TFFM) that maps local features to latent graph space using Graph Attention Networks, plus hybrid objective function combining Tversky loss for class imbalance and soft clDice loss to penalize topological disconnects.", "result": "Achieves state-of-the-art performance on Fundus-AVSeg dataset: 90.97% combined Dice score, 95% Hausdorff Distance of 3.50 pixels, and reduces vessel fragmentation by approximately 38% relative to baselines.", "conclusion": "The method produces topologically coherent vascular trees suitable for automated biomarker quantification, addressing the critical need for connected segmentations in clinical analysis of retinal vasculature."}}
{"id": "2601.18981", "categories": ["cs.LG", "cs.CR", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.18981", "abs": "https://arxiv.org/abs/2601.18981", "authors": ["Ruslan Abdulin", "Mohammad Rasoul Narimani"], "title": "Attention-Enhanced Graph Filtering for False Data Injection Attack Detection and Localization", "comment": null, "summary": "The increasing deployment of Internet-of-Things (IoT)-enabled measurement devices in modern power systems has expanded the cyberattack surface of the grid. As a result, this critical infrastructure is increasingly exposed to cyberattacks, including false data injection attacks (FDIAs) that compromise measurement integrity and threaten reliable system operation. Existing FDIA detection methods primarily exploit spatial correlations and network topology using graph-based learning; however, these approaches often rely on high-dimensional representations and shallow classifiers, limiting their ability to capture local structural dependencies and global contextual relationships. Moreover, naively incorporating Transformer architectures can result in overly deep models that struggle to model localized grid dynamics. This paper proposes a joint FDIA detection and localization framework that integrates auto-regressive moving average (ARMA) graph convolutional filters with an Encoder-Only Transformer architecture. The ARMA-based graph filters provide robust, topology-aware feature extraction and adaptability to abrupt spectral changes, while the Transformer encoder leverages self-attention to capture long-range dependencies among grid elements without sacrificing essential local context. The proposed method is evaluated using real-world load data from the New York Independent System Operator (NYISO) applied to the IEEE 14- and 300-bus systems. Numerical results demonstrate that the proposed model effectively exploits both the state and topology of the power grid, achieving high accuracy in detecting FDIA events and localizing compromised nodes.", "AI": {"tldr": "Proposes a joint false data injection attack detection and localization framework for power grids using ARMA graph convolutional filters with Transformer encoder architecture.", "motivation": "Increasing IoT deployment in power systems expands cyberattack surface, exposing critical infrastructure to false data injection attacks that compromise measurement integrity. Existing methods rely on high-dimensional representations and shallow classifiers that fail to capture both local structural dependencies and global contextual relationships.", "method": "Integrates auto-regressive moving average (ARMA) graph convolutional filters with an Encoder-Only Transformer architecture. ARMA filters provide topology-aware feature extraction adaptable to abrupt spectral changes, while Transformer encoder uses self-attention to capture long-range dependencies without sacrificing local context.", "result": "Evaluated using real-world NYISO load data on IEEE 14- and 300-bus systems. The model effectively exploits both state and topology of power grid, achieving high accuracy in detecting FDIA events and localizing compromised nodes.", "conclusion": "Proposed framework successfully addresses limitations of existing FDIA detection methods by combining ARMA graph filters for local structural awareness with Transformer encoders for global contextual relationships, providing robust detection and localization capabilities for power grid cybersecurity."}}
{"id": "2601.19404", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19404", "abs": "https://arxiv.org/abs/2601.19404", "authors": ["Hongzhu Yi", "Xinming Wang", "Zhenghao zhang", "Tianyu Zong", "Yuanxiang Wang", "Jun Xie", "Tao Yu", "Haopeng Jin", "Zhepeng Wang", "Kaixin Xu", "Feng Chen", "Jiahuan Chen", "Yujia Yang", "Zhenyu Guan", "Bingkang Shi", "Jungang Xu"], "title": "RPO:Reinforcement Fine-Tuning with Partial Reasoning Optimization", "comment": null, "summary": "Within the domain of large language models, reinforcement fine-tuning algorithms necessitate the generation of a complete reasoning trajectory beginning from the input query, which incurs significant computational overhead during the rollout phase of training. To address this issue, we analyze the impact of different segments of the reasoning path on the correctness of the final result and, based on these insights, propose Reinforcement Fine-Tuning with Partial Reasoning Optimization (RPO), a plug-and-play reinforcement fine-tuning algorithm. Unlike traditional reinforcement fine-tuning algorithms that generate full reasoning paths, RPO trains the model by generating suffixes of the reasoning path using experience cache. During the rollout phase of training, RPO reduces token generation in this phase by approximately 95%, greatly lowering the theoretical time overhead. Compared with full-path reinforcement fine-tuning algorithms, RPO reduces the training time of the 1.5B model by 90% and the 7B model by 72%. At the same time, it can be integrated with typical algorithms such as GRPO and DAPO, enabling them to achieve training acceleration while maintaining performance comparable to the original algorithms. Our code is open-sourced at https://github.com/yhz5613813/RPO.", "AI": {"tldr": "RPO is a reinforcement fine-tuning algorithm that reduces computational overhead by training on reasoning path suffixes instead of full paths, achieving 90% training time reduction for 1.5B models while maintaining performance.", "motivation": "Traditional reinforcement fine-tuning for LLMs requires generating complete reasoning trajectories from input queries, which incurs significant computational overhead during training rollout phases.", "method": "Analyzes impact of different reasoning path segments on final correctness, then proposes RPO which trains models using reasoning path suffixes from experience cache instead of full paths, reducing rollout token generation by ~95%.", "result": "RPO reduces training time by 90% for 1.5B models and 72% for 7B models compared to full-path methods, while maintaining comparable performance when integrated with algorithms like GRPO and DAPO.", "conclusion": "RPO provides an efficient plug-and-play reinforcement fine-tuning approach that dramatically reduces computational overhead while preserving model performance, with open-source implementation available."}}
{"id": "2601.19634", "categories": ["cs.RO", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.19634", "abs": "https://arxiv.org/abs/2601.19634", "authors": ["Wenda Yu", "Tianshi Wang", "Fengling Li", "Jingjing Li", "Lei Zhu"], "title": "AC^2-VLA: Action-Context-Aware Adaptive Computation in Vision-Language-Action Models for Efficient Robotic Manipulation", "comment": null, "summary": "Vision-Language-Action (VLA) models have demonstrated strong performance in robotic manipulation, yet their closed-loop deployment is hindered by the high latency and compute cost of repeatedly running large vision-language backbones at every timestep. We observe that VLA inference exhibits structured redundancies across temporal, spatial, and depth dimensions, and that most existing efficiency methods ignore action context, despite its central role in embodied tasks. To address this gap, we propose Action-Context-aware Adaptive Computation for VLA models (AC^2-VLA), a unified framework that conditions computation on current visual observations, language instructions, and previous action states. Based on this action-centric context, AC^2-VLA adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components within a unified mechanism. To train the adaptive policy, we introduce an action-guided self-distillation scheme that preserves the behavior of the dense VLA policy while enabling structured sparsification that transfers across tasks and settings. Extensive experiments on robotic manipulation benchmarks show that AC^2-VLA achieves up to a 1.79\\times speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success.", "AI": {"tldr": "AC\u00b2-VLA is an adaptive computation framework for Vision-Language-Action models that reduces latency and compute costs by conditioning computation on action context and performing structured sparsification across temporal, spatial, and depth dimensions.", "motivation": "Current VLA models suffer from high latency and compute costs due to repeatedly running large vision-language backbones at every timestep, and existing efficiency methods ignore the crucial action context in embodied tasks.", "method": "Proposes AC\u00b2-VLA framework that conditions computation on visual observations, language instructions, and previous action states, then adaptively performs cognition reuse across timesteps, token pruning, and selective execution of model components. Uses action-guided self-distillation to train the adaptive policy while preserving dense VLA behavior.", "result": "Achieves up to 1.79\u00d7 speedup while reducing FLOPs to 29.4% of the dense baseline, with comparable task success on robotic manipulation benchmarks.", "conclusion": "AC\u00b2-VLA effectively addresses the efficiency bottleneck in VLA models by leveraging action context for adaptive computation, enabling faster and more efficient robotic manipulation while maintaining performance."}}
{"id": "2601.19157", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19157", "abs": "https://arxiv.org/abs/2601.19157", "authors": ["Yongsong Huang", "Tzu-Hsuan Peng", "Tomo Miyazaki", "Xiaofeng Liu", "Chun-Ting Chou", "Ai-Chun Pang", "Shinichiro Omachi"], "title": "GTFMN: Guided Texture and Feature Modulation Network for Low-Light Image Enhancement and Super-Resolution", "comment": "\\c{opyright} 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works", "summary": "Low-light image super-resolution (LLSR) is a challenging task due to the coupled degradation of low resolution and poor illumination. To address this, we propose the Guided Texture and Feature Modulation Network (GTFMN), a novel framework that decouples the LLSR task into two sub-problems: illumination estimation and texture restoration. First, our network employs a dedicated Illumination Stream whose purpose is to predict a spatially varying illumination map that accurately captures lighting distribution. Further, this map is utilized as an explicit guide within our novel Illumination Guided Modulation Block (IGM Block) to dynamically modulate features in the Texture Stream. This mechanism achieves spatially adaptive restoration, enabling the network to intensify enhancement in poorly lit regions while preserving details in well-exposed areas. Extensive experiments demonstrate that GTFMN achieves the best performance among competing methods on the OmniNormal5 and OmniNormal15 datasets, outperforming them in both quantitative metrics and visual quality.", "AI": {"tldr": "GTFMN is a novel framework for low-light image super-resolution that decouples the problem into illumination estimation and texture restoration using guided modulation.", "motivation": "Low-light image super-resolution is challenging due to the coupled degradation of low resolution and poor illumination. Existing methods struggle with this joint problem, requiring a solution that can handle both issues simultaneously while being spatially adaptive.", "method": "Proposes Guided Texture and Feature Modulation Network (GTFMN) with two streams: 1) Illumination Stream predicts spatially varying illumination maps, and 2) Texture Stream uses Illumination Guided Modulation Blocks (IGM Blocks) that dynamically modulate features based on the illumination map for spatially adaptive restoration.", "result": "GTFMN achieves state-of-the-art performance on OmniNormal5 and OmniNormal15 datasets, outperforming competing methods in both quantitative metrics and visual quality.", "conclusion": "The decoupled approach with explicit illumination guidance enables effective low-light super-resolution by allowing spatially adaptive enhancement in poorly lit regions while preserving details in well-exposed areas."}}
{"id": "2601.18984", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.18984", "abs": "https://arxiv.org/abs/2601.18984", "authors": ["Haolin Liu", "Dian Yu", "Sidi Lu", "Yujun Zhou", "Rui Liu", "Zhenwen Liang", "Haitao Mi", "Chen-Yu Wei", "Dong Yu"], "title": "Save the Good Prefix: Precise Error Penalization via Process-Supervised RL to Enhance LLM Reasoning", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a powerful framework for improving the reasoning capabilities of large language models (LLMs). However, most existing RL approaches rely on sparse outcome rewards, which fail to credit correct intermediate steps in partially successful solutions. Process reward models (PRMs) offer fine-grained step-level supervision, but their scores are often noisy and difficult to evaluate. As a result, recent PRM benchmarks focus on a more objective capability: detecting the first incorrect step in a reasoning path. However, this evaluation target is misaligned with how PRMs are typically used in RL, where their step-wise scores are treated as raw rewards to maximize. To bridge this gap, we propose Verifiable Prefix Policy Optimization (VPPO), which uses PRMs only to localize the first error during RL. Given an incorrect rollout, VPPO partitions the trajectory into a verified correct prefix and an erroneous suffix based on the first error, rewarding the former while applying targeted penalties only after the detected mistake. This design yields stable, interpretable learning signals and improves credit assignment. Across multiple reasoning benchmarks, VPPO consistently outperforms sparse-reward RL and prior PRM-guided baselines on both Pass@1 and Pass@K.", "AI": {"tldr": "VPPO improves RL for LLM reasoning by using PRMs only to detect the first error in reasoning paths, then rewarding correct prefixes and penalizing only after mistakes, leading to better credit assignment and performance.", "motivation": "Existing RL approaches for LLMs use sparse outcome rewards that fail to credit correct intermediate steps. Process reward models (PRMs) offer step-level supervision but their scores are noisy, and current PRM benchmarks focus on detecting first incorrect steps, which is misaligned with how PRMs are actually used in RL.", "method": "Proposes Verifiable Prefix Policy Optimization (VPPO) that uses PRMs only to localize the first error during RL. For incorrect rollouts, it partitions trajectories into verified correct prefixes and erroneous suffixes based on the first error, rewarding the former while applying targeted penalties only after the detected mistake.", "result": "VPPO consistently outperforms sparse-reward RL and prior PRM-guided baselines across multiple reasoning benchmarks on both Pass@1 and Pass@K metrics.", "conclusion": "VPPO bridges the gap between PRM evaluation and RL usage by focusing on error localization rather than noisy step-wise scores, yielding stable, interpretable learning signals and improved credit assignment for LLM reasoning."}}
{"id": "2601.19527", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19527", "abs": "https://arxiv.org/abs/2601.19527", "authors": ["Temirbolat Maratuly", "Pakizar Shamoi", "Timur Samigulin"], "title": "Fuzzy expert system for the process of collecting and purifying acidic water: a digital twin approach", "comment": null, "summary": "Purifying sour water is essential for reducing emissions, minimizing corrosion risks, enabling the reuse of treated water in industrial or domestic applications, and ultimately lowering operational costs. Moreover, automating the purification process helps reduce the risk of worker harm by limiting human involvement. Crude oil contains acidic components such as hydrogen sulfide, carbon dioxide, and other chemical compounds. During processing, these substances are partially released into sour water. If not properly treated, sour water poses serious environmental threats and accelerates the corrosion of pipelines and equipment. This paper presents a fuzzy expert system, combined with a custom-generated digital twin, developed from a documented industrial process to maintain key parameters at desired levels by mimicking human reasoning. The control strategy is designed to be simple and intuitive, allowing junior or non-expert personnel to interact with the system effectively. The digital twin was developed using Honeywell UniSim Design R492 to simulate real industrial behavior accurately. Valve dynamics were modeled through system identification in MATLAB, and real-time data exchange between the simulator and controller was established using OPC DA. The fuzzy controller applies split-range control to two valves and was tested under 21 different initial pressure conditions using five distinct defuzzification strategies, resulting in a total of 105 unique test scenarios. System performance was evaluated using both error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics, including overshoot, undershoot, rise time, fall time, settling time, and steady-state error. A web-based simulation interface was developed in Python using the Streamlit framework. Although demonstrated here for sour water treatment, the proposed fuzzy expert system is general-purpose.", "AI": {"tldr": "A fuzzy expert system with digital twin for automated sour water purification control, tested under 105 scenarios with comprehensive performance metrics.", "motivation": "Sour water purification is essential for reducing emissions, minimizing corrosion risks, enabling water reuse, lowering costs, and reducing worker harm through automation. Untreated sour water poses environmental threats and accelerates equipment corrosion.", "method": "Developed a fuzzy expert system combined with a digital twin using Honeywell UniSim Design R492 for simulation. Valve dynamics modeled via MATLAB system identification, with real-time OPC DA data exchange. Fuzzy controller uses split-range control on two valves, tested under 21 initial pressure conditions with 5 defuzzification strategies (105 total scenarios). Performance evaluated using error-based metrics (MSE, RMSE, MAE, IAE, ISE, ITAE) and dynamic response metrics (overshoot, undershoot, rise/fall/settling times, steady-state error). Web interface built with Python/Streamlit.", "result": "The system was successfully tested under comprehensive scenarios with performance evaluated using multiple metrics. The control strategy proved simple and intuitive for junior/non-expert personnel. Although demonstrated for sour water treatment, the fuzzy expert system is general-purpose.", "conclusion": "The fuzzy expert system with digital twin effectively automates sour water purification, maintaining key parameters at desired levels while reducing human involvement. The approach is generalizable beyond sour water treatment applications."}}
{"id": "2601.19643", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19643", "abs": "https://arxiv.org/abs/2601.19643", "authors": ["Zoe Betta", "Davide Corongiu", "Carmine Tommaso Recchiuto", "Antonio Sgorbissa"], "title": "Enhancing Worker Safety in Harbors Using Quadruped Robots", "comment": null, "summary": "Infrastructure inspection is becoming increasingly relevant in the field of robotics due to its significant impact on ensuring workers' safety. The harbor environment presents various challenges in designing a robotic solution for inspection, given the complexity of daily operations. This work introduces an initial phase to identify critical areas within the port environment. Following this, a preliminary solution using a quadruped robot for inspecting these critical areas is analyzed.", "AI": {"tldr": "This paper presents a robotic inspection system for harbor infrastructure using a quadruped robot to identify and inspect critical areas, addressing safety concerns in complex port environments.", "motivation": "Infrastructure inspection is crucial for worker safety in hazardous environments like harbors. Port operations present complex challenges that make traditional inspection methods risky, necessitating robotic solutions to improve safety and efficiency.", "method": "The approach involves two phases: first identifying critical areas within the port environment, then deploying a quadruped robot to inspect these identified critical areas. The quadruped platform is chosen for its mobility in complex terrain.", "result": "The paper presents an initial phase for critical area identification and a preliminary analysis of using a quadruped robot for harbor infrastructure inspection, suggesting this as a viable solution for the identified challenges.", "conclusion": "Quadruped robots show promise for harbor infrastructure inspection by addressing safety concerns and navigating complex port environments, though this represents preliminary work that requires further development and validation."}}
{"id": "2601.19180", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19180", "abs": "https://arxiv.org/abs/2601.19180", "authors": ["Lifan Jiang", "Boxi Wu", "Yuhang Pei", "Tianrun Wu", "Yongyuan Chen", "Yan Zhao", "Shiyu Yu", "Deng Cai"], "title": "SNR-Edit: Structure-Aware Noise Rectification for Inversion-Free Flow-Based Editing", "comment": null, "summary": "Inversion-free image editing using flow-based generative models challenges the prevailing inversion-based pipelines. However, existing approaches rely on fixed Gaussian noise to construct the source trajectory, leading to biased trajectory dynamics and causing structural degradation or quality loss. To address this, we introduce SNR-Edit, a training-free framework achieving faithful Latent Trajectory Correction via adaptive noise control. Mechanistically, SNR-Edit uses structure-aware noise rectification to inject segmentation constraints into the initial noise, anchoring the stochastic component of the source trajectory to the real image's implicit inversion position and reducing trajectory drift during source--target transport. This lightweight modification yields smoother latent trajectories and ensures high-fidelity structural preservation without requiring model tuning or inversion. Across SD3 and FLUX, evaluations on PIE-Bench and SNR-Bench show that SNR-Edit delivers performance on pixel-level metrics and VLM-based scoring, while adding only about 1s overhead per image.", "AI": {"tldr": "SNR-Edit is a training-free framework for inversion-free image editing that corrects latent trajectory drift via adaptive noise control, improving structural preservation without model tuning.", "motivation": "Existing inversion-free image editing methods using flow-based generative models rely on fixed Gaussian noise for source trajectory construction, which leads to biased trajectory dynamics and causes structural degradation or quality loss in edited images.", "method": "SNR-Edit introduces a training-free framework with structure-aware noise rectification that injects segmentation constraints into the initial noise. This anchors the stochastic component of the source trajectory to the real image's implicit inversion position, reducing trajectory drift during source-target transport without requiring model tuning or inversion.", "result": "Evaluations on SD3 and FLUX models using PIE-Bench and SNR-Bench show SNR-Edit delivers strong performance on pixel-level metrics and VLM-based scoring while adding only about 1 second overhead per image. The method yields smoother latent trajectories and ensures high-fidelity structural preservation.", "conclusion": "SNR-Edit provides an effective solution to the trajectory drift problem in inversion-free image editing through adaptive noise control, achieving faithful editing with minimal computational overhead and no need for model retraining or inversion processes."}}
{"id": "2601.18999", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.18999", "abs": "https://arxiv.org/abs/2601.18999", "authors": ["Fangzhou Wu", "Sandeep Silwal", "Qiuyi", "Zhang"], "title": "Randomization Boosts KV Caching, Learning Balances Query Load: A Joint Perspective", "comment": "ICLR 2026", "summary": "KV caching is a fundamental technique for accelerating Large Language Model (LLM) inference by reusing key-value (KV) pairs from previous queries, but its effectiveness under limited memory is highly sensitive to the eviction policy. The default Least Recently Used (LRU) eviction algorithm struggles with dynamic online query arrivals, especially in multi-LLM serving scenarios, where balancing query load across workers and maximizing cache hit rate of each worker are inherently conflicting objectives. We give the first unified mathematical model that captures the core trade-offs between KV cache eviction and query routing. Our analysis reveals the theoretical limitations of existing methods and leads to principled algorithms that integrate provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns, thus balancing query load and cache hit rate. Our theoretical results are validated by extensive experiments across 4 benchmarks and 3 prefix-sharing settings, demonstrating improvements of up to 6.92$\\times$ in cache hit rate, 11.96$\\times$ reduction in latency, 14.06$\\times$ reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over the state-of-the-art methods. Our code is available at https://github.com/fzwark/KVRouting.", "AI": {"tldr": "KV caching for LLM inference faces memory limitations; existing LRU eviction struggles with dynamic queries. The paper presents a unified model for KV cache eviction and query routing, proposing competitive randomized eviction with learning-based routing to balance load and cache hit rate.", "motivation": "KV caching accelerates LLM inference but faces memory constraints. The default LRU eviction algorithm performs poorly with dynamic online queries, especially in multi-LLM serving where balancing query load and maximizing cache hit rate are conflicting objectives.", "method": "Developed a unified mathematical model capturing trade-offs between KV cache eviction and query routing. Proposed principled algorithms integrating provably competitive randomized KV cache eviction with learning-based methods to adaptively route queries with evolving patterns.", "result": "Extensive experiments across 4 benchmarks and 3 prefix-sharing settings show improvements: up to 6.92\u00d7 in cache hit rate, 11.96\u00d7 reduction in latency, 14.06\u00d7 reduction in time-to-first-token (TTFT), and 77.4% increase in throughput over state-of-the-art methods.", "conclusion": "The unified model reveals theoretical limitations of existing methods and enables effective algorithms that balance query load and cache hit rate through integrated randomized eviction and adaptive routing, significantly improving LLM serving performance under memory constraints."}}
{"id": "2601.19532", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19532", "abs": "https://arxiv.org/abs/2601.19532", "authors": ["Marthe Ballon", "Andres Algaba", "Brecht Verbeken", "Vincent Ginis"], "title": "Benchmarks Saturate When The Model Gets Smarter Than The Judge", "comment": "17 pages, 10 figures, 3 tables", "summary": "Benchmarks are important tools to track progress in the development of Large Language Models (LLMs), yet inaccuracies in datasets and evaluation methods consistently undermine their effectiveness. Here, we present Omni-MATH-2, a manually revised version of the Omni-MATH dataset comprising a clean, exact-answer subset ($n{=}4181$) and a tagged, non-standard subset ($n{=}247$). Each problem was audited to ensure LaTeX compilability, solvability and verifiability, which involved adding missing figures or information, labeling problems requiring a proof, estimation or image, and removing clutter. This process significantly reduces dataset-induced noise, thereby providing a more precise assessment of model performance. The annotated dataset also allows us to evaluate judge-induced noise by comparing GPT-5 mini with the original Omni-Judge, revealing substantial discrepancies between judges on both the clean and tagged problem subsets. Expert annotations reveal that Omni-Judge is wrong in $96.4\\%$ of the judge disagreements, indicating its inability to differentiate between models' abilities, even well before saturation of the benchmark occurs. As problems become more challenging, we find that increasingly competent judges become essential in order to prevent judge errors from masking genuine differences between models. Finally, neither judge identifies the present failure modes for the subset of tagged problems, demonstrating that dataset quality and judge reliability are both critical to develop accurate benchmarks of model performance.", "AI": {"tldr": "Omni-MATH-2 is a manually revised math benchmark dataset that reduces dataset noise and reveals significant judge-induced noise in LLM evaluation, showing that both dataset quality and judge reliability are critical for accurate benchmarking.", "motivation": "Current LLM benchmarks suffer from inaccuracies in datasets and evaluation methods that undermine their effectiveness in tracking model progress. There's a need for cleaner datasets and better understanding of evaluation noise.", "method": "Created Omni-MATH-2 by manually auditing the original Omni-MATH dataset: ensuring LaTeX compilability, solvability, and verifiability; adding missing figures/information; labeling problems requiring proofs/estimation/images; removing clutter. Then evaluated judge-induced noise by comparing GPT-5 mini with the original Omni-Judge on both clean and tagged problem subsets.", "result": "The clean dataset (n=4181) significantly reduces dataset-induced noise. Expert annotations show Omni-Judge is wrong in 96.4% of judge disagreements, indicating inability to differentiate model abilities. Neither judge identifies failure modes for tagged problems (n=247), showing both dataset quality and judge reliability are critical.", "conclusion": "Both dataset quality and judge reliability are essential for accurate LLM benchmarking. As problems become more challenging, increasingly competent judges are needed to prevent judge errors from masking genuine model differences. The Omni-MATH-2 dataset provides a cleaner benchmark for more precise assessment of model performance."}}
{"id": "2601.19742", "categories": ["cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.19742", "abs": "https://arxiv.org/abs/2601.19742", "authors": ["Ali Jnadi", "Hadi Salloum", "Yaroslav Kholodov", "Alexander Gasnikov", "Karam Almaghout"], "title": "SCOPE: Smooth Convex Optimization for Planned Evolution of Deformable Linear Objects", "comment": "Proceedings of Machine Learning Research tbd:1_13, 2025 International Conference on Computational Optimization", "summary": "We present SCOPE, a fast and efficient framework for modeling and manipulating deformable linear objects (DLOs). Unlike conventional energy-based approaches, SCOPE leverages convex approximations to significantly reduce computational cost while maintaining smooth and physically plausible deformations. This trade-off between speed and accuracy makes the method particularly suitable for applications requiring real-time or near-real-time response. The effectiveness of the proposed framework is demonstrated through comprehensive simulation experiments, highlighting its ability to generate smooth shape trajectories under geometric and length constraints.", "AI": {"tldr": "SCOPE is a fast framework for modeling deformable linear objects using convex approximations instead of energy-based methods, enabling real-time performance with physically plausible deformations.", "motivation": "Existing energy-based approaches for modeling deformable linear objects (DLOs) are computationally expensive, limiting their use in applications requiring real-time or near-real-time response.", "method": "SCOPE uses convex approximations to model DLO deformations, trading some accuracy for significantly reduced computational cost compared to conventional energy-based methods.", "result": "The framework demonstrates efficient performance in simulation experiments, generating smooth shape trajectories while satisfying geometric and length constraints.", "conclusion": "SCOPE provides a practical solution for real-time DLO manipulation by balancing speed and accuracy through convex approximations, making it suitable for applications requiring fast response times."}}
{"id": "2601.19210", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19210", "abs": "https://arxiv.org/abs/2601.19210", "authors": ["Sen Nie", "Jie Zhang", "Zhuo Wang", "Shiguang Shan", "Xilin Chen"], "title": "Contrastive Spectral Rectification: Test-Time Defense towards Zero-shot Adversarial Robustness of CLIP", "comment": "21 pages", "summary": "Vision-language models (VLMs) such as CLIP have demonstrated remarkable zero-shot generalization, yet remain highly vulnerable to adversarial examples (AEs). While test-time defenses are promising, existing methods fail to provide sufficient robustness against strong attacks and are often hampered by high inference latency and task-specific applicability. To address these limitations, we start by investigating the intrinsic properties of AEs, which reveals that AEs exhibit severe feature inconsistency under progressive frequency attenuation. We further attribute this to the model's inherent spectral bias. Leveraging this insight, we propose an efficient test-time defense named Contrastive Spectral Rectification (CSR). CSR optimizes a rectification perturbation to realign the input with the natural manifold under a spectral-guided contrastive objective, which is applied input-adaptively. Extensive experiments across 16 classification benchmarks demonstrate that CSR outperforms the SOTA by an average of 18.1% against strong AutoAttack with modest inference overhead. Furthermore, CSR exhibits broad applicability across diverse visual tasks. Code is available at https://github.com/Summu77/CSR.", "AI": {"tldr": "CSR is an efficient test-time defense that uses spectral-guided contrastive optimization to realign adversarial examples with natural data manifolds, achieving superior robustness with low inference overhead.", "motivation": "Current test-time defenses for vision-language models lack sufficient robustness against strong attacks, have high inference latency, and are task-specific. The authors discovered that adversarial examples show feature inconsistency under frequency attenuation due to model spectral bias.", "method": "Proposes Contrastive Spectral Rectification (CSR) which optimizes a rectification perturbation to realign inputs with natural manifold using spectral-guided contrastive objective, applied input-adaptively.", "result": "Outperforms state-of-the-art by average 18.1% against AutoAttack across 16 classification benchmarks with modest inference overhead, and shows broad applicability across diverse visual tasks.", "conclusion": "CSR effectively addresses limitations of existing test-time defenses by leveraging insights about adversarial examples' spectral properties, providing efficient and robust protection for vision-language models."}}
{"id": "2601.19568", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19568", "abs": "https://arxiv.org/abs/2601.19568", "authors": ["Ke Xu", "Siyang Xiao", "Ming Liang", "Yichen Yu", "Zhixiang Wang", "Jingxuan Xu", "Dajun Chen", "Wei Jiang", "Yong Li"], "title": "Learning Adaptive Parallel Execution for Efficient Code Localization", "comment": "13 pages, 4 figures", "summary": "Code localization constitutes a key bottleneck in automated software development pipelines. While concurrent tool execution can enhance discovery speed, current agents demonstrate a 34.9\\% redundant invocation rate, which negates parallelism benefits. We propose \\textbf{FuseSearch}, reformulating parallel code localization as a \\textbf{joint quality-efficiency optimization} task. Through defining \\textbf{tool efficiency} -- the ratio of unique information gain to invocation count -- we utilize a two-phase SFT and RL training approach for learning adaptive parallel strategies. Different from fixed-breadth approaches, FuseSearch dynamically modulates search breadth according to task context, evolving from exploration phases to refinement stages. Evaluated on SWE-bench Verified, FuseSearch-4B achieves SOTA-level performance (84.7\\% file-level and 56.4\\% function-level $F_1$ scores) with 93.6\\% speedup, utilizing 67.7\\% fewer turns and 68.9\\% fewer tokens. Results indicate that efficiency-aware training naturally improves quality through eliminating noisy redundant signals, enabling high-performance cost-effective localization agents.", "AI": {"tldr": "FuseSearch is a parallel code localization method that optimizes both quality and efficiency by dynamically adjusting search breadth, achieving state-of-the-art performance with significant speedup and reduced resource usage.", "motivation": "Current parallel code localization agents suffer from high redundant invocation rates (34.9%) that negate parallelism benefits, creating a bottleneck in automated software development pipelines.", "method": "Reformulates parallel code localization as joint quality-efficiency optimization, defines tool efficiency metric (unique information gain to invocation count ratio), uses two-phase SFT and RL training for adaptive parallel strategies, and dynamically modulates search breadth based on task context.", "result": "Achieves SOTA-level performance on SWE-bench Verified with 84.7% file-level and 56.4% function-level F1 scores, 93.6% speedup, 67.7% fewer turns, and 68.9% fewer tokens using the 4B parameter model.", "conclusion": "Efficiency-aware training naturally improves quality by eliminating noisy redundant signals, enabling high-performance cost-effective localization agents that balance discovery speed with resource efficiency."}}
{"id": "2601.19761", "categories": ["cs.RO", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.19761", "abs": "https://arxiv.org/abs/2601.19761", "authors": ["Jin Huang", "Fethiye Irmak Do\u011fan", "Hatice Gunes"], "title": "Reimagining Social Robots as Recommender Systems: Foundations, Framework, and Applications", "comment": "HRI 2026", "summary": "Personalization in social robots refers to the ability of the robot to meet the needs and/or preferences of an individual user. Existing approaches typically rely on large language models (LLMs) to generate context-aware responses based on user metadata and historical interactions or on adaptive methods such as reinforcement learning (RL) to learn from users' immediate reactions in real time. However, these approaches fall short of comprehensively capturing user preferences-including long-term, short-term, and fine-grained aspects-, and of using them to rank and select actions, proactively personalize interactions, and ensure ethically responsible adaptations. To address the limitations, we propose drawing on recommender systems (RSs), which specialize in modeling user preferences and providing personalized recommendations. To ensure the integration of RS techniques is well-grounded and seamless throughout the social robot pipeline, we (i) align the paradigms underlying social robots and RSs, (ii) identify key techniques that can enhance personalization in social robots, and (iii) design them as modular, plug-and-play components. This work not only establishes a framework for integrating RS techniques into social robots but also opens a pathway for deep collaboration between the RS and HRI communities, accelerating innovation in both fields.", "AI": {"tldr": "The paper proposes integrating recommender system techniques into social robots to improve personalization by better capturing user preferences and enabling proactive, ethically responsible adaptations.", "motivation": "Current approaches using LLMs and RL in social robots fail to comprehensively capture user preferences (long-term, short-term, fine-grained) and lack capabilities for ranking/selecting actions, proactive personalization, and ethical adaptation.", "method": "The authors propose integrating recommender system techniques by: (i) aligning paradigms between social robots and recommender systems, (ii) identifying key techniques that enhance personalization, and (iii) designing them as modular, plug-and-play components.", "result": "The work establishes a framework for integrating RS techniques into social robots and creates a pathway for collaboration between recommender systems and human-robot interaction communities.", "conclusion": "Recommender systems offer specialized techniques for modeling user preferences that can significantly enhance personalization in social robots, accelerating innovation in both fields through interdisciplinary collaboration."}}
{"id": "2601.19222", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19222", "abs": "https://arxiv.org/abs/2601.19222", "authors": ["Fuxiang Sun", "Xi Jiang", "Jiansheng Wu", "Haigang Zhang", "Feng Zheng", "Jinfeng Yang"], "title": "UniPCB: A Unified Vision-Language Benchmark for Open-Ended PCB Quality Inspection", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) show promise for general industrial quality inspection, but fall short in complex scenarios, such as Printed Circuit Board (PCB) inspection. PCB inspection poses unique challenges due to densely packed components, complex wiring structures, and subtle defect patterns that require specialized domain expertise. However, a high-quality, unified vision-language benchmark for quantitatively evaluating MLLMs across PCB inspection tasks remains absent, stemming not only from limited data availability but also from fragmented datasets and inconsistent standardization. To fill this gap, we propose UniPCB, the first unified vision-language benchmark for open-ended PCB quality inspection. UniPCB is built via a systematic pipeline that curates and standardizes data from disparate sources across three annotated scenarios. Furthermore, we introduce PCB-GPT, an MLLM trained on a new instruction dataset generated by this pipeline, utilizing a novel progressive curriculum that mimics the learning process of human experts. Evaluations on the UniPCB benchmark show that while existing MLLMs falter on domain-specific tasks, PCB-GPT establishes a new baseline. Notably, it more than doubles the performance on fine-grained defect localization compared to the strongest competitors, with significant advantages in localization and analysis. We will release the instruction data, benchmark, and model to facilitate future research.", "AI": {"tldr": "UniPCB is the first unified vision-language benchmark for PCB quality inspection, addressing MLLMs' limitations in complex industrial scenarios. PCB-GPT, a specialized MLLM trained with progressive curriculum learning, doubles performance on defect localization compared to existing models.", "motivation": "Current MLLMs underperform in complex industrial inspection like PCB quality control due to densely packed components, complex wiring, and subtle defects requiring domain expertise. There's no unified benchmark for evaluating MLLMs on PCB inspection tasks, with fragmented datasets and inconsistent standardization hindering progress.", "method": "1) Created UniPCB benchmark via systematic pipeline curating/standardizing data from disparate sources across three annotated scenarios. 2) Developed PCB-GPT MLLM trained on new instruction dataset generated by this pipeline. 3) Used novel progressive curriculum learning mimicking human expert learning process.", "result": "PCB-GPT establishes new baseline on UniPCB benchmark, more than doubling performance on fine-grained defect localization compared to strongest competitors. Shows significant advantages in localization and analysis tasks. Existing MLLMs falter on domain-specific PCB inspection tasks.", "conclusion": "UniPCB fills critical gap for evaluating MLLMs in industrial quality inspection. PCB-GPT demonstrates effectiveness of domain-specific training with progressive curriculum. The benchmark, instruction data, and model will be released to facilitate future research in specialized industrial applications of MLLMs."}}
{"id": "2601.19022", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19022", "abs": "https://arxiv.org/abs/2601.19022", "authors": ["Antanas Zilinskas", "Robert N. Shorten", "Jakub Marecek"], "title": "EVEREST: An Evidential, Tail-Aware Transformer for Rare-Event Time-Series Forecasting", "comment": null, "summary": "Forecasting rare events in multivariate time-series data is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. We introduce EVEREST, a transformer-based architecture for probabilistic rare-event forecasting that delivers calibrated predictions and tail-aware risk estimation, with auxiliary interpretability via attention-based signal attribution. EVEREST integrates four components: (i) a learnable attention bottleneck for soft aggregation of temporal dynamics; (ii) an evidential head for estimating aleatoric and epistemic uncertainty via a Normal--Inverse--Gamma distribution; (iii) an extreme-value head that models tail risk using a Generalized Pareto Distribution; and (iv) a lightweight precursor head for early-event detection. These modules are jointly optimized with a composite loss (focal loss, evidential NLL, and a tail-sensitive EVT penalty) and act only at training time; deployment uses a single classification head with no inference overhead (approximately 0.81M parameters). On a decade of space-weather data, EVEREST achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares. The model is compact, efficient to train on commodity hardware, and applicable to high-stakes domains such as industrial monitoring, weather, and satellite diagnostics. Limitations include reliance on fixed-length inputs and exclusion of image-based modalities, motivating future extensions to streaming and multimodal forecasting.", "AI": {"tldr": "EVEREST is a transformer-based model for probabilistic rare-event forecasting that handles class imbalance, uncertainty, and tail risk with interpretable attention, achieving state-of-the-art performance on space-weather flare prediction.", "motivation": "Forecasting rare events in multivariate time-series is challenging due to severe class imbalance, long-range dependencies, and distributional uncertainty. Existing methods struggle with these issues in high-stakes domains like space weather, industrial monitoring, and satellite diagnostics.", "method": "EVEREST integrates four components: (1) learnable attention bottleneck for soft temporal aggregation, (2) evidential head for aleatoric/epistemic uncertainty via Normal-Inverse-Gamma distribution, (3) extreme-value head for tail risk using Generalized Pareto Distribution, and (4) lightweight precursor head for early detection. Joint optimization with composite loss (focal loss, evidential NLL, tail-sensitive EVT penalty).", "result": "Achieves state-of-the-art True Skill Statistic (TSS) of 0.973/0.970/0.966 at 24/48/72-hour horizons for C-class flares on decade-long space-weather data. Model is compact (~0.81M parameters), efficient to train on commodity hardware, with no inference overhead.", "conclusion": "EVEREST provides calibrated probabilistic forecasting with uncertainty quantification and tail risk estimation for rare events. Limitations include fixed-length inputs and exclusion of image modalities, motivating future work on streaming and multimodal forecasting."}}
{"id": "2601.19607", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19607", "abs": "https://arxiv.org/abs/2601.19607", "authors": ["Haoyun Li", "Ming Xiao", "Kezhi Wang", "Robert Schober", "Dong In Kim", "Yong Liang Guan"], "title": "ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks", "comment": null, "summary": "Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.", "AI": {"tldr": "ComAgent is a multi-LLM agent framework that automates translating high-level intents into mathematical formulations for 6G network optimization, outperforming monolithic LLM approaches.", "motivation": "Manually translating high-level intents into mathematical formulations for 6G network optimization is a bottleneck. Monolithic LLM approaches lack sufficient domain grounding, constraint awareness, and verification capabilities needed for complex wireless network design.", "method": "ComAgent employs a multi-LLM agentic AI framework with a closed-loop Perception-Planning-Action-Reflection cycle. It coordinates specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations through iterative problem decomposition and self-correction.", "result": "ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, demonstrating its effectiveness in bridging the gap between user intent and execution.", "conclusion": "The ComAgent framework shows significant potential for automating design in emerging wireless networks by effectively addressing the limitations of both manual approaches and monolithic LLMs through its multi-agent, iterative refinement architecture."}}
{"id": "2601.19826", "categories": ["cs.RO", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19826", "abs": "https://arxiv.org/abs/2601.19826", "authors": ["Fan Yang", "Renkai Ma", "Yaxin Hu", "Lingyao Li"], "title": "Whether We Care, How We Reason: The Dual Role of Anthropomorphism and Moral Foundations in Robot Abuse", "comment": null, "summary": "As robots become increasingly integrated into daily life, understanding responses to robot mistreatment carries important ethical and design implications. This mixed-methods study (N = 201) examined how anthropomorphic levels and moral foundations shape reactions to robot abuse. Participants viewed videos depicting physical mistreatment of robots varying in humanness (Spider, Twofoot, Humanoid) and completed measures assessing moral foundations, anger, and social distance. Results revealed that anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis revealed distinct reasoning patterns: low-progressivism individuals employed character-based judgments, while high-progressivism individuals engaged in future-oriented moral deliberation. Findings offer implications for robot design and policy communication.", "AI": {"tldr": "People's reactions to robot mistreatment depend on robot anthropomorphism and individual moral foundations, with different reasoning patterns based on progressivism levels.", "motivation": "As robots become more integrated into daily life, understanding ethical responses to robot mistreatment has important implications for both robot design and policy development.", "method": "Mixed-methods study with 201 participants who viewed videos of physical mistreatment of robots with varying anthropomorphism levels (Spider, Twofoot, Humanoid), then completed measures of moral foundations, anger, and social distance.", "result": "Anthropomorphism determines whether people extend moral consideration to robots, while moral foundations shape how they reason about such consideration. Qualitative analysis showed low-progressivism individuals use character-based judgments, while high-progressivism individuals engage in future-oriented moral deliberation.", "conclusion": "Findings offer implications for robot design and policy communication, suggesting that both robot appearance and individual moral frameworks influence ethical responses to robot treatment."}}
{"id": "2601.19228", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19228", "abs": "https://arxiv.org/abs/2601.19228", "authors": ["Tianhui Song", "Haoyu Lu", "Hao Yang", "Lin Sui", "Haoning Wu", "Zaida Zhou", "Zhiqi Huang", "Yiping Bao", "Y. Charles", "Xinyu Zhou", "Limin Wang"], "title": "Towards Pixel-Level VLM Perception via Simple Points Prediction", "comment": null, "summary": "We present SimpleSeg, a strikingly simple yet highly effective approach to endow Multimodal Large Language Models (MLLMs) with native pixel-level perception. Our method reframes segmentation as a simple sequence generation problem: the model directly predicts sequences of points (textual coordinates) delineating object boundaries, entirely within its language space. To achieve high fidelity, we introduce a two-stage SF$\\to$RL training pipeline, where Reinforcement Learning with an IoU-based reward refines the point sequences to accurately match ground-truth contours. We find that the standard MLLM architecture possesses a strong, inherent capacity for low-level perception that can be unlocked without any specialized architecture. On segmentation benchmarks, SimpleSeg achieves performance that is comparable to, and often surpasses, methods relying on complex, task-specific designs. This work lays out that precise spatial understanding can emerge from simple point prediction, challenging the prevailing need for auxiliary components and paving the way for more unified and capable VLMs. Homepage: https://simpleseg.github.io/", "AI": {"tldr": "SimpleSeg enables MLLMs to perform segmentation by predicting sequences of boundary points as textual coordinates, using a two-stage training pipeline with RL refinement, achieving competitive performance without specialized architectures.", "motivation": "To demonstrate that MLLMs have inherent low-level perception capabilities for pixel-level tasks like segmentation, and that this can be achieved through simple point prediction without complex task-specific architectures or auxiliary components.", "method": "Reframes segmentation as sequence generation of boundary points (textual coordinates). Uses two-stage training: SF\u2192RL pipeline where Reinforcement Learning with IoU-based reward refines point sequences to match ground-truth contours accurately.", "result": "Achieves performance comparable to or surpassing methods with complex task-specific designs on segmentation benchmarks, showing MLLMs' strong inherent capacity for low-level perception.", "conclusion": "Precise spatial understanding can emerge from simple point prediction, challenging the need for auxiliary components and paving the way for more unified and capable Vision-Language Models."}}
{"id": "2601.19026", "categories": ["cs.LG", "cs.AR", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19026", "abs": "https://arxiv.org/abs/2601.19026", "authors": ["Andrea Fasoli", "Monodeep Kar", "Chi-Chun Liu", "Swagath Venkataramani", "Viji Srinivasan", "Leland Chang", "Naigang Wang"], "title": "Is Finer Better? The Limits of Microscaling Formats in Large Language Models", "comment": "31 pages, 17 figures, 3 tables; accepted to ICLR 2026", "summary": "Microscaling data formats leverage per-block tensor quantization to enable aggressive model compression with limited loss in accuracy. Unlocking their potential for efficient training and inference necessitates hardware-friendly implementations that handle matrix multiplications in a native format and adopt efficient error-mitigation strategies. Herein, we report the emergence of a surprising behavior associated with microscaling quantization, whereas the output of a quantized model degrades as block size is decreased below a given threshold. This behavior clashes with the expectation that a smaller block size should allow for a better representation of the tensor elements. We investigate this phenomenon both experimentally and theoretically, decoupling the sources of quantization error behind it. Experimentally, we analyze the distributions of several Large Language Models and identify the conditions driving the anomalous behavior. Theoretically, we lay down a framework showing remarkable agreement with experimental data from pretrained model distributions and ideal ones. Overall, we show that the anomaly is driven by the interplay between narrow tensor distributions and the limited dynamic range of the quantized scales. Based on these insights, we propose the use of FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for the scales in FP4 microscaling data types. We demonstrate that UE5M3 achieves comparable performance to the conventional FP8 unsigned E4M3 scales while obviating the need of global scaling operations on weights and activations.", "AI": {"tldr": "Microscaling quantization shows unexpected performance degradation with smaller block sizes due to narrow tensor distributions and limited scale dynamic range. The paper proposes using FP8 unsigned E5M3 format for scales to fix this issue.", "motivation": "Microscaling data formats enable aggressive model compression but require hardware-friendly implementations. The paper investigates a surprising anomaly where smaller block sizes (which should improve representation) actually degrade model performance, contradicting expectations.", "method": "Combined experimental and theoretical approach: 1) Experimentally analyzed distributions of several Large Language Models to identify conditions driving the anomalous behavior, 2) Theoretically developed a framework to explain the phenomenon, 3) Proposed FP8 unsigned E5M3 (UE5M3) as a novel hardware-friendly format for scales in FP4 microscaling data types.", "result": "Identified that the anomaly is driven by interplay between narrow tensor distributions and limited dynamic range of quantized scales. The theoretical framework shows remarkable agreement with experimental data. UE5M3 format achieves comparable performance to conventional FP8 unsigned E4M3 scales while eliminating need for global scaling operations on weights and activations.", "conclusion": "The paper explains the counterintuitive degradation in microscaling quantization with smaller blocks, provides theoretical understanding, and offers a practical solution with UE5M3 format that maintains performance while being hardware-friendly and eliminating extra scaling operations."}}
{"id": "2601.19622", "categories": ["cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.19622", "abs": "https://arxiv.org/abs/2601.19622", "authors": ["Thomas B\u00f6mer", "Nico Koltermann", "Max Disselnmeyer", "Bastian Amberg", "Anne Meyer"], "title": "Algorithmic Prompt-Augmentation for Efficient LLM-Based Heuristic Design for A* Search", "comment": "accepted at EvoStar conference; Code: https://github.com/tb-git-tud/a-ceoh-evolution-of-heuristics?tab=readme-ov-file", "summary": "Heuristic functions are essential to the performance of tree search algorithms such as A*, where their accuracy and efficiency directly impact search outcomes. Traditionally, such heuristics are handcrafted, requiring significant expertise. Recent advances in large language models (LLMs) and evolutionary frameworks have opened the door to automating heuristic design. In this paper, we extend the Evolution of Heuristics (EoH) framework to investigate the automated generation of guiding heuristics for A* search. We introduce a novel domain-agnostic prompt augmentation strategy that includes the A* code into the prompt to leverage in-context learning, named Algorithmic - Contextual EoH (A-CEoH). To evaluate the effectiveness of A-CeoH, we study two problem domains: the Unit-Load Pre-Marshalling Problem (UPMP), a niche problem from warehouse logistics, and the classical sliding puzzle problem (SPP). Our computational experiments show that A-CEoH can significantly improve the quality of the generated heuristics and even outperform expert-designed heuristics.", "AI": {"tldr": "A-CEoH framework automates A* heuristic design using LLMs with algorithmic context, outperforming handcrafted heuristics in warehouse logistics and sliding puzzle problems.", "motivation": "Traditional heuristic design for A* search requires significant expertise and manual effort. Recent advances in LLMs and evolutionary frameworks create opportunities to automate heuristic generation, potentially improving both quality and accessibility.", "method": "Extends Evolution of Heuristics (EoH) framework with A-CEoH: domain-agnostic prompt augmentation that includes A* code in prompts to leverage in-context learning. Evaluated on Unit-Load Pre-Marshalling Problem (warehouse logistics) and classical sliding puzzle problem.", "result": "A-CEoH significantly improves generated heuristic quality and even outperforms expert-designed heuristics in computational experiments across both problem domains.", "conclusion": "Automated heuristic generation using LLMs with algorithmic context (A-CEoH) is effective and can surpass human-designed heuristics, demonstrating the potential for AI-driven optimization in search algorithms."}}
{"id": "2601.19832", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19832", "abs": "https://arxiv.org/abs/2601.19832", "authors": ["Elena Merlo", "Marta Lagomarsino", "Arash Ajoudani"], "title": "Information-Theoretic Detection of Bimanual Interactions for Dual-Arm Robot Plan Generation", "comment": null, "summary": "Programming by demonstration is a strategy to simplify the robot programming process for non-experts via human demonstrations. However, its adoption for bimanual tasks is an underexplored problem due to the complexity of hand coordination, which also hinders data recording. This paper presents a novel one-shot method for processing a single RGB video of a bimanual task demonstration to generate an execution plan for a dual-arm robotic system. To detect hand coordination policies, we apply Shannon's information theory to analyze the information flow between scene elements and leverage scene graph properties. The generated plan is a modular behavior tree that assumes different structures based on the desired arms coordination. We validated the effectiveness of this framework through multiple subject video demonstrations, which we collected and made open-source, and exploiting data from an external, publicly available dataset. Comparisons with existing methods revealed significant improvements in generating a centralized execution plan for coordinating two-arm systems.", "AI": {"tldr": "One-shot method to generate dual-arm robot execution plans from single RGB video demonstrations using information theory and scene graphs.", "motivation": "Bimanual robot programming is complex and underexplored due to hand coordination challenges, making it difficult for non-experts to program dual-arm systems through demonstration.", "method": "Uses Shannon's information theory to analyze information flow between scene elements and leverages scene graph properties to detect hand coordination policies from a single RGB video demonstration.", "result": "Generates modular behavior trees with different structures based on desired arm coordination, validated through multiple subject video demonstrations and external datasets, showing significant improvements over existing methods.", "conclusion": "The framework successfully enables one-shot generation of centralized execution plans for coordinating dual-arm robotic systems from single video demonstrations, advancing bimanual programming by demonstration."}}
{"id": "2601.19236", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.19236", "abs": "https://arxiv.org/abs/2601.19236", "authors": ["Zhiyu Yin", "Zhipeng Liu", "Kehai Chen", "Lemao Liu", "Jin Liu", "Hong-Dong Li", "Yang Xiang", "Min Zhang"], "title": "VC-Bench: Pioneering the Video Connecting Benchmark with a Dataset and Evaluation Metrics", "comment": null, "summary": "While current video generation focuses on text or image conditions, practical applications like video editing and vlogging often need to seamlessly connect separate clips. In our work, we introduce Video Connecting, an innovative task that aims to generate smooth intermediate video content between given start and end clips. However, the absence of standardized evaluation benchmarks has hindered the development of this task. To bridge this gap, we proposed VC-Bench, a novel benchmark specifically designed for video connecting. It includes 1,579 high-quality videos collected from public platforms, covering 15 main categories and 72 subcategories to ensure diversity and structure. VC-Bench focuses on three core aspects: Video Quality Score VQS, Start-End Consistency Score SECS, and Transition Smoothness Score TSS. Together, they form a comprehensive framework that moves beyond conventional quality-only metrics. We evaluated multiple state-of-the-art video generation models on VC-Bench. Experimental results reveal significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity. We expect that VC-Bench will serve as a pioneering benchmark to inspire and guide future research in video connecting. The evaluation metrics and dataset are publicly available at: https://anonymous.4open.science/r/VC-Bench-1B67/.", "AI": {"tldr": "VC-Bench is a new benchmark for video connecting task that generates smooth transitions between start and end clips, featuring 1,579 diverse videos and comprehensive evaluation metrics beyond just video quality.", "motivation": "Current video generation focuses on text/image conditions, but practical applications like video editing and vlogging need seamless connections between separate clips. The lack of standardized evaluation benchmarks has hindered development of video connecting tasks.", "method": "Proposed VC-Bench benchmark with 1,579 high-quality videos from public platforms covering 15 main categories and 72 subcategories for diversity. Introduced three core evaluation metrics: Video Quality Score (VQS), Start-End Consistency Score (SECS), and Transition Smoothness Score (TSS).", "result": "Evaluation of state-of-the-art video generation models on VC-Bench revealed significant limitations in maintaining start-end consistency and transition smoothness, leading to lower overall coherence and fluidity.", "conclusion": "VC-Bench serves as a pioneering benchmark to inspire and guide future research in video connecting, with publicly available evaluation metrics and dataset."}}
{"id": "2601.19030", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19030", "abs": "https://arxiv.org/abs/2601.19030", "authors": ["Philip Amortila", "Audrey Huang", "Akshay Krishnamurthy", "Nan Jiang"], "title": "A Unifying View of Coverage in Linear Off-Policy Evaluation", "comment": "To appear at ICLR 2026", "summary": "Off-policy evaluation (OPE) is a fundamental task in reinforcement learning (RL). In the classic setting of linear OPE, finite-sample guarantees often take the form $$ \\textrm{Evaluation error} \\le \\textrm{poly}(C^\u03c0, d, 1/n,\\log(1/\u03b4)), $$ where $d$ is the dimension of the features and $C^\u03c0$ is a coverage parameter that characterizes the degree to which the visited features lie in the span of the data distribution. While such guarantees are well-understood for several popular algorithms under stronger assumptions (e.g. Bellman completeness), the understanding is lacking and fragmented in the minimal setting where only the target value function is linearly realizable in the features. Despite recent interest in tight characterizations of the statistical rate in this setting, the right notion of coverage remains unclear, and candidate definitions from prior analyses have undesirable properties and are starkly disconnected from more standard definitions in the literature.\n  We provide a novel finite-sample analysis of a canonical algorithm for this setting, LSTDQ. Inspired by an instrumental-variable view, we develop error bounds that depend on a novel coverage parameter, the feature-dynamics coverage, which can be interpreted as linear coverage in an induced dynamical system for feature evolution. With further assumptions -- such as Bellman-completeness -- our definition successfully recovers the coverage parameters specialized to those settings, finally yielding a unified understanding for coverage in linear OPE.", "AI": {"tldr": "The paper provides a novel finite-sample analysis of LSTDQ for linear off-policy evaluation, introducing a new coverage parameter called \"feature-dynamics coverage\" that unifies coverage definitions across different settings.", "motivation": "Existing coverage definitions for linear OPE are fragmented and have undesirable properties, especially in the minimal setting where only the target value function is linearly realizable. There's a need for a unified understanding of coverage that works across different assumptions.", "method": "The authors analyze the canonical LSTDQ algorithm using an instrumental-variable perspective. They develop error bounds that depend on a novel coverage parameter called \"feature-dynamics coverage,\" which can be interpreted as linear coverage in an induced dynamical system for feature evolution.", "result": "The new coverage parameter successfully recovers specialized coverage parameters when stronger assumptions (like Bellman-completeness) are made, providing a unified framework for understanding coverage in linear OPE.", "conclusion": "The paper introduces a unified coverage definition that bridges different settings in linear off-policy evaluation, offering a clearer understanding of coverage requirements and enabling more consistent finite-sample guarantees across various assumptions."}}
{"id": "2601.19752", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19752", "abs": "https://arxiv.org/abs/2601.19752", "authors": ["Minh-Dung Dao", "Quy Minh Le", "Hoang Thanh Lam", "Duc-Trong Le", "Quoc-Viet Pham", "Barry O'Sullivan", "Hoang D. Nguyen"], "title": "Agentic Design Patterns: A System-Theoretic Framework", "comment": null, "summary": "With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or convenience-based taxonomies that are difficult to implement. This paper addresses this gap by introducing a principled methodology for engineering robust AI agents. We propose two primary contributions: first, a novel system-theoretic framework that deconstructs an agentic AI system into five core, interacting functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. Second, derived from this architecture and directly mapped to a comprehensive taxonomy of agentic challenges, we present a collection of 12 agentic design patterns. These patterns - categorised as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning - offer reusable, structural solutions to recurring problems in agent design. The utility of the framework is demonstrated by a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. This work provides a foundational language and a structured methodology to standardise agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems.", "AI": {"tldr": "The paper introduces a system-theoretic framework for engineering robust AI agents with 5 core subsystems and 12 design patterns to address reliability issues in agentic AI systems.", "motivation": "Current agentic AI systems suffer from hallucination, poor reasoning, and ad-hoc design approaches, leading to unreliable applications. Existing design pattern characterizations lack rigorous systems-theoretic foundations, resulting in high-level taxonomies that are difficult to implement.", "method": "1) A novel system-theoretic framework that deconstructs agentic AI systems into five core functional subsystems: Reasoning & World Model, Perception & Grounding, Action Execution, Learning & Adaptation, and Inter-Agent Communication. 2) A collection of 12 agentic design patterns derived from this architecture, categorized as Foundational, Cognitive & Decisional, Execution & Interaction, and Adaptive & Learning patterns.", "result": "The utility of the framework is demonstrated through a case study on the ReAct framework, showing how the proposed patterns can rectify systemic architectural deficiencies. The approach provides a structured methodology for standardizing agentic design communication.", "conclusion": "This work provides a foundational language and structured methodology to standardize agentic design communication among researchers and engineers, leading to more modular, understandable, and reliable autonomous systems."}}
{"id": "2601.19839", "categories": ["cs.RO", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.19839", "abs": "https://arxiv.org/abs/2601.19839", "authors": ["Jeanne Mal\u00e9cot", "Hamed Rahimi", "Jeanne Cattoni", "Marie Samson", "Mouad Abrini", "Mahdi Khoramshahi", "Maribel Pino", "Mohamed Chetouani"], "title": "HARMONI: Multimodal Personalization of Multi-User Human-Robot Interactions with LLMs", "comment": null, "summary": "Existing human-robot interaction systems often lack mechanisms for sustained personalization and dynamic adaptation in multi-user environments, limiting their effectiveness in real-world deployments. We present HARMONI, a multimodal personalization framework that leverages large language models to enable socially assistive robots to manage long-term multi-user interactions. The framework integrates four key modules: (i) a perception module that identifies active speakers and extracts multimodal input; (ii) a world modeling module that maintains representations of the environment and short-term conversational context; (iii) a user modeling module that updates long-term speaker-specific profiles; and (iv) a generation module that produces contextually grounded and ethically informed responses. Through extensive evaluation and ablation studies on four datasets, as well as a real-world scenario-driven user-study in a nursing home environment, we demonstrate that HARMONI supports robust speaker identification, online memory updating, and ethically aligned personalization, outperforming baseline LLM-driven approaches in user modeling accuracy, personalization quality, and user satisfaction.", "AI": {"tldr": "HARMONI is a multimodal personalization framework using LLMs for socially assistive robots to manage long-term multi-user interactions through perception, world modeling, user modeling, and generation modules.", "motivation": "Existing human-robot interaction systems lack sustained personalization and dynamic adaptation in multi-user environments, limiting real-world effectiveness.", "method": "Four-module framework: (1) perception module identifies active speakers and extracts multimodal input, (2) world modeling maintains environment and short-term context, (3) user modeling updates long-term speaker-specific profiles, (4) generation produces contextually grounded, ethically informed responses.", "result": "Outperforms baseline LLM approaches in user modeling accuracy, personalization quality, and user satisfaction through evaluations on four datasets and real-world nursing home user study.", "conclusion": "HARMONI enables robust speaker identification, online memory updating, and ethically aligned personalization for socially assistive robots in multi-user environments."}}
{"id": "2601.19247", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19247", "abs": "https://arxiv.org/abs/2601.19247", "authors": ["Jiarun Liu", "Qifeng Chen", "Yiru Zhao", "Minghua Liu", "Baorui Ma", "Sheng Yang"], "title": "TIGaussian: Disentangle Gaussians for Spatial-Awared Text-Image-3D Alignment", "comment": null, "summary": "While visual-language models have profoundly linked features between texts and images, the incorporation of 3D modality data, such as point clouds and 3D Gaussians, further enables pretraining for 3D-related tasks, e.g., cross-modal retrieval, zero-shot classification, and scene recognition. As challenges remain in extracting 3D modal features and bridging the gap between different modalities, we propose TIGaussian, a framework that harnesses 3D Gaussian Splatting (3DGS) characteristics to strengthen cross-modality alignment through multi-branch 3DGS tokenizer and modality-specific 3D feature alignment strategies. Specifically, our multi-branch 3DGS tokenizer decouples the intrinsic properties of 3DGS structures into compact latent representations, enabling more generalizable feature extraction. To further bridge the modality gap, we develop a bidirectional cross-modal alignment strategies: a multi-view feature fusion mechanism that leverages diffusion priors to resolve perspective ambiguity in image-3D alignment, while a text-3D projection module adaptively maps 3D features to text embedding space for better text-3D alignment. Extensive experiments on various datasets demonstrate the state-of-the-art performance of TIGaussian in multiple tasks.", "AI": {"tldr": "TIGaussian is a framework that uses 3D Gaussian Splatting characteristics to improve cross-modality alignment between 3D data (point clouds, 3D Gaussians) and vision-language models through specialized tokenizers and alignment strategies.", "motivation": "While visual-language models have successfully linked text and images, incorporating 3D modality data (point clouds, 3D Gaussians) enables pretraining for 3D tasks like cross-modal retrieval, zero-shot classification, and scene recognition. However, challenges remain in extracting 3D features and bridging gaps between different modalities.", "method": "TIGaussian uses a multi-branch 3DGS tokenizer that decouples intrinsic properties of 3DGS structures into compact latent representations for generalizable feature extraction. It employs bidirectional cross-modal alignment: 1) multi-view feature fusion with diffusion priors to resolve perspective ambiguity in image-3D alignment, and 2) text-3D projection module that adaptively maps 3D features to text embedding space for better text-3D alignment.", "result": "Extensive experiments on various datasets demonstrate state-of-the-art performance of TIGaussian in multiple tasks.", "conclusion": "TIGaussian effectively bridges the modality gap between 3D data and vision-language models through specialized 3DGS-based feature extraction and alignment strategies, achieving superior performance in cross-modal 3D tasks."}}
{"id": "2601.19035", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19035", "abs": "https://arxiv.org/abs/2601.19035", "authors": ["Mortaza S. Bargh", "Sunil Choenni", "Floris ter Braak"], "title": "Unravelling the (In)compatibility of Statistical-Parity and Equalized-Odds", "comment": null, "summary": "A key challenge in employing data, algorithms and data-driven systems is to adhere to the principle of fairness and justice. Statistical fairness measures belong to an important category of technical/formal mechanisms for detecting fairness issues in data and algorithms. In this contribution we study the relations between two types of statistical fairness measures namely Statistical-Parity and Equalized-Odds. The Statistical-Parity measure does not rely on having ground truth, i.e., (objectively) labeled target attributes. This makes Statistical-Parity a suitable measure in practice for assessing fairness in data and data classification algorithms. Therefore, Statistical-Parity is adopted in many legal and professional frameworks for assessing algorithmic fairness. The Equalized-Odds measure, on the contrary, relies on having (reliable) ground-truth, which is not always feasible in practice. Nevertheless, there are several situations where the Equalized-Odds definition should be satisfied to enforce false prediction parity among sensitive social groups. We present a novel analyze of the relation between Statistical-Parity and Equalized-Odds, depending on the base-rates of sensitive groups. The analysis intuitively shows how and when base-rate imbalance causes incompatibility between Statistical-Parity and Equalized-Odds measures. As such, our approach provides insight in (how to make design) trade-offs between these measures in practice. Further, based on our results, we plea for examining base-rate (im)balance and investigating the possibility of such an incompatibility before enforcing or relying on the Statistical-Parity criterion. The insights provided, we foresee, may trigger initiatives to improve or adjust the current practice and/or the existing legal frameworks.", "AI": {"tldr": "The paper analyzes the relationship between Statistical-Parity and Equalized-Odds fairness measures, showing how base-rate imbalances between sensitive groups cause incompatibility between these measures.", "motivation": "Statistical fairness measures are crucial for detecting fairness issues in data and algorithms. Statistical-Parity is widely adopted in legal frameworks but doesn't require ground truth, while Equalized-Odds requires reliable ground truth but is important for ensuring false prediction parity. Understanding their relationship is essential for practical fairness assessment.", "method": "The authors present a novel analysis of the relationship between Statistical-Parity and Equalized-Odds measures, focusing on how base-rates of sensitive groups affect their compatibility. The analysis examines when base-rate imbalance causes incompatibility between these fairness measures.", "result": "The analysis shows how base-rate imbalances between sensitive groups lead to incompatibility between Statistical-Parity and Equalized-Odds measures. This provides insights into making design trade-offs between these measures in practice.", "conclusion": "Before enforcing or relying on Statistical-Parity criterion, practitioners should examine base-rate balance and investigate potential incompatibility with Equalized-Odds. The insights may trigger improvements to current practices and legal frameworks for algorithmic fairness assessment."}}
{"id": "2601.19768", "categories": ["cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19768", "abs": "https://arxiv.org/abs/2601.19768", "authors": ["Shir Rozenfeld", "Rahul Pankajakshan", "Itay Zloczower", "Eyal Lenga", "Gilad Gressel", "Yisroel Mirsky"], "title": "GAVEL: Towards rule-based safety through activation monitoring", "comment": "Accepted to ICLR 2026", "summary": "Large language models (LLMs) are increasingly paired with activation-based monitoring to detect and prevent harmful behaviors that may not be apparent at the surface-text level. However, existing activation safety approaches, trained on broad misuse datasets, struggle with poor precision, limited flexibility, and lack of interpretability. This paper introduces a new paradigm: rule-based activation safety, inspired by rule-sharing practices in cybersecurity. We propose modeling activations as cognitive elements (CEs), fine-grained, interpretable factors such as ''making a threat'' and ''payment processing'', that can be composed to capture nuanced, domain-specific behaviors with higher precision. Building on this representation, we present a practical framework that defines predicate rules over CEs and detects violations in real time. This enables practitioners to configure and update safeguards without retraining models or detectors, while supporting transparency and auditability. Our results show that compositional rule-based activation safety improves precision, supports domain customization, and lays the groundwork for scalable, interpretable, and auditable AI governance. We will release GAVEL as an open-source framework and provide an accompanying automated rule creation tool.", "AI": {"tldr": "Rule-based activation safety framework using cognitive elements for precise, interpretable detection of harmful behaviors in LLMs.", "motivation": "Existing activation safety approaches have poor precision, limited flexibility, and lack interpretability, making them inadequate for nuanced domain-specific safety needs.", "method": "Model activations as cognitive elements (CEs) - fine-grained interpretable factors like 'making a threat' and 'payment processing'. Define predicate rules over CEs to detect violations in real time, enabling configuration without retraining.", "result": "Compositional rule-based activation safety improves precision, supports domain customization, and enables scalable, interpretable, and auditable AI governance.", "conclusion": "Rule-based activation safety offers a practical framework for precise, flexible, and transparent AI safety monitoring, with GAVEL released as open-source."}}
{"id": "2601.19856", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19856", "abs": "https://arxiv.org/abs/2601.19856", "authors": ["Giulio Campagna", "Marta Lagomarsino", "Marta Lorenzini", "Dimitrios Chrysostomou", "Matthias Rehm", "Arash Ajoudani"], "title": "Estimating Trust in Human-Robot Collaboration through Behavioral Indicators and Explainability", "comment": null, "summary": "Industry 5.0 focuses on human-centric collaboration between humans and robots, prioritizing safety, comfort, and trust. This study introduces a data-driven framework to assess trust using behavioral indicators. The framework employs a Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. This feedback serves as ground truth for training machine learning models to predict trust levels from behavioral indicators. The framework was tested in a chemical industry scenario where a robot assisted a human operator in mixing chemicals. Machine learning models classified trust with over 80\\% accuracy, with the Voting Classifier achieving 84.07\\% accuracy and an AUC-ROC score of 0.90. These findings underscore the effectiveness of data-driven methods in assessing trust within human-robot collaboration, emphasizing the valuable role behavioral indicators play in predicting the dynamics of human trust.", "AI": {"tldr": "A data-driven framework for assessing trust in human-robot collaboration using behavioral indicators and preference-based optimization to generate trust-enhancing trajectories.", "motivation": "Industry 5.0 emphasizes human-centric collaboration where safety, comfort, and trust are crucial. Current methods lack effective ways to quantitatively assess and enhance trust in human-robot interactions.", "method": "Developed a framework using Preference-Based Optimization algorithm to generate trust-enhancing trajectories based on operator feedback. Used this feedback as ground truth to train machine learning models that predict trust levels from behavioral indicators.", "result": "Tested in chemical industry scenario with robot assisting human in mixing chemicals. ML models achieved over 80% accuracy in trust classification, with Voting Classifier reaching 84.07% accuracy and AUC-ROC score of 0.90.", "conclusion": "Data-driven methods effectively assess trust in human-robot collaboration, demonstrating behavioral indicators' value in predicting human trust dynamics for Industry 5.0 applications."}}
{"id": "2601.19262", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19262", "abs": "https://arxiv.org/abs/2601.19262", "authors": ["Syed Mehedi Hasan Nirob", "Moqsadur Rahman", "Shamim Ehsan", "Summit Haque"], "title": "Handcrafted Feature Fusion for Reliable Detection of AI-Generated Images", "comment": null, "summary": "The rapid progress of generative models has enabled the creation of highly realistic synthetic images, raising concerns about authenticity and trust in digital media. Detecting such fake content reliably is an urgent challenge. While deep learning approaches dominate current literature, handcrafted features remain attractive for their interpretability, efficiency, and generalizability. In this paper, we conduct a systematic evaluation of handcrafted descriptors, including raw pixels, color histograms, Discrete Cosine Transform (DCT), Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gray-Level Co-occurrence Matrix (GLCM), and wavelet features, on the CIFAKE dataset of real versus synthetic images. Using 50,000 training and 10,000 test samples, we benchmark seven classifiers ranging from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost). Results demonstrate that LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and a Brier score of 0.0414 with mixed features, representing strong gains in calibration and discrimination over simpler descriptors. Across three configurations (baseline, advanced, mixed), performance improves monotonically, confirming that combining diverse handcrafted features yields substantial benefit. These findings highlight the continued relevance of carefully engineered features and ensemble learning for detecting synthetic images, particularly in contexts where interpretability and computational efficiency are critical.", "AI": {"tldr": "Systematic evaluation shows LightGBM with combined handcrafted features achieves state-of-the-art synthetic image detection performance on CIFAKE dataset, outperforming other classifiers and simpler feature sets.", "motivation": "The rapid advancement of generative models creating highly realistic synthetic images raises concerns about authenticity and trust in digital media, creating an urgent need for reliable fake content detection. While deep learning dominates current approaches, handcrafted features remain attractive for their interpretability, efficiency, and generalizability.", "method": "Systematic evaluation of seven handcrafted descriptors (raw pixels, color histograms, DCT, HOG, LBP, GLCM, wavelet features) on CIFAKE dataset (50k training, 10k test samples). Benchmarking seven classifiers from Logistic Regression to advanced gradient-boosted ensembles (LightGBM, XGBoost, CatBoost) across three configurations: baseline, advanced, and mixed features.", "result": "LightGBM consistently outperforms alternatives, achieving PR-AUC 0.9879, ROC-AUC 0.9878, F1 0.9447, and Brier score 0.0414 with mixed features. Performance improves monotonically across three configurations, confirming that combining diverse handcrafted features yields substantial benefits in both calibration and discrimination.", "conclusion": "Handcrafted features combined with ensemble learning remain highly relevant for synthetic image detection, particularly in contexts requiring interpretability and computational efficiency. The systematic approach demonstrates that careful feature engineering can achieve state-of-the-art performance without deep learning architectures."}}
{"id": "2601.19037", "categories": ["cs.LG", "q-bio.QM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19037", "abs": "https://arxiv.org/abs/2601.19037", "authors": ["Anatol Ehrlich", "Lorenz Kummer", "Vojtech Voracek", "Franka Bause", "Nils M. Kriege"], "title": "XIMP: Cross Graph Inter-Message Passing for Molecular Property Prediction", "comment": null, "summary": "Accurate molecular property prediction is central to drug discovery, yet graph neural networks often underperform in data-scarce regimes and fail to surpass traditional fingerprints. We introduce cross-graph inter-message passing (XIMP), which performs message passing both within and across multiple related graph representations. For small molecules, we combine the molecular graph with scaffold-aware junction trees and pharmacophore-encoding extended reduced graphs, integrating complementary abstractions. While prior work is either limited to a single abstraction or non-iterative communication across graphs, XIMP supports an arbitrary number of abstractions and both direct and indirect communication between them in each layer. Across ten diverse molecular property prediction tasks, XIMP outperforms state-of-the-art baselines in most cases, leveraging interpretable abstractions as an inductive bias that guides learning toward established chemical concepts, enhancing generalization in low-data settings.", "AI": {"tldr": "XIMP introduces cross-graph inter-message passing that enables message passing both within and across multiple graph representations of molecules, outperforming state-of-the-art methods in low-data molecular property prediction.", "motivation": "Graph neural networks often underperform in data-scarce regimes and fail to surpass traditional fingerprints for molecular property prediction, which is central to drug discovery.", "method": "Cross-graph inter-message passing (XIMP) performs message passing both within and across multiple related graph representations (molecular graph, scaffold-aware junction trees, pharmacophore-encoding extended reduced graphs), supporting arbitrary abstractions and both direct/indirect communication between them in each layer.", "result": "XIMP outperforms state-of-the-art baselines in most cases across ten diverse molecular property prediction tasks, leveraging interpretable abstractions as inductive bias that enhances generalization in low-data settings.", "conclusion": "XIMP's ability to integrate complementary graph abstractions through cross-graph message passing provides an effective inductive bias that guides learning toward established chemical concepts, improving molecular property prediction especially in data-scarce regimes."}}
{"id": "2601.19793", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19793", "abs": "https://arxiv.org/abs/2601.19793", "authors": ["Shanyv Liu", "Xuyang Yuan", "Tao Chen", "Zijun Zhan", "Zhu Han", "Danyang Zheng", "Weishan Zhang", "Shaohua Cao"], "title": "CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing", "comment": null, "summary": "Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semantic embeddings with structural meta-features to estimate task difficulty. During training, the router self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from its own routing failures via on-policy negative feedback. Experiments using LLM-as-a-Judge evaluation across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity demonstrate that CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching their success rates, and consistently outperforms both heuristic routing and FrugalGPT across all domains.", "AI": {"tldr": "CASTER is a lightweight router for dynamic model selection in graph-based multi-agent systems that reduces inference costs by 72.4% while maintaining success rates.", "motivation": "Graph-based MAS enable complex workflows but suffer from inefficient static model allocation where strong models are wasted on trivial sub-tasks, leading to unnecessary computational costs.", "method": "CASTER uses a Dual-Signal Router combining semantic embeddings with structural meta-features to estimate task difficulty. It self-optimizes through a Cold Start to Iterative Evolution paradigm, learning from routing failures via on-policy negative feedback.", "result": "Experiments across Software Engineering, Data Analysis, Scientific Discovery, and Cybersecurity show CASTER reduces inference cost by up to 72.4% compared to strong-model baselines while matching success rates, and outperforms heuristic routing and FrugalGPT.", "conclusion": "CASTER provides an effective solution for dynamic model selection in graph-based MAS, achieving significant computational savings without compromising task success rates across diverse domains."}}
{"id": "2601.19266", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19266", "abs": "https://arxiv.org/abs/2601.19266", "authors": ["Yuting Hong", "Li Dong", "Xiaojie Qiu", "Hui Xiao", "Baochen Yao", "Siming Zheng", "Chengbin Peng"], "title": "A Multi-View Consistency Framework with Semi-Supervised Domain Adaptation", "comment": "11 pages, 7 figures", "summary": "Semi-Supervised Domain Adaptation (SSDA) leverages knowledge from a fully labeled source domain to classify data in a partially labeled target domain. Due to the limited number of labeled samples in the target domain, there can be intrinsic similarity of classes in the feature space, which may result in biased predictions, even when the model is trained on a balanced dataset. To overcome this limitation, we introduce a multi-view consistency framework, which includes two views for training strongly augmented data. One is a debiasing strategy for correcting class-wise prediction probabilities according to the prediction performance of the model. The other involves leveraging pseudo-negative labels derived from the model predictions. Furthermore, we introduce a cross-domain affinity learning aimed at aligning features of the same class across different domains, thereby enhancing overall performance. Experimental results demonstrate that our method outperforms the competing methods on two standard domain adaptation datasets, DomainNet and Office-Home. Combining unsupervised domain adaptation and semi-supervised learning offers indispensable contributions to the industrial sector by enhancing model adaptability, reducing annotation costs, and improving performance.", "AI": {"tldr": "A multi-view consistency framework for SSDA that uses debiasing strategies and pseudo-negative labels to address class similarity bias, with cross-domain affinity learning to align features across domains.", "motivation": "In SSDA, limited labeled target samples can cause intrinsic class similarity in feature space, leading to biased predictions even with balanced training data. Need to overcome this limitation.", "method": "Multi-view consistency framework with two training views: 1) debiasing strategy correcting class-wise prediction probabilities based on model performance, 2) leveraging pseudo-negative labels from model predictions, plus cross-domain affinity learning to align same-class features across domains.", "result": "Outperforms competing methods on two standard domain adaptation datasets: DomainNet and Office-Home.", "conclusion": "Combining unsupervised domain adaptation and semi-supervised learning enhances model adaptability, reduces annotation costs, and improves performance, offering valuable contributions to industrial applications."}}
{"id": "2601.19040", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19040", "abs": "https://arxiv.org/abs/2601.19040", "authors": ["Junwei Deng", "Chang Xu", "Jiaqi W. Ma", "Ming Jin", "Chenghao Liu", "Jiang Bian"], "title": "OATS: Online Data Augmentation for Time Series Foundation Models", "comment": null, "summary": "Time Series Foundation Models (TSFMs) are a powerful paradigm for time series analysis and are often enhanced by synthetic data augmentation to improve the training data quality. Existing augmentation methods, however, typically rely on heuristics and static paradigms. Motivated by dynamic data optimization, which shows that the contribution of samples varies across training stages, we propose OATS (Online Data Augmentation for Time Series Foundation Models), a principled strategy that generates synthetic data tailored to different training steps. OATS leverages valuable training samples as principled guiding signals and dynamically generates high-quality synthetic data conditioned on them. We further design a diffusion-based framework to produce realistic time series and introduce an explore-exploit mechanism to balance efficiency and effectiveness. Experiments on TSFMs demonstrate that OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two TSFM architectures. The code is available at the link https://github.com/microsoft/TimeCraft.", "AI": {"tldr": "OATS is an online data augmentation method for time series foundation models that dynamically generates synthetic data tailored to different training stages using diffusion models and explore-exploit mechanisms.", "motivation": "Existing time series data augmentation methods rely on heuristics and static paradigms, failing to account for how sample contributions vary across training stages. The authors are motivated by dynamic data optimization principles to create adaptive augmentation.", "method": "OATS uses a diffusion-based framework to generate realistic time series data, conditioned on valuable training samples as guiding signals. It incorporates an explore-exploit mechanism to balance efficiency and effectiveness, and dynamically generates synthetic data tailored to different training steps.", "result": "OATS consistently outperforms regular training and yields substantial performance gains over static data augmentation baselines across six validation datasets and two time series foundation model architectures.", "conclusion": "The proposed OATS framework provides a principled, dynamic approach to data augmentation for time series foundation models that adapts to different training stages, leading to significant performance improvements over static augmentation methods."}}
{"id": "2601.19824", "categories": ["cs.AI", "cs.HC", "cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.19824", "abs": "https://arxiv.org/abs/2601.19824", "authors": ["Andre Paulino de Lima", "Paula Castro", "Suzana Carvalho Vaz de Andrade", "Rosa Maria Marcucci", "Ruth Caldeira de Melo", "Marcelo Garcia Manzato"], "title": "An Interpretable Recommendation Model for Psychometric Data, With an Application to Gerontological Primary Care", "comment": "81 pages, 19 figures, 3 annexes", "summary": "There are challenges that must be overcome to make recommender systems useful in healthcare settings. The reasons are varied: the lack of publicly available clinical data, the difficulty that users may have in understanding the reasons why a recommendation was made, the risks that may be involved in following that recommendation, and the uncertainty about its effectiveness. In this work, we address these challenges with a recommendation model that leverages the structure of psychometric data to provide visual explanations that are faithful to the model and interpretable by care professionals. We focus on a narrow healthcare niche, gerontological primary care, to show that the proposed recommendation model can assist the attending professional in the creation of personalised care plans. We report results of a comparative offline performance evaluation of the proposed model on healthcare datasets that were collected by research partners in Brazil, as well as the results of a user study that evaluates the interpretability of the visual explanations the model generates. The results suggest that the proposed model can advance the application of recommender systems in this healthcare niche, which is expected to grow in demand , opportunities, and information technology needs as demographic changes become more pronounced.", "AI": {"tldr": "A recommender system for gerontological primary care that provides visual explanations to address healthcare challenges like data scarcity, interpretability, and risk concerns.", "motivation": "Recommender systems face unique challenges in healthcare: lack of public clinical data, difficulty understanding recommendations, risks of following recommendations, and uncertainty about effectiveness. These issues limit their usefulness in clinical settings.", "method": "Developed a recommendation model that leverages psychometric data structure to provide visual explanations that are both faithful to the model and interpretable by care professionals. Focused specifically on gerontological primary care for personalized care plan creation.", "result": "Conducted comparative offline performance evaluation on Brazilian healthcare datasets and user studies evaluating visual explanation interpretability. Results suggest the model can advance recommender system applications in gerontological care.", "conclusion": "The proposed model addresses key healthcare recommender system challenges and shows promise for gerontological primary care, a growing niche with increasing demand due to demographic changes."}}
{"id": "2601.19295", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19295", "abs": "https://arxiv.org/abs/2601.19295", "authors": ["Yingtie Lei", "Zimeng Li", "Chi-Man Pun", "Wangyu Wu", "Junke Yang", "Xuhang Chen"], "title": "ProMist-5K: A Comprehensive Dataset for Digital Emulation of Cinematic Pro-Mist Filter Effects", "comment": "Accepted by ICASSP2026", "summary": "Pro-Mist filters are widely used in cinematography for their ability to create soft halation, lower contrast, and produce a distinctive, atmospheric style. These effects are difficult to reproduce digitally due to the complex behavior of light diffusion. We present ProMist-5K, a dataset designed to support cinematic style emulation. It is built using a physically inspired pipeline in a scene-referred linear space and includes 20,000 high-resolution image pairs across four configurations, covering two filter densities (1/2 and 1/8) and two focal lengths (20mm and 50mm). Unlike general style datasets, ProMist-5K focuses on realistic glow and highlight diffusion effects. Multiple blur layers and carefully tuned weighting are used to model the varying intensity and spread of optical diffusion. The dataset provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show that the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances. ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is available at https://www.kaggle.com/datasets/yingtielei/promist5k.", "AI": {"tldr": "ProMist-5K is a dataset of 20,000 high-resolution image pairs for digitally emulating Pro-Mist filter effects like soft halation and glow, using a physically inspired pipeline with multiple blur layers and weighting for realistic optical diffusion.", "motivation": "Pro-Mist filters create distinctive cinematic effects (soft halation, lower contrast, atmospheric style) that are difficult to reproduce digitally due to complex light diffusion behavior. There's a need to bridge the gap between digital flexibility and traditional lens aesthetics.", "method": "Built a physically inspired pipeline in scene-referred linear space with 20,000 high-resolution image pairs across 4 configurations (2 filter densities: 1/2 and 1/8; 2 focal lengths: 20mm and 50mm). Used multiple blur layers and carefully tuned weighting to model varying intensity and spread of optical diffusion.", "result": "ProMist-5K provides a consistent and controllable target domain that supports various image translation models and learning paradigms. Experiments show the dataset works well across different training settings and helps capture both subtle and strong cinematic appearances.", "conclusion": "ProMist-5K offers a practical and physically grounded resource for film-inspired image transformation, bridging the gap between digital flexibility and traditional lens aesthetics. The dataset is publicly available on Kaggle."}}
{"id": "2601.19055", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19055", "abs": "https://arxiv.org/abs/2601.19055", "authors": ["Dipendra Misra", "Aldo Pacchiano", "Ta-Chung Chi", "Ge Gao"], "title": "Principled Fine-tuning of LLMs from User-Edits: A Medley of Preference, Supervision, and Reward", "comment": "Accepted at NeurIPS 2025", "summary": "We study how to fine-tune LLMs using user-edit deployment data consisting of a set of context, an agent's response, and user edits. This deployment data is naturally generated by users in applications such as LLMs-based writing assistants and coding agents. The _natural_ origin of user edits makes it a desired source for adapting and personalizing LLMs. In this setup, there emerges a unification of various feedback types namely preferences, supervised labels, and cost that are typically studied separately in the literature. In this paper, we initiate the theoretical investigation of learning from user edits. We first derive bounds for learning algorithms that learn from each of these feedback types. We prove that these algorithms have different trade-offs depending upon the user, data distribution, and model class. We then propose a simple ensembling procedure to jointly learn from these feedback types. On two domains adapted from Gao et al. 2024, we show our ensembling procedure outperforms these methods that learn from individual feedback. Further, we show that our proposed procedure can robustly adapt to different user-edit distributions at test time.", "AI": {"tldr": "The paper proposes a theoretical framework and ensembling method for fine-tuning LLMs using user-edit deployment data, unifying different feedback types (preferences, supervised labels, cost) that are typically studied separately.", "motivation": "User-edit deployment data (context, agent response, user edits) is naturally generated in applications like writing assistants and coding agents, making it a valuable source for adapting and personalizing LLMs. Current literature studies different feedback types separately, but user edits naturally unify these feedback types.", "method": "1) Derive theoretical bounds for learning algorithms using different feedback types (preferences, supervised labels, cost). 2) Propose a simple ensembling procedure to jointly learn from these unified feedback types in user-edit data.", "result": "On two domains adapted from Gao et al. 2024, the ensembling procedure outperforms methods that learn from individual feedback types. The proposed procedure also robustly adapts to different user-edit distributions at test time.", "conclusion": "User-edit deployment data provides a natural unification of different feedback types, and the proposed ensembling approach effectively leverages this unified feedback for better LLM adaptation and personalization, with theoretical guarantees and empirical validation."}}
{"id": "2601.19825", "categories": ["cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.19825", "abs": "https://arxiv.org/abs/2601.19825", "authors": ["Saikrishna Sudarshan", "Tanay Kulkarni", "Manasi Patwardhan", "Lovekesh Vig", "Ashwin Srinivasan", "Tanmay Tulsidas Verlekar"], "title": "Routing End User Queries to Enterprise Databases", "comment": "6 pages, 2 figures", "summary": "We address the task of routing natural language queries in multi-database enterprise environments. We construct realistic benchmarks by extending existing NL-to-SQL datasets. Our study shows that routing becomes increasingly challenging with larger, domain-overlapping DB repositories and ambiguous queries, motivating the need for more structured and robust reasoning-based solutions. By explicitly modelling schema coverage, structural connectivity, and fine-grained semantic alignment, the proposed modular, reasoning-driven reranking strategy consistently outperforms embedding-only and direct LLM-prompting baselines across all the metrics.", "AI": {"tldr": "A modular reasoning-driven reranking strategy outperforms embedding-only and LLM-prompting baselines for routing natural language queries in multi-database enterprise environments.", "motivation": "Routing natural language queries in multi-database enterprise environments is challenging, especially with larger domain-overlapping databases and ambiguous queries, requiring more structured and robust reasoning-based solutions.", "method": "Proposed modular, reasoning-driven reranking strategy that explicitly models schema coverage, structural connectivity, and fine-grained semantic alignment between queries and databases.", "result": "The proposed approach consistently outperforms embedding-only and direct LLM-prompting baselines across all metrics on realistic benchmarks constructed by extending existing NL-to-SQL datasets.", "conclusion": "Explicit modeling of schema coverage, structural connectivity, and semantic alignment through reasoning-driven reranking provides superior performance for multi-database query routing compared to simpler approaches."}}
{"id": "2601.19557", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19557", "abs": "https://arxiv.org/abs/2601.19557", "authors": ["Riccardo Giubilato", "Marcus Gerhard M\u00fcller", "Marco Sewtz", "Laura Alejandra Encinar Gonzalez", "John Folkesson", "Rudolph Triebel"], "title": "The S3LI Vulcano Dataset: A Dataset for Multi-Modal SLAM in Unstructured Planetary Environments", "comment": "Accepted submission to the 2026 IEEE Aerospace Conference", "summary": "We release the S3LI Vulcano dataset, a multi-modal dataset towards development and benchmarking of Simultaneous Localization and Mapping (SLAM) and place recognition algorithms that rely on visual and LiDAR modalities. Several sequences are recorded on the volcanic island of Vulcano, from the Aeolian Islands in Sicily, Italy. The sequences provide users with data from a variety of environments, textures and terrains, including basaltic or iron-rich rocks, geological formations from old lava channels, as well as dry vegetation and water. The data (rmc.dlr.de/s3li_dataset) is accompanied by an open source toolkit (github.com/DLR-RM/s3li-toolkit) providing tools for generating ground truth poses as well as preparation of labelled samples for place recognition tasks.", "AI": {"tldr": "S3LI Vulcano dataset release for multi-modal SLAM and place recognition benchmarking with visual and LiDAR data from volcanic environments", "motivation": "Need for standardized multi-modal datasets to develop and benchmark SLAM and place recognition algorithms using both visual and LiDAR modalities", "method": "Recorded sequences on volcanic island of Vulcano, Italy, capturing diverse environments including basaltic/iron-rich rocks, lava channels, dry vegetation, and water", "result": "Released S3LI Vulcano dataset with open source toolkit for ground truth pose generation and preparation of labelled samples for place recognition tasks", "conclusion": "Dataset provides valuable multi-modal benchmark for SLAM and place recognition research with diverse environmental conditions and accompanying tools"}}
{"id": "2601.19309", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19309", "abs": "https://arxiv.org/abs/2601.19309", "authors": ["Tailong Luo", "Jiesong Bai", "Jinyang Huang", "Junyu Xia", "Wangyu Wu", "Xuhang Chen"], "title": "Beyond Shadows: A Large-Scale Benchmark and Multi-Stage Framework for High-Fidelity Facial Shadow Removal", "comment": "Accepted by ICASSP2026", "summary": "Facial shadows often degrade image quality and the performance of vision algorithms. Existing methods struggle to remove shadows while preserving texture, especially under complex lighting conditions, and they lack real-world paired datasets for training. We present the Augmented Shadow Face in the Wild (ASFW) dataset, the first large-scale real-world dataset for facial shadow removal, containing 1,081 paired shadow and shadow-free images created via a professional Photoshop workflow. ASFW offers photorealistic shadow variations and accurate ground truths, bridging the gap between synthetic and real domains. Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions. We also introduce the Face Shadow Eraser (FSE) method to showcase the effectiveness of the dataset. Experiments demonstrate that ASFW enhances the performance of facial shadow removal models, setting new standards for this task.", "AI": {"tldr": "The paper introduces ASFW, the first large-scale real-world facial shadow removal dataset with 1,081 paired images, and proposes the Face Shadow Eraser method to demonstrate its effectiveness.", "motivation": "Facial shadows degrade image quality and vision algorithm performance, but existing methods struggle with texture preservation under complex lighting and lack real-world paired training datasets.", "method": "Created ASFW dataset using professional Photoshop workflow for photorealistic shadow variations, and introduced Face Shadow Eraser (FSE) method to showcase dataset effectiveness.", "result": "Deep models trained on ASFW demonstrate improved shadow removal in real-world conditions, and experiments show ASFW enhances facial shadow removal model performance, setting new standards.", "conclusion": "ASFW bridges the gap between synthetic and real domains for facial shadow removal, providing accurate ground truths that enable better model training and performance in real-world applications."}}
{"id": "2601.19070", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19070", "abs": "https://arxiv.org/abs/2601.19070", "authors": ["W. A. Z\u00fa\u00f1iga-Galindo"], "title": "Critical Organization of Deep Neural Networks, and p-Adic Statistical Field Theories", "comment": null, "summary": "We rigorously study the thermodynamic limit of deep neural networks (DNNS) and recurrent neural networks (RNNs), assuming that the activation functions are sigmoids. A thermodynamic limit is a continuous neural network, where the neurons form a continuous space with infinitely many points. We show that such a network admits a unique state in a certain region of the parameter space, which depends continuously on the parameters. This state breaks into an infinite number of states outside the mentioned region of parameter space. Then, the critical organization is a bifurcation in the parameter space, where a network transitions from a unique state to infinitely many states. We use p-adic integers to codify hierarchical structures. Indeed, we present an algorithm that recasts the hierarchical topologies used in DNNs and RNNs as p-adic tree-like structures. In this framework, the hierarchical and the critical organizations are connected. We study rigorously the critical organization of a toy model, a hierarchical edge detector for grayscale images based on p-adic cellular neural networks. The critical organization of such a network can be described as a strange attractor. In the second part, we study random versions of DNNs and RNNs. In this case, the network parameters are generalized Gaussian random variables in a space of quadratic integrable functions. We compute the probability distribution of the output given the input, in the infinite-width case. We show that it admits a power-type expansion, where the constant term is a Gaussian distribution.", "AI": {"tldr": "The paper studies thermodynamic limits of neural networks using p-adic integers to model hierarchical structures, showing unique vs. infinite state transitions and analyzing random networks in infinite-width limits.", "motivation": "To rigorously understand the thermodynamic limit (continuous neural networks with infinite neurons) of deep and recurrent neural networks, particularly how they transition between unique and infinite states, and to connect hierarchical structures with critical organization using p-adic mathematics.", "method": "Uses p-adic integers to codify hierarchical structures, presenting an algorithm to recast DNN/RNN topologies as p-adic tree-like structures. Studies critical organization through a toy model (hierarchical edge detector based on p-adic cellular neural networks). For random networks, analyzes generalized Gaussian random variables in infinite-width case.", "result": "Shows that networks admit unique states in certain parameter regions (continuous dependence on parameters) but break into infinite states outside those regions. Critical organization is a bifurcation between these regimes. For random networks in infinite-width case, output distribution admits power-type expansion with Gaussian constant term.", "conclusion": "The paper establishes rigorous connections between hierarchical neural network structures and p-adic mathematics, revealing critical transitions in network behavior and providing analytical results for random neural networks in the thermodynamic limit."}}
{"id": "2601.19834", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19834", "abs": "https://arxiv.org/abs/2601.19834", "authors": ["Jialong Wu", "Xiaoying Zhang", "Hongyi Yuan", "Xiangcheng Zhang", "Tianhao Huang", "Changjing He", "Chaoyi Deng", "Renrui Zhang", "Youbin Wu", "Mingsheng Long"], "title": "Visual Generation Unlocks Human-Like Reasoning through Multimodal World Models", "comment": "Project page: https://thuml.github.io/Reasoning-Visual-World", "summary": "Humans construct internal world models and reason by manipulating the concepts within these models. Recent advances in AI, particularly chain-of-thought (CoT) reasoning, approximate such human cognitive abilities, where world models are believed to be embedded within large language models. Expert-level performance in formal and abstract domains such as mathematics and programming has been achieved in current systems by relying predominantly on verbal reasoning. However, they still lag far behind humans in domains like physical and spatial intelligence, which require richer representations and prior knowledge. The emergence of unified multimodal models (UMMs) capable of both verbal and visual generation has therefore sparked interest in more human-like reasoning grounded in complementary multimodal pathways, though their benefits remain unclear. From a world-model perspective, this paper presents the first principled study of when and how visual generation benefits reasoning. Our key position is the visual superiority hypothesis: for certain tasks--particularly those grounded in the physical world--visual generation more naturally serves as world models, whereas purely verbal world models encounter bottlenecks arising from representational limitations or insufficient prior knowledge. Theoretically, we formalize internal world modeling as a core component of CoT reasoning and analyze distinctions among different forms of world models. Empirically, we identify tasks that necessitate interleaved visual-verbal CoT reasoning, constructing a new evaluation suite, VisWorld-Eval. Controlled experiments on a state-of-the-art UMM show that interleaved CoT significantly outperforms purely verbal CoT on tasks that favor visual world modeling, but offers no clear advantage otherwise. Together, this work clarifies the potential of multimodal world modeling for more powerful, human-like multimodal AI.", "AI": {"tldr": "This paper investigates when visual generation benefits reasoning in AI systems, proposing that for physical/spatial tasks, visual world models outperform purely verbal ones, and demonstrates this through a new evaluation suite.", "motivation": "Current AI systems excel at verbal reasoning (math, programming) but lag in physical/spatial intelligence requiring richer representations. The emergence of unified multimodal models (UMMs) with visual generation capabilities raises questions about when visual reasoning actually helps, which remains unclear.", "method": "Theoretical: Formalize internal world modeling as core to chain-of-thought reasoning and analyze different world model forms. Empirical: Identify tasks needing interleaved visual-verbal reasoning, create VisWorld-Eval evaluation suite, conduct controlled experiments on state-of-the-art UMM comparing interleaved vs. purely verbal CoT.", "result": "Interleaved CoT significantly outperforms purely verbal CoT on tasks favoring visual world modeling (physical/spatial tasks), but offers no clear advantage on other tasks, supporting the visual superiority hypothesis.", "conclusion": "Visual generation benefits reasoning specifically for physical/spatial tasks where visual world models overcome limitations of purely verbal representations, clarifying the potential of multimodal world modeling for more human-like AI."}}
{"id": "2601.19612", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19612", "abs": "https://arxiv.org/abs/2601.19612", "authors": ["Manuel Wendl", "Yarden As", "Manish Prajapat", "Anton Pollak", "Stelian Coros", "Andreas Krause"], "title": "Safe Exploration via Policy Priors", "comment": null, "summary": "Safe exploration is a key requirement for reinforcement learning (RL) agents to learn and adapt online, beyond controlled (e.g. simulated) environments. In this work, we tackle this challenge by utilizing suboptimal yet conservative policies (e.g., obtained from offline data or simulators) as priors. Our approach, SOOPER, uses probabilistic dynamics models to optimistically explore, yet pessimistically fall back to the conservative policy prior if needed. We prove that SOOPER guarantees safety throughout learning, and establish convergence to an optimal policy by bounding its cumulative regret. Extensive experiments on key safe RL benchmarks and real-world hardware demonstrate that SOOPER is scalable, outperforms the state-of-the-art and validate our theoretical guarantees in practice.", "AI": {"tldr": "SOOPER is a safe RL method that uses conservative policy priors and probabilistic dynamics models to enable optimistic exploration with safety fallbacks, guaranteeing safety throughout learning while achieving optimal performance.", "motivation": "Safe exploration is crucial for RL agents to learn and adapt in real-world environments beyond controlled simulations. The challenge is to explore effectively while maintaining safety guarantees throughout the learning process.", "method": "SOOPER uses suboptimal conservative policies (from offline data or simulators) as priors, combined with probabilistic dynamics models to enable optimistic exploration. It pessimistically falls back to the conservative policy prior when needed to ensure safety.", "result": "The method guarantees safety throughout learning, establishes convergence to an optimal policy by bounding cumulative regret, and outperforms state-of-the-art methods on key safe RL benchmarks and real-world hardware.", "conclusion": "SOOPER provides a scalable, theoretically-grounded approach to safe RL that balances exploration and safety, with practical validation on both benchmarks and real hardware."}}
{"id": "2601.19314", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19314", "abs": "https://arxiv.org/abs/2601.19314", "authors": ["Chen-Chou Lo", "Patrick Vandewalle"], "title": "Instance-Guided Radar Depth Estimation for 3D Object Detection", "comment": "Accepted to IPMV2026", "summary": "Accurate depth estimation is fundamental to 3D perception in autonomous driving, supporting tasks such as detection, tracking, and motion planning. However, monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness under challenging conditions. Radar provides complementary advantages such as resilience to poor lighting and adverse weather, but its sparsity and low resolution limit its direct use in detection frameworks. This motivates the need for effective Radar-camera fusion with improved preprocessing and depth estimation strategies. We propose an end-to-end framework that enhances monocular 3D object detection through two key components. First, we introduce InstaRadar, an instance segmentation-guided expansion method that leverages pre-trained segmentation masks to enhance Radar density and semantic alignment, producing a more structured representation. InstaRadar achieves state-of-the-art results in Radar-guided depth estimation, showing its effectiveness in generating high-quality depth features. Second, we integrate the pre-trained RCDPT into the BEVDepth framework as a replacement for its depth module. With InstaRadar-enhanced inputs, the RCDPT integration consistently improves 3D detection performance. Overall, these components yield steady gains over the baseline BEVDepth model, demonstrating the effectiveness of InstaRadar and the advantage of explicit depth supervision in 3D object detection. Although the framework lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than an independent feature stream, this limitation highlights potential for improvement. Future work will extend InstaRadar to point cloud-like representations and integrate a dedicated Radar branch with temporal cues for enhanced BEV fusion.", "AI": {"tldr": "InstaRadar enhances monocular 3D object detection by using instance segmentation to improve Radar density and semantic alignment, then integrates with RCDPT depth estimation in BEVDepth framework.", "motivation": "Monocular camera-based 3D detection suffers from depth ambiguity and reduced robustness in challenging conditions, while Radar provides resilience to poor lighting/weather but has sparsity and low resolution limitations. Need effective Radar-camera fusion with improved preprocessing and depth estimation.", "method": "Two key components: 1) InstaRadar - instance segmentation-guided expansion method using pre-trained segmentation masks to enhance Radar density and semantic alignment; 2) Integration of pre-trained RCDPT into BEVDepth framework as replacement for its depth module, using InstaRadar-enhanced inputs.", "result": "InstaRadar achieves state-of-the-art results in Radar-guided depth estimation. RCDPT integration with InstaRadar-enhanced inputs consistently improves 3D detection performance, yielding steady gains over baseline BEVDepth model. Framework demonstrates effectiveness of InstaRadar and advantage of explicit depth supervision.", "conclusion": "The proposed framework shows promise but lags behind Radar-camera fusion models that directly extract BEV features, since Radar serves only as guidance rather than independent feature stream. Future work will extend InstaRadar to point cloud-like representations and integrate dedicated Radar branch with temporal cues for enhanced BEV fusion."}}
{"id": "2601.19085", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19085", "abs": "https://arxiv.org/abs/2601.19085", "authors": ["Joshua V. Dillon"], "title": "Speed is Confidence", "comment": null, "summary": "Biological neural systems must be fast but are energy-constrained. Evolution's solution: act on the first signal. Winner-take-all circuits and time-to-first-spike coding implicitly treat when a neuron fires as an expression of confidence. We apply this principle to ensembles of Tiny Recursive Models (TRM). By basing the ensemble prediction solely on the first to halt rather than averaging predictions, we achieve 97.2% puzzle accuracy on Sudoku-Extreme while using 10x less compute than test-time augmentation (the baseline achieves 86.1% single-pass, 97.3% with TTA). Inference speed is an implicit indication of confidence. But can this capability be manifested as a training-only cost? Evidently yes: by maintaining K = 4 parallel latent states during training but backpropping only through the lowest-loss \"winner,\" a single model achieves 96.9% +/- 0.6% puzzle accuracy with a single forward pass-matching TTA performance without any test-time augmentation. As in nature, this work was also resource constrained: all experimentation used a single RTX 5090. This necessitated efficiency and compelled our invention of a modified SwiGLU which made Muon viable. With Muon and K = 1 training, we exceed TRM baseline performance in 7k steps (40 min). Higher accuracy requires 36k steps: 1.5 hours for K = 1, 6 hours for K = 4.", "AI": {"tldr": "The paper introduces a \"first-to-halt\" ensemble method inspired by biological neural systems, achieving 97.2% Sudoku accuracy with 10x less compute than test-time augmentation, and develops a training-only variant that matches TTA performance with single forward passes.", "motivation": "Biological neural systems must be fast while energy-constrained, using \"act on the first signal\" principles like winner-take-all circuits and time-to-first-spike coding. The authors aim to apply this evolutionary solution to improve computational efficiency in neural networks.", "method": "1) Ensemble approach: Use Tiny Recursive Models (TRM) where ensemble prediction is based solely on the first model to halt rather than averaging predictions. 2) Training-only variant: Maintain K=4 parallel latent states during training but backprop only through the lowest-loss \"winner,\" enabling single forward pass inference. 3) Efficiency innovations: Modified SwiGLU activation and resource-constrained experimentation on a single RTX 5090.", "result": "First-to-halt ensemble achieves 97.2% puzzle accuracy on Sudoku-Extreme using 10x less compute than test-time augmentation (baseline: 86.1% single-pass, 97.3% with TTA). Training-only variant with K=4 achieves 96.9% \u00b1 0.6% accuracy with single forward pass, matching TTA performance without test-time augmentation. Efficiency: Muon with K=1 training exceeds TRM baseline in 7k steps (40 min); higher accuracy requires 36k steps (1.5h for K=1, 6h for K=4).", "conclusion": "The work demonstrates that inference speed can serve as an implicit confidence measure, and this capability can be manifested as a training-only cost. Inspired by biological efficiency principles, the methods achieve state-of-the-art performance with significantly reduced computational requirements, enabling resource-constrained research to advance."}}
{"id": "2601.19325", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19325", "abs": "https://arxiv.org/abs/2601.19325", "authors": ["Zichen Wen", "Boxue Yang", "Shuang Chen", "Yaojie Zhang", "Yuhang Han", "Junlong Ke", "Cong Wang", "Yicheng Fu", "Jiawang Zhao", "Jiangchao Yao", "Xi Fang", "Zhen Wang", "Henxing Cai", "Lin Yao", "Zhifeng Gao", "Yanhui Hong", "Nang Yuan", "Yixuan Li", "Guojiang Zhao", "Haoyi Tao", "Nan Wang", "Han Lyu", "Guolin Ke", "Ning Liao", "Xiaoxing Wang", "Kai Chen", "Zhiyu Li", "Feiyu Xiong", "Sihan Hu", "Kun Chen", "Yanfeng Wang", "Weinan E", "Linfeng Zhang", "Linfeng Zhang"], "title": "Innovator-VL: A Multimodal Large Language Model for Scientific Discovery", "comment": "Innovator-VL tech report", "summary": "We present Innovator-VL, a scientific multimodal large language model designed to advance understanding and reasoning across diverse scientific domains while maintaining excellent performance on general vision tasks. Contrary to the trend of relying on massive domain-specific pretraining and opaque pipelines, our work demonstrates that principled training design and transparent methodology can yield strong scientific intelligence with substantially reduced data requirements. (i) First, we provide a fully transparent, end-to-end reproducible training pipeline, covering data collection, cleaning, preprocessing, supervised fine-tuning, reinforcement learning, and evaluation, along with detailed optimization recipes. This facilitates systematic extension by the community. (ii) Second, Innovator-VL exhibits remarkable data efficiency, achieving competitive performance on various scientific tasks using fewer than five million curated samples without large-scale pretraining. These results highlight that effective reasoning can be achieved through principled data selection rather than indiscriminate scaling. (iii) Third, Innovator-VL demonstrates strong generalization, achieving competitive performance on general vision, multimodal reasoning, and scientific benchmarks. This indicates that scientific alignment can be integrated into a unified model without compromising general-purpose capabilities. Our practices suggest that efficient, reproducible, and high-performing scientific multimodal models can be built even without large-scale data, providing a practical foundation for future research.", "AI": {"tldr": "Innovator-VL is a scientific multimodal LLM that achieves strong scientific reasoning with data-efficient, transparent training using <5M curated samples, maintaining general vision capabilities without large-scale pretraining.", "motivation": "To advance scientific multimodal understanding while challenging the trend of massive domain-specific pretraining and opaque pipelines, demonstrating that principled design and transparency can yield strong scientific intelligence with reduced data requirements.", "method": "Provides fully transparent, end-to-end reproducible training pipeline covering data collection, cleaning, preprocessing, SFT, RL, and evaluation. Uses principled data selection with fewer than 5M curated samples, avoiding large-scale pretraining.", "result": "Achieves competitive performance on various scientific tasks with remarkable data efficiency. Demonstrates strong generalization across general vision, multimodal reasoning, and scientific benchmarks without compromising general-purpose capabilities.", "conclusion": "Efficient, reproducible, and high-performing scientific multimodal models can be built without large-scale data, providing a practical foundation for future research through principled training design and transparent methodology."}}
{"id": "2601.19089", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19089", "abs": "https://arxiv.org/abs/2601.19089", "authors": ["Rezaul Karim", "Maryam Dialameh", "Yang Liu", "Boxing Chen", "Walid Ahmed"], "title": "EPAS: Efficient Training with Progressive Activation Sharing", "comment": "This is a preprint of a paper accepted at the 39th Canadian Conference on Artificial Intelligence (Canadian AI 2026)", "summary": "We present a novel method for Efficient training with Progressive Activation Sharing (EPAS). This method bridges progressive training paradigm with the phenomenon of redundant QK (or KV ) activations across deeper layers of transformers. EPAS gradually grows a sharing region during training by switching decoder layers to activation sharing mode. This results in throughput increase due to reduced compute. To utilize deeper layer redundancy, the sharing region starts from the deep end of the model and grows towards the shallow end. The EPAS trained models allow for variable region lengths of activation sharing for different compute budgets during inference. Empirical evaluations with QK activation sharing in LLaMA models ranging from 125M to 7B parameters show up to an 11.1% improvement in training throughput and up to a 29% improvement in inference throughput while maintaining similar loss curve to the baseline models. Furthermore, applying EPAS in continual pretraining to transform TinyLLaMA into an attention-sharing model yields up to a 10% improvement in average accuracy over state-of-the-art methods, emphasizing the significance of progressive training in cross layer activation sharing models.", "AI": {"tldr": "EPAS is a progressive training method that gradually enables activation sharing in transformer layers, starting from deep layers and moving toward shallow ones, improving training and inference throughput while maintaining performance.", "motivation": "To leverage the phenomenon of redundant QK/KV activations across deeper transformer layers to reduce computational overhead while maintaining model performance.", "method": "Progressive training that gradually grows a sharing region by switching decoder layers to activation sharing mode, starting from deep layers and expanding toward shallow layers during training.", "result": "Up to 11.1% training throughput improvement and 29% inference throughput improvement in LLaMA models (125M-7B parameters) while maintaining similar loss curves; 10% average accuracy improvement in continual pretraining of TinyLLaMA.", "conclusion": "EPAS effectively bridges progressive training with activation sharing, demonstrating significant throughput improvements while maintaining performance, highlighting the importance of progressive training for cross-layer activation sharing models."}}
{"id": "2601.19810", "categories": ["cs.LG", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19810", "abs": "https://arxiv.org/abs/2601.19810", "authors": ["Octavio Pappalardo"], "title": "Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals", "comment": "To appear at ICLR 2026", "summary": "Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream tasks where solving every task zero-shot is infeasible. Such settings naturally arise when the target tasks lie outside of the pre-training distribution or when their identities are unknown to the agent. In this work, we (i) optimize for efficient multi-episode exploration and adaptation within a meta-learning framework, and (ii) guide the training curriculum with evolving estimates of the agent's post-adaptation performance. We present ULEE, an unsupervised meta-learning method that combines an in-context learner with an adversarial goal-generation strategy that maintains training at the frontier of the agent's capabilities. On XLand-MiniGrid benchmarks, ULEE pre-training yields improved exploration and adaptation abilities that generalize to novel objectives, environment dynamics, and map structures. The resulting policy attains improved zero-shot and few-shot performance, and provides a strong initialization for longer fine-tuning processes. It outperforms learning from scratch, DIAYN pre-training, and alternative curricula.", "AI": {"tldr": "ULEE: Unsupervised meta-learning method that combines in-context learning with adversarial goal generation to improve exploration and adaptation for reinforcement learning agents on novel downstream tasks.", "motivation": "Unsupervised pre-training can accelerate RL learning, but current methods struggle when downstream tasks are outside the pre-training distribution or their identities are unknown. Need efficient exploration and adaptation for broad task distributions where zero-shot solving is infeasible.", "method": "ULEE combines: (1) meta-learning framework for multi-episode exploration/adaptation, (2) in-context learner, (3) adversarial goal-generation strategy that maintains training at frontier of agent's capabilities, guided by evolving estimates of post-adaptation performance.", "result": "On XLand-MiniGrid benchmarks, ULEE yields improved exploration/adaptation abilities that generalize to novel objectives, dynamics, and map structures. Achieves better zero-shot/few-shot performance and provides strong initialization for fine-tuning, outperforming learning from scratch, DIAYN, and alternative curricula.", "conclusion": "ULEE's unsupervised meta-learning approach with adversarial goal generation effectively prepares RL agents for novel downstream tasks, demonstrating strong generalization across diverse task variations and providing superior initialization for adaptation."}}
{"id": "2601.19365", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19365", "abs": "https://arxiv.org/abs/2601.19365", "authors": ["Jinming Zhang", "Xi Yang", "Youpeng Yang", "Haosen Shi", "Yuyao Yan", "Qiufeng Wang", "Guangliang Cheng", "Kaizhu Huang"], "title": "Pareto-Guided Optimization for Uncertainty-Aware Medical Image Segmentation", "comment": null, "summary": "Uncertainty in medical image segmentation is inherently non-uniform, with boundary regions exhibiting substantially higher ambiguity than interior areas. Conventional training treats all pixels equally, leading to unstable optimization during early epochs when predictions are unreliable. We argue that this instability hinders convergence toward Pareto-optimal solutions and propose a region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones, reducing gradient variance. Methodologically, we introduce a Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping the loss landscape and constraining convergence dynamics between interior and boundary regions; this guides the model toward Pareto-approximate solutions. To address boundary ambiguity, we further develop a fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries, stabilizing gradients, and expanding flat regions in the loss surface. Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations, with our method outperforming traditional crisp-set approaches in all tumor subregions.", "AI": {"tldr": "A region-wise curriculum learning approach for medical image segmentation that prioritizes certain regions over uncertain ones, using Pareto-consistent loss and fuzzy labeling to handle boundary ambiguity.", "motivation": "Medical image segmentation uncertainty is non-uniform (higher at boundaries than interiors), but conventional training treats all pixels equally, causing unstable optimization during early epochs when predictions are unreliable. This instability hinders convergence toward Pareto-optimal solutions.", "method": "1) Region-wise curriculum strategy that prioritizes learning from certain regions and gradually incorporates uncertain ones to reduce gradient variance. 2) Pareto-consistent loss that balances trade-offs between regional uncertainties by adaptively reshaping loss landscape and constraining convergence dynamics. 3) Fuzzy labeling mechanism that maintains binary confidence in non-boundary areas while enabling smooth transitions near boundaries to stabilize gradients and expand flat regions in loss surface.", "result": "Experiments on brain metastasis and non-metastatic tumor segmentation show consistent improvements across multiple configurations. The method outperforms traditional crisp-set approaches in all tumor subregions.", "conclusion": "The proposed region-wise curriculum learning with Pareto-consistent loss and fuzzy labeling effectively addresses non-uniform uncertainty in medical image segmentation, particularly boundary ambiguity, leading to more stable optimization and better performance than conventional approaches."}}
{"id": "2601.19090", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19090", "abs": "https://arxiv.org/abs/2601.19090", "authors": ["Bochao Liu", "Shiming Ge", "Pengju Wang", "Shikun Li", "Tongliang Liu"], "title": "Privacy-Preserving Model Transcription with Differentially Private Synthetic Distillation", "comment": "Accepted by IEEE Trans. Pattern Anal. Mach. Intell. (TPAMI)", "summary": "While many deep learning models trained on private datasets have been deployed in various practical tasks, they may pose a privacy leakage risk as attackers could recover informative data or label knowledge from models. In this work, we present \\emph{privacy-preserving model transcription}, a data-free model-to-model conversion solution to facilitate model deployment with a privacy guarantee. To this end, we propose a cooperative-competitive learning approach termed \\emph{differentially private synthetic distillation} that learns to convert a pretrained model (teacher) into its privacy-preserving counterpart (student) via a trainable generator without access to private data. The learning collaborates with three players in a unified framework and performs alternate optimization: i)~the generator is learned to generate synthetic data, ii)~the teacher and student accept the synthetic data and compute differential private labels by flexible data or label noisy perturbation, and iii)~the student is updated with noisy labels and the generator is updated by taking the student as a discriminator for adversarial training. We theoretically prove that our approach can guarantee differential privacy and convergence. The transcribed student has good performance and privacy protection, while the resulting generator can generate private synthetic data for downstream tasks. Extensive experiments clearly demonstrate that our approach outperforms 26 state-of-the-arts.", "AI": {"tldr": "A data-free model-to-model conversion method that transforms pretrained models into privacy-preserving versions without accessing original private data, using differential privacy guarantees.", "motivation": "Deep learning models trained on private datasets pose privacy leakage risks where attackers could recover sensitive data or label information from deployed models. There's a need for privacy-preserving model deployment solutions that don't require access to original private data.", "method": "Proposes \"differentially private synthetic distillation\" - a cooperative-competitive learning approach with three players: 1) a generator that creates synthetic data, 2) a teacher model (original pretrained model) and student model (privacy-preserving version) that compute differentially private labels via data/label noisy perturbation, and 3) adversarial training where the generator is updated using the student as discriminator. Uses alternate optimization without accessing private data.", "result": "Theoretically proven differential privacy and convergence guarantees. The transcribed student model maintains good performance while providing privacy protection. The generator can produce private synthetic data for downstream tasks. Extensive experiments show the approach outperforms 26 state-of-the-art methods.", "conclusion": "Privacy-preserving model transcription enables safe deployment of deep learning models by converting them into privacy-protected versions without needing original private data, offering both theoretical privacy guarantees and practical performance."}}
{"id": "2601.19887", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.19887", "abs": "https://arxiv.org/abs/2601.19887", "authors": ["Dominic Maggio", "Luca Carlone"], "title": "VGGT-SLAM 2.0: Real time Dense Feed-forward Scene Reconstruction", "comment": null, "summary": "We present VGGT-SLAM 2.0, a real time RGB feed-forward SLAM system which substantially improves upon VGGT-SLAM for incrementally aligning submaps created from VGGT. Firstly, we remove high-dimensional 15-degree-of-freedom drift and planar degeneracy from VGGT-SLAM by creating a new factor graph design while still addressing the reconstruction ambiguity of VGGT given unknown camera intrinsics. Secondly, by studying the attention layers of VGGT, we show that one of the layers is well suited to assist in image retrieval verification for free without additional training, which enables both rejecting false positive matches and allows for completing more loop closures. Finally, we conduct a suite of experiments which includes showing VGGT-SLAM 2.0 can easily be adapted for open-set object detection and demonstrating real time performance while running online onboard a ground robot using a Jetson Thor. We also test in environments ranging from cluttered indoor apartments and office scenes to a 4,200 square foot barn, and we also demonstrate VGGT-SLAM 2.0 achieves the highest accuracy on the TUM dataset with about 23 percent less pose error than VGGT-SLAM. Code will be released upon publication.", "AI": {"tldr": "VGGT-SLAM 2.0 improves upon VGGT-SLAM with better factor graph design to remove drift and planar degeneracy, uses attention layers for free image retrieval verification, and achieves real-time performance with 23% less pose error on TUM dataset.", "motivation": "To address limitations in VGGT-SLAM including high-dimensional drift, planar degeneracy, and reconstruction ambiguity, while improving loop closure detection and enabling real-time performance on resource-constrained hardware.", "method": "1) New factor graph design to remove 15-DoF drift and planar degeneracy while handling reconstruction ambiguity with unknown camera intrinsics. 2) Leveraging VGGT's attention layers for image retrieval verification without additional training to reject false positives and enable more loop closures. 3) Real-time implementation on Jetson Thor hardware.", "result": "Achieves 23% less pose error than VGGT-SLAM on TUM dataset, demonstrates real-time performance on ground robot with Jetson Thor, works in diverse environments (indoor apartments, offices, 4200 sq ft barn), and can be adapted for open-set object detection.", "conclusion": "VGGT-SLAM 2.0 significantly improves SLAM performance through better factor graph design and attention-based verification, enabling robust real-time operation across diverse environments with reduced pose error."}}
{"id": "2601.19378", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19378", "abs": "https://arxiv.org/abs/2601.19378", "authors": ["Ziyang Xu", "Mingquan Lin", "Yiliang Zhou", "Zihan Xu", "Seth J. Orlow", "Zihan Xu", "Shane A. Meehan", "Alexandra Flamm", "Ata S. Moshiri", "Yifan Peng"], "title": "Establishing dermatopathology encyclopedia DermpathNet with Artificial Intelligence-Based Workflow", "comment": "Accepted by Scientific Data", "summary": "Accessing high-quality, open-access dermatopathology image datasets for learning and cross-referencing is a common challenge for clinicians and dermatopathology trainees. To establish a comprehensive open-access dermatopathology dataset for educational, cross-referencing, and machine-learning purposes, we employed a hybrid workflow to curate and categorize images from the PubMed Central (PMC) repository. We used specific keywords to extract relevant images, and classified them using a novel hybrid method that combined deep learning-based image modality classification with figure caption analyses. Validation on 651 manually annotated images demonstrated the robustness of our workflow, with an F-score of 89.6\\% for the deep learning approach, 61.0\\% for the keyword-based retrieval method, and 90.4\\% for the hybrid approach. We retrieved over 7,772 images across 166 diagnoses and released this fully annotated dataset, reviewed by board-certified dermatopathologists. Using our dataset as a challenging task, we found the current image analysis algorithm from OpenAI inadequate for analyzing dermatopathology images. In conclusion, we have developed a large, peer-reviewed, open-access dermatopathology image dataset, DermpathNet, which features a semi-automated curation workflow.", "AI": {"tldr": "Researchers created DermpathNet, a large open-access dermatopathology image dataset using a hybrid curation workflow combining deep learning and caption analysis, achieving 90.4% accuracy and containing 7,772 images across 166 diagnoses.", "motivation": "Clinicians and trainees face challenges accessing high-quality, open-access dermatopathology image datasets for education, cross-referencing, and machine learning applications.", "method": "Hybrid workflow using PubMed Central repository: keyword-based image extraction combined with deep learning image modality classification and figure caption analysis for categorization.", "result": "Created DermpathNet with 7,772 images across 166 diagnoses; validation showed 90.4% F-score for hybrid approach; dataset reviewed by board-certified dermatopathologists; found current OpenAI image analysis inadequate for dermatopathology.", "conclusion": "Developed a large, peer-reviewed, open-access dermatopathology image dataset (DermpathNet) with semi-automated curation workflow to address educational and research needs in dermatopathology."}}
{"id": "2601.19091", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19091", "abs": "https://arxiv.org/abs/2601.19091", "authors": ["Zhao Wei", "Chin Chun Ooi", "Jian Cheng Wong", "Abhishek Gupta", "Pao-Hsiung Chiu", "Yew-Soon Ong"], "title": "Out-of-Distribution Generalization for Neural Physics Solvers", "comment": null, "summary": "Neural physics solvers are increasingly used in scientific discovery, given their potential for rapid in silico insights into physical, materials, or biological systems and their long-time evolution. However, poor generalization beyond their training support limits exploration of novel designs and long-time horizon predictions. We introduce NOVA, a route to generalizable neural physics solvers that can provide rapid, accurate solutions to scenarios even under distributional shifts in partial differential equation parameters, geometries and initial conditions. By learning physics-aligned representations from an initial sparse set of scenarios, NOVA consistently achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex, nonlinear problems including heat transfer, diffusion-reaction and fluid flow. We further showcase NOVA's dual impact on stabilizing long-time dynamical rollouts and improving generative design through application to the simulation of nonlinear Turing systems and fluidic chip optimization. Unlike neural physics solvers that are constrained to retrieval and/or emulation within an a priori space, NOVA enables reliable extrapolation beyond known regimes, a key capability given the need for exploration of novel hypothesis spaces in scientific discovery", "AI": {"tldr": "NOVA is a neural physics solver that achieves strong generalization beyond training data for solving PDEs under distribution shifts in parameters, geometries, and initial conditions.", "motivation": "Current neural physics solvers have poor generalization beyond their training support, which limits exploration of novel designs and long-time horizon predictions in scientific discovery applications.", "method": "NOVA learns physics-aligned representations from an initial sparse set of scenarios, enabling generalizable neural physics solving that can handle distributional shifts.", "result": "NOVA achieves 1-2 orders of magnitude lower out-of-distribution errors than data-driven baselines across complex nonlinear problems including heat transfer, diffusion-reaction, and fluid flow.", "conclusion": "NOVA enables reliable extrapolation beyond known regimes, which is crucial for exploring novel hypothesis spaces in scientific discovery, unlike traditional neural physics solvers constrained to retrieval/emulation within a priori spaces."}}
{"id": "2601.19380", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19380", "abs": "https://arxiv.org/abs/2601.19380", "authors": ["Fakrul Islam Tushar", "Joseph Y. Lo"], "title": "Tri-Reader: An Open-Access, Multi-Stage AI Pipeline for First-Pass Lung Nodule Annotation in Screening CT", "comment": "1 figure , 2 tables, 20 page supplement", "summary": "Using multiple open-access models trained on public datasets, we developed Tri-Reader, a comprehensive, freely available pipeline that integrates lung segmentation, nodule detection, and malignancy classification into a unified tri-stage workflow. The pipeline is designed to prioritize sensitivity while reducing the candidate burden for annotators. To ensure accuracy and generalizability across diverse practices, we evaluated Tri-Reader on multiple internal and external datasets as compared with expert annotations and dataset-provided reference standards.", "AI": {"tldr": "Tri-Reader is a free, three-stage AI pipeline for lung cancer screening that integrates lung segmentation, nodule detection, and malignancy classification to improve sensitivity while reducing annotation workload.", "motivation": "To create an accessible, comprehensive AI solution for lung cancer screening that addresses the need for sensitive detection while minimizing the burden on human annotators, using open-source models and public datasets.", "method": "Developed a tri-stage workflow integrating lung segmentation, nodule detection, and malignancy classification using multiple open-access models trained on public datasets. The pipeline prioritizes sensitivity while reducing candidate burden for annotators.", "result": "Evaluated on multiple internal and external datasets compared with expert annotations and dataset-provided reference standards to ensure accuracy and generalizability across diverse practices.", "conclusion": "Tri-Reader represents a freely available, comprehensive pipeline for lung cancer screening that demonstrates good performance across diverse datasets while reducing annotation workload through its integrated three-stage approach."}}
{"id": "2601.19094", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19094", "abs": "https://arxiv.org/abs/2601.19094", "authors": ["Jingcheng Yu", "Mingliang Zeng", "Qiwei Ye"], "title": "FloydNet: A Learning Paradigm for Global Relational Reasoning", "comment": "29 pages, 9 figures, 14 tables", "summary": "Developing models capable of complex, multi-step reasoning is a central goal in artificial intelligence. While representing problems as graphs is a powerful approach, Graph Neural Networks (GNNs) are fundamentally constrained by their message-passing mechanism, which imposes a local bottleneck that limits global, holistic reasoning. We argue that dynamic programming (DP), which solves problems by iteratively refining a global state, offers a more powerful and suitable learning paradigm. We introduce FloydNet, a new architecture that embodies this principle. In contrast to local message passing, FloydNet maintains a global, all-pairs relationship tensor and learns a generalized DP operator to progressively refine it. This enables the model to develop a task-specific relational calculus, providing a principled framework for capturing long-range dependencies. Theoretically, we prove that FloydNet achieves 3-WL (2-FWL) expressive power, and its generalized form aligns with the k-FWL hierarchy. FloydNet demonstrates state-of-the-art performance across challenging domains: it achieves near-perfect scores (often >99\\%) on the CLRS-30 algorithmic benchmark, finds exact optimal solutions for the general Traveling Salesman Problem (TSP) at rates significantly exceeding strong heuristics, and empirically matches the 3-WL test on the BREC benchmark. Our results establish this learned, DP-style refinement as a powerful and practical alternative to message passing for high-level graph reasoning.", "AI": {"tldr": "FloydNet introduces a new neural architecture based on dynamic programming principles that outperforms traditional GNNs by maintaining global all-pairs relationships and achieving 3-WL expressive power.", "motivation": "GNNs are limited by their local message-passing mechanism which creates a bottleneck for global reasoning. The authors argue that dynamic programming, which refines global states iteratively, offers a more powerful learning paradigm for complex multi-step reasoning tasks.", "method": "FloydNet maintains a global all-pairs relationship tensor and learns a generalized dynamic programming operator to progressively refine it. This enables the model to develop task-specific relational calculus and capture long-range dependencies, achieving 3-WL (2-FWL) expressive power.", "result": "State-of-the-art performance: near-perfect scores (>99%) on CLRS-30 algorithmic benchmark, significantly outperforms strong heuristics for exact optimal TSP solutions, and empirically matches 3-WL test on BREC benchmark.", "conclusion": "Learned dynamic programming-style refinement is a powerful and practical alternative to message passing for high-level graph reasoning, establishing a new paradigm for complex reasoning tasks."}}
{"id": "2601.19430", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19430", "abs": "https://arxiv.org/abs/2601.19430", "authors": ["Yao Xiao", "Weiyan Chen", "Jiahao Chen", "Zijie Cao", "Weijian Deng", "Binbin Yang", "Ziyi Dong", "Xiangyang Ji", "Wei Ke", "Pengxu Wei", "Liang Lin"], "title": "Unveiling Perceptual Artifacts: A Fine-Grained Benchmark for Interpretable AI-Generated Image Detection", "comment": null, "summary": "Current AI-Generated Image (AIGI) detection approaches predominantly rely on binary classification to distinguish real from synthetic images, often lacking interpretable or convincing evidence to substantiate their decisions. This limitation stems from existing AIGI detection benchmarks, which, despite featuring a broad collection of synthetic images, remain restricted in their coverage of artifact diversity and lack detailed, localized annotations. To bridge this gap, we introduce a fine-grained benchmark towards eXplainable AI-Generated image Detection, named X-AIGD, which provides pixel-level, categorized annotations of perceptual artifacts, spanning low-level distortions, high-level semantics, and cognitive-level counterfactuals. These comprehensive annotations facilitate fine-grained interpretability evaluation and deeper insight into model decision-making processes. Our extensive investigation using X-AIGD provides several key insights: (1) Existing AIGI detectors demonstrate negligible reliance on perceptual artifacts, even at the most basic distortion level. (2) While AIGI detectors can be trained to identify specific artifacts, they still substantially base their judgment on uninterpretable features. (3) Explicitly aligning model attention with artifact regions can increase the interpretability and generalization of detectors. The data and code are available at: https://github.com/Coxy7/X-AIGD.", "AI": {"tldr": "X-AIGD introduces a fine-grained benchmark for explainable AI-generated image detection with pixel-level artifact annotations, revealing that current detectors ignore perceptual artifacts and proposing attention alignment to improve interpretability.", "motivation": "Current AIGI detection methods lack interpretability and convincing evidence for their decisions due to limited benchmark coverage of artifact diversity and absence of detailed localized annotations.", "method": "Created X-AIGD benchmark with pixel-level categorized annotations of perceptual artifacts across three levels: low-level distortions, high-level semantics, and cognitive-level counterfactuals.", "result": "Three key findings: (1) Existing detectors show negligible reliance on perceptual artifacts; (2) Even when trained on specific artifacts, detectors still use uninterpretable features; (3) Aligning model attention with artifact regions improves interpretability and generalization.", "conclusion": "X-AIGD enables fine-grained interpretability evaluation and reveals the need for more explainable AIGI detection methods that explicitly focus on perceptual artifacts rather than uninterpretable features."}}
{"id": "2601.19102", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19102", "abs": "https://arxiv.org/abs/2601.19102", "authors": ["Lecheng Zheng", "Dongqi Fu", "Zihao Li", "Jingrui He"], "title": "OWLEYE: Zero-Shot Learner for Cross-Domain Graph Data Anomaly Detection", "comment": "Accepted by ICLR 2026", "summary": "Graph data is informative to represent complex relationships such as transactions between accounts, communications between devices, and dependencies among machines or processes. Correspondingly, graph anomaly detection (GAD) plays a critical role in identifying anomalies across various domains, including finance, cybersecurity, manufacturing, etc. Facing the large-volume and multi-domain graph data, nascent efforts attempt to develop foundational generalist models capable of detecting anomalies in unseen graphs without retraining. To the best of our knowledge, the different feature semantics and dimensions of cross-domain graph data heavily hinder the development of the graph foundation model, leaving further in-depth continual learning and inference capabilities a quite open problem. Hence, we propose OWLEYE, a novel zero-shot GAD framework that learns transferable patterns of normal behavior from multiple graphs, with a threefold contribution. First, OWLEYE proposes a cross-domain feature alignment module to harmonize feature distributions, which preserves domain-specific semantics during alignment. Second, with aligned features, to enable continuous learning capabilities, OWLEYE designs the multi-domain multi-pattern dictionary learning to encode shared structural and attribute-based patterns. Third, for achieving the in-context learning ability, OWLEYE develops a truncated attention-based reconstruction module to robustly detect anomalies without requiring labeled data for unseen graph-structured data. Extensive experiments on real-world datasets demonstrate that OWLEYE achieves superior performance and generalizability compared to state-of-the-art baselines, establishing a strong foundation for scalable and label-efficient anomaly detection.", "AI": {"tldr": "OWLEYE is a zero-shot graph anomaly detection framework that learns transferable normal behavior patterns from multiple graphs, enabling anomaly detection in unseen graphs without retraining through cross-domain feature alignment, multi-pattern dictionary learning, and attention-based reconstruction.", "motivation": "Graph anomaly detection is critical across domains like finance and cybersecurity, but developing foundational models is hindered by varying feature semantics and dimensions across different graph domains. Existing approaches struggle with zero-shot detection, continual learning, and inference capabilities for unseen graphs.", "method": "1) Cross-domain feature alignment module to harmonize feature distributions while preserving domain-specific semantics; 2) Multi-domain multi-pattern dictionary learning to encode shared structural and attribute-based patterns for continuous learning; 3) Truncated attention-based reconstruction module for in-context learning to detect anomalies without labeled data for unseen graphs.", "result": "Extensive experiments on real-world datasets demonstrate that OWLEYE achieves superior performance and generalizability compared to state-of-the-art baselines, establishing a strong foundation for scalable and label-efficient anomaly detection.", "conclusion": "OWLEYE successfully addresses the challenges of cross-domain graph anomaly detection by providing a zero-shot framework with transferable pattern learning, enabling effective anomaly detection in unseen graphs without retraining, and outperforming existing methods."}}
{"id": "2601.19433", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19433", "abs": "https://arxiv.org/abs/2601.19433", "authors": ["Jisheng Chu", "Wenrui Li", "Rui Zhao", "Wangmeng Zuo", "Shifeng Chen", "Xiaopeng Fan"], "title": "RoamScene3D: Immersive Text-to-3D Scene Generation via Adaptive Object-aware Roaming", "comment": null, "summary": "Generating immersive 3D scenes from texts is a core task in computer vision, crucial for applications in virtual reality and game development. Despite the promise of leveraging 2D diffusion priors, existing methods suffer from spatial blindness and rely on predefined trajectories that fail to exploit the inner relationships among salient objects. Consequently, these approaches are unable to comprehend the semantic layout, preventing them from exploring the scene adaptively to infer occluded content. Moreover, current inpainting models operate in 2D image space, struggling to plausibly fill holes caused by camera motion. To address these limitations, we propose RoamScene3D, a novel framework that bridges the gap between semantic guidance and spatial generation. Our method reasons about the semantic relations among objects and produces consistent and photorealistic scenes. Specifically, we employ a vision-language model (VLM) to construct a scene graph that encodes object relations, guiding the camera to perceive salient object boundaries and plan an adaptive roaming trajectory. Furthermore, to mitigate the limitations of static 2D priors, we introduce a Motion-Injected Inpainting model that is fine-tuned on a synthetic panoramic dataset integrating authentic camera trajectories, making it adaptive to camera motion. Extensive experiments demonstrate that with semantic reasoning and geometric constraints, our method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic scenes. Our code is available at https://github.com/JS-CHU/RoamScene3D.", "AI": {"tldr": "RoamScene3D: A novel 3D scene generation framework that uses semantic reasoning and adaptive camera trajectories to overcome spatial blindness in existing text-to-3D methods.", "motivation": "Existing text-to-3D scene generation methods suffer from spatial blindness, rely on predefined trajectories that ignore object relationships, and struggle with occluded content. Current 2D inpainting models can't plausibly fill holes caused by camera motion.", "method": "Uses a vision-language model to construct scene graphs encoding object relations, guiding adaptive camera roaming trajectories. Introduces Motion-Injected Inpainting model fine-tuned on synthetic panoramic data with authentic camera trajectories to handle camera motion.", "result": "Extensive experiments show the method significantly outperforms state-of-the-art approaches in producing consistent and photorealistic 3D scenes from text descriptions.", "conclusion": "RoamScene3D successfully bridges semantic guidance with spatial generation through semantic reasoning and geometric constraints, enabling adaptive exploration and high-quality 3D scene generation from text."}}
{"id": "2601.19107", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19107", "abs": "https://arxiv.org/abs/2601.19107", "authors": ["Vijay Janapa Reddi"], "title": "TinyTorch: Building Machine Learning Systems from First Principles", "comment": null, "summary": "Machine learning systems engineering requires a deep understanding of framework internals. Yet most current education separates algorithms from systems. Students learn gradient descent without measuring memory usage, and attention mechanisms without profiling computational cost. This split leaves graduates unprepared to debug real production failures and widens the gap between machine learning research and reliable deployment. We present TinyTorch, a 20 module curriculum in which students implement the core components of PyTorch, including tensors, autograd, optimizers, and neural networks, entirely in pure Python. The curriculum is built around three pedagogical principles. Progressive disclosure gradually introduces complexity as students build confidence. Systems first integration embeds memory and performance awareness from the very beginning. Historical milestone validation guides students to recreate key breakthroughs, from the Perceptron in 1958 to modern Transformers, using only code they have written themselves. TinyTorch requires only a laptop with 4GB of RAM and no GPU, making machine learning systems education accessible worldwide. Its goal is to prepare the next generation of AI engineers, practitioners who understand not only what machine learning systems do, but why they work and how to make them scale. The curriculum is available as open source at mlsysbook.ai slash tinytorch.", "AI": {"tldr": "TinyTorch is a 20-module curriculum teaching ML systems engineering by having students implement PyTorch core components in pure Python, focusing on bridging the gap between algorithms and systems.", "motivation": "Current ML education separates algorithms from systems, leaving graduates unprepared for real production debugging and creating a gap between research and reliable deployment. There's a need for engineers who understand both what ML systems do and how they work at a systems level.", "method": "A 20-module curriculum where students implement PyTorch core components (tensors, autograd, optimizers, neural networks) entirely in pure Python. Built on three pedagogical principles: progressive disclosure (gradual complexity introduction), systems-first integration (embedding memory/performance awareness from start), and historical milestone validation (recreating key breakthroughs from 1958 Perceptron to modern Transformers).", "result": "TinyTorch requires only a laptop with 4GB RAM and no GPU, making ML systems education accessible worldwide. The curriculum is available as open source at mlsysbook.ai/tinytorch.", "conclusion": "TinyTorch aims to prepare the next generation of AI engineers who understand not only what ML systems do, but why they work and how to make them scale, bridging the gap between ML research and reliable deployment."}}
{"id": "2601.19446", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19446", "abs": "https://arxiv.org/abs/2601.19446", "authors": ["Yalin Luo", "Shun Long", "Huijin Wang", "Jieyun Bai"], "title": "DSTCS: Dual-Student Teacher Framework with Segment Anything Model for Semi-Supervised Pubic Symphysis Fetal Head Segmentation", "comment": null, "summary": "Segmentation of the pubic symphysis and fetal head (PSFH) is a critical procedure in intrapartum monitoring and is essential for evaluating labor progression and identifying potential delivery complications. However, achieving accurate segmentation remains a significant challenge due to class imbalance, ambiguous boundaries, and noise interference in ultrasound images, compounded by the scarcity of high-quality annotated data. Current research on PSFH segmentation predominantly relies on CNN and Transformer architectures, leaving the potential of more powerful models underexplored. In this work, we propose a Dual-Student and Teacher framework combining CNN and SAM (DSTCS), which integrates the Segment Anything Model (SAM) into a dual student-teacher architecture. A cooperative learning mechanism between the CNN and SAM branches significantly improves segmentation accuracy. The proposed scheme also incorporates a specialized data augmentation strategy optimized for boundary processing and a novel loss function. Extensive experiments on the MICCAI 2023 and 2024 PSFH segmentation benchmarks demonstrate that our method exhibits superior robustness and significantly outperforms existing techniques, providing a reliable segmentation tool for clinical practice.", "AI": {"tldr": "A Dual-Student and Teacher framework combining CNN and SAM (DSTCS) for pubic symphysis and fetal head segmentation in ultrasound images, addressing class imbalance, ambiguous boundaries, and data scarcity.", "motivation": "Accurate PSFH segmentation is critical for intrapartum monitoring but challenging due to class imbalance, ambiguous boundaries, noise in ultrasound images, and limited annotated data. Current methods rely on CNN/Transformers, leaving more powerful models underexplored.", "method": "Proposed DSTCS framework integrates Segment Anything Model (SAM) into dual student-teacher architecture with CNN and SAM branches. Includes cooperative learning mechanism, specialized data augmentation for boundary processing, and novel loss function.", "result": "Extensive experiments on MICCAI 2023 and 2024 PSFH segmentation benchmarks show superior robustness and significantly outperforms existing techniques.", "conclusion": "The method provides a reliable segmentation tool for clinical practice by effectively addressing PSFH segmentation challenges through SAM integration and dual student-teacher architecture."}}
{"id": "2601.19139", "categories": ["cs.LG", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.19139", "abs": "https://arxiv.org/abs/2601.19139", "authors": ["Wayner Barrios"], "title": "Native LLM and MLLM Inference at Scale on Apple Silicon", "comment": null, "summary": "The growing adoption of Apple Silicon for machine learning development has created demand for efficient inference solutions that leverage its unique unified memory architecture. However, existing tools either lack native optimization (PyTorch MPS) or focus solely on text models (llama.cpp), leaving multimodal workloads underserved. We present vllm-mlx, a framework for efficient LLM and MLLM inference on Apple Silicon built natively on MLX. For text models, we achieve 21% to 87% higher throughput than llama.cpp across models ranging from Qwen3-0.6B to Nemotron-30B, while providing continuous batching that scales to 4.3x aggregate throughput at 16 concurrent requests. For multimodal models, we introduce content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format. Our evaluation on Apple M4 Max demonstrates throughput of up to 525 tokens per second on text models and 28x speedup on repeated image queries, reducing multimodal latency from 21.7 seconds to under 1 second. Video analysis with up to 64 frames achieves 24.7x cache speedup. We release our implementation as open source to support efficient inference on consumer Apple hardware.", "AI": {"tldr": "vllm-mlx: Efficient LLM and multimodal inference framework for Apple Silicon using MLX, achieving up to 87% higher throughput than llama.cpp and 28x speedup on repeated image queries through content-based prefix caching.", "motivation": "Apple Silicon's growing adoption for ML development creates demand for efficient inference solutions that leverage its unified memory architecture. Existing tools either lack native optimization (PyTorch MPS) or focus only on text models (llama.cpp), leaving multimodal workloads underserved.", "method": "Built natively on MLX for Apple Silicon. For text models: continuous batching that scales with concurrent requests. For multimodal models: content-based prefix caching that eliminates redundant vision encoding by identifying identical images through content hashing, regardless of input format.", "result": "On Apple M4 Max: 21-87% higher throughput than llama.cpp across models from Qwen3-0.6B to Nemotron-30B; 4.3x aggregate throughput at 16 concurrent requests; up to 525 tokens/sec on text models; 28x speedup on repeated image queries (reducing latency from 21.7s to <1s); 24.7x cache speedup on video analysis with up to 64 frames.", "conclusion": "vllm-mlx provides efficient LLM and multimodal inference on Apple Silicon, addressing gaps in existing tools. The framework is released as open source to support efficient inference on consumer Apple hardware."}}
{"id": "2601.19149", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.19149", "abs": "https://arxiv.org/abs/2601.19149", "authors": ["Jingjie Ning", "Xiangzhen Shen", "Li Hou", "Shiyi Shen", "Jiahao Yang", "Junrui Li", "Hong Shan", "Sanan Wu", "Sihan Gao", "Huaqiang Eric Xu", "Xinheng He"], "title": "GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery", "comment": null, "summary": "G protein-coupled receptors (GPCRs) govern diverse physiological processes and are central to modern pharmacology. Yet discovering GPCR modulators remains challenging because receptor activation often arises from complex allosteric effects rather than direct binding affinity, and conventional assays are slow, costly, and not optimized for capturing these dynamics. Here we present GPCR-Filter, a deep learning framework specifically developed for GPCR modulator discovery. We assembled a high-quality dataset of over 90,000 experimentally validated GPCR-ligand pairs, providing a robust foundation for training and evaluation. GPCR-Filter integrates the ESM-3 protein language model for high-fidelity GPCR sequence representations with graph neural networks that encode ligand structures, coupled through an attention-based fusion mechanism that learns receptor-ligand functional relationships. Across multiple evaluation settings, GPCR-Filter consistently outperforms state-of-the-art compound-protein interaction models and exhibits strong generalization to unseen receptors and ligands. Notably, the model successfully identified micromolar-level agonists of the 5-HT\\textsubscript{1A} receptor with distinct chemical frameworks. These results establish GPCR-Filter as a scalable and effective computational approach for GPCR modulator discovery, advancing AI-assisted drug development for complex signaling systems.", "AI": {"tldr": "GPCR-Filter is a deep learning framework that combines protein language models and graph neural networks to predict GPCR-ligand interactions, outperforming existing methods and successfully identifying novel 5-HT1A receptor agonists.", "motivation": "GPCRs are crucial pharmacological targets but discovering modulators is difficult due to complex allosteric effects and limitations of conventional assays (slow, costly, not capturing dynamics).", "method": "Developed GPCR-Filter framework using: 1) High-quality dataset of 90,000+ experimentally validated GPCR-ligand pairs, 2) ESM-3 protein language model for GPCR sequence representations, 3) Graph neural networks for ligand structure encoding, 4) Attention-based fusion mechanism to learn receptor-ligand functional relationships.", "result": "Outperformed state-of-the-art compound-protein interaction models across multiple evaluation settings, demonstrated strong generalization to unseen receptors/ligands, and successfully identified micromolar-level 5-HT1A receptor agonists with distinct chemical frameworks.", "conclusion": "GPCR-Filter establishes a scalable and effective computational approach for GPCR modulator discovery, advancing AI-assisted drug development for complex signaling systems."}}
{"id": "2601.19484", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19484", "abs": "https://arxiv.org/abs/2601.19484", "authors": ["Yin Wang", "Zhiying Leng", "Haitian Liu", "Frederick W. B. Li", "Mu Li", "Xiaohui Liang"], "title": "Dynamic Worlds, Dynamic Humans: Generating Virtual Human-Scene Interaction Motion in Dynamic Scenes", "comment": null, "summary": "Scenes are continuously undergoing dynamic changes in the real world. However, existing human-scene interaction generation methods typically treat the scene as static, which deviates from reality. Inspired by world models, we introduce Dyn-HSI, the first cognitive architecture for dynamic human-scene interaction, which endows virtual humans with three humanoid components. (1)Vision (human eyes): we equip the virtual human with a Dynamic Scene-Aware Navigation, which continuously perceives changes in the surrounding environment and adaptively predicts the next waypoint. (2)Memory (human brain): we equip the virtual human with a Hierarchical Experience Memory, which stores and updates experiential data accumulated during training. This allows the model to leverage prior knowledge during inference for context-aware motion priming, thereby enhancing both motion quality and generalization. (3) Control (human body): we equip the virtual human with Human-Scene Interaction Diffusion Model, which generates high-fidelity interaction motions conditioned on multimodal inputs. To evaluate performance in dynamic scenes, we extend the existing static human-scene interaction datasets to construct a dynamic benchmark, Dyn-Scenes. We conduct extensive qualitative and quantitative experiments to validate Dyn-HSI, showing that our method consistently outperforms existing approaches and generates high-quality human-scene interaction motions in both static and dynamic settings.", "AI": {"tldr": "Dyn-HSI is a cognitive architecture for dynamic human-scene interaction generation that gives virtual humans vision, memory, and control capabilities to handle changing environments.", "motivation": "Existing human-scene interaction methods treat scenes as static, which doesn't reflect real-world dynamic environments where scenes continuously change.", "method": "Three humanoid components: 1) Vision (Dynamic Scene-Aware Navigation) for perceiving environmental changes and predicting waypoints; 2) Memory (Hierarchical Experience Memory) for storing/updating training data to enable context-aware motion priming; 3) Control (Human-Scene Interaction Diffusion Model) for generating high-fidelity motions conditioned on multimodal inputs.", "result": "Method outperforms existing approaches and generates high-quality human-scene interaction motions in both static and dynamic settings, validated on the new Dyn-Scenes benchmark.", "conclusion": "Dyn-HSI successfully addresses the limitation of static scene assumptions in human-scene interaction generation by introducing a cognitive architecture that enables virtual humans to perceive, remember, and interact with dynamically changing environments."}}
{"id": "2601.19175", "categories": ["cs.LG", "cs.AI", "cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.19175", "abs": "https://arxiv.org/abs/2601.19175", "authors": ["Jinkyu Sung", "Myunggeum Jee", "Joonseok Lee"], "title": "A Scalable Inter-edge Correlation Modeling in CopulaGNN for Link Sign Prediction", "comment": "Accepted to ICLR 2026", "summary": "Link sign prediction on a signed graph is a task to determine whether the relationship represented by an edge is positive or negative. Since the presence of negative edges violates the graph homophily assumption that adjacent nodes are similar, regular graph methods have not been applicable without auxiliary structures to handle them. We aim to directly model the latent statistical dependency among edges with the Gaussian copula and its corresponding correlation matrix, extending CopulaGNN. However, a naive modeling of edge-edge relations is computationally intractable even for a graph with moderate scale. To address this, we propose to 1) represent the correlation matrix as a Gramian of edge embeddings, significantly reducing the number of parameters, and 2) reformulate the conditional probability distribution to dramatically reduce the inference cost. We theoretically verify scalability of our method by proving its linear convergence. Also, our extensive experiments demonstrate that it achieves significantly faster convergence than baselines, maintaining competitive prediction performance to the state-of-the-art models.", "AI": {"tldr": "Proposed a scalable Gaussian copula-based method for link sign prediction on signed graphs that reduces computational complexity while maintaining competitive performance.", "motivation": "Signed graphs with negative edges violate the homophily assumption, making regular graph methods inapplicable without auxiliary structures. Existing copula-based approaches face computational intractability for moderate-scale graphs.", "method": "1) Model edge-edge dependencies using Gaussian copula with correlation matrix represented as Gramian of edge embeddings to reduce parameters. 2) Reformulate conditional probability distribution to dramatically reduce inference cost. 3) Prove linear convergence theoretically.", "result": "Achieves significantly faster convergence than baselines while maintaining competitive prediction performance to state-of-the-art models. Extensive experiments validate scalability and efficiency.", "conclusion": "Proposed method provides a scalable solution for link sign prediction on signed graphs by addressing computational challenges of edge-edge dependency modeling while preserving accuracy."}}
{"id": "2601.19488", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19488", "abs": "https://arxiv.org/abs/2601.19488", "authors": ["Yizhao Han", "Tianxing Shi", "Zhao Wang", "Zifan Xu", "Zhiyuan Pu", "Mingxiao Li", "Qian Zhang", "Wei Yin", "Xiao-Xiao Long"], "title": "Entropy-Guided k-Guard Sampling for Long-Horizon Autoregressive Video Generation", "comment": null, "summary": "Autoregressive (AR) architectures have achieved significant successes in LLMs, inspiring explorations for video generation. In LLMs, top-p/top-k sampling strategies work exceptionally well: language tokens have high semantic density and low redundancy, so a fixed size of token candidates already strikes a balance between semantic accuracy and generation diversity. In contrast, video tokens have low semantic density and high spatio-temporal redundancy. This mismatch makes static top-k/top-p strategies ineffective for video decoders: they either introduce unnecessary randomness for low-uncertainty regions (static backgrounds) or get stuck in early errors for high-uncertainty regions (foreground objects). Prediction errors will accumulate as more frames are generated and eventually severely degrade long-horizon quality. To address this, we propose Entropy-Guided k-Guard (ENkG) sampling, a simple yet effective strategy that adapts sampling to token-wise dispersion, quantified by the entropy of each token's predicted distribution. ENkG uses adaptive token candidate sizes: for low-entropy regions, it employs fewer candidates to suppress redundant noise and preserve structural integrity; for high-entropy regions, it uses more candidates to mitigate error compounding. ENkG is model-agnostic, training-free, and adds negligible overhead. Experiments demonstrate consistent improvements in perceptual quality and structural stability compared to static top-k/top-p strategies.", "AI": {"tldr": "ENkG sampling adapts token candidate sizes based on entropy to address limitations of static top-k/top-p strategies in autoregressive video generation, improving long-horizon quality.", "motivation": "Static top-k/top-p sampling strategies that work well for language models fail for video generation due to fundamental differences: video tokens have low semantic density and high spatio-temporal redundancy, causing either unnecessary randomness in static backgrounds or error compounding in dynamic foregrounds.", "method": "Entropy-Guided k-Guard (ENkG) sampling adapts token candidate sizes based on token-wise dispersion measured by entropy. For low-entropy regions (static backgrounds), it uses fewer candidates to suppress noise; for high-entropy regions (foreground objects), it uses more candidates to mitigate error accumulation.", "result": "ENkG consistently improves perceptual quality and structural stability compared to static top-k/top-p strategies. It's model-agnostic, training-free, and adds negligible computational overhead.", "conclusion": "Adaptive sampling based on token entropy is crucial for autoregressive video generation to handle the unique characteristics of video tokens, addressing the mismatch between language and video domains for better long-horizon quality."}}
{"id": "2601.19179", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19179", "abs": "https://arxiv.org/abs/2601.19179", "authors": ["Qipeng Zhan", "Zhuoping Zhou", "Zexuan Wang", "Li Shen"], "title": "Learning Ordered Representations in Latent Space for Intrinsic Dimension Estimation via Principal Component Autoencoder", "comment": null, "summary": "Autoencoders have long been considered a nonlinear extension of Principal Component Analysis (PCA). Prior studies have demonstrated that linear autoencoders (LAEs) can recover the ordered, axis-aligned principal components of PCA by incorporating non-uniform $\\ell_2$ regularization or by adjusting the loss function. However, these approaches become insufficient in the nonlinear setting, as the remaining variance cannot be properly captured independently of the nonlinear mapping. In this work, we propose a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint. This design serves as a natural generalization of PCA, enabling the model to preserve key advantages, such as ordered representations and variance retention, while remaining effective for nonlinear dimensionality reduction tasks.", "AI": {"tldr": "Novel autoencoder framework combines non-uniform variance regularization with isometric constraint to generalize PCA for nonlinear dimensionality reduction while preserving ordered representations and variance retention.", "motivation": "Existing approaches for making autoencoders generalize PCA (like non-uniform \u2113\u2082 regularization or loss adjustments) work for linear autoencoders but fail in nonlinear settings where remaining variance cannot be properly captured independently of the nonlinear mapping.", "method": "Proposes a novel autoencoder framework that integrates non-uniform variance regularization with an isometric constraint, creating a natural generalization of PCA for nonlinear dimensionality reduction.", "result": "The framework enables preservation of key PCA advantages (ordered representations and variance retention) while remaining effective for nonlinear dimensionality reduction tasks.", "conclusion": "The proposed autoencoder framework successfully generalizes PCA to nonlinear settings by combining variance regularization with isometric constraints, overcoming limitations of previous approaches."}}
{"id": "2601.19489", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19489", "abs": "https://arxiv.org/abs/2601.19489", "authors": ["Ziyu Zhang", "Tianle Liu", "Diantao Tu", "Shuhan Shen"], "title": "Fast Converging 3D Gaussian Splatting for 1-Minute Reconstruction", "comment": "First Rank of SIGGRAPH Asia 2025 3DGS Challenge. Code available at", "summary": "We present a fast 3DGS reconstruction pipeline designed to converge within one minute, developed for the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge. The challenge consists of an initial round using SLAM-generated camera poses (with noisy trajectories) and a final round using COLMAP poses (highly accurate). To robustly handle these heterogeneous settings, we develop a two-stage solution. In the first round, we use reverse per-Gaussian parallel optimization and compact forward splatting based on Taming-GS and Speedy-splat, load-balanced tiling, an anchor-based Neural-Gaussian representation enabling rapid convergence with fewer learnable parameters, initialization from monocular depth and partially from feed-forward 3DGS models, and a global pose refinement module for noisy SLAM trajectories. In the final round, the accurate COLMAP poses change the optimization landscape; we disable pose refinement, revert from Neural-Gaussians back to standard 3DGS to eliminate MLP inference overhead, introduce multi-view consistency-guided Gaussian splitting inspired by Fast-GS, and introduce a depth estimator to supervise the rendered depth. Together, these techniques enable high-fidelity reconstruction under a strict one-minute budget. Our method achieved the top performance with a PSNR of 28.43 and ranked first in the competition.", "AI": {"tldr": "Fast 3DGS reconstruction pipeline that converges within 1 minute, winning SIGGRAPH Asia 3DGS Fast Reconstruction Challenge with top PSNR of 28.43.", "motivation": "To develop a fast 3D Gaussian Splatting (3DGS) reconstruction pipeline that can achieve high-fidelity results within a strict one-minute time budget for the SIGGRAPH Asia competition, while handling both noisy SLAM poses and accurate COLMAP poses.", "method": "Two-stage approach: For noisy SLAM poses (Round 1), uses reverse per-Gaussian parallel optimization, compact forward splatting, load-balanced tiling, anchor-based Neural-Gaussian representation, monocular depth initialization, and global pose refinement. For accurate COLMAP poses (Final Round), disables pose refinement, reverts to standard 3DGS, adds multi-view consistency-guided Gaussian splitting, and introduces depth estimator supervision.", "result": "Achieved top performance with PSNR of 28.43 and ranked first in the SIGGRAPH Asia 3DGS Fast Reconstruction Challenge.", "conclusion": "The proposed two-stage pipeline successfully enables high-fidelity 3DGS reconstruction within a strict one-minute budget by adapting techniques to different pose quality scenarios, demonstrating state-of-the-art performance in fast 3D reconstruction."}}
{"id": "2601.19189", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19189", "abs": "https://arxiv.org/abs/2601.19189", "authors": ["Benjamin Turtel", "Paul Wilczewski", "Danny Franklin", "Kris Skotheim"], "title": "Foresight Learning for SEC Risk Prediction", "comment": null, "summary": "Risk disclosures in SEC filings describe potential adverse events but rarely quantify their likelihood, limiting their usefulness for probabilistic analysis. A central obstacle is the absence of large-scale, risk-level supervision linking disclosed risks to realized outcomes.\n  We introduce a fully automated data generation pipeline that converts qualitative SEC risk disclosures into temporally grounded supervision using only public data. For each filing, the pipeline generates firm-specific, time-bounded risk queries from the Risk Factors section and labels them by automatically resolving outcomes against subsequent disclosures.\n  Using this dataset of risk queries and outcomes grounded in SEC filings, we train a compact large language model to estimate the probability that a disclosed risk will materialize within a specified horizon. Despite its modest size, the resulting model substantially improves over pretrained and heuristic baselines, and outperforms frontier general-purpose models, including GPT-5, on probabilistic accuracy and calibration.\n  More broadly, this work demonstrates that Foresight Learning enables scalable and fully automated training of domain-specific expert models using only raw, chronological, in-domain text -- without proprietary data, external corpora, or manual annotation. The resulting models achieve frontier-level performance while remaining deployable on a single GPU. This result suggests a general pathway for learning calibrated, decision-relevant signals from naturally occurring enterprise documents.\n  To support transparency and reproducibility, we open-source the evaluation dataset used in this study.\n  Evaluation Data: https://huggingface.co/datasets/LightningRodLabs/sec_risk_questions_test_set\n  Data Generation Platform: https://lightningrod.ai/\n  SDK: https://github.com/lightning-rod-labs/lightningrod-python-sdk", "AI": {"tldr": "Automated pipeline converts SEC risk disclosures into quantifiable risk queries with outcomes, trains compact LLM to estimate risk materialization probabilities, outperforming larger models.", "motivation": "SEC risk disclosures are qualitative and lack probability quantification, limiting their usefulness for probabilistic analysis due to absence of large-scale risk-level supervision linking disclosed risks to realized outcomes.", "method": "Fully automated data generation pipeline converts SEC risk disclosures into firm-specific, time-bounded risk queries and labels them by resolving outcomes against subsequent disclosures. Uses this dataset to train a compact LLM to estimate risk materialization probabilities.", "result": "The compact model substantially improves over pretrained and heuristic baselines, outperforms frontier general-purpose models (including GPT-5) on probabilistic accuracy and calibration, while remaining deployable on a single GPU.", "conclusion": "Foresight Learning enables scalable, automated training of domain-specific expert models using only raw chronological text without proprietary data or manual annotation, achieving frontier performance and suggesting a general pathway for learning calibrated signals from enterprise documents."}}
{"id": "2601.19498", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19498", "abs": "https://arxiv.org/abs/2601.19498", "authors": ["Fabian Bongratz", "Yitong Li", "Sama Elbaroudy", "Christian Wachinger"], "title": "Cortex-Grounded Diffusion Models for Brain Image Generation", "comment": "preprint", "summary": "Synthetic neuroimaging data can mitigate critical limitations of real-world datasets, including the scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage. However, existing generative models largely rely on weak conditioning signals, such as labels or text, which lack anatomical grounding and often produce biologically implausible outputs. To this end, we introduce Cor2Vox, a cortex-grounded generative framework for brain magnetic resonance image (MRI) synthesis that ties image generation to continuous structural priors of the cerebral cortex. It leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process, enabling topologically faithful synthesis and precise control over underlying anatomies. To support the generation of new, realistic brain shapes, we developed a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans. We validated the fidelity of Cor2Vox based on traditional image quality metrics, advanced cortical surface reconstruction, and whole-brain segmentation quality, outperforming many baseline methods. Across three applications, namely (i) anatomically consistent synthesis, (ii) simulation of progressive gray matter atrophy, and (iii) harmonization of in-house frontotemporal dementia scans with public datasets, Cor2Vox preserved fine-grained cortical morphology at the sub-voxel level, exhibiting remarkable robustness to variations in cortical geometry and disease phenotype without retraining.", "AI": {"tldr": "Cor2Vox is a cortex-grounded generative framework for brain MRI synthesis that uses cortical surface priors to guide a 3D shape-to-image diffusion process, enabling anatomically faithful brain image generation with precise control over cortical morphology.", "motivation": "Existing synthetic neuroimaging data generation methods rely on weak conditioning signals (labels/text) that lack anatomical grounding and produce biologically implausible outputs. There's a need for anatomically faithful brain image synthesis to address limitations of real-world datasets including scarcity of rare phenotypes, domain shifts across scanners, and insufficient longitudinal coverage.", "method": "Cor2Vox uses a cortex-grounded generative framework that leverages high-resolution cortical surfaces to guide a 3D shape-to-image Brownian bridge diffusion process. It incorporates a large-scale statistical shape model of cortical morphology derived from over 33,000 UK Biobank scans to support generation of new, realistic brain shapes.", "result": "Cor2Vox outperformed baseline methods on traditional image quality metrics, cortical surface reconstruction, and whole-brain segmentation quality. It preserved fine-grained cortical morphology at sub-voxel level and demonstrated robustness to variations in cortical geometry and disease phenotype without retraining across three applications: anatomically consistent synthesis, simulation of progressive gray matter atrophy, and harmonization of frontotemporal dementia scans.", "conclusion": "Cor2Vox provides a robust framework for anatomically faithful brain MRI synthesis that can address key limitations in neuroimaging research, enabling precise control over cortical anatomy and supporting applications in rare phenotype simulation, disease progression modeling, and dataset harmonization."}}
{"id": "2601.19220", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19220", "abs": "https://arxiv.org/abs/2601.19220", "authors": ["Dai Hai Nguyen", "Duc Dung Nguyen", "Atsuyoshi Nakamura", "Hiroshi Mamitsuka"], "title": "Accelerated Multiple Wasserstein Gradient Flows for Multi-objective Distributional Optimization", "comment": null, "summary": "We study multi-objective optimization over probability distributions in Wasserstein space. Recently, Nguyen et al. (2025) introduced Multiple Wasserstein Gradient Descent (MWGraD) algorithm, which exploits the geometric structure of Wasserstein space to jointly optimize multiple objectives. Building on this approach, we propose an accelerated variant, A-MWGraD, inspired by Nesterov's acceleration. We analyze the continuous-time dynamics and establish convergence to weakly Pareto optimal points in probability space. Our theoretical results show that A-MWGraD achieves a convergence rate of O(1/t^2) for geodesically convex objectives and O(e^{-\\sqrt\u03b2t}) for $\u03b2$-strongly geodesically convex objectives, improving upon the O(1/t) rate of MWGraD in the geodesically convex setting. We further introduce a practical kernel-based discretization for A-MWGraD and demonstrate through numerical experiments that it consistently outperforms MWGraD in convergence speed and sampling efficiency on multi-target sampling tasks.", "AI": {"tldr": "Proposes A-MWGraD, an accelerated variant of MWGraD for multi-objective optimization in Wasserstein space, achieving faster convergence rates through Nesterov-inspired acceleration.", "motivation": "To improve upon the convergence speed of existing multi-objective optimization methods in Wasserstein space, specifically the MWGraD algorithm which has O(1/t) convergence rate for geodesically convex objectives.", "method": "Develops A-MWGraD (Accelerated Multiple Wasserstein Gradient Descent) by applying Nesterov's acceleration principles to the continuous-time dynamics of MWGraD, with a practical kernel-based discretization for implementation.", "result": "Theoretical analysis shows A-MWGraD achieves O(1/t\u00b2) convergence for geodesically convex objectives and O(e^{-\u221a\u03b2t}) for \u03b2-strongly geodesically convex objectives, outperforming MWGraD's O(1/t) rate. Numerical experiments demonstrate faster convergence and better sampling efficiency on multi-target sampling tasks.", "conclusion": "A-MWGraD successfully accelerates multi-objective optimization in Wasserstein space, providing both theoretical guarantees and practical improvements over the baseline MWGraD algorithm."}}
{"id": "2601.19506", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19506", "abs": "https://arxiv.org/abs/2601.19506", "authors": ["Zhengjian Yao", "Jiakui Hu", "Kaiwen Li", "Hangzhou He", "Xinliang Zhang", "Shuang Zeng", "Lei Zhu", "Yanye Lu"], "title": "Bridging Information Asymmetry: A Hierarchical Framework for Deterministic Blind Face Restoration", "comment": null, "summary": "Blind face restoration remains a persistent challenge due to the inherent ill-posedness of reconstructing holistic structures from severely constrained observations. Current generative approaches, while capable of synthesizing realistic textures, often suffer from information asymmetry -- the intrinsic disparity between the information-sparse low quality inputs and the information-dense high quality outputs. This imbalance leads to a one-to-many mapping, where insufficient constraints result in stochastic uncertainty and hallucinatory artifacts. To bridge this gap, we present \\textbf{Pref-Restore}, a hierarchical framework that integrates discrete semantic logic with continuous texture generation to achieve deterministic, preference-aligned restoration. Our methodology fundamentally addresses this information disparity through two complementary strategies: (1) Augmenting Input Density: We employ an auto-regressive integrator to reformulate textual instructions into dense latent queries, injecting high-level semantic stability to constrain the degraded signals; (2) Pruning Output Distribution: We pioneer the integration of on-policy reinforcement learning directly into the diffusion restoration loop. By transforming human preferences into differentiable constraints, we explicitly penalize stochastic deviations, thereby sharpening the posterior distribution toward the desired high-fidelity outcomes. Extensive experiments demonstrate that Pref-Restore achieves state-of-the-art performance across synthetic and real-world benchmarks. Furthermore, empirical analysis confirms that our preference-aligned strategy significantly reduces solution entropy, establishing a robust pathway toward reliable and deterministic blind restoration.", "AI": {"tldr": "Pref-Restore: A hierarchical framework for blind face restoration that integrates semantic logic with texture generation to achieve deterministic, preference-aligned results by addressing information asymmetry through input augmentation and output pruning.", "motivation": "Current generative approaches for blind face restoration suffer from information asymmetry - the disparity between information-sparse low-quality inputs and information-dense high-quality outputs. This leads to stochastic uncertainty and hallucinatory artifacts due to insufficient constraints in the one-to-many mapping problem.", "method": "Two complementary strategies: (1) Augmenting Input Density: Using an auto-regressive integrator to reformulate textual instructions into dense latent queries for semantic stability; (2) Pruning Output Distribution: Integrating on-policy reinforcement learning directly into the diffusion restoration loop to transform human preferences into differentiable constraints that penalize stochastic deviations.", "result": "Pref-Restore achieves state-of-the-art performance across synthetic and real-world benchmarks. The preference-aligned strategy significantly reduces solution entropy, establishing a robust pathway toward reliable and deterministic blind restoration.", "conclusion": "The hierarchical framework successfully addresses the information asymmetry problem in blind face restoration by integrating discrete semantic logic with continuous texture generation, enabling deterministic, preference-aligned restoration through input augmentation and output distribution pruning."}}
{"id": "2601.19232", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19232", "abs": "https://arxiv.org/abs/2601.19232", "authors": ["Qi Si", "Xuyang Liu", "Penglei Wang", "Xin Guo", "Yuan Qi", "Yuan Cheng"], "title": "Structure-based RNA Design by Step-wise Optimization of Latent Diffusion Model", "comment": "20 pages (7 pages content + 2 pages references + 11 pages appendix), 11 figures, 8 tables. Source code available at https://github.com/darkflash03/SOLD Accepted to AAAI 2026", "summary": "RNA inverse folding, designing sequences to form specific 3D structures, is critical for therapeutics, gene regulation, and synthetic biology. Current methods, focused on sequence recovery, struggle to address structural objectives like secondary structure consistency (SS), minimum free energy (MFE), and local distance difference test (LDDT), leading to suboptimal structural accuracy. To tackle this, we propose a reinforcement learning (RL) framework integrated with a latent diffusion model (LDM). Drawing inspiration from the success of diffusion models in RNA inverse folding, which adeptly model complex sequence-structure interactions, we develop an LDM incorporating pre-trained RNA-FM embeddings from a large-scale RNA model. These embeddings capture co-evolutionary patterns, markedly improving sequence recovery accuracy. However, existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives. By contrast, RL excels in this task by using policy-driven reward optimization to navigate complex, non-gradient-based objectives, offering a significant advantage over traditional methods. In summary, we propose the Step-wise Optimization of Latent Diffusion Model (SOLD), a novel RL framework that optimizes single-step noise without sampling the full diffusion trajectory, achieving efficient refinement of multiple structural objectives. Experimental results demonstrate SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, establishing a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications.", "AI": {"tldr": "SOLD is a reinforcement learning framework that optimizes latent diffusion models for RNA inverse folding, achieving superior structural accuracy by efficiently refining multiple non-differentiable structural objectives.", "motivation": "Current RNA inverse folding methods focus on sequence recovery but struggle with structural objectives like secondary structure consistency, minimum free energy, and LDDT, leading to suboptimal structural accuracy. Existing approaches, including diffusion-based methods, cannot effectively handle non-differentiable structural objectives.", "method": "Propose SOLD (Step-wise Optimization of Latent Diffusion Model), a reinforcement learning framework integrated with latent diffusion model. Uses pre-trained RNA-FM embeddings to capture co-evolutionary patterns. RL optimizes single-step noise without sampling full diffusion trajectory, enabling efficient refinement of multiple structural objectives through policy-driven reward optimization.", "result": "SOLD surpasses its LDM baseline and state-of-the-art methods across all metrics, demonstrating superior performance in RNA inverse folding with improved structural accuracy.", "conclusion": "SOLD establishes a robust framework for RNA inverse folding with profound implications for biotechnological and therapeutic applications, effectively addressing the limitations of existing methods in handling non-differentiable structural objectives."}}
{"id": "2601.19519", "categories": ["cs.CV", "cs.AI", "cs.GR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19519", "abs": "https://arxiv.org/abs/2601.19519", "authors": ["Ofir Abramovich", "Ariel Shamir", "Andreas Aristidou"], "title": "Mocap Anywhere: Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)", "comment": "14 pages, 15 figures", "summary": "We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference. At the core of our system is Wild-Poser (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.", "AI": {"tldr": "A novel motion capture system reconstructs full-body 3D motion using only sparse pairwise distance measurements from body-mounted UWB sensors, eliminating need for external cameras and enabling robust outdoor operation.", "motivation": "Traditional motion capture systems (optical/inertial) require external cameras, controlled environments, and are sensitive to lighting/magnetic interference. There's a need for robust, shape-invariant systems that work in uncontrolled outdoor environments without requiring individual body measurements.", "method": "Uses time-of-flight ranging between wireless UWB sensors for pairwise distance measurements. Core is Wild-Poser (WiP), a compact real-time Transformer-based architecture that directly predicts 3D joint positions from noisy/corrupted distance measurements. Joint rotations can be reconstructed later via learned methods.", "result": "WiP achieves low joint position error, operates in real-time, generalizes across subjects of varying morphologies (including non-human species) without individual body measurements or shape fitting, and demonstrates accurate 3D motion reconstruction in-the-wild for both human and animal subjects.", "conclusion": "The system shows potential for scalable, low-cost, general purpose motion capture in real-world settings, overcoming limitations of traditional systems by being shape-invariant, resilient to environmental constraints, and requiring only sparse distance measurements."}}
{"id": "2601.19243", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.19243", "abs": "https://arxiv.org/abs/2601.19243", "authors": ["Yutong Du", "Zicheng Liu"], "title": "Contrast-Source-Based Physics-Driven Neural Network for Inverse Scattering Problems", "comment": null, "summary": "Deep neural networks (DNNs) have recently been applied to inverse scattering problems (ISPs) due to their strong nonlinear mapping capabilities. However, supervised DNN solvers require large-scale datasets, which limits their generalization in practical applications. Untrained neural networks (UNNs) address this issue by updating weights from measured electric fields and prior physical knowledge, but existing UNN solvers suffer from long inference time. To overcome these limitations, this paper proposes a contrast-source-based physics-driven neural network (CSPDNN), which predicts the induced current distribution to improve efficiency and incorporates an adaptive total variation loss for robust reconstruction under varying contrast and noise conditions. The improved imaging performance is validated through comprehensive numerical simulations and experimental data.", "AI": {"tldr": "Proposes CSPDNN - a contrast-source-based physics-driven neural network for inverse scattering problems that improves efficiency and robustness compared to existing supervised and untrained neural network approaches.", "motivation": "Supervised DNNs for inverse scattering require large datasets limiting generalization, while untrained neural networks (UNNs) address this but suffer from long inference times. Need a more efficient and robust solution.", "method": "Contrast-source-based physics-driven neural network (CSPDNN) that predicts induced current distribution to improve efficiency, with adaptive total variation loss for robust reconstruction under varying contrast and noise conditions.", "result": "Improved imaging performance validated through comprehensive numerical simulations and experimental data, showing better efficiency and robustness.", "conclusion": "CSPDNN provides an effective solution for inverse scattering problems that balances efficiency, robustness, and generalization without requiring large training datasets."}}
{"id": "2601.19526", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19526", "abs": "https://arxiv.org/abs/2601.19526", "authors": ["Fouad Boutaleb", "Emery Pierson", "Mohamed Daoudi", "Cl\u00e9mence Nineuil", "Ali Amad", "Fabien D'Hondt"], "title": "A Non-Invasive 3D Gait Analysis Framework for Quantifying Psychomotor Retardation in Major Depressive Disorder", "comment": null, "summary": "Predicting the status of Major Depressive Disorder (MDD) from objective, non-invasive methods is an active research field. Yet, extracting automatically objective, interpretable features for a detailed analysis of the patient state remains largely unexplored.\n  Among MDD's symptoms, Psychomotor retardation (PMR) is a core item, yet its clinical assessment remains largely subjective. While 3D motion capture offers an objective alternative, its reliance on specialized hardware often precludes routine clinical use. In this paper, we propose a non-invasive computational framework that transforms monocular RGB video into clinically relevant 3D gait kinematics. Our pipeline uses Gravity-View Coordinates along with a novel trajectory-correction algorithm that leverages the closed-loop topology of our adapted Timed Up and Go (TUG) protocol to mitigate monocular depth errors. This novel pipeline enables the extraction of 297 explicit gait biomechanical biomarkers from a single camera capture.\n  To address the challenges of small clinical datasets, we introduce a stability-based machine learning framework that identifies robust motor signatures while preventing overfitting. Validated on the CALYPSO dataset, our method achieves an 83.3% accuracy in detecting PMR and explains 64% of the variance in overall depression severity (R^2=0.64). Notably, our study reveals a strong link between reduced ankle propulsion and restricted pelvic mobility to the depressive motor phenotype. These results demonstrate that physical movement serves as a robust proxy for the cognitive state, offering a transparent and scalable tool for the objective monitoring of depression in standard clinical environments.", "AI": {"tldr": "Non-invasive computational framework transforms monocular RGB video into 3D gait kinematics to objectively assess Major Depressive Disorder via Psychomotor Retardation biomarkers.", "motivation": "Current clinical assessment of Psychomotor Retardation (a core MDD symptom) is subjective, and while 3D motion capture offers objectivity, it requires specialized hardware unsuitable for routine clinical use. There's a need for objective, interpretable features from non-invasive methods for detailed patient state analysis.", "method": "Proposes a computational pipeline that transforms monocular RGB video into 3D gait kinematics using Gravity-View Coordinates and a novel trajectory-correction algorithm leveraging closed-loop topology of adapted Timed Up and Go protocol to mitigate depth errors. Extracts 297 explicit gait biomechanical biomarkers. Uses stability-based ML framework to identify robust motor signatures while preventing overfitting on small clinical datasets.", "result": "Achieves 83.3% accuracy in detecting Psychomotor Retardation and explains 64% of variance in overall depression severity (R\u00b2=0.64) on CALYPSO dataset. Reveals strong link between reduced ankle propulsion and restricted pelvic mobility to depressive motor phenotype.", "conclusion": "Physical movement serves as robust proxy for cognitive state, offering transparent and scalable tool for objective monitoring of depression in standard clinical environments using only monocular RGB video capture."}}
{"id": "2601.19255", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19255", "abs": "https://arxiv.org/abs/2601.19255", "authors": ["Haoting Zhang", "Shekhar Jain"], "title": "LLM-Assisted Logic Rule Learning: Scaling Human Expertise for Time Series Anomaly Detection", "comment": null, "summary": "Time series anomaly detection is critical for supply chain management to take proactive operations, but faces challenges: classical unsupervised anomaly detection based on exploiting data patterns often yields results misaligned with business requirements and domain knowledge, while manual expert analysis cannot scale to millions of products in the supply chain. We propose a framework that leverages large language models (LLMs) to systematically encode human expertise into interpretable, logic-based rules for detecting anomaly patterns in supply chain time series data. Our approach operates in three stages: 1) LLM-based labeling of training data instructed by domain knowledge, 2) automated generation and iterative improvements of symbolic rules through LLM-driven optimization, and 3) rule augmentation with business-relevant anomaly categories supported by LLMs to enhance interpretability. The experiment results showcase that our approach outperforms the unsupervised learning methods in both detection accuracy and interpretability. Furthermore, compared to direct LLM deployment for time series anomaly detection, our approach provides consistent, deterministic results with low computational latency and cost, making it ideal for production deployment. The proposed framework thus demonstrates how LLMs can bridge the gap between scalable automation and expert-driven decision-making in operational settings.", "AI": {"tldr": "LLM-powered framework converts human expertise into interpretable logic rules for supply chain time series anomaly detection, outperforming unsupervised methods while being production-ready.", "motivation": "Classical unsupervised anomaly detection yields results misaligned with business requirements, while manual expert analysis cannot scale to millions of products in supply chains.", "method": "Three-stage framework: 1) LLM-based labeling of training data using domain knowledge, 2) automated generation and iterative improvement of symbolic rules through LLM-driven optimization, 3) rule augmentation with business-relevant anomaly categories using LLMs.", "result": "Outperforms unsupervised learning methods in both detection accuracy and interpretability; provides consistent, deterministic results with low computational latency and cost compared to direct LLM deployment.", "conclusion": "LLMs can bridge the gap between scalable automation and expert-driven decision-making in operational settings by systematically encoding human expertise into interpretable, logic-based rules."}}
{"id": "2601.19256", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19256", "abs": "https://arxiv.org/abs/2601.19256", "authors": ["Zhiyang Liang", "Qingkai Zhang"], "title": "E-QRGMM: Efficient Generative Metamodeling for Covariate-Dependent Uncertainty Quantification", "comment": null, "summary": "Covariate-dependent uncertainty quantification in simulation-based inference is crucial for high-stakes decision-making but remains challenging due to the limitations of existing methods such as conformal prediction and classical bootstrap, which struggle with covariate-specific conditioning. We propose Efficient Quantile-Regression-Based Generative Metamodeling (E-QRGMM), a novel framework that accelerates the quantile-regression-based generative metamodeling (QRGMM) approach by integrating cubic Hermite interpolation with gradient estimation. Theoretically, we show that E-QRGMM preserves the convergence rate of the original QRGMM while reducing grid complexity from $O(n^{1/2})$ to $O(n^{1/5})$ for the majority of quantile levels, thereby substantially improving computational efficiency. Empirically, E-QRGMM achieves a superior trade-off between distributional accuracy and training speed compared to both QRGMM and other advanced deep generative models on synthetic and practical datasets. Moreover, by enabling bootstrap-based construction of confidence intervals for arbitrary estimands of interest, E-QRGMM provides a practical solution for covariate-dependent uncertainty quantification.", "AI": {"tldr": "E-QRGMM accelerates quantile-regression-based generative metamodeling using cubic Hermite interpolation and gradient estimation, reducing grid complexity from O(n^{1/2}) to O(n^{1/5}) while maintaining accuracy for covariate-dependent uncertainty quantification.", "motivation": "Existing methods like conformal prediction and classical bootstrap struggle with covariate-specific conditioning for uncertainty quantification in simulation-based inference, which is crucial for high-stakes decision-making.", "method": "Efficient Quantile-Regression-Based Generative Metamodeling (E-QRGMM) integrates cubic Hermite interpolation with gradient estimation to accelerate the original QRGMM approach.", "result": "Theoretically, E-QRGMM preserves convergence rate while reducing grid complexity from O(n^{1/2}) to O(n^{1/5}) for most quantile levels. Empirically, it achieves superior trade-off between distributional accuracy and training speed compared to QRGMM and other deep generative models.", "conclusion": "E-QRGMM provides a practical solution for covariate-dependent uncertainty quantification by enabling bootstrap-based construction of confidence intervals for arbitrary estimands of interest."}}
{"id": "2601.19577", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19577", "abs": "https://arxiv.org/abs/2601.19577", "authors": ["Ronglai Zuo", "Rolandos Alexandros Potamias", "Qi Sun", "Evangelos Ververas", "Jiankang Deng", "Stefanos Zafeiriou"], "title": "MaDiS: Taming Masked Diffusion Language Models for Sign Language Generation", "comment": null, "summary": "Sign language generation (SLG) aims to translate written texts into expressive sign motions, bridging communication barriers for the Deaf and Hard-of-Hearing communities. Recent studies formulate SLG within the language modeling framework using autoregressive language models, which suffer from unidirectional context modeling and slow token-by-token inference. To address these limitations, we present MaDiS, a masked-diffusion-based language model for SLG that captures bidirectional dependencies and supports efficient parallel multi-token generation. We further introduce a tri-level cross-modal pretraining scheme that jointly learns from token-, latent-, and 3D physical-space objectives, leading to richer and more grounded sign representations. To accelerate model convergence in the fine-tuning stage, we design a novel unmasking strategy with temporal checkpoints, reducing the combinatorial complexity of unmasking orders by over $10^{41}$ times. In addition, a mixture-of-parts embedding layer is developed to effectively fuse information stored in different part-wise sign tokens through learnable gates and well-optimized codebooks. Extensive experiments on CSL-Daily, Phoenix-2014T, and How2Sign demonstrate that MaDiS achieves superior performance across multiple metrics, including DTW error and two newly introduced metrics, SiBLEU and SiCLIP, while reducing inference latency by nearly 30%. Code and models will be released on our project page.", "AI": {"tldr": "MaDiS is a masked-diffusion-based language model for sign language generation that uses bidirectional context modeling and parallel multi-token generation to overcome limitations of autoregressive approaches.", "motivation": "Autoregressive language models for sign language generation suffer from unidirectional context modeling and slow token-by-token inference, limiting their efficiency and ability to capture bidirectional dependencies in sign motions.", "method": "Proposes MaDiS with: 1) masked-diffusion framework for bidirectional modeling and parallel generation, 2) tri-level cross-modal pretraining (token, latent, 3D physical-space), 3) novel unmasking strategy with temporal checkpoints to reduce combinatorial complexity, and 4) mixture-of-parts embedding layer with learnable gates and codebooks.", "result": "Achieves superior performance on CSL-Daily, Phoenix-2014T, and How2Sign datasets across multiple metrics (DTW error, SiBLEU, SiCLIP) while reducing inference latency by nearly 30%.", "conclusion": "MaDiS effectively addresses limitations of autoregressive SLG models through bidirectional modeling, efficient parallel generation, and comprehensive cross-modal learning, advancing sign language generation technology."}}
{"id": "2601.19261", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19261", "abs": "https://arxiv.org/abs/2601.19261", "authors": ["Anower Zihad", "Felix Owino", "Haibo Yang", "Ming Tang", "Chao Huang"], "title": "Decoupled Split Learning via Auxiliary Loss", "comment": null, "summary": "Split learning is a distributed training paradigm where a neural network is partitioned between clients and a server, which allows data to remain at the client while only intermediate activations are shared. Traditional split learning relies on end-to-end backpropagation across the client-server split point. This incurs a large communication overhead (i.e., forward activations and backward gradients need to be exchanged every iteration) and significant memory use (for storing activations and gradients). In this paper, we develop a beyond-backpropagation training method for split learning. In this approach, the client and server train their model partitions semi-independently, using local loss signals instead of propagated gradients. In particular, the client's network is augmented with a small auxiliary classifier at the split point to provide a local error signal, while the server trains on the client's transmitted activations using the true loss function. This decoupling removes the need to send backward gradients, which cuts communication costs roughly in half and also reduces memory overhead (as each side only stores local activations for its own backward pass). We evaluate our approach on CIFAR-10 and CIFAR-100. Our experiments show two key results. First, the proposed approach achieves performance on par with standard split learning that uses backpropagation. Second, it significantly reduces communication (of transmitting activations/gradient) by 50% and peak memory usage by up to 58%.", "AI": {"tldr": "Split learning with beyond-backpropagation training reduces communication and memory overhead by 50% while maintaining performance parity with traditional backpropagation-based split learning.", "motivation": "Traditional split learning requires end-to-end backpropagation across client-server split, which incurs large communication overhead (exchanging forward activations and backward gradients every iteration) and significant memory usage for storing activations and gradients.", "method": "Proposes a beyond-backpropagation training method where client and server train model partitions semi-independently using local loss signals instead of propagated gradients. Client's network is augmented with a small auxiliary classifier at split point for local error signal, while server trains on client's transmitted activations using true loss function.", "result": "Achieves performance on par with standard split learning using backpropagation, reduces communication (transmitting activations/gradients) by 50%, and reduces peak memory usage by up to 58% on CIFAR-10 and CIFAR-100 datasets.", "conclusion": "The beyond-backpropagation approach successfully decouples client-server training, eliminating backward gradient transmission while maintaining model performance, making split learning more communication and memory efficient."}}
{"id": "2601.19580", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19580", "abs": "https://arxiv.org/abs/2601.19580", "authors": ["Cuong Le", "Pavlo Melnyk", "Urs Waldmann", "M\u00e5rten Wadenb\u00e4ck", "Bastian Wandt"], "title": "QuaMo: Quaternion Motions for Vision-based 3D Human Kinematics Capture", "comment": "10 pages, 4 figures, accepted to ICLR 2026", "summary": "Vision-based 3D human motion capture from videos remains a challenge in computer vision. Traditional 3D pose estimation approaches often ignore the temporal consistency between frames, causing implausible and jittery motion. The emerging field of kinematics-based 3D motion capture addresses these issues by estimating the temporal transitioning between poses instead. A major drawback in current kinematics approaches is their reliance on Euler angles. Despite their simplicity, Euler angles suffer from discontinuity that leads to unstable motion reconstructions, especially in online settings where trajectory refinement is unavailable. Contrarily, quaternions have no discontinuity and can produce continuous transitions between poses. In this paper, we propose QuaMo, a novel Quaternion Motions method using quaternion differential equations (QDE) for human kinematics capture. We utilize the state-space model, an effective system for describing real-time kinematics estimations, with quaternion state and the QDE describing quaternion velocity. The corresponding angular acceleration is computed from a meta-PD controller with a novel acceleration enhancement that adaptively regulates the control signals as the human quickly changes to a new pose. Unlike previous work, our QDE is solved under the quaternion unit-sphere constraint that results in more accurate estimations. Experimental results show that our novel formulation of the QDE with acceleration enhancement accurately estimates 3D human kinematics with no discontinuity and minimal implausibilities. QuaMo outperforms comparable state-of-the-art methods on multiple datasets, namely Human3.6M, Fit3D, SportsPose and AIST. The code is available at https://github.com/cuongle1206/QuaMo", "AI": {"tldr": "QuaMo: A novel quaternion-based motion capture method using quaternion differential equations with acceleration enhancement for continuous, stable 3D human kinematics estimation from videos.", "motivation": "Traditional 3D pose estimation ignores temporal consistency, causing jittery motion. Current kinematics approaches rely on Euler angles which suffer from discontinuity, especially in online settings. Quaternions offer continuous transitions without discontinuity problems.", "method": "Proposes QuaMo using quaternion differential equations (QDE) with state-space model for real-time kinematics. Uses meta-PD controller with novel acceleration enhancement to adaptively regulate control signals during pose changes. Solves QDE under quaternion unit-sphere constraint for accuracy.", "result": "Outperforms state-of-the-art methods on Human3.6M, Fit3D, SportsPose and AIST datasets. Accurately estimates 3D human kinematics with no discontinuity and minimal implausibilities.", "conclusion": "QuaMo's novel QDE formulation with acceleration enhancement provides superior 3D human motion capture by overcoming Euler angle discontinuity issues and ensuring continuous, stable motion reconstruction from videos."}}
{"id": "2601.19280", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19280", "abs": "https://arxiv.org/abs/2601.19280", "authors": ["Kishan Panaganti", "Zhenwen Liang", "Wenhao Yu", "Haitao Mi", "Dong Yu"], "title": "Group Distributionally Robust Optimization-Driven Reinforcement Learning for LLM Reasoning", "comment": "Keywords: Large Language Models, Reasoning Models, Reinforcement Learning, Distributionally Robust Optimization, GRPO", "summary": "Recent progress in Large Language Model (LLM) reasoning is increasingly driven by the refinement of post-training loss functions and alignment strategies. However, standard Reinforcement Learning (RL) paradigms like Group Relative Policy Optimization (GRPO) remain constrained by static uniformity: uniform prompt sampling and a fixed number of rollouts per prompt. For heterogeneous, heavy-tailed reasoning data, this creates structural inefficiencies that waste compute on already-solved patterns while under-training the long tail of hard problems. To address this, we propose Multi-Adversary Group Distributionally Robust Optimization (GDRO), an optimization-first framework that moves beyond uniform reasoning models by dynamically adapting the training distribution.\n  We introduce an Online Difficulty Classifier that partitions prompts into dynamic pass@k difficulty groups. We then propose two independent GDRO games for post-training: (1) Prompt-GDRO, which employs an EMA-debiased multiplicative-weights bandit sampler to target the intensive difficulty margin and upweight persistently hard groups without frequency bias; and (2) Rollout-GDRO, which uses a shadow-price controller to reallocate rollouts across groups, maximizing gradient variance reduction on hard tasks under a fixed mean budget (compute-neutral). We provide no-regret guarantees for both controllers and additionally a variance-proxy analysis motivating a square-root optimal rollout allocation for Rollout-GDRO. We validate our framework on the DAPO 14.1k dataset using Qwen3-Base models. Prompt-GDRO and Rollout-GDRO achieve average relative gains of +10.6% and +10.1%, respectively, in pass@8 accuracy across 1.7B, 4B, and 8B scales compared to the GRPO baseline. Qualitative analysis shows an emergent curriculum: the adversaries shift resources to the evolving reasoning frontier, enhancing the reasoning model's performance.", "AI": {"tldr": "Multi-Adversary Group Distributionally Robust Optimization (GDRO) improves LLM reasoning by dynamically adapting training distribution to focus on hard problems, achieving +10% gains over standard RL methods.", "motivation": "Standard RL methods like GRPO use uniform prompt sampling and fixed rollouts, which is inefficient for heterogeneous reasoning data - wasting compute on easy problems while under-training hard ones.", "method": "Proposes GDRO framework with two components: (1) Prompt-GDRO uses EMA-debiased multiplicative-weights bandit sampler to upweight persistently hard difficulty groups; (2) Rollout-GDRO uses shadow-price controller to reallocate rollouts across groups to maximize gradient variance reduction on hard tasks.", "result": "Achieved average relative gains of +10.6% (Prompt-GDRO) and +10.1% (Rollout-GDRO) in pass@8 accuracy across 1.7B, 4B, and 8B Qwen3-Base models compared to GRPO baseline on DAPO 14.1k dataset.", "conclusion": "GDRO framework successfully addresses inefficiencies in standard RL by dynamically adapting training distribution, creating an emergent curriculum that shifts resources to the evolving reasoning frontier, significantly improving LLM reasoning performance."}}
{"id": "2601.19582", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19582", "abs": "https://arxiv.org/abs/2601.19582", "authors": ["Yujin Wang", "Yutong Zheng", "Wenxian Fan", "Tianyi Wang", "Hongqing Chu", "Daxin Tian", "Bingzhao Gao", "Jianqiang Wang", "Hong Chen"], "title": "ScenePilot-Bench: A Large-Scale Dataset and Benchmark for Evaluation of Vision-Language Models in Autonomous Driving", "comment": null, "summary": "In this paper, we introduce ScenePilot-Bench, a large-scale first-person driving benchmark designed to evaluate vision-language models (VLMs) in autonomous driving scenarios. ScenePilot-Bench is built upon ScenePilot-4K, a diverse dataset comprising 3,847 hours of driving videos, annotated with multi-granularity information including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. The benchmark features a four-axis evaluation suite that assesses VLM capabilities in scene understanding, spatial perception, motion planning, and GPT-Score, with safety-aware metrics and cross-region generalization settings. We benchmark representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning. ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts.", "AI": {"tldr": "ScenePilot-Bench is a large-scale first-person driving benchmark for evaluating vision-language models in autonomous driving scenarios, built on 3,847 hours of annotated driving videos with multi-granularity information.", "motivation": "There's a need for comprehensive evaluation frameworks to assess vision-language models in safety-critical autonomous driving contexts, particularly for driving-oriented reasoning capabilities.", "method": "Built on ScenePilot-4K dataset (3,847 hours of driving videos) with multi-granularity annotations including scene descriptions, risk assessments, key participant identification, ego trajectories, and camera parameters. Features a four-axis evaluation suite assessing scene understanding, spatial perception, motion planning, and GPT-Score with safety-aware metrics and cross-region generalization settings.", "result": "Benchmarked representative VLMs on ScenePilot-Bench, providing empirical analyses that clarify current performance boundaries and identify gaps for driving-oriented reasoning.", "conclusion": "ScenePilot-Bench offers a comprehensive framework for evaluating and advancing VLMs in safety-critical autonomous driving contexts, addressing current limitations in driving-oriented reasoning capabilities."}}
{"id": "2601.19285", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19285", "abs": "https://arxiv.org/abs/2601.19285", "authors": ["Xinyu Zhou", "Jiawei Zhang", "Stephen J. Wright"], "title": "Smoothing the Score Function for Generalization in Diffusion Models: An Optimization-based Explanation Framework", "comment": "61pages,32 figures", "summary": "Diffusion models achieve remarkable generation quality, yet face a fundamental challenge known as memorization, where generated samples can replicate training samples exactly. We develop a theoretical framework to explain this phenomenon by showing that the empirical score function (the score function corresponding to the empirical distribution) is a weighted sum of the score functions of Gaussian distributions, in which the weights are sharp softmax functions. This structure causes individual training samples to dominate the score function, resulting in sampling collapse. In practice, approximating the empirical score function with a neural network can partially alleviate this issue and improve generalization. Our theoretical framework explains why: In training, the neural network learns a smoother approximation of the weighted sum, allowing the sampling process to be influenced by local manifolds rather than single points. Leveraging this insight, we propose two novel methods to further enhance generalization: (1) Noise Unconditioning enables each training sample to adaptively determine its score function weight to increase the effect of more training samples, thereby preventing single-point dominance and mitigating collapse. (2) Temperature Smoothing introduces an explicit parameter to control the smoothness. By increasing the temperature in the softmax weights, we naturally reduce the dominance of any single training sample and mitigate memorization. Experiments across multiple datasets validate our theoretical analysis and demonstrate the effectiveness of the proposed methods in improving generalization while maintaining high generation quality.", "AI": {"tldr": "The paper develops a theoretical framework explaining diffusion model memorization, showing empirical score functions are weighted sums with sharp softmax weights causing single training samples to dominate. It proposes two methods (Noise Unconditioning and Temperature Smoothing) to enhance generalization by preventing single-point dominance.", "motivation": "Diffusion models suffer from memorization where generated samples replicate training data exactly, which is a fundamental challenge that needs theoretical understanding and practical solutions.", "method": "1) Theoretical framework showing empirical score functions are weighted sums of Gaussian score functions with sharp softmax weights. 2) Two proposed methods: Noise Unconditioning (adaptive weight adjustment) and Temperature Smoothing (explicit smoothness control via temperature parameter).", "result": "Experiments across multiple datasets validate the theoretical analysis and demonstrate that both proposed methods effectively improve generalization while maintaining high generation quality.", "conclusion": "The theoretical framework explains diffusion model memorization, and the proposed methods successfully mitigate this issue by preventing single training samples from dominating the score function, leading to better generalization without sacrificing generation quality."}}
{"id": "2601.19593", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19593", "abs": "https://arxiv.org/abs/2601.19593", "authors": ["Est\u00e8phe Arnaud", "Mohamed Daoudi", "Pierre Guerreschi"], "title": "Localized Latent Editing for Dose-Response Modeling in Botulinum Toxin Injection Planning", "comment": null, "summary": "Botulinum toxin (Botox) injections are the gold standard for managing facial asymmetry and aesthetic rejuvenation, yet determining the optimal dosage remains largely intuitive, often leading to suboptimal outcomes. We propose a localized latent editing framework that simulates Botulinum Toxin injection effects for injection planning through dose-response modeling. Our key contribution is a Region-Specific Latent Axis Discovery method that learns localized muscle relaxation trajectories in StyleGAN2's latent space, enabling precise control over specific facial regions without global side effects. By correlating these localized latent trajectories with injected toxin units, we learn a predictive dose-response model. We rigorously compare two approaches: direct metric regression versus image-based generative simulation on a clinical dataset of N=360 images from 46 patients. On a hold-out test set, our framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics, confirming that the generative model correctly captures the direction of morphological changes. While biological variability limits absolute precision, we introduce a hybrid \"Human-in-the-Loop\" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning.", "AI": {"tldr": "A generative AI framework that simulates Botox injection effects for treatment planning using localized latent editing in StyleGAN2, enabling dose-response modeling and interactive clinician refinement.", "motivation": "Current Botox dosage determination is largely intuitive and often leads to suboptimal outcomes. There's a need for a systematic approach to predict injection effects for better treatment planning.", "method": "Proposes a localized latent editing framework using Region-Specific Latent Axis Discovery in StyleGAN2's latent space. Learns localized muscle relaxation trajectories correlated with injected toxin units. Compares direct metric regression vs. image-based generative simulation on clinical data (N=360 images from 46 patients).", "result": "The framework demonstrates moderate-to-strong structural correlations for geometric asymmetry metrics on hold-out test sets. The generative model correctly captures the direction of morphological changes, though biological variability limits absolute precision.", "conclusion": "Introduces a hybrid \"Human-in-the-Loop\" workflow where clinicians interactively refine simulations, bridging the gap between pathological reconstruction and cosmetic planning for more precise Botox treatment outcomes."}}
{"id": "2601.19296", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19296", "abs": "https://arxiv.org/abs/2601.19296", "authors": ["Yongjae Lee", "Eunhee Park", "Daesan Park", "Dongho Kim", "Jongho Choi", "Hyerim Bae"], "title": "Process-Aware Procurement Lead Time Prediction for Shipyard Delay Mitigation", "comment": null, "summary": "Accurately predicting procurement lead time (PLT) remains a challenge in engineered-to-order industries such as shipbuilding and plant construction, where delays in a single key component can disrupt project timelines. In shipyards, pipe spools are critical components; installed deep within hull blocks soon after steel erection, any delay in their procurement can halt all downstream tasks. Recognizing their importance, existing studies predict PLT using the static physical attributes of pipe spools. However, procurement is inherently a dynamic, multi-stakeholder business process involving a continuous sequence of internal and external events at the shipyard, factors often overlooked in traditional approaches. To address this issue, this paper proposes a novel framework that combines event logs, dataset records of the procurement events, with static attributes to predict PLT. The temporal attributes of each event are extracted to reflect the continuity and temporal context of the process. Subsequently, a deep sequential neural network combined with a multi-layered perceptron is employed to integrate these static and dynamic features, enabling the model to capture both structural and contextual information in procurement. Comparative experiments are conducted using real-world pipe spool procurement data from a globally renowned South Korean shipbuilding corporation. Three tasks are evaluated, which are production, post-processing, and procurement lead time prediction. The results show a 22.6% to 50.4% improvement in prediction performance in terms of mean absolute error over the best-performing existing approaches across the three tasks. These findings indicate the value of considering procurement process information for more accurate PLT prediction.", "AI": {"tldr": "Proposes a novel framework combining event logs with static attributes using deep sequential neural networks to predict procurement lead time in shipbuilding, achieving 22.6-50.4% improvement over existing methods.", "motivation": "Procurement lead time prediction is challenging in engineered-to-order industries like shipbuilding, where delays in critical components like pipe spools can disrupt entire project timelines. Traditional approaches only use static physical attributes, ignoring the dynamic, multi-stakeholder business process involving continuous sequences of internal/external events.", "method": "Proposes a framework combining event logs (procurement event records) with static attributes. Extracts temporal attributes from events to reflect process continuity and temporal context. Uses deep sequential neural network combined with multi-layered perceptron to integrate static and dynamic features, capturing both structural and contextual information.", "result": "Experimental evaluation using real-world pipe spool procurement data from a major South Korean shipbuilding corporation. Three tasks evaluated: production, post-processing, and procurement lead time prediction. Achieved 22.6% to 50.4% improvement in prediction performance (mean absolute error) over best-performing existing approaches across all three tasks.", "conclusion": "The results demonstrate the value of considering procurement process information for more accurate lead time prediction. The proposed approach effectively captures both structural (static attributes) and contextual (dynamic event sequences) aspects of procurement processes."}}
{"id": "2601.19606", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.19606", "abs": "https://arxiv.org/abs/2601.19606", "authors": ["Shentong Mo", "Zehua Chen", "Jun Zhu"], "title": "GMS-CAVP: Improving Audio-Video Correspondence with Multi-Scale Contrastive and Generative Pretraining", "comment": null, "summary": "Recent advances in video-audio (V-A) understanding and generation have increasingly relied on joint V-A embeddings, which serve as the foundation for tasks such as cross-modal retrieval and generation. While prior methods like CAVP effectively model semantic and temporal correspondences between modalities using contrastive objectives, their performance remains suboptimal. A key limitation is the insufficient modeling of the dense, multi-scale nature of both video and audio signals, correspondences often span fine- to coarse-grained spatial-temporal structures, which are underutilized in existing frameworks. To this end, we propose GMS-CAVP, a novel framework that combines Multi-Scale Video-Audio Alignment and Multi-Scale Spatial-Temporal Diffusion-based pretraining objectives to enhance V-A correspondence modeling. First, GMS-CAVP introduces a multi-scale contrastive learning strategy that captures semantic and temporal relations across varying granularities. Second, we go beyond traditional contrastive learning by incorporating a diffusion-based generative objective, enabling modality translation and synthesis between video and audio. This unified discriminative-generative formulation facilitates deeper cross-modal understanding and paves the way for high-fidelity generation. Extensive experiments on VGGSound, AudioSet, and Panda70M demonstrate that GMS-CAVP outperforms previous methods in generation and retrieval.", "AI": {"tldr": "GMS-CAVP is a novel framework that enhances video-audio understanding by combining multi-scale contrastive learning with diffusion-based generative objectives for improved cross-modal correspondence modeling.", "motivation": "Existing video-audio joint embedding methods have limitations in modeling dense, multi-scale nature of video and audio signals. Current approaches like CAVP underutilize fine- to coarse-grained spatial-temporal correspondences, leading to suboptimal performance in cross-modal tasks.", "method": "GMS-CAVP combines two key components: 1) Multi-scale contrastive learning strategy that captures semantic and temporal relations across varying granularities, and 2) Diffusion-based generative objective enabling modality translation and synthesis between video and audio, creating a unified discriminative-generative formulation.", "result": "Extensive experiments on VGGSound, AudioSet, and Panda70M datasets demonstrate that GMS-CAVP outperforms previous methods in both generation and retrieval tasks.", "conclusion": "The proposed framework successfully addresses limitations of prior methods by better modeling multi-scale video-audio correspondences through a combined contrastive and generative approach, enabling deeper cross-modal understanding and high-fidelity generation."}}
{"id": "2601.19300", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19300", "abs": "https://arxiv.org/abs/2601.19300", "authors": ["Seoungbin Bae", "Garyeong Kang", "Dabeen Lee"], "title": "Queue Length Regret Bounds for Contextual Queueing Bandits", "comment": null, "summary": "We introduce contextual queueing bandits, a new context-aware framework for scheduling while simultaneously learning unknown service rates. Individual jobs carry heterogeneous contextual features, based on which the agent chooses a job and matches it with a server to maximize the departure rate. The service/departure rate is governed by a logistic model of the contextual feature with an unknown server-specific parameter. To evaluate the performance of a policy, we consider queue length regret, defined as the difference in queue length between the policy and the optimal policy. The main challenge in the analysis is that the lists of remaining job features in the queue may differ under our policy versus the optimal policy for a given time step, since they may process jobs in different orders. To address this, we propose the idea of policy-switching queues equipped with a sophisticated coupling argument. This leads to a novel queue length regret decomposition framework, allowing us to understand the short-term effect of choosing a suboptimal job-server pair and its long-term effect on queue state differences. We show that our algorithm, CQB-$\\varepsilon$, achieves a regret upper bound of $\\widetilde{\\mathcal{O}}(T^{-1/4})$. We also consider the setting of adversarially chosen contexts, for which our second algorithm, CQB-Opt, achieves a regret upper bound of $\\mathcal{O}(\\log^2 T)$. Lastly, we provide experimental results that validate our theoretical findings.", "AI": {"tldr": "The paper introduces contextual queueing bandits, a framework for scheduling jobs with unknown service rates based on contextual features, with algorithms achieving sublinear queue length regret bounds.", "motivation": "Traditional scheduling problems assume known service rates, but in practice, service rates are often unknown and depend on contextual features of jobs. There's a need to simultaneously learn these unknown rates while making optimal scheduling decisions to maximize departure rates and minimize queue lengths.", "method": "The authors propose a contextual queueing bandits framework where jobs have heterogeneous contextual features. They use a logistic model with unknown server-specific parameters to govern service rates. They introduce policy-switching queues with sophisticated coupling arguments to handle the challenge that different policies may process jobs in different orders, leading to different queue states. They develop two algorithms: CQB-\u03b5 for stochastic contexts and CQB-Opt for adversarial contexts.", "result": "CQB-\u03b5 achieves a regret upper bound of \u00d5(T^{-1/4}) for stochastic contexts, while CQB-Opt achieves \u00d5(log\u00b2 T) for adversarial contexts. Experimental results validate the theoretical findings.", "conclusion": "The paper successfully introduces a new contextual queueing bandits framework that addresses the joint learning and scheduling problem. The proposed algorithms achieve sublinear regret bounds, with theoretical analysis overcoming the challenge of different queue states under different policies through novel coupling techniques."}}
{"id": "2601.19618", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19618", "abs": "https://arxiv.org/abs/2601.19618", "authors": ["Soroosh Tayebi Arasteh", "Mina Farajiamiri", "Mahshad Lotfinia", "Behrus Hinrichs-Puladi", "Jonas Bienzeisler", "Mohamed Alhaskir", "Mirabela Rusu", "Christiane Kuhl", "Sven Nebelung", "Daniel Truhn"], "title": "The role of self-supervised pretraining in differentially private medical image analysis", "comment": null, "summary": "Differential privacy (DP) provides formal protection for sensitive data but typically incurs substantial losses in diagnostic performance. Model initialization has emerged as a critical factor in mitigating this degradation, yet the role of modern self-supervised learning under full-model DP remains poorly understood. Here, we present a large-scale evaluation of initialization strategies for differentially private medical image analysis, using chest radiograph classification as a representative benchmark with more than 800,000 images. Using state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, we compare non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR, the largest publicly available chest radiograph dataset. Evaluations are conducted across five external datasets spanning diverse institutions and acquisition settings. We show that DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. We further demonstrate that initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints. The results establish initialization strategy as a central determinant of utility, fairness, and generalization in differentially private medical imaging.", "AI": {"tldr": "DINOv3 initialization improves diagnostic utility under differential privacy but is inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines in medical imaging.", "motivation": "Differential privacy (DP) provides formal protection for sensitive medical data but typically causes substantial performance degradation. Model initialization has emerged as critical for mitigating this degradation, but the role of modern self-supervised learning under full-model DP remains poorly understood.", "method": "Large-scale evaluation of initialization strategies for differentially private medical image analysis using chest radiograph classification with 800,000+ images. Compared three strategies: non-domain-specific supervised ImageNet initialization, non-domain-specific self-supervised DINOv3 initialization, and domain-specific supervised pretraining on MIMIC-CXR. Used state-of-the-art ConvNeXt models trained with DP-SGD across realistic privacy regimes, evaluated across five external datasets spanning diverse institutions and acquisition settings.", "result": "DINOv3 initialization consistently improves diagnostic utility relative to ImageNet initialization under DP, but remains inferior to domain-specific supervised pretraining, which achieves performance closest to non-private baselines. Initialization choice strongly influences demographic fairness, cross-dataset generalization, and robustness to data scale and model capacity under privacy constraints.", "conclusion": "Initialization strategy is a central determinant of utility, fairness, and generalization in differentially private medical imaging. Domain-specific supervised pretraining provides the best performance under privacy constraints, establishing clear guidance for practical DP implementations in medical imaging."}}
{"id": "2601.19312", "categories": ["cs.LG", "eess.SY", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19312", "abs": "https://arxiv.org/abs/2601.19312", "authors": ["Alexandre Alouadi", "Pierre Henry-Labord\u00e8re", "Gr\u00e9goire Loeper", "Othmane Mazhar", "Huy\u00ean Pham", "Nizar Touzi"], "title": "LightSBB-M: Bridging Schr\u00f6dinger and Bass for Generative Diffusion Modeling", "comment": null, "summary": "The Schrodinger Bridge and Bass (SBB) formulation, which jointly controls drift and volatility, is an established extension of the classical Schrodinger Bridge (SB). Building on this framework, we introduce LightSBB-M, an algorithm that computes the optimal SBB transport plan in only a few iterations. The method exploits a dual representation of the SBB objective to obtain analytic expressions for the optimal drift and volatility, and it incorporates a tunable parameter beta greater than zero that interpolates between pure drift (the Schrodinger Bridge) and pure volatility (Bass martingale transport). We show that LightSBB-M achieves the lowest 2-Wasserstein distance on synthetic datasets against state-of-the-art SB and diffusion baselines with up to 32 percent improvement. We also illustrate the generative capability of the framework on an unpaired image-to-image translation task (adult to child faces in FFHQ). These findings demonstrate that LightSBB-M provides a scalable, high-fidelity SBB solver that outperforms existing SB and diffusion baselines across both synthetic and real-world generative tasks. The code is available at https://github.com/alexouadi/LightSBB-M.", "AI": {"tldr": "LightSBB-M is a fast algorithm that computes optimal Schrodinger Bridge and Bass transport plans, outperforming existing methods on both synthetic and real-world generative tasks.", "motivation": "The Schrodinger Bridge and Bass (SBB) formulation extends classical Schrodinger Bridge by jointly controlling drift and volatility, but existing methods need improvement in computational efficiency and performance.", "method": "LightSBB-M uses a dual representation of the SBB objective to derive analytic expressions for optimal drift and volatility, with a tunable parameter \u03b2 that interpolates between pure drift (SB) and pure volatility (Bass martingale transport).", "result": "LightSBB-M achieves up to 32% improvement in 2-Wasserstein distance on synthetic datasets compared to state-of-the-art SB and diffusion baselines, and demonstrates generative capability on unpaired image-to-image translation (adult to child faces).", "conclusion": "LightSBB-M provides a scalable, high-fidelity SBB solver that outperforms existing SB and diffusion baselines across both synthetic and real-world generative tasks."}}
{"id": "2601.19640", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19640", "abs": "https://arxiv.org/abs/2601.19640", "authors": ["Hao Chang", "Zhihui Wang", "Lingxiang Wu", "Peijin Wang", "Wenhui Diao", "Jinqiao Wang"], "title": "Towards Governance-Oriented Low-Altitude Intelligence: A Management-Centric Multi-Modal Benchmark With Implicitly Coordinated Vision-Language Reasoning Framework", "comment": null, "summary": "Low-altitude vision systems are becoming a critical infrastructure for smart city governance. However, existing object-centric perception paradigms and loosely coupled vision-language pipelines are still difficult to support management-oriented anomaly understanding required in real-world urban governance. To bridge this gap, we introduce GovLA-10K, the first management-oriented multi-modal benchmark for low-altitude intelligence, along with GovLA-Reasoner, a unified vision-language reasoning framework tailored for governance-aware aerial perception. Unlike existing studies that aim to exhaustively annotate all visible objects, GovLA-10K is deliberately designed around functionally salient targets that directly correspond to practical management needs, and further provides actionable management suggestions grounded in these observations. To effectively coordinate the fine-grained visual grounding with high-level contextual language reasoning, GovLA-Reasoner introduces an efficient feature adapter that implicitly coordinates discriminative representation sharing between the visual detector and the large language model (LLM). Extensive experiments show that our method significantly improves performance while avoiding the need of fine-tuning for any task-specific individual components. We believe our work offers a new perspective and foundation for future studies on management-aware low-altitude vision-language systems.", "AI": {"tldr": "GovLA-10K: First management-oriented multi-modal benchmark for low-altitude intelligence with GovLA-Reasoner framework for governance-aware aerial perception.", "motivation": "Existing object-centric perception and loosely coupled vision-language pipelines fail to support management-oriented anomaly understanding needed for real-world urban governance.", "method": "GovLA-10K benchmark focuses on functionally salient targets aligned with practical management needs, plus GovLA-Reasoner framework with efficient feature adapter to coordinate visual grounding with LLM reasoning.", "result": "Method significantly improves performance without needing fine-tuning of task-specific components, offering new foundation for management-aware low-altitude vision-language systems.", "conclusion": "Work provides new perspective for future studies on management-oriented low-altitude vision-language systems, bridging gap between aerial perception and urban governance needs."}}
{"id": "2601.19315", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19315", "abs": "https://arxiv.org/abs/2601.19315", "authors": ["Arunan Sivanathan", "David Warren", "Deepak Mishra", "Sushmita Ruj", "Natasha Fernandes", "Quan Z. Sheng", "Minh Tran", "Ben Luo", "Daniel Coscia", "Gustavo Batista", "Hassan Habibi Gharakaheili"], "title": "Generalizable IoT Traffic Representations for Cross-Network Device Identification", "comment": "15 pages, 15 figures", "summary": "Machine learning models have demonstrated strong performance in classifying network traffic and identifying Internet-of-Things (IoT) devices, enabling operators to discover and manage IoT assets at scale. However, many existing approaches rely on end-to-end supervised pipelines or task-specific fine-tuning, resulting in traffic representations that are tightly coupled to labeled datasets and deployment environments, which can limit generalizability. In this paper, we study the problem of learning generalizable traffic representations for IoT device identification. We design compact encoder architectures that learn per-flow embeddings from unlabeled IoT traffic and evaluate them using a frozen-encoder protocol with a simple supervised classifier. Our specific contributions are threefold. (1) We develop unsupervised encoder--decoder models that learn compact traffic representations from unlabeled IoT network flows and assess their quality through reconstruction-based analysis. (2) We show that these learned representations can be used effectively for IoT device-type classification using simple, lightweight classifiers trained on frozen embeddings. (3) We provide a systematic benchmarking study against the state-of-the-art pretrained traffic encoders, showing that larger models do not necessarily yield more robust representations for IoT traffic. Using more than 18 million real IoT traffic flows collected across multiple years and deployment environments, we learn traffic representations from unlabeled data and evaluate device-type classification on disjoint labeled subsets, achieving macro F1-scores exceeding 0.9 for device-type classification and demonstrating robustness under cross-environment deployment.", "AI": {"tldr": "The paper proposes unsupervised encoder-decoder models to learn generalizable traffic representations from unlabeled IoT network flows, enabling effective device-type classification with simple classifiers while showing robustness across different deployment environments.", "motivation": "Existing IoT device identification approaches rely on supervised learning or task-specific fine-tuning, resulting in traffic representations that are tightly coupled to labeled datasets and deployment environments, limiting generalizability across different settings.", "method": "Develop compact encoder architectures that learn per-flow embeddings from unlabeled IoT traffic using unsupervised encoder-decoder models. Evaluate using a frozen-encoder protocol with simple supervised classifiers, and benchmark against state-of-the-art pretrained traffic encoders.", "result": "Achieved macro F1-scores exceeding 0.9 for device-type classification using learned representations with simple classifiers. Demonstrated robustness under cross-environment deployment and showed that larger models don't necessarily yield more robust representations for IoT traffic.", "conclusion": "Unsupervised learning of traffic representations from unlabeled IoT flows enables generalizable device identification that works well across different environments, with compact models performing effectively without the need for large-scale supervised training."}}
{"id": "2601.19659", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19659", "abs": "https://arxiv.org/abs/2601.19659", "authors": ["Mao-Lin Luo", "Zi-Hao Zhou", "Yi-Lin Zhang", "Yuanyu Wan", "Tong Wei", "Min-Ling Zhang"], "title": "KeepLoRA: Continual Learning with Residual Gradient Adaptation", "comment": "Accepted at ICLR 2026", "summary": "Continual learning for pre-trained vision-language models requires balancing three competing objectives: retaining pre-trained knowledge, preserving knowledge from a sequence of learned tasks, and maintaining the plasticity to acquire new knowledge. This paper presents a simple but effective approach called KeepLoRA to effectively balance these objectives. We first analyze the knowledge retention mechanism within the model parameter space and find that general knowledge is mainly encoded in the principal subspace, while task-specific knowledge is encoded in the residual subspace. Motivated by this finding, KeepLoRA learns new tasks by restricting LoRA parameter updates in the residual subspace to prevent interfering with previously learned capabilities. Specifically, we infuse knowledge for a new task by projecting its gradient onto a subspace orthogonal to both the principal subspace of pre-trained model and the dominant directions of previous task features. Our theoretical and empirical analyses confirm that KeepLoRA balances the three objectives and achieves state-of-the-art performance. The implementation code is available at https://github.com/MaolinLuo/KeepLoRA.", "AI": {"tldr": "KeepLoRA is a continual learning method for vision-language models that balances pre-trained knowledge retention, previous task preservation, and new task learning by restricting LoRA updates to residual subspaces orthogonal to principal knowledge and previous task features.", "motivation": "Continual learning for pre-trained vision-language models needs to balance three competing objectives: retaining pre-trained knowledge, preserving knowledge from previously learned tasks, and maintaining plasticity to learn new tasks effectively.", "method": "KeepLoRA analyzes model parameter space, finding general knowledge in principal subspace and task-specific knowledge in residual subspace. It restricts LoRA parameter updates to the residual subspace orthogonal to both pre-trained model's principal subspace and previous task features' dominant directions to prevent interference with existing capabilities.", "result": "Theoretical and empirical analyses confirm that KeepLoRA effectively balances the three objectives and achieves state-of-the-art performance in continual learning for vision-language models.", "conclusion": "KeepLoRA presents a simple but effective approach for continual learning that successfully balances knowledge retention, task preservation, and learning plasticity through subspace-aware parameter updates."}}
{"id": "2601.19320", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19320", "abs": "https://arxiv.org/abs/2601.19320", "authors": ["Tianyi Chen", "Sihan Chen", "Xiaoyi Qu", "Dan Zhao", "Ruomei Yan", "Jongwoo Ko", "Luming Liang", "Pashmina Cameron"], "title": "StableQAT: Stable Quantization-Aware Training at Ultra-Low Bitwidths", "comment": null, "summary": "Quantization-aware training (QAT) is essential for deploying large models under strict memory and latency constraints, yet achieving stable and robust optimization at ultra-low bitwidths remains challenging. Common approaches based on the straight-through estimator (STE) or soft quantizers often suffer from gradient mismatch, instability, or high computational overhead. As such, we propose StableQAT, a unified and efficient QAT framework that stabilizes training in ultra low-bit settings via a novel, lightweight, and theoretically grounded surrogate for backpropagation derived from a discrete Fourier analysis of the rounding operator. StableQAT strictly generalizes STE as the latter arises as a special case of our more expressive surrogate family, yielding smooth, bounded, and inexpensive gradients that improve QAT training performance and stability across various hyperparameter choices. In experiments, StableQAT exhibits stable and efficient QAT at 2-4 bit regimes, demonstrating improved training stability, robustness, and superior performance with negligible training overhead against standard QAT techniques. Our code is available at https://github.com/microsoft/StableQAT.", "AI": {"tldr": "StableQAT: A unified QAT framework using Fourier analysis to stabilize ultra-low bitwidth training with lightweight gradients, outperforming STE-based methods.", "motivation": "Current QAT methods (STE-based or soft quantizers) suffer from gradient mismatch, instability, or high computational overhead, especially at ultra-low bitwidths (2-4 bits).", "method": "Proposes StableQAT with a novel surrogate for backpropagation derived from discrete Fourier analysis of the rounding operator, yielding smooth, bounded, inexpensive gradients that generalize STE as a special case.", "result": "StableQAT enables stable and efficient QAT at 2-4 bit regimes with improved training stability, robustness, and superior performance, with negligible training overhead compared to standard QAT techniques.", "conclusion": "StableQAT provides a theoretically grounded, lightweight solution for stable ultra-low bitwidth QAT, generalizing existing approaches and demonstrating practical advantages in challenging quantization settings."}}
{"id": "2601.19680", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19680", "abs": "https://arxiv.org/abs/2601.19680", "authors": ["Antonio Di Marino", "Vincenzo Bevilacqua", "Emanuel Di Nardo", "Angelo Ciaramella", "Ivanoe De Falco", "Giovanna Sannino"], "title": "A new Image Similarity Metric for a Perceptual and Transparent Geometric and Chromatic Assessment", "comment": null, "summary": "In the literature, several studies have shown that state-of-the-art image similarity metrics are not perceptual metrics; moreover, they have difficulty evaluating images, especially when texture distortion is also present. In this work, we propose a new perceptual metric composed of two terms. The first term evaluates the dissimilarity between the textures of two images using Earth Mover's Distance. The second term evaluates the chromatic dissimilarity between two images in the Oklab perceptual color space. We evaluated the performance of our metric on a non-traditional dataset, called Berkeley-Adobe Perceptual Patch Similarity, which contains a wide range of complex distortions in shapes and colors. We have shown that our metric outperforms the state of the art, especially when images contain shape distortions, confirming also its greater perceptiveness. Furthermore, although deep black-box metrics could be very accurate, they only provide similarity scores between two images, without explaining their main differences and similarities. Our metric, on the other hand, provides visual explanations to support the calculated score, making the similarity assessment transparent and justified.", "AI": {"tldr": "Proposes a new perceptual image similarity metric with texture and color components that outperforms state-of-the-art metrics, especially for shape distortions, and provides visual explanations for transparency.", "motivation": "Existing image similarity metrics are not truly perceptual, struggle with texture distortions, and lack transparency - they only provide similarity scores without explaining the differences between images.", "method": "Two-component metric: 1) Texture dissimilarity using Earth Mover's Distance, 2) Chromatic dissimilarity in Oklab perceptual color space. Evaluated on Berkeley-Adobe Perceptual Patch Similarity dataset with complex shape and color distortions.", "result": "Outperforms state-of-the-art metrics, especially for images containing shape distortions, confirming better perceptiveness. Provides visual explanations to support similarity scores, making assessment transparent.", "conclusion": "Proposed metric addresses limitations of existing methods by being more perceptual, handling texture distortions better, and providing transparent visual explanations - offering both accuracy and interpretability."}}
{"id": "2601.19333", "categories": ["cs.LG", "cs.DS"], "pdf": "https://arxiv.org/pdf/2601.19333", "abs": "https://arxiv.org/abs/2601.19333", "authors": ["Rahul Raychaudhury", "Aryan Esmailpour", "Sainyam Galhotra", "Stavros Sintos"], "title": "Metric $k$-clustering using only Weak Comparison Oracles", "comment": null, "summary": "Clustering is a fundamental primitive in unsupervised learning. However, classical algorithms for $k$-clustering (such as $k$-median and $k$-means) assume access to exact pairwise distances -- an unrealistic requirement in many modern applications. We study clustering in the \\emph{Rank-model (R-model)}, where access to distances is entirely replaced by a \\emph{quadruplet oracle} that provides only relative distance comparisons. In practice, such an oracle can represent learned models or human feedback, and is expected to be noisy and entail an access cost.\n  Given a metric space with $n$ input items, we design randomized algorithms that, using only a noisy quadruplet oracle, compute a set of $O(k \\cdot \\mathsf{polylog}(n))$ centers along with a mapping from the input items to the centers such that the clustering cost of the mapping is at most constant times the optimum $k$-clustering cost. Our method achieves a query complexity of $O(n\\cdot k \\cdot \\mathsf{polylog}(n))$ for arbitrary metric spaces and improves to $O((n+k^2) \\cdot \\mathsf{polylog}(n))$ when the underlying metric has bounded doubling dimension. When the metric has bounded doubling dimension we can further improve the approximation from constant to $1+\\varepsilon$, for any arbitrarily small constant $\\varepsilon\\in(0,1)$, while preserving the same asymptotic query complexity. Our framework demonstrates how noisy, low-cost oracles, such as those derived from large language models, can be systematically integrated into scalable clustering algorithms.", "AI": {"tldr": "Clustering with only relative distance comparisons (quadruplet oracle) instead of exact distances, achieving constant approximation with polylog query complexity.", "motivation": "Classical clustering algorithms require exact pairwise distances, which is unrealistic in modern applications where distances may come from learned models or human feedback that are noisy and costly to access.", "method": "Design randomized algorithms using only a noisy quadruplet oracle that provides relative distance comparisons. The approach works with Rank-model (R-model) where exact distances are replaced by quadruplet comparisons.", "result": "Achieves O(k\u00b7polylog(n)) centers with constant approximation to optimal k-clustering cost using O(n\u00b7k\u00b7polylog(n)) queries for arbitrary metrics, improving to O((n+k\u00b2)\u00b7polylog(n)) for bounded doubling dimension metrics. For bounded doubling dimension, achieves (1+\u03b5)-approximation with same asymptotic complexity.", "conclusion": "Demonstrates how noisy, low-cost oracles (like those from large language models) can be systematically integrated into scalable clustering algorithms, providing practical solutions for modern applications where exact distances are unavailable."}}
{"id": "2601.19683", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19683", "abs": "https://arxiv.org/abs/2601.19683", "authors": ["Hanting Niu", "Junkai Deng", "Fei Hou", "Wencheng Wang", "Ying He"], "title": "SharpNet: Enhancing MLPs to Represent Functions with Controlled Non-differentiability", "comment": null, "summary": "Multi-layer perceptrons (MLPs) are a standard tool for learning and function approximation, but they inherently yield outputs that are globally smooth. As a result, they struggle to represent functions that are continuous yet deliberately non-differentiable (i.e., with prescribed $C^0$ sharp features) without relying on ad hoc post-processing. We present SharpNet, a modified MLP architecture capable of encoding functions with user-defined sharp features by enriching the network with an auxiliary feature function, which is defined as the solution to a Poisson equation with jump Neumann boundary conditions. It is evaluated via an efficient local integral that is fully differentiable with respect to the feature locations, enabling our method to jointly optimize both the feature locations and the MLP parameters to recover the target functions/models. The $C^0$-continuity of SharpNet is precisely controllable, ensuring $C^0$-continuity at the feature locations and smoothness elsewhere. We validate SharpNet on 2D problems and 3D CAD model reconstruction, and compare it against several state-of-the-art baselines. In both types of tasks, SharpNet accurately recovers sharp edges and corners while maintaining smooth behavior away from those features, whereas existing methods tend to smooth out gradient discontinuities. Both qualitative and quantitative evaluations highlight the benefits of our approach.", "AI": {"tldr": "SharpNet is a modified MLP architecture that can represent functions with user-defined sharp features by incorporating an auxiliary feature function from Poisson equations, enabling joint optimization of feature locations and network parameters.", "motivation": "Standard MLPs produce globally smooth outputs and struggle to represent continuous but deliberately non-differentiable functions with prescribed C^0 sharp features without ad hoc post-processing.", "method": "Enriches MLP with auxiliary feature function defined as solution to Poisson equation with jump Neumann boundary conditions, evaluated via efficient local integral that's differentiable w.r.t. feature locations, enabling joint optimization of feature locations and MLP parameters.", "result": "SharpNet accurately recovers sharp edges and corners while maintaining smooth behavior away from features, outperforming state-of-the-art baselines that tend to smooth out gradient discontinuities in both 2D problems and 3D CAD model reconstruction.", "conclusion": "SharpNet provides precise control over C^0-continuity, ensuring C^0-continuity at feature locations and smoothness elsewhere, offering a superior approach for representing functions with prescribed sharp features compared to existing methods."}}
{"id": "2601.19336", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19336", "abs": "https://arxiv.org/abs/2601.19336", "authors": ["Zhao-Han Peng", "Shaohui Li", "Zhi Li", "Shulan Ruan", "Yu Liu", "You He"], "title": "From Observations to Events: Event-Aware World Model for Reinforcement Learning", "comment": "43 pages, accepted by ICLR 2026", "summary": "While model-based reinforcement learning (MBRL) improves sample efficiency by learning world models from raw observations, existing methods struggle to generalize across structurally similar scenes and remain vulnerable to spurious variations such as textures or color shifts. From a cognitive science perspective, humans segment continuous sensory streams into discrete events and rely on these key events for decision-making. Motivated by this principle, we propose the Event-Aware World Model (EAWM), a general framework that learns event-aware representations to streamline policy learning without requiring handcrafted labels. EAWM employs an automated event generator to derive events from raw observations and introduces a Generic Event Segmentor (GES) to identify event boundaries, which mark the start and end time of event segments. Through event prediction, the representation space is shaped to capture meaningful spatio-temporal transitions. Beyond this, we present a unified formulation of seemingly distinct world model architectures and show the broad applicability of our methods. Experiments on Atari 100K, Craftax 1M, and DeepMind Control 500K, DMC-GB2 500K demonstrate that EAWM consistently boosts the performance of strong MBRL baselines by 10%-45%, setting new state-of-the-art results across benchmarks. Our code is released at https://github.com/MarquisDarwin/EAWM.", "AI": {"tldr": "EAWM introduces an event-aware world model for MBRL that learns to segment observations into discrete events, improving generalization across structurally similar scenes and robustness to spurious variations.", "motivation": "Existing MBRL methods struggle with generalization across structurally similar scenes and are vulnerable to spurious variations like textures or color shifts. Inspired by human cognition where we segment continuous sensory streams into discrete events for decision-making.", "method": "Proposes Event-Aware World Model (EAWM) with automated event generator and Generic Event Segmentor (GES) to identify event boundaries. Learns event-aware representations through event prediction, shaping representation space to capture meaningful spatio-temporal transitions.", "result": "EAWM boosts performance of strong MBRL baselines by 10%-45% across Atari 100K, Craftax 1M, DeepMind Control 500K, and DMC-GB2 500K benchmarks, setting new state-of-the-art results.", "conclusion": "Event-aware representation learning inspired by human cognitive processes effectively improves MBRL generalization and robustness, with broad applicability across different world model architectures."}}
{"id": "2601.19686", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19686", "abs": "https://arxiv.org/abs/2601.19686", "authors": ["Ziyue Wang", "Sheng Jin", "Zhongrong Zuo", "Jiawei Wu", "Han Qiu", "Qi She", "Hao Zhang", "Xudong Jiang"], "title": "Video-KTR: Reinforcing Video Reasoning via Key Token Attribution", "comment": "Accepted to ICLR 2026", "summary": "Reinforcement learning (RL) has shown strong potential for enhancing reasoning in multimodal large language models, yet existing video reasoning methods often rely on coarse sequence-level rewards or single-factor token selection, neglecting fine-grained links among visual inputs, temporal dynamics, and linguistic outputs, limiting both accuracy and interpretability. We propose Video-KTR, a modality-aware policy shaping framework that performs selective, token-level RL by combining three attribution signals: (1) visual-aware tokens identified via counterfactual masking to reveal perceptual dependence; (2) temporal-aware tokens detected through frame shuffling to expose temporal sensitivity; and (3) high-entropy tokens signaling predictive uncertainty. By reinforcing only these key tokens, Video-KTR focuses learning on semantically informative, modality-sensitive content while filtering out low-value tokens. Across five challenging benchmarks, Video-KTR achieves state-of-the-art or highly competitive results, achieving 42.7\\% on Video-Holmes (surpassing GPT-4o) with consistent gains on both reasoning and general video understanding tasks. Ablation studies verify the complementary roles of the attribution signals and the robustness of targeted token-level updates. Overall, Video-KTR improves accuracy and interpretability, offering a simple, drop-in extension to RL for complex video reasoning. Our code and models are available at https://github.com/zywang0104/Video-KTR.", "AI": {"tldr": "Video-KTR: A modality-aware policy shaping framework for video reasoning that performs selective token-level reinforcement learning using three attribution signals (visual-aware, temporal-aware, and high-entropy tokens) to improve accuracy and interpretability.", "motivation": "Existing RL methods for video reasoning rely on coarse sequence-level rewards or single-factor token selection, neglecting fine-grained links among visual inputs, temporal dynamics, and linguistic outputs, which limits both accuracy and interpretability.", "method": "Video-KTR combines three attribution signals: (1) visual-aware tokens identified via counterfactual masking to reveal perceptual dependence; (2) temporal-aware tokens detected through frame shuffling to expose temporal sensitivity; and (3) high-entropy tokens signaling predictive uncertainty. The framework reinforces only these key tokens, focusing learning on semantically informative, modality-sensitive content.", "result": "Achieves state-of-the-art or highly competitive results across five challenging benchmarks, with 42.7% on Video-Holmes (surpassing GPT-4o) and consistent gains on both reasoning and general video understanding tasks. Ablation studies verify the complementary roles of attribution signals and robustness of targeted token-level updates.", "conclusion": "Video-KTR improves accuracy and interpretability for video reasoning, offering a simple, drop-in extension to RL that focuses learning on modality-sensitive content while filtering out low-value tokens."}}
{"id": "2601.19341", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19341", "abs": "https://arxiv.org/abs/2601.19341", "authors": ["Xinran Xu", "Li Rong Wang", "Xiuyi Fan"], "title": "Robust Uncertainty Estimation under Distribution Shift via Difference Reconstruction", "comment": null, "summary": "Estimating uncertainty in deep learning models is critical for reliable decision-making in high-stakes applications such as medical imaging. Prior research has established that the difference between an input sample and its reconstructed version produced by an auxiliary model can serve as a useful proxy for uncertainty. However, directly comparing reconstructions with the original input is degraded by information loss and sensitivity to superficial details, which limits its effectiveness. In this work, we propose Difference Reconstruction Uncertainty Estimation (DRUE), a method that mitigates this limitation by reconstructing inputs from two intermediate layers and measuring the discrepancy between their outputs as the uncertainty score. To evaluate uncertainty estimation in practice, we follow the widely used out-of-distribution (OOD) detection paradigm, where in-distribution (ID) training data are compared against datasets with increasing domain shift. Using glaucoma detection as the ID task, we demonstrate that DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets, highlighting its robustness and reliability under distribution shift. This work provides a principled and effective framework for enhancing model reliability in uncertain environments.", "AI": {"tldr": "DRUE improves uncertainty estimation by comparing reconstructions from two intermediate layers instead of direct input-reconstruction comparison, achieving better OOD detection performance for medical imaging tasks.", "motivation": "Existing uncertainty estimation methods that compare input samples with their reconstructions suffer from information loss and sensitivity to superficial details, limiting their effectiveness for reliable decision-making in high-stakes medical applications.", "method": "Proposes Difference Reconstruction Uncertainty Estimation (DRUE) which reconstructs inputs from two intermediate layers and measures the discrepancy between their outputs as the uncertainty score, avoiding direct input-reconstruction comparison.", "result": "DRUE consistently achieves superior AUC and AUPR across multiple OOD datasets in glaucoma detection tasks, demonstrating robustness and reliability under distribution shift.", "conclusion": "DRUE provides a principled and effective framework for enhancing model reliability in uncertain environments, particularly for medical imaging applications where uncertainty estimation is critical."}}
{"id": "2601.19690", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19690", "abs": "https://arxiv.org/abs/2601.19690", "authors": ["Renrong Shao", "Dongyang Li", "Dong Xia", "Lin Shao", "Jiangdong Lu", "Fen Zheng", "Lulu Zhang"], "title": "DSVM-UNet : Enhancing VM-UNet with Dual Self-distillation for Medical Image Segmentation", "comment": "5 pages, 1 figures", "summary": "Vision Mamba models have been extensively researched in various fields, which address the limitations of previous models by effectively managing long-range dependencies with a linear-time overhead. Several prospective studies have further designed Vision Mamba based on UNet(VM-UNet) for medical image segmentation. These approaches primarily focus on optimizing architectural designs by creating more complex structures to enhance the model's ability to perceive semantic features. In this paper, we propose a simple yet effective approach to improve the model by Dual Self-distillation for VM-UNet (DSVM-UNet) without any complex architectural designs. To achieve this goal, we develop double self-distillation methods to align the features at both the global and local levels. Extensive experiments conducted on the ISIC2017, ISIC2018, and Synapse benchmarks demonstrate that our approach achieves state-of-the-art performance while maintaining computational efficiency. Code is available at https://github.com/RoryShao/DSVM-UNet.git.", "AI": {"tldr": "DSVM-UNet improves Vision Mamba UNet for medical image segmentation through dual self-distillation at global and local levels, achieving SOTA performance without complex architectural changes.", "motivation": "Existing Vision Mamba UNet approaches focus on complex architectural designs to enhance semantic feature perception, but this paper proposes a simpler alternative through knowledge distillation to improve model performance without architectural complexity.", "method": "Proposes Dual Self-distillation for VM-UNet (DSVM-UNet) with double self-distillation methods that align features at both global and local levels, maintaining the original architecture while enhancing feature learning.", "result": "Extensive experiments on ISIC2017, ISIC2018, and Synapse benchmarks demonstrate state-of-the-art performance while maintaining computational efficiency.", "conclusion": "The proposed DSVM-UNet approach provides a simple yet effective way to improve Vision Mamba UNet performance through dual self-distillation, achieving superior results without complex architectural modifications."}}
{"id": "2601.19352", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19352", "abs": "https://arxiv.org/abs/2601.19352", "authors": ["Zhixiao Wang", "Chaofan Zhu", "Qihan Feng", "Jian Zhang", "Xiaobin Rui", "Philip S Yu"], "title": "GraphSB: Boosting Imbalanced Node Classification on Graphs through Structural Balance", "comment": null, "summary": "Imbalanced node classification is a critical challenge in graph learning, where most existing methods typically utilize Graph Neural Networks (GNNs) to learn node representations. These methods can be broadly categorized into the data-level and the algorithm-level. The former aims to synthesize minority-class nodes to mitigate quantity imbalance, while the latter tries to optimize the learning process to highlight minority classes. However, neither of them addresses the inherently imbalanced graph structure, which is a fundamental factor that incurs majority-class dominance and minority-class assimilation in GNNs. Our theoretical analysis further supports this critical insight. Therefore, we propose GraphSB (Graph Structural Balance), a novel framework that incorporates Structural Balance as a key strategy to address the underlying imbalanced graph structure before node synthesis. Structural Balance performs a two-stage structure optimization: Structure Enhancement that mines hard samples near decision boundaries through dual-view analysis and enhances connectivity for minority classes through adaptive augmentation, and Relation Diffusion that propagates the enhanced minority context while simultaneously capturing higher-order structural dependencies. Thus, GraphSB balances structural distribution before node synthesis, enabling more effective learning in GNNs. Extensive experiments demonstrate that GraphSB significantly outperforms the state-of-the-art methods. More importantly, the proposed Structural Balance can be seamlessly integrated into state-of-the-art methods as a simple plug-and-play module, increasing their accuracy by an average of 4.57%.", "AI": {"tldr": "GraphSB addresses imbalanced node classification by optimizing graph structure before node synthesis, using Structural Balance with two-stage optimization to mitigate majority-class dominance and minority-class assimilation in GNNs.", "motivation": "Existing methods for imbalanced node classification focus on data-level (synthesizing minority nodes) or algorithm-level (optimizing learning process) approaches, but neither addresses the inherently imbalanced graph structure which causes majority-class dominance and minority-class assimilation in GNNs.", "method": "Proposes GraphSB framework with Structural Balance strategy: 1) Structure Enhancement - mines hard samples near decision boundaries via dual-view analysis and enhances minority connectivity through adaptive augmentation; 2) Relation Diffusion - propagates enhanced minority context while capturing higher-order structural dependencies.", "result": "Extensive experiments show GraphSB significantly outperforms state-of-the-art methods. Structural Balance can be integrated as plug-and-play module into existing methods, increasing their accuracy by average 4.57%.", "conclusion": "Addressing imbalanced graph structure before node synthesis is crucial for effective imbalanced node classification. Structural Balance provides fundamental solution that can be easily integrated into existing methods to improve performance."}}
{"id": "2601.19694", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19694", "abs": "https://arxiv.org/abs/2601.19694", "authors": ["Yucheng Xie", "Fu Feng", "Ruixiao Shi", "Jing Wang", "Yong Rui", "Xin Geng"], "title": "Self-Supervised Weight Templates for Scalable Vision Model Initialization", "comment": null, "summary": "The increasing scale and complexity of modern model parameters underscore the importance of pre-trained models. However, deployment often demands architectures of varying sizes, exposing limitations of conventional pre-training and fine-tuning. To address this, we propose SWEET, a self-supervised framework that performs constraint-based pre-training to enable scalable initialization in vision tasks. Instead of pre-training a fixed-size model, we learn a shared weight template and size-specific weight scalers under Tucker-based factorization, which promotes modularity and supports flexible adaptation to architectures with varying depths and widths. Target models are subsequently initialized by composing and reweighting the template through lightweight weight scalers, whose parameters can be efficiently learned from minimal training data. To further enhance flexibility in width expansion, we introduce width-wise stochastic scaling, which regularizes the template along width-related dimensions and encourages robust, width-invariant representations for improved cross-width generalization. Extensive experiments on \\textsc{classification}, \\textsc{detection}, \\textsc{segmentation} and \\textsc{generation} tasks demonstrate the state-of-the-art performance of SWEET for initializing variable-sized vision models.", "AI": {"tldr": "SWEET is a self-supervised framework that learns a shared weight template and size-specific scalers to enable flexible initialization of vision models with varying depths and widths, outperforming conventional pre-training methods.", "motivation": "Modern models require varying architectures for deployment, but conventional pre-training and fine-tuning are limited to fixed-size models, creating inefficiencies when adapting to different computational constraints or application needs.", "method": "Uses Tucker-based factorization to learn a shared weight template and size-specific weight scalers, with width-wise stochastic scaling for regularization. Target models are initialized by composing and reweighting the template through lightweight scalers learned from minimal data.", "result": "Extensive experiments on classification, detection, segmentation, and generation tasks demonstrate state-of-the-art performance for initializing variable-sized vision models.", "conclusion": "SWEET provides an effective self-supervised framework for scalable model initialization that supports flexible adaptation to architectures with varying depths and widths, addressing limitations of conventional pre-training approaches."}}
{"id": "2601.19375", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19375", "abs": "https://arxiv.org/abs/2601.19375", "authors": ["Quy-Anh Dang", "Chris Ngo"], "title": "Selective Steering: Norm-Preserving Control Through Discriminative Layer Selection", "comment": null, "summary": "Despite significant progress in alignment, large language models (LLMs) remain vulnerable to adversarial attacks that elicit harmful behaviors. Activation steering techniques offer a promising inference-time intervention approach, but existing methods suffer from critical limitations: activation addition requires careful coefficient tuning and is sensitive to layer-specific norm variations, while directional ablation provides only binary control. Recent work on Angular Steering introduces continuous control via rotation in a 2D subspace, but its practical implementation violates norm preservation, causing distribution shift and generation collapse, particularly in models below 7B parameters. We propose Selective Steering, which addresses these limitations through two key innovations: (1) a mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations exhibit opposite-signed class alignment. Experiments across nine models demonstrate that Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100\\% capability retention on standard benchmarks. Our approach provides a principled, efficient framework for controllable and stable LLM behavior modification. Code: https://github.com/knoveleng/steering", "AI": {"tldr": "Selective Steering introduces norm-preserving rotation and discriminative layer selection for stable activation steering in LLMs, achieving 5.5x higher attack success rates with zero perplexity violations.", "motivation": "Existing activation steering methods have limitations: activation addition requires careful tuning and is sensitive to norm variations, directional ablation offers only binary control, and Angular Steering violates norm preservation causing distribution shift and generation collapse, especially in smaller models.", "method": "Proposes Selective Steering with two key innovations: (1) mathematically rigorous norm-preserving rotation formulation that maintains activation distribution integrity, and (2) discriminative layer selection that applies steering only where feature representations show opposite-signed class alignment.", "result": "Experiments across nine models show Selective Steering achieves 5.5x higher attack success rates than prior methods while maintaining zero perplexity violations and approximately 100% capability retention on standard benchmarks.", "conclusion": "Selective Steering provides a principled, efficient framework for controllable and stable LLM behavior modification, addressing critical limitations of existing activation steering techniques."}}
{"id": "2601.19394", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19394", "abs": "https://arxiv.org/abs/2601.19394", "authors": ["Xudong Han", "Senkang Hu", "Yihang Tao", "Yu Guo", "Philip Birch", "Sam Tak Wu Kwong", "Yuguang Fang"], "title": "DSP-Reg: Domain-Sensitive Parameter Regularization for Robust Domain Generalization", "comment": null, "summary": "Domain Generalization (DG) is a critical area that focuses on developing models capable of performing well on data from unseen distributions, which is essential for real-world applications. Existing approaches primarily concentrate on learning domain-invariant features, which assume that a model robust to variations in the source domains will generalize well to unseen target domains. However, these approaches neglect a deeper analysis at the parameter level, which makes the model hard to explicitly differentiate between parameters sensitive to domain shifts and those robust, potentially hindering its overall ability to generalize. In order to address these limitations, we first build a covariance-based parameter sensitivity analysis framework to quantify the sensitivity of each parameter in a model to domain shifts. By computing the covariance of parameter gradients across multiple source domains, we can identify parameters that are more susceptible to domain variations, which serves as our theoretical foundation. Based on this, we propose Domain-Sensitive Parameter Regularization (DSP-Reg), a principled framework that guides model optimization by a soft regularization technique that encourages the model to rely more on domain-invariant parameters while suppressing those that are domain-specific. This approach provides a more granular control over the model's learning process, leading to improved robustness and generalization to unseen domains. Extensive experiments on benchmarks, such as PACS, VLCS, OfficeHome, and DomainNet, demonstrate that DSP-Reg outperforms state-of-the-art approaches, achieving an average accuracy of 66.7\\% and surpassing all baselines.", "AI": {"tldr": "Proposes Domain-Sensitive Parameter Regularization (DSP-Reg), a framework that identifies domain-sensitive parameters via covariance analysis and regularizes them to improve domain generalization.", "motivation": "Existing domain generalization methods focus on learning domain-invariant features but neglect parameter-level analysis, making models unable to explicitly differentiate between domain-sensitive and domain-invariant parameters, which limits generalization ability.", "method": "First builds a covariance-based parameter sensitivity analysis framework to quantify each parameter's sensitivity to domain shifts by computing covariance of parameter gradients across source domains. Then proposes DSP-Reg, a soft regularization technique that encourages reliance on domain-invariant parameters while suppressing domain-specific ones.", "result": "Extensive experiments on PACS, VLCS, OfficeHome, and DomainNet benchmarks show DSP-Reg outperforms state-of-the-art approaches, achieving 66.7% average accuracy and surpassing all baselines.", "conclusion": "The proposed parameter-level analysis and regularization framework provides more granular control over model learning, leading to improved robustness and generalization to unseen domains, addressing limitations of existing domain-invariant feature approaches."}}
{"id": "2601.19753", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19753", "abs": "https://arxiv.org/abs/2601.19753", "authors": ["Xinrui Zhang", "Yufeng Wang", "Shuangkang Fang", "Zesheng Wang", "Dacheng Qi", "Wenrui Ding"], "title": "WaterClear-GS: Optical-Aware Gaussian Splatting for Underwater Reconstruction and Restoration", "comment": null, "summary": "Underwater 3D reconstruction and appearance restoration are hindered by the complex optical properties of water, such as wavelength-dependent attenuation and scattering. Existing Neural Radiance Fields (NeRF)-based methods struggle with slow rendering speeds and suboptimal color restoration, while 3D Gaussian Splatting (3DGS) inherently lacks the capability to model complex volumetric scattering effects. To address these issues, we introduce WaterClear-GS, the first pure 3DGS-based framework that explicitly integrates underwater optical properties of local attenuation and scattering into Gaussian primitives, eliminating the need for an auxiliary medium network. Our method employs a dual-branch optimization strategy to ensure underwater photometric consistency while naturally recovering water-free appearances. This strategy is enhanced by depth-guided geometry regularization and perception-driven image loss, together with exposure constraints, spatially-adaptive regularization, and physically guided spectral regularization, which collectively enforce local 3D coherence and maintain natural visual perception. Experiments on standard benchmarks and our newly collected dataset demonstrate that WaterClear-GS achieves outstanding performance on both novel view synthesis (NVS) and underwater image restoration (UIR) tasks, while maintaining real-time rendering. The code will be available at https://buaaxrzhang.github.io/WaterClear-GS/.", "AI": {"tldr": "WaterClear-GS is a 3D Gaussian Splatting-based framework that integrates underwater optical properties (attenuation and scattering) into Gaussian primitives for real-time underwater 3D reconstruction and appearance restoration, without needing auxiliary networks.", "motivation": "Existing NeRF-based methods for underwater 3D reconstruction suffer from slow rendering and poor color restoration, while 3D Gaussian Splatting lacks the ability to model complex volumetric scattering effects inherent in underwater environments.", "method": "A pure 3DGS framework that explicitly integrates underwater optical properties (local attenuation and scattering) into Gaussian primitives. Uses dual-branch optimization for photometric consistency and water-free appearance recovery, enhanced by depth-guided geometry regularization, perception-driven image loss, exposure constraints, spatially-adaptive regularization, and physically guided spectral regularization.", "result": "Achieves outstanding performance on both novel view synthesis and underwater image restoration tasks while maintaining real-time rendering, as demonstrated on standard benchmarks and a newly collected dataset.", "conclusion": "WaterClear-GS successfully addresses the limitations of existing methods by integrating underwater optical properties directly into 3D Gaussian Splatting, enabling efficient and high-quality underwater 3D reconstruction and appearance restoration with real-time rendering capabilities."}}
{"id": "2601.19395", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19395", "abs": "https://arxiv.org/abs/2601.19395", "authors": ["Saeed Nasehi Basharzad", "Farhana Choudhury", "Egemen Tanin"], "title": "SEAFormer: A Spatial Proximity and Edge-Aware Transformer for Real-World Vehicle Routing Problems", "comment": "26 pages", "summary": "Real-world Vehicle Routing Problems (RWVRPs) require solving complex, sequence-dependent challenges at scale with constraints such as delivery time window, replenishment or recharging stops, asymmetric travel cost, etc. While recent neural methods achieve strong results on large-scale classical VRP benchmarks, they struggle to address RWVRPs because their strategies overlook sequence dependencies and underutilize edge-level information, which are precisely the characteristics that define the complexity of RWVRPs. We present SEAFormer, a novel transformer that incorporates both node-level and edge-level information in decision-making through two key innovations. First, our Clustered Proximity Attention (CPA) exploits locality-aware clustering to reduce the complexity of attention from $O(n^2)$ to $O(n)$ while preserving global perspective, allowing SEAFormer to efficiently train on large instances. Second, our lightweight edge-aware module captures pairwise features through residual fusion, enabling effective incorporation of edge-based information and faster convergence. Extensive experiments across four RWVRP variants with various scales demonstrate that SEAFormer achieves superior results over state-of-the-art methods. Notably, SEAFormer is the first neural method to solve 1,000+ node RWVRPs effectively, while also achieving superior performance on classic VRPs, making it a versatile solution for both research benchmarks and real-world applications.", "AI": {"tldr": "SEAFormer is a novel transformer model that efficiently solves large-scale Real-world Vehicle Routing Problems by incorporating both node-level and edge-level information through clustered proximity attention and edge-aware modules.", "motivation": "Real-world VRP variants have complex sequence dependencies and constraints (time windows, recharging, asymmetric costs) that existing neural methods struggle with because they overlook sequence dependencies and underutilize edge-level information.", "method": "SEAFormer uses two key innovations: 1) Clustered Proximity Attention (CPA) that reduces attention complexity from O(n\u00b2) to O(n) while preserving global perspective through locality-aware clustering, and 2) lightweight edge-aware module that captures pairwise features through residual fusion.", "result": "SEAFormer achieves superior results across four RWVRP variants at various scales, becoming the first neural method to effectively solve 1,000+ node RWVRPs while also achieving superior performance on classic VRPs.", "conclusion": "SEAFormer provides a versatile solution for both research benchmarks and real-world applications by efficiently handling large-scale RWVRPs with complex constraints through its innovative attention mechanism and edge-aware design."}}
{"id": "2601.19771", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19771", "abs": "https://arxiv.org/abs/2601.19771", "authors": ["Deeksha Arun", "Kevin W. Bowyer", "Patrick Flynn"], "title": "PaW-ViT: A Patch-based Warping Vision Transformer for Robust Ear Verification", "comment": null, "summary": "The rectangular tokens common to vision transformer methods for visual recognition can strongly affect performance of these methods due to incorporation of information outside the objects to be recognized. This paper introduces PaW-ViT, Patch-based Warping Vision Transformer, a preprocessing approach rooted in anatomical knowledge that normalizes ear images to enhance the efficacy of ViT. By accurately aligning token boundaries to detected ear feature boundaries, PaW-ViT obtains greater robustness to shape, size, and pose variation. By aligning feature boundaries to natural ear curvature, it produces more consistent token representations for various morphologies. Experiments confirm the effectiveness of PaW-ViT on various ViT models (ViT-T, ViT-S, ViT-B, ViT-L) and yield reasonable alignment robustness to variation in shape, size, and pose. Our work aims to solve the disconnect between ear biometric morphological variation and transformer architecture positional sensitivity, presenting a possible avenue for authentication schemes.", "AI": {"tldr": "PaW-ViT is a preprocessing method that warps ear images using anatomical knowledge to align transformer token boundaries with ear feature boundaries, improving ViT performance for ear biometrics by addressing morphological variations.", "motivation": "Rectangular tokens in vision transformers can incorporate irrelevant background information when recognizing objects like ears, and transformers are sensitive to positional variations while ear biometrics involve significant morphological variations in shape, size, and pose.", "method": "Patch-based Warping Vision Transformer (PaW-ViT) preprocesses ear images by warping them based on anatomical knowledge to align token boundaries with detected ear feature boundaries, creating more consistent token representations across different ear morphologies.", "result": "Experiments show PaW-ViT improves various ViT models (ViT-T, ViT-S, ViT-B, ViT-L) and demonstrates robust alignment to variations in ear shape, size, and pose, enhancing ear recognition performance.", "conclusion": "PaW-ViT successfully bridges the gap between ear biometric morphological variation and transformer positional sensitivity, offering a promising approach for ear authentication systems by improving feature alignment and representation consistency."}}
{"id": "2601.19439", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19439", "abs": "https://arxiv.org/abs/2601.19439", "authors": ["Giuseppe Chiari", "Michele Piccoli", "Davide Zoni"], "title": "OSIRIS: Bridging Analog Circuit Design and Machine Learning with Scalable Dataset Generation", "comment": null, "summary": "The automation of analog integrated circuit (IC) design remains a longstanding challenge, primarily due to the intricate interdependencies among physical layout, parasitic effects, and circuit-level performance. These interactions impose complex constraints that are difficult to accurately capture and optimize using conventional design methodologies. Although recent advances in machine learning (ML) have shown promise in automating specific stages of the analog design flow, the development of holistic, end-to-end frameworks that integrate these stages and iteratively refine layouts using post-layout, parasitic-aware performance feedback is still in its early stages. Furthermore, progress in this direction is hindered by the limited availability of open, high-quality datasets tailored to the analog domain, restricting both the benchmarking and the generalizability of ML-based techniques. To address these limitations, we present OSIRIS, a scalable dataset generation pipeline for analog IC design. OSIRIS systematically explores the design space of analog circuits while producing comprehensive performance metrics and metadata, thereby enabling ML-driven research in electronic design automation (EDA). In addition, we release a dataset consisting of 87,100 circuit variations generated with OSIRIS, accompanied by a reinforcement learning (RL)-based baseline method that exploits OSIRIS for analog design optimization.", "AI": {"tldr": "OSIRIS is a scalable dataset generation pipeline for analog IC design that creates comprehensive circuit variations with performance metrics to enable ML research in EDA, addressing the lack of open, high-quality analog datasets.", "motivation": "Analog IC design automation faces challenges due to complex interdependencies between layout, parasitics, and performance. Current ML approaches lack holistic end-to-end frameworks and are hindered by limited open, high-quality analog datasets for benchmarking and generalizability.", "method": "OSIRIS is a scalable dataset generation pipeline that systematically explores analog circuit design space while producing comprehensive performance metrics and metadata. The authors also release a dataset of 87,100 circuit variations generated with OSIRIS and provide a reinforcement learning-based baseline method for analog design optimization.", "result": "The paper presents OSIRIS pipeline and releases a substantial dataset of 87,100 circuit variations with comprehensive performance metrics, enabling ML-driven research in electronic design automation. The RL-based baseline demonstrates how OSIRIS can be exploited for analog design optimization.", "conclusion": "OSIRIS addresses critical data limitations in analog IC design automation by providing a scalable dataset generation pipeline and a substantial open dataset, facilitating ML research and benchmarking in electronic design automation for analog circuits."}}
{"id": "2601.19785", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19785", "abs": "https://arxiv.org/abs/2601.19785", "authors": ["Haozhi Zhu", "Miaomiao Zhao", "Dingyao Liu", "Runze Tian", "Yan Zhang", "Jie Guo", "Fenggen Yu"], "title": "GeoDiff3D: Self-Supervised 3D Scene Generation with Geometry-Constrained 2D Diffusion Guidance", "comment": null, "summary": "3D scene generation is a core technology for gaming, film/VFX, and VR/AR. Growing demand for rapid iteration, high-fidelity detail, and accessible content creation has further increased interest in this area. Existing methods broadly follow two paradigms - indirect 2D-to-3D reconstruction and direct 3D generation - but both are limited by weak structural modeling and heavy reliance on large-scale ground-truth supervision, often producing structural artifacts, geometric inconsistencies, and degraded high-frequency details in complex scenes. We propose GeoDiff3D, an efficient self-supervised framework that uses coarse geometry as a structural anchor and a geometry-constrained 2D diffusion model to provide texture-rich reference images. Importantly, GeoDiff3D does not require strict multi-view consistency of the diffusion-generated references and remains robust to the resulting noisy, inconsistent guidance. We further introduce voxel-aligned 3D feature aggregation and dual self-supervision to maintain scene coherence and fine details while substantially reducing dependence on labeled data. GeoDiff3D also trains with low computational cost and enables fast, high-quality 3D scene generation. Extensive experiments on challenging scenes show improved generalization and generation quality over existing baselines, offering a practical solution for accessible and efficient 3D scene construction.", "AI": {"tldr": "GeoDiff3D is a self-supervised 3D scene generation framework that uses coarse geometry as structural anchor and geometry-constrained 2D diffusion for texture-rich references, achieving high-quality generation with reduced supervision and computational cost.", "motivation": "Existing 3D scene generation methods (indirect 2D-to-3D reconstruction and direct 3D generation) suffer from weak structural modeling, heavy reliance on large-scale ground-truth supervision, structural artifacts, geometric inconsistencies, and degraded high-frequency details in complex scenes.", "method": "Uses coarse geometry as structural anchor, geometry-constrained 2D diffusion model for texture-rich reference images (doesn't require strict multi-view consistency), voxel-aligned 3D feature aggregation, and dual self-supervision to maintain scene coherence and fine details.", "result": "Extensive experiments on challenging scenes show improved generalization and generation quality over existing baselines, with low computational cost and fast, high-quality 3D scene generation.", "conclusion": "GeoDiff3D offers a practical solution for accessible and efficient 3D scene construction with reduced dependence on labeled data, robust to noisy/inconsistent guidance, and maintains scene coherence and fine details."}}
{"id": "2601.19448", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.19448", "abs": "https://arxiv.org/abs/2601.19448", "authors": ["Binyan Xu", "Fan Yang", "Xilin Dai", "Di Tang", "Kehuan Zhang"], "title": "From Internal Diagnosis to External Auditing: A VLM-Driven Paradigm for Online Test-Time Backdoor Defense", "comment": "19 pages, 10 figures, 12 tables", "summary": "Deep Neural Networks remain inherently vulnerable to backdoor attacks. Traditional test-time defenses largely operate under the paradigm of internal diagnosis methods like model repairing or input robustness, yet these approaches are often fragile under advanced attacks as they remain entangled with the victim model's corrupted parameters. We propose a paradigm shift from Internal Diagnosis to External Semantic Auditing, arguing that effective defense requires decoupling safety from the victim model via an independent, semantically grounded auditor. To this end, we present a framework harnessing Universal Vision-Language Models (VLMs) as evolving semantic gatekeepers. We introduce PRISM (Prototype Refinement & Inspection via Statistical Monitoring), which overcomes the domain gap of general VLMs through two key mechanisms: a Hybrid VLM Teacher that dynamically refines visual prototypes online, and an Adaptive Router powered by statistical margin monitoring to calibrate gating thresholds in real-time. Extensive evaluation across 17 datasets and 11 attack types demonstrates that PRISM achieves state-of-the-art performance, suppressing Attack Success Rate to <1% on CIFAR-10 while improving clean accuracy, establishing a new standard for model-agnostic, externalized security.", "AI": {"tldr": "PRISM is a new defense framework that uses universal vision-language models as external semantic auditors to detect backdoor attacks, achieving <1% attack success rate on CIFAR-10 while maintaining clean accuracy.", "motivation": "Traditional test-time defenses for backdoor attacks rely on internal diagnosis methods that are fragile under advanced attacks because they remain entangled with the victim model's corrupted parameters. There's a need to decouple safety from the victim model through independent, semantically grounded auditing.", "method": "PRISM uses Universal Vision-Language Models as evolving semantic gatekeepers with two key mechanisms: 1) Hybrid VLM Teacher that dynamically refines visual prototypes online, and 2) Adaptive Router powered by statistical margin monitoring to calibrate gating thresholds in real-time.", "result": "Extensive evaluation across 17 datasets and 11 attack types shows PRISM achieves state-of-the-art performance, suppressing Attack Success Rate to <1% on CIFAR-10 while improving clean accuracy.", "conclusion": "PRISM establishes a new standard for model-agnostic, externalized security by shifting from internal diagnosis to external semantic auditing, effectively decoupling safety from the victim model's corrupted parameters."}}
{"id": "2601.19795", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19795", "abs": "https://arxiv.org/abs/2601.19795", "authors": ["Deeksha Arun", "Kevin W. Bowyer", "Patrick Flynn"], "title": "Diffusion for De-Occlusion: Accessory-Aware Diffusion Inpainting for Robust Ear Biometric Recognition", "comment": null, "summary": "Ear occlusions (arising from the presence of ear accessories such as earrings and earphones) can negatively impact performance in ear-based biometric recognition systems, especially in unconstrained imaging circumstances. In this study, we assess the effectiveness of a diffusion-based ear inpainting technique as a pre-processing aid to mitigate the issues of ear accessory occlusions in transformer-based ear recognition systems. Given an input ear image and an automatically derived accessory mask, the inpainting model reconstructs clean and anatomically plausible ear regions by synthesizing missing pixels while preserving local geometric coherence along key ear structures, including the helix, antihelix, concha, and lobule. We evaluate the effectiveness of this pre-processing aid in transformer-based recognition systems for several vision transformer models and different patch sizes for a range of benchmark datasets. Experiments show that diffusion-based inpainting can be a useful pre-processing aid to alleviate ear accessory occlusions to improve overall recognition performance.", "AI": {"tldr": "Diffusion-based ear inpainting improves transformer-based ear recognition by reconstructing occluded ear regions from accessory masks.", "motivation": "Ear occlusions from accessories like earrings and earphones degrade performance in ear biometric recognition systems, especially in unconstrained imaging scenarios.", "method": "Uses diffusion-based ear inpainting as pre-processing: given input ear image and automatically derived accessory mask, reconstructs clean ear regions by synthesizing missing pixels while preserving anatomical structures (helix, antihelix, concha, lobule). Evaluated with transformer-based recognition systems across multiple vision transformer models and patch sizes.", "result": "Experiments show diffusion-based inpainting effectively alleviates ear accessory occlusions and improves overall recognition performance across benchmark datasets.", "conclusion": "Diffusion-based inpainting serves as a useful pre-processing aid to mitigate ear accessory occlusions and enhance transformer-based ear recognition systems."}}
{"id": "2601.19449", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19449", "abs": "https://arxiv.org/abs/2601.19449", "authors": ["Celia Rubio-Madrigal", "Rebekka Burkholz"], "title": "Fixed Aggregation Features Can Rival GNNs", "comment": null, "summary": "Graph neural networks (GNNs) are widely believed to excel at node representation learning through trainable neighborhood aggregations. We challenge this view by introducing Fixed Aggregation Features (FAFs), a training-free approach that transforms graph learning tasks into tabular problems. This simple shift enables the use of well-established tabular methods, offering strong interpretability and the flexibility to deploy diverse classifiers. Across 14 benchmarks, well-tuned multilayer perceptrons trained on FAFs rival or outperform state-of-the-art GNNs and graph transformers on 12 tasks -- often using only mean aggregation. The only exceptions are the Roman Empire and Minesweeper datasets, which typically require unusually deep GNNs. To explain the theoretical possibility of non-trainable aggregations, we connect our findings to Kolmogorov-Arnold representations and discuss when mean aggregation can be sufficient. In conclusion, our results call for (i) richer benchmarks benefiting from learning diverse neighborhood aggregations, (ii) strong tabular baselines as standard, and (iii) employing and advancing tabular models for graph data to gain new insights into related tasks.", "AI": {"tldr": "Training-free fixed aggregation features (FAFs) transform graph learning into tabular problems, enabling standard tabular methods to match or beat state-of-the-art GNNs on most benchmarks.", "motivation": "To challenge the prevailing belief that trainable neighborhood aggregations are essential for GNNs' success, and to explore whether simple, non-trainable aggregation features can achieve comparable performance while offering better interpretability and flexibility.", "method": "Introduces Fixed Aggregation Features (FAFs) - a training-free approach that transforms graph learning tasks into tabular problems by computing fixed aggregation statistics (often just mean aggregation) for each node's neighborhood, then applying well-established tabular methods like multilayer perceptrons.", "result": "Across 14 benchmarks, well-tuned MLPs trained on FAFs rival or outperform state-of-the-art GNNs and graph transformers on 12 tasks, with only Roman Empire and Minesweeper datasets (requiring deep GNNs) as exceptions.", "conclusion": "The results call for: (i) richer benchmarks that truly benefit from learning diverse neighborhood aggregations, (ii) strong tabular baselines as standard in graph learning research, and (iii) employing tabular models for graph data to gain new insights into related tasks."}}
{"id": "2601.19798", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19798", "abs": "https://arxiv.org/abs/2601.19798", "authors": ["Zhixiang Wei", "Yi Li", "Zhehan Kan", "Xinghua Jiang", "Zuwei Long", "Shifeng Liu", "Hongze Shen", "Wei Liu", "Xiaoyu Tan", "Haojia Lin", "Yubo Zhu", "Qianyu Li", "Di Yin", "Haoyu Cao", "Weibo Gu", "Xin Li", "Yinsong Liu", "Deqiang Jiang", "Xing Sun", "Yunsheng Wu", "Mingkong Tang", "Shuangyin Liu", "Lexiang Tang", "Haodong Lin", "Junru Lu", "Jiarui Qin", "Lingfeng Qiao", "Ruizhi Qiao", "Bo Ke", "Jianfeng He", "Ke Li", "Yangning Li", "Yunhang Shen", "Mengdan Zhang", "Peixian Chen", "Kun Yin", "Bing Liu", "Yunfei Wu", "Huang Chen", "Zhongpeng Cai", "Xiaotian Li"], "title": "Youtu-VL: Unleashing Visual Potential via Unified Vision-Language Supervision", "comment": null, "summary": "Despite the significant advancements represented by Vision-Language Models (VLMs), current architectures often exhibit limitations in retaining fine-grained visual information, leading to coarse-grained multimodal comprehension. We attribute this deficiency to a suboptimal training paradigm inherent in prevailing VLMs, which exhibits a text-dominant optimization bias by conceptualizing visual signals merely as passive conditional inputs rather than supervisory targets. To mitigate this, we introduce Youtu-VL, a framework leveraging the Vision-Language Unified Autoregressive Supervision (VLUAS) paradigm, which fundamentally shifts the optimization objective from ``vision-as-input'' to ``vision-as-target.'' By integrating visual tokens directly into the prediction stream, Youtu-VL applies unified autoregressive supervision to both visual details and linguistic content. Furthermore, we extend this paradigm to encompass vision-centric tasks, enabling a standard VLM to perform vision-centric tasks without task-specific additions. Extensive empirical evaluations demonstrate that Youtu-VL achieves competitive performance on both general multimodal tasks and vision-centric tasks, establishing a robust foundation for the development of comprehensive generalist visual agents.", "AI": {"tldr": "Youtu-VL introduces a new training paradigm (VLUAS) that treats visual signals as targets rather than just inputs, improving fine-grained visual understanding in VLMs and enabling vision-centric tasks without task-specific modifications.", "motivation": "Current VLMs lose fine-grained visual information due to text-dominant optimization bias where visual signals are treated as passive conditional inputs rather than supervisory targets, leading to coarse-grained multimodal comprehension.", "method": "Proposes Vision-Language Unified Autoregressive Supervision (VLUAS) paradigm that shifts from \"vision-as-input\" to \"vision-as-target\" by integrating visual tokens into the prediction stream and applying unified autoregressive supervision to both visual details and linguistic content.", "result": "Youtu-VL achieves competitive performance on both general multimodal tasks and vision-centric tasks, establishing a foundation for comprehensive generalist visual agents.", "conclusion": "The VLUAS paradigm addresses limitations in current VLM training by treating visual signals as targets, enabling better fine-grained visual understanding and extending VLMs to vision-centric tasks without task-specific modifications."}}
{"id": "2601.19452", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19452", "abs": "https://arxiv.org/abs/2601.19452", "authors": ["Finn Rietz", "Pedro Zuidberg dos Martires", "Johannes Andreas Stork"], "title": "APC-RL: Exceeding Data-Driven Behavior Priors with Adaptive Policy Composition", "comment": null, "summary": "Incorporating demonstration data into reinforcement learning (RL) can greatly accelerate learning, but existing approaches often assume demonstrations are optimal and fully aligned with the target task. In practice, demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when these demonstrations are integrated into RL. We propose Adaptive Policy Composition (APC), a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of enforcing strict adherence to the priors, APC estimates each prior's applicability to the target task while leveraging them for exploration. Moreover, APC either refines useful priors, or sidesteps misaligned ones when necessary to optimize downstream reward. Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.", "AI": {"tldr": "APC is a hierarchical RL method that adaptively composes multiple Normalizing Flow priors from demonstration data, estimating each prior's applicability to the target task and refining useful priors while sidestepping misaligned ones.", "motivation": "Existing RL methods that incorporate demonstrations often assume demonstrations are optimal and fully aligned with the target task, but in practice demonstrations are frequently sparse, suboptimal, or misaligned, which can degrade performance when integrated into RL.", "method": "Adaptive Policy Composition (APC) - a hierarchical model that adaptively composes multiple data-driven Normalizing Flow (NF) priors. Instead of strict adherence to priors, APC estimates each prior's applicability to the target task while leveraging them for exploration, and either refines useful priors or sidesteps misaligned ones when necessary.", "result": "Across diverse benchmarks, APC accelerates learning when demonstrations are aligned, remains robust under severe misalignment, and leverages suboptimal demonstrations to bootstrap exploration while avoiding performance degradation caused by overly strict adherence to suboptimal demonstrations.", "conclusion": "APC provides an effective approach for incorporating diverse demonstration data into RL by adaptively composing and refining priors based on their relevance to the target task, overcoming limitations of existing methods that assume optimal and aligned demonstrations."}}
{"id": "2601.19821", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19821", "abs": "https://arxiv.org/abs/2601.19821", "authors": ["Kun Li", "Michael Ying Yang", "Sami Sebastian Brandt"], "title": "Query-Guided Spatial-Temporal-Frequency Interaction for Music Audio-Visual Question Answering", "comment": null, "summary": "Audio--Visual Question Answering (AVQA) is a challenging multimodal task that requires jointly reasoning over audio, visual, and textual information in a given video to answer natural language questions. Inspired by recent advances in Video QA, many existing AVQA approaches primarily focus on visual information processing, leveraging pre-trained models to extract object-level and motion-level representations. However, in those methods, the audio input is primarily treated as complementary to video analysis, and the textual question information contributes minimally to audio--visual understanding, as it is typically integrated only in the final stages of reasoning. To address these limitations, we propose a novel Query-guided Spatial--Temporal--Frequency (QSTar) interaction method, which effectively incorporates question-guided clues and exploits the distinctive frequency-domain characteristics of audio signals, alongside spatial and temporal perception, to enhance audio--visual understanding. Furthermore, we introduce a Query Context Reasoning (QCR) block inspired by prompting, which guides the model to focus more precisely on semantically relevant audio and visual features. Extensive experiments conducted on several AVQA benchmarks demonstrate the effectiveness of our proposed method, achieving significant performance improvements over existing Audio QA, Visual QA, Video QA, and AVQA approaches. The code and pretrained models will be released after publication.", "AI": {"tldr": "QSTar method enhances AVQA by incorporating question-guided clues and exploiting audio frequency-domain characteristics alongside spatial-temporal perception, with Query Context Reasoning block for better feature focus.", "motivation": "Existing AVQA approaches focus too much on visual information, treat audio as complementary, and integrate textual questions only in final stages, limiting effective multimodal reasoning.", "method": "Proposes Query-guided Spatial-Temporal-Frequency (QSTar) interaction method that incorporates question-guided clues and exploits audio frequency-domain characteristics. Also introduces Query Context Reasoning (QCR) block inspired by prompting to focus on semantically relevant audio/visual features.", "result": "Extensive experiments on AVQA benchmarks show significant performance improvements over existing Audio QA, Visual QA, Video QA, and AVQA approaches.", "conclusion": "The proposed method effectively addresses limitations of existing AVQA approaches by better integrating question information and exploiting audio frequency characteristics, achieving state-of-the-art performance."}}
{"id": "2601.19479", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19479", "abs": "https://arxiv.org/abs/2601.19479", "authors": ["Victoria Catterall", "Cise Midoglu", "Stephen Lynch"], "title": "Time-to-Injury Forecasting in Elite Female Football: A DeepHit Survival Approach", "comment": null, "summary": "Injury occurrence in football poses significant challenges for athletes and teams, carrying personal, competitive, and financial consequences. While machine learning has been applied to injury prediction before, existing approaches often rely on static pre-season data and binary outcomes, limiting their real-world utility. This study investigates the feasibility of using a DeepHit neural network to forecast time-to-injury from longitudinal athlete monitoring data, while providing interpretable predictions. The analysis utilised the publicly available SoccerMon dataset, containing two seasons of training, match, and wellness records from elite female footballers. Data was pre-processed through cleaning, feature engineering, and the application of three imputation strategies. Baseline models (Random Forest, XGBoost, Logistic Regression) were optimised via grid search for benchmarking, while the DeepHit model, implemented with a multilayer perceptron backbone, was evaluated using chronological and leave-one-player-out (LOPO) validation. DeepHit achieved a concordance index of 0.762, outperforming baseline models and delivering individualised, time-varying risk estimates. Shapley Additive Explanations (SHAP) identified clinically relevant predictors consistent with established risk factors, enhancing interpretability. Overall, this study provides a novel proof of concept: survival modelling with DeepHit shows strong potential to advance injury forecasting in football, offering accurate, explainable, and actionable insights for injury prevention across competitive levels.", "AI": {"tldr": "DeepHit neural network outperforms traditional ML models for time-to-injury prediction in football using longitudinal monitoring data, providing interpretable, individualized risk estimates.", "motivation": "Injury prediction in football has limitations with current ML approaches that use static pre-season data and binary outcomes, reducing real-world utility. There's a need for more dynamic, time-sensitive, and interpretable injury forecasting methods.", "method": "Used DeepHit neural network with multilayer perceptron backbone on SoccerMon dataset (elite female footballers' training, match, and wellness data). Applied data preprocessing, feature engineering, and three imputation strategies. Compared against optimized Random Forest, XGBoost, and Logistic Regression baselines using chronological and leave-one-player-out validation.", "result": "DeepHit achieved concordance index of 0.762, outperforming baseline models. Provided individualized, time-varying risk estimates. SHAP analysis identified clinically relevant predictors aligned with established risk factors, enhancing interpretability.", "conclusion": "DeepHit survival modeling offers a novel proof of concept for advancing injury forecasting in football, delivering accurate, explainable, and actionable insights for injury prevention across competitive levels."}}
{"id": "2601.19849", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19849", "abs": "https://arxiv.org/abs/2601.19849", "authors": ["Haya Alyoussef", "Ahmad Bdeir", "Diego Coello de Portugal Mecke", "Tom Hanika", "Niels Landwehr", "Lars Schmidt-Thieme"], "title": "HexFormer: Hyperbolic Vision Transformer with Exponential Map Aggregation", "comment": null, "summary": "Data across modalities such as images, text, and graphs often contains hierarchical and relational structures, which are challenging to model within Euclidean geometry. Hyperbolic geometry provides a natural framework for representing such structures. Building on this property, this work introduces HexFormer, a hyperbolic vision transformer for image classification that incorporates exponential map aggregation within its attention mechanism. Two designs are explored: a hyperbolic ViT (HexFormer) and a hybrid variant (HexFormer-Hybrid) that combines a hyperbolic encoder with an Euclidean linear classification head. HexFormer incorporates a novel attention mechanism based on exponential map aggregation, which yields more accurate and stable aggregated representations than standard centroid based averaging, showing that simpler approaches retain competitive merit. Experiments across multiple datasets demonstrate consistent performance improvements over Euclidean baselines and prior hyperbolic ViTs, with the hybrid variant achieving the strongest overall results. Additionally, this study provides an analysis of gradient stability in hyperbolic transformers. The results reveal that hyperbolic models exhibit more stable gradients and reduced sensitivity to warmup strategies compared to Euclidean architectures, highlighting their robustness and efficiency in training. Overall, these findings indicate that hyperbolic geometry can enhance vision transformer architectures by improving gradient stability and accuracy. In addition, relatively simple mechanisms such as exponential map aggregation can provide strong practical benefits.", "AI": {"tldr": "HexFormer introduces a hyperbolic vision transformer with exponential map aggregation for image classification, showing improved performance and gradient stability over Euclidean baselines.", "motivation": "Hierarchical and relational structures in multimodal data (images, text, graphs) are challenging to model in Euclidean geometry. Hyperbolic geometry provides a natural framework for representing such structures, motivating the development of hyperbolic vision transformers.", "method": "HexFormer incorporates exponential map aggregation within its attention mechanism. Two variants: hyperbolic ViT (HexFormer) and hybrid (HexFormer-Hybrid) combining hyperbolic encoder with Euclidean linear classification head. Novel attention uses exponential map aggregation instead of standard centroid averaging.", "result": "Experiments show consistent performance improvements over Euclidean baselines and prior hyperbolic ViTs, with hybrid variant achieving strongest results. Hyperbolic models exhibit more stable gradients and reduced sensitivity to warmup strategies compared to Euclidean architectures.", "conclusion": "Hyperbolic geometry enhances vision transformers by improving gradient stability and accuracy. Simple mechanisms like exponential map aggregation provide strong practical benefits for modeling hierarchical structures in vision tasks."}}
{"id": "2601.19487", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19487", "abs": "https://arxiv.org/abs/2601.19487", "authors": ["Haonan Zhang", "Dongxia Wang", "Yi Liu", "Kexin Chen", "Wenhai Wang"], "title": "LLM-VA: Resolving the Jailbreak-Overrefusal Trade-off via Vector Alignment", "comment": null, "summary": "Safety-aligned LLMs suffer from two failure modes: jailbreak (answering harmful inputs) and over-refusal (declining benign queries). Existing vector steering methods adjust the magnitude of answer vectors, but this creates a fundamental trade-off -- reducing jailbreak increases over-refusal and vice versa. We identify the root cause: LLMs encode the decision to answer (answer vector $v_a$) and the judgment of input safety (benign vector $v_b$) as nearly orthogonal directions, treating them as independent processes. We propose LLM-VA, which aligns $v_a$ with $v_b$ through closed-form weight updates, making the model's willingness to answer causally dependent on its safety assessment -- without fine-tuning or architectural changes. Our method identifies vectors at each layer using SVMs, selects safety-relevant layers, and iteratively aligns vectors via minimum-norm weight modifications. Experiments on 12 LLMs demonstrate that LLM-VA achieves 11.45% higher F1 than the best baseline while preserving 95.92% utility, and automatically adapts to each model's safety bias without manual tuning. Code and models are available at https://hotbento.github.io/LLM-VA-Web/.", "AI": {"tldr": "LLM-VA aligns answer and safety judgment vectors in LLMs to reduce both jailbreak and over-refusal simultaneously, without fine-tuning or architecture changes.", "motivation": "Current safety-aligned LLMs suffer from two opposing failure modes: jailbreak (answering harmful inputs) and over-refusal (declining benign queries). Existing vector steering methods create a trade-off - reducing one increases the other.", "method": "LLM-VA aligns the answer vector (v_a) with the benign vector (v_b) through closed-form weight updates. It identifies vectors at each layer using SVMs, selects safety-relevant layers, and iteratively aligns vectors via minimum-norm weight modifications.", "result": "Experiments on 12 LLMs show LLM-VA achieves 11.45% higher F1 than the best baseline while preserving 95.92% utility, and automatically adapts to each model's safety bias without manual tuning.", "conclusion": "LLM-VA successfully makes models' willingness to answer causally dependent on their safety assessment, addressing both jailbreak and over-refusal simultaneously through vector alignment without requiring fine-tuning or architectural changes."}}
{"id": "2601.19850", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19850", "abs": "https://arxiv.org/abs/2601.19850", "authors": ["Binzhu Xie", "Shi Qiu", "Sicheng Zhang", "Yinqiao Wang", "Hao Xu", "Muzammal Naseer", "Chi-Wing Fu", "Pheng-Ann Heng"], "title": "EgoHandICL: Egocentric 3D Hand Reconstruction with In-Context Learning", "comment": "Accepted in ICLR 2026, Codebase: https://github.com/Nicous20/EgoHandICL", "summary": "Robust 3D hand reconstruction in egocentric vision is challenging due to depth ambiguity, self-occlusion, and complex hand-object interactions. Prior methods mitigate these issues by scaling training data or adding auxiliary cues, but they often struggle in unseen contexts. We present EgoHandICL, the first in-context learning (ICL) framework for 3D hand reconstruction that improves semantic alignment, visual consistency, and robustness under challenging egocentric conditions. EgoHandICL introduces complementary exemplar retrieval guided by vision-language models (VLMs), an ICL-tailored tokenizer for multimodal context, and a masked autoencoder (MAE)-based architecture trained with hand-guided geometric and perceptual objectives. Experiments on ARCTIC and EgoExo4D show consistent gains over state-of-the-art methods. We also demonstrate real-world generalization and improve EgoVLM hand-object interaction reasoning by using reconstructed hands as visual prompts. Code and data: https://github.com/Nicous20/EgoHandICL", "AI": {"tldr": "EgoHandICL is an in-context learning framework for robust 3D hand reconstruction in egocentric vision that addresses depth ambiguity, self-occlusion, and complex hand-object interactions through VLM-guided exemplar retrieval, ICL-tailored tokenization, and MAE-based architecture with geometric and perceptual objectives.", "motivation": "Robust 3D hand reconstruction in egocentric vision is challenging due to depth ambiguity, self-occlusion, and complex hand-object interactions. Prior methods that scale training data or add auxiliary cues often struggle in unseen contexts.", "method": "EgoHandICL introduces: 1) Complementary exemplar retrieval guided by vision-language models (VLMs), 2) ICL-tailored tokenizer for multimodal context, and 3) Masked autoencoder (MAE)-based architecture trained with hand-guided geometric and perceptual objectives.", "result": "Experiments on ARCTIC and EgoExo4D datasets show consistent gains over state-of-the-art methods. The framework demonstrates real-world generalization and improves EgoVLM hand-object interaction reasoning by using reconstructed hands as visual prompts.", "conclusion": "EgoHandICL is the first in-context learning framework for 3D hand reconstruction that improves semantic alignment, visual consistency, and robustness under challenging egocentric conditions, with demonstrated effectiveness across multiple benchmarks and real-world applications."}}
{"id": "2601.19541", "categories": ["cs.LG", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.19541", "abs": "https://arxiv.org/abs/2601.19541", "authors": ["Tianrun Gao", "Haoren Zheng", "Wenhao Deng", "Haodong Feng", "Tao Zhang", "Ruiqi Feng", "Qianyi Chen", "Tailin Wu"], "title": "GenCP: Towards Generative Modeling Paradigm of Coupled Physics", "comment": "ICLR 2026 Accpeted", "summary": "Real-world physical systems are inherently complex, often involving the coupling of multiple physics, making their simulation both highly valuable and challenging. Many mainstream approaches face challenges when dealing with decoupled data. Besides, they also suffer from low efficiency and fidelity in strongly coupled spatio-temporal physical systems. Here we propose GenCP, a novel and elegant generative paradigm for coupled multiphysics simulation. By formulating coupled-physics modeling as a probability modeling problem, our key innovation is to integrate probability density evolution in generative modeling with iterative multiphysics coupling, thereby enabling training on data from decoupled simulation and inferring coupled physics during sampling. We also utilize operator-splitting theory in the space of probability evolution to establish error controllability guarantees for this \"conditional-to-joint\" sampling scheme. We evaluate our paradigm on a synthetic setting and three challenging multi-physics scenarios to demonstrate both principled insight and superior application performance of GenCP. Code is available at this repo: github.com/AI4Science-WestlakeU/GenCP.", "AI": {"tldr": "GenCP is a generative paradigm for coupled multiphysics simulation that formulates coupled-physics modeling as a probability modeling problem, enabling training on decoupled data while inferring coupled physics during sampling.", "motivation": "Real-world physical systems involve complex coupling of multiple physics, making simulation valuable but challenging. Mainstream approaches struggle with decoupled data and have low efficiency/fidelity in strongly coupled spatio-temporal systems.", "method": "Integrates probability density evolution in generative modeling with iterative multiphysics coupling. Uses operator-splitting theory in probability evolution space to establish error controllability guarantees for \"conditional-to-joint\" sampling scheme.", "result": "Evaluated on synthetic setting and three challenging multi-physics scenarios, demonstrating both principled insight and superior application performance compared to existing approaches.", "conclusion": "GenCP provides a novel generative paradigm that enables effective coupled multiphysics simulation by bridging probability modeling with physical coupling, offering theoretical guarantees and practical performance improvements."}}
{"id": "2601.19884", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19884", "abs": "https://arxiv.org/abs/2601.19884", "authors": ["Gijs Joppe Moens", "Regina Beets-Tan", "Eduardo H. P. Pooch"], "title": "SONIC: Spectral Oriented Neural Invariant Convolutions", "comment": "10 pages, 4 figures. Accepted at ICLR 2026", "summary": "Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these limitations requires a representation that is both structured and global. We introduce SONIC (Spectral Oriented Neural Invariant Convolutions), a continuous spectral parameterisation that models convolutional operators using a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions. Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters. These results demonstrate that continuous, orientation-aware spectral parameterisations provide a principled and scalable alternative to conventional spatial and spectral operators.", "AI": {"tldr": "SONIC introduces a continuous spectral parameterization for convolutional operators using orientation-selective components, achieving global receptive fields with fewer parameters while improving robustness to transformations.", "motivation": "CNNs have limited global context capture and require deep architectures for long-range dependencies, while Vision Transformers lack spatial inductive bias and depend on explicit positional encodings. There's a need for representations that are both structured and global.", "method": "SONIC uses a continuous spectral parameterization that models convolutional operators with a small set of shared, orientation-selective components. These components define smooth responses across the full frequency domain, yielding global receptive fields and filters that adapt naturally across resolutions.", "result": "Across synthetic benchmarks, large-scale image classification, and 3D medical datasets, SONIC shows improved robustness to geometric transformations, noise, and resolution shifts, and matches or exceeds convolutional, attention-based, and prior spectral architectures with an order of magnitude fewer parameters.", "conclusion": "Continuous, orientation-aware spectral parameterizations provide a principled and scalable alternative to conventional spatial and spectral operators, bridging the limitations of both CNNs and Vision Transformers."}}
{"id": "2601.19551", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19551", "abs": "https://arxiv.org/abs/2601.19551", "authors": ["Geunhyeok Yu", "Hyoseok Hwang"], "title": "Scale-Consistent State-Space Dynamics via Fractal of Stationary Transformations", "comment": "8 pages (excluding 2 pages of references), 3 tables, 2 figures. Appendix: 4 pages", "summary": "Recent deep learning models increasingly rely on depth without structural guarantees on the validity of intermediate representations, rendering early stopping and adaptive computation ill-posed. We address this limitation by formulating a structural requirement for state-space model's scale-consistent latent dynamics across iterative refinement, and derive Fractal of Stationary Transformations (FROST), which enforces a self-similar representation manifold through a fractal inductive bias. Under this geometry, intermediate states correspond to different resolutions of a shared representation, and we provide a geometric analysis establishing contraction and stable convergence across iterations. As a consequence of this scale-consistent structure, halting naturally admits a ranking-based formulation driven by intrinsic feature quality rather than extrinsic objectives. Controlled experiments on ImageNet-100 empirically verify the predicted scale-consistent behavior, showing that adaptive efficiency emerges from the aligned latent geometry.", "AI": {"tldr": "FROST introduces fractal inductive bias for scale-consistent latent dynamics in state-space models, enabling valid intermediate representations and natural adaptive computation.", "motivation": "Current deep learning models lack structural guarantees on intermediate representation validity, making early stopping and adaptive computation problematic. There's a need for models where intermediate states maintain meaningful structure across refinement iterations.", "method": "Proposes Fractal of Stationary Transformations (FROST) that enforces self-similar representation manifolds through fractal inductive bias. This creates scale-consistent latent dynamics where intermediate states correspond to different resolutions of a shared representation, with geometric analysis establishing contraction and stable convergence.", "result": "Controlled experiments on ImageNet-100 empirically verify predicted scale-consistent behavior, showing adaptive efficiency emerges from aligned latent geometry. Halting naturally admits ranking-based formulation driven by intrinsic feature quality.", "conclusion": "FROST provides structural guarantees for intermediate representations in deep models, enabling valid early stopping and adaptive computation through fractal geometry and scale-consistent latent dynamics."}}
{"id": "2601.19561", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19561", "abs": "https://arxiv.org/abs/2601.19561", "authors": ["Dayoung Kang", "JongWon Kim", "Jiho Park", "Keonseock Lee", "Ji-Woong Choi", "Jinhyun So"], "title": "AROMMA: Unifying Olfactory Embeddings for Single Molecules and Mixtures", "comment": null, "summary": "Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Recent works either learn single-molecule embeddings or address mixtures via similarity or pairwise label prediction, leaving representations separate and unaligned. In this work, we propose AROMMA, a framework that learns a unified embedding space for single molecules and two-molecule mixtures. Each molecule is encoded by a chemical foundation model and the mixtures are composed by an attention-based aggregator, ensuring both permutation invariance and asymmetric molecular interactions. We further align odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations. AROMMA achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating a robust generalization in two domains.", "AI": {"tldr": "AROMMA learns unified embeddings for single molecules and mixtures using chemical foundation models and attention-based aggregation, achieving SOTA performance with up to 19.1% AUROC improvement.", "motivation": "Public olfaction datasets are small and fragmented across single molecules and mixtures, limiting learning of generalizable odor representations. Existing approaches leave single-molecule and mixture representations separate and unaligned.", "method": "Proposes AROMMA framework that learns unified embedding space: encodes molecules with chemical foundation models, composes mixtures via attention-based aggregator (permutation invariant, captures asymmetric interactions), aligns odor descriptor sets using knowledge distillation and class-aware pseudo-labeling to enrich missing mixture annotations.", "result": "Achieves state-of-the-art performance in both single-molecule and molecule-pair datasets, with up to 19.1% AUROC improvement, demonstrating robust generalization in two domains.", "conclusion": "AROMMA successfully creates a unified representation space for single molecules and mixtures, overcoming dataset fragmentation and enabling better generalization in olfaction prediction tasks."}}
{"id": "2601.19898", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.19898", "abs": "https://arxiv.org/abs/2601.19898", "authors": ["Shubham Patle", "Sara Ghaboura", "Hania Tariq", "Mohammad Usman Khan", "Omkar Thawakar", "Rao Muhammad Anwer", "Salman Khan"], "title": "DuwatBench: Bridging Language and Visual Heritage through an Arabic Calligraphy Benchmark for Multimodal Understanding", "comment": "Accepted to EACL-2026 (Main Track)", "summary": "Arabic calligraphy represents one of the richest visual traditions of the Arabic language, blending linguistic meaning with artistic form. Although multimodal models have advanced across languages, their ability to process Arabic script, especially in artistic and stylized calligraphic forms, remains largely unexplored. To address this gap, we present DuwatBench, a benchmark of 1,272 curated samples containing about 1,475 unique words across six classical and modern calligraphic styles, each paired with sentence-level detection annotations. The dataset reflects real-world challenges in Arabic writing, such as complex stroke patterns, dense ligatures, and stylistic variations that often challenge standard text recognition systems. Using DuwatBench, we evaluated 13 leading Arabic and multilingual multimodal models and showed that while they perform well on clean text, they struggle with calligraphic variation, artistic distortions, and precise visual-text alignment. By publicly releasing DuwatBench and its annotations, we aim to advance culturally grounded multimodal research, foster fair inclusion of the Arabic language and visual heritage in AI systems, and support continued progress in this area. Our dataset (https://huggingface.co/datasets/MBZUAI/DuwatBench) and evaluation suit (https://github.com/mbzuai-oryx/DuwatBench) are publicly available.", "AI": {"tldr": "DuwatBench is a new benchmark dataset for evaluating multimodal AI models on Arabic calligraphy, containing 1,272 samples across 6 calligraphic styles with sentence-level annotations, revealing current models struggle with artistic variations despite good performance on clean text.", "motivation": "Arabic calligraphy is a rich visual tradition that blends linguistic meaning with artistic form, but multimodal AI models have largely unexplored capabilities in processing stylized Arabic script. There's a gap in evaluating how well these models handle the artistic and calligraphic variations of Arabic writing.", "method": "Created DuwatBench - a curated dataset of 1,272 samples containing about 1,475 unique words across six classical and modern calligraphic styles, each with sentence-level detection annotations. The dataset includes real-world challenges like complex stroke patterns, dense ligatures, and stylistic variations. Evaluated 13 leading Arabic and multilingual multimodal models using this benchmark.", "result": "Evaluation showed that while models perform well on clean text, they struggle significantly with calligraphic variation, artistic distortions, and precise visual-text alignment. The benchmark reveals current limitations in handling culturally specific visual forms of Arabic script.", "conclusion": "DuwatBench addresses the gap in multimodal AI evaluation for Arabic calligraphy, providing a tool to advance culturally grounded research and promote fair inclusion of Arabic language and visual heritage in AI systems. The publicly available dataset and evaluation suite aim to support continued progress in this area."}}
{"id": "2601.19588", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19588", "abs": "https://arxiv.org/abs/2601.19588", "authors": ["Yongqi Wang", "Xiaofeng Ji", "Jie Wang", "Qingbin Li", "Xiao Xiong", "Zheming Yang", "Jian Xu", "Minghui Qiu", "Xinxiao Wu"], "title": "From Atoms to Chains: Divergence-Guided Reasoning Curriculum for Unlabeled LLM Domain Adaptation", "comment": "Code: https://github.com/bytedance/DGRC", "summary": "Adapting Large Language Models (LLMs) to specialized domains without human-annotated data is a crucial yet formidable challenge. Widely adopted knowledge distillation methods often devolve into coarse-grained mimicry, where the student model inefficiently targets its own weaknesses and risks inheriting the teacher's reasoning flaws. This exposes a critical pedagogical dilemma: how to devise a reliable curriculum when the teacher itself is not an infallible expert. Our work resolves this by capitalizing on a key insight: while LLMs may exhibit fallibility in complex, holistic reasoning, they often exhibit high fidelity on focused, atomic sub-problems. Based on this, we propose Divergence-Guided Reasoning Curriculum (DGRC), which constructs a learning path from atomic knowledge to reasoning chains by dynamically deriving two complementary curricula from disagreements in reasoning pathways. When a student and teacher produce conflicting results, DGRC directs the teacher to perform a diagnostic analysis: it analyzes both reasoning paths to formulate atomic queries that target the specific points of divergence, and then self-answers these queries to create high-confidence atomic question-answer pairs. These pairs then serve a dual purpose: (1) providing an atomic curriculum to rectify the student's knowledge gaps, and (2) serving as factual criteria to filter the teacher's original reasoning chains, yielding a verified CoT curriculum that teaches the student how to integrate atomic knowledge into complete reasoning paths. Experiments across the medical and legal domains on student models of various sizes demonstrate the effectiveness of our DGRC framework. Notably, our method achieves a 7.76% relative improvement for the 1.5B student model in the medical domain over strong unlabeled baseline.", "AI": {"tldr": "DGRC is a novel knowledge distillation method that creates a curriculum from atomic knowledge to reasoning chains by analyzing disagreements between teacher and student models, achieving significant improvements in specialized domains without human-annotated data.", "motivation": "Adapting LLMs to specialized domains without human-annotated data is challenging. Traditional knowledge distillation methods risk coarse mimicry and inheriting teacher reasoning flaws, creating a pedagogical dilemma when the teacher isn't infallible.", "method": "Divergence-Guided Reasoning Curriculum (DGRC) analyzes disagreements between teacher and student reasoning paths. When conflicts occur, it formulates atomic queries targeting divergence points, creates high-confidence atomic QA pairs for knowledge gaps, and filters teacher reasoning chains using these facts to create verified CoT curriculum.", "result": "Experiments in medical and legal domains show DGRC's effectiveness across various student model sizes. Notably achieves 7.76% relative improvement for 1.5B student model in medical domain over strong unlabeled baselines.", "conclusion": "DGRC successfully addresses the challenge of adapting LLMs to specialized domains without human data by leveraging teacher-student disagreements to create reliable atomic-to-reasoning curricula, demonstrating significant performance gains."}}
{"id": "2601.19595", "categories": ["cs.LG", "cs.AI", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19595", "abs": "https://arxiv.org/abs/2601.19595", "authors": ["Ji\u0159\u00ed N\u011bme\u010dek", "Mark Kozdoba", "Illia Kryvoviaz", "Tom\u00e1\u0161 Pevn\u00fd", "Jakub Mare\u010dek"], "title": "Intersectional Fairness via Mixed-Integer Optimization", "comment": "17 pages, 10 figures, 1 table", "summary": "The deployment of Artificial Intelligence in high-risk domains, such as finance and healthcare, necessitates models that are both fair and transparent. While regulatory frameworks, including the EU's AI Act, mandate bias mitigation, they are deliberately vague about the definition of bias. In line with existing research, we argue that true fairness requires addressing bias at the intersections of protected groups. We propose a unified framework that leverages Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. We prove the equivalence of two measures of intersectional fairness (MSD and SPSF) in detecting the most unfair subgroup and empirically demonstrate that our MIO-based algorithm improves performance in finding bias. We train high-performing, interpretable classifiers that bound intersectional bias below an acceptable threshold, offering a robust solution for regulated industries and beyond.", "AI": {"tldr": "Proposes a unified MIO framework for training intersectionally fair and interpretable classifiers that bound bias below acceptable thresholds for regulated industries.", "motivation": "AI deployment in high-risk domains (finance, healthcare) requires fair and transparent models. Regulatory frameworks like EU's AI Act mandate bias mitigation but are vague about bias definitions. True fairness requires addressing bias at intersections of protected groups.", "method": "Unified framework using Mixed-Integer Optimization (MIO) to train intersectionally fair and intrinsically interpretable classifiers. Proves equivalence of two intersectional fairness measures (MSD and SPSF) in detecting most unfair subgroup.", "result": "MIO-based algorithm improves performance in finding bias. Trains high-performing, interpretable classifiers that bound intersectional bias below acceptable threshold.", "conclusion": "Offers robust solution for regulated industries and beyond by providing intersectionally fair, interpretable classifiers that comply with regulatory requirements while maintaining performance."}}
{"id": "2601.19597", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19597", "abs": "https://arxiv.org/abs/2601.19597", "authors": ["Yichao Cai", "Zhen Zhang", "Yuhang Liu", "Javen Qinfeng Shi"], "title": "The Geometric Mechanics of Contrastive Representation Learning: Alignment Potentials, Entropic Dispersion, and Cross-Modal Divergence", "comment": null, "summary": "While InfoNCE powers modern contrastive learning, its geometric mechanisms remain under-characterized beyond the canonical alignment--uniformity decomposition. We present a measure-theoretic framework that models learning as the evolution of representation measures on a fixed embedding manifold. By establishing value and gradient consistency in the large-batch limit, we bridge the stochastic objective to explicit deterministic energy landscapes, uncovering a fundamental geometric bifurcation between the unimodal and multimodal regimes. In the unimodal setting, the intrinsic landscape is strictly convex with a unique Gibbs equilibrium; here, entropy acts merely as a tie-breaker, clarifying \"uniformity\" as a constrained expansion within the alignment basin. In contrast, the symmetric multimodal objective contains a persistent negative symmetric divergence term that remains even after kernel sharpening. We show that this term induces barrier-driven co-adaptation, enforcing a population-level modality gap as a structural geometric necessity rather than an initialization artifact. Our results shift the analytical lens from pointwise discrimination to population geometry, offering a principled basis for diagnosing and controlling distributional misalignment.", "AI": {"tldr": "The paper develops a measure-theoretic framework to analyze the geometric mechanisms of InfoNCE contrastive learning, revealing fundamental bifurcations between unimodal and multimodal regimes with different optimization landscapes.", "motivation": "Current understanding of InfoNCE contrastive learning is limited to the basic alignment-uniformity decomposition, lacking deeper geometric characterization of how representations evolve during learning.", "method": "A measure-theoretic framework that models learning as evolution of representation measures on a fixed embedding manifold, establishing value and gradient consistency in the large-batch limit to bridge stochastic objectives to deterministic energy landscapes.", "result": "Uncovers a geometric bifurcation: unimodal regimes have strictly convex landscapes with unique Gibbs equilibrium (entropy as tie-breaker), while multimodal regimes contain persistent negative symmetric divergence inducing barrier-driven co-adaptation and modality gaps as structural necessities.", "conclusion": "Shifts analytical focus from pointwise discrimination to population geometry, providing principled basis for diagnosing and controlling distributional misalignment in contrastive learning."}}
{"id": "2601.19611", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19611", "abs": "https://arxiv.org/abs/2601.19611", "authors": ["Runyu Peng", "Yunhua Zhou", "Demin Song", "Kai Lv", "Bo Wang", "Qipeng Guo", "Xipeng Qiu"], "title": "Explicit Multi-head Attention for Inter-head Interaction in Large Language Models", "comment": null, "summary": "In large language models built upon the Transformer architecture, recent studies have shown that inter-head interaction can enhance attention performance. Motivated by this, we propose Multi-head Explicit Attention (MEA), a simple yet effective attention variant that explicitly models cross-head interaction. MEA consists of two key components: a Head-level Linear Composition (HLC) module that separately applies learnable linear combinations to the key and value vectors across heads, thereby enabling rich inter-head communication; and a head-level Group Normalization layer that aligns the statistical properties of the recombined heads. MEA shows strong robustness in pretraining, which allows the use of larger learning rates that lead to faster convergence, ultimately resulting in lower validation loss and improved performance across a range of tasks. Furthermore, we explore the parameter efficiency of MEA by reducing the number of attention heads and leveraging HLC to reconstruct them using low-rank \"virtual heads\". This enables a practical key-value cache compression strategy that reduces KV-cache memory usage by 50% with negligible performance loss on knowledge-intensive and scientific reasoning tasks, and only a 3.59% accuracy drop for Olympiad-level mathematical benchmarks.", "AI": {"tldr": "MEA (Multi-head Explicit Attention) is a Transformer attention variant that explicitly models cross-head interaction through learnable linear combinations of key/value vectors across heads, enabling better pretraining robustness, faster convergence, and KV-cache compression via virtual heads.", "motivation": "Recent studies show that inter-head interaction can enhance attention performance in Transformers. The authors aim to explicitly model cross-head communication to improve attention mechanisms.", "method": "MEA consists of two components: 1) Head-level Linear Composition (HLC) module that applies learnable linear combinations to key and value vectors across heads, enabling inter-head communication; 2) head-level Group Normalization layer that aligns statistical properties of recombined heads. Also explores parameter efficiency by reducing attention heads and reconstructing them using low-rank \"virtual heads\" for KV-cache compression.", "result": "MEA shows strong pretraining robustness, allowing larger learning rates leading to faster convergence, lower validation loss, and improved task performance. KV-cache compression reduces memory usage by 50% with negligible performance loss on knowledge-intensive/scientific reasoning tasks, and only 3.59% accuracy drop on Olympiad-level math benchmarks.", "conclusion": "MEA effectively models cross-head interaction, improving attention performance while enabling practical KV-cache compression strategies for memory efficiency with minimal performance degradation."}}
{"id": "2601.19620", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19620", "abs": "https://arxiv.org/abs/2601.19620", "authors": ["Zhizheng Jiang", "Kang Zhao", "Weikai Xu", "Xinkui Lin", "Wei Liu", "Jian Luan", "Shuo Shang", "Peng Han"], "title": "R^3: Replay, Reflection, and Ranking Rewards for LLM Reinforcement Learning", "comment": null, "summary": "Large reasoning models (LRMs) aim to solve diverse and complex problems through structured reasoning. Recent advances in group-based policy optimization methods have shown promise in enabling stable advantage estimation without reliance on process-level annotations. However, these methods rely on advantage gaps induced by high-quality samples within the same batch, which makes the training process fragile and inefficient when intra-group advantages collapse under challenging tasks. To address these problems, we propose a reinforcement learning mechanism named \\emph{\\textbf{R^3}} that along three directions: (1) a \\emph{cross-context \\underline{\\textbf{R}}eplay} strategy that maintains the intra-group advantage by recalling valuable examples from historical trajectories of the same query, (2) an \\emph{in-context self-\\underline{\\textbf{R}}eflection} mechanism enabling models to refine outputs by leveraging past failures, and (3) a \\emph{structural entropy \\underline{\\textbf{R}}anking reward}, which assigns relative rewards to truncated or failed samples by ranking responses based on token-level entropy patterns, capturing both local exploration and global stability. We implement our method on Deepseek-R1-Distill-Qwen-1.5B and train it on the DeepscaleR-40k in the math domain. Experiments demonstrate our method achieves SoTA performance on several math benchmarks, representing significant improvements and fewer reasoning tokens over the base models. Code and model will be released.", "AI": {"tldr": "R\u00b3 is a reinforcement learning method for large reasoning models that uses cross-context replay, in-context self-reflection, and structural entropy ranking to improve training stability and efficiency on challenging tasks.", "motivation": "Existing group-based policy optimization methods for large reasoning models are fragile and inefficient because they rely on intra-group advantage gaps that collapse under challenging tasks, making training unstable.", "method": "R\u00b3 introduces three components: (1) cross-context replay to maintain intra-group advantage by recalling valuable examples from historical trajectories, (2) in-context self-reflection for models to refine outputs using past failures, and (3) structural entropy ranking reward that assigns relative rewards to truncated/failed samples based on token-level entropy patterns.", "result": "The method achieves state-of-the-art performance on several math benchmarks with significant improvements and fewer reasoning tokens compared to base models, implemented on Deepseek-R1-Distill-Qwen-1.5B trained on DeepscaleR-40k.", "conclusion": "R\u00b3 addresses the fragility of existing group-based policy optimization methods by maintaining advantage stability through cross-context replay, self-reflection, and entropy-based ranking, leading to more efficient and effective training for large reasoning models."}}
{"id": "2601.19624", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19624", "abs": "https://arxiv.org/abs/2601.19624", "authors": ["Tongxi Wang", "Zhuoyang Xia", "Xinran Chen", "Shan Liu"], "title": "Tracking Drift: Variation-Aware Entropy Scheduling for Non-Stationary Reinforcement Learning", "comment": null, "summary": "Real-world reinforcement learning often faces environment drift, but most existing methods rely on static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (thus slow recovery), and leaving unanswered the principled question of how exploration intensity should scale with drift magnitude. We prove that entropy scheduling under non-stationarity can be reduced to a one-dimensional, round-by-round trade-off, faster tracking of the optimal solution after drift vs. avoiding gratuitous randomness when the environment is stable, so exploration strength can be driven by measurable online drift signals. Building on this, we propose AES (Adaptive Entropy Scheduling), which adaptively adjusts the entropy coefficient/temperature online using observable drift proxies during training, requiring almost no structural changes and incurring minimal overhead. Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.", "AI": {"tldr": "AES adaptively schedules entropy coefficients using online drift signals to handle environment drift in RL, reducing performance degradation and accelerating recovery.", "motivation": "Real-world RL faces environment drift, but existing methods use static entropy coefficients/target entropy, causing over-exploration during stable periods and under-exploration after drift (slow recovery). There's also no principled understanding of how exploration intensity should scale with drift magnitude.", "method": "Proves entropy scheduling under non-stationarity reduces to a one-dimensional, round-by-round trade-off. Proposes AES (Adaptive Entropy Scheduling) which adaptively adjusts entropy coefficient/temperature online using observable drift proxies during training, requiring minimal structural changes and overhead.", "result": "Across 4 algorithm variants, 12 tasks, and 4 drift modes, AES significantly reduces the fraction of performance degradation caused by drift and accelerates recovery after abrupt changes.", "conclusion": "AES provides a principled approach to adaptive entropy scheduling that effectively handles environment drift in RL by using online drift signals to dynamically adjust exploration intensity."}}
{"id": "2601.19668", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19668", "abs": "https://arxiv.org/abs/2601.19668", "authors": ["Luis Amorim", "Moises Santos", "Paulo J. Azevedo", "Carlos Soares", "Vitor Cerqueira"], "title": "Grasynda: Graph-based Synthetic Time Series Generation", "comment": "Accepted in IDA'26", "summary": "Data augmentation is a crucial tool in time series forecasting, especially for deep learning architectures that require a large training sample size to generalize effectively. However, extensive datasets are not always available in real-world scenarios. Although many data augmentation methods exist, their limitations include the use of transformations that do not adequately preserve data properties. This paper introduces Grasynda, a novel graph-based approach for synthetic time series generation that: (1) converts univariate time series into a network structure using a graph representation, where each state is a node and each transition is represented as a directed edge; and (2) encodes their temporal dynamics in a transition probability matrix. We performed an extensive evaluation of Grasynda as a data augmentation method for time series forecasting. We use three neural network variations on six benchmark datasets. The results indicate that Grasynda consistently outperforms other time series data augmentation methods, including ones used in state-of-the-art time series foundation models. The method and all experiments are publicly available.", "AI": {"tldr": "Grasynda is a graph-based data augmentation method for time series forecasting that converts time series into network structures with transition probabilities, outperforming other augmentation methods including those used in state-of-the-art foundation models.", "motivation": "Deep learning for time series forecasting requires large datasets for effective generalization, but real-world scenarios often lack extensive data. Existing data augmentation methods have limitations in preserving data properties during transformations.", "method": "Grasynda converts univariate time series into graph networks where each state is a node and each transition is a directed edge, encoding temporal dynamics in a transition probability matrix for synthetic time series generation.", "result": "Extensive evaluation using three neural network variations on six benchmark datasets shows Grasynda consistently outperforms other time series data augmentation methods, including those used in state-of-the-art time series foundation models.", "conclusion": "Grasynda provides an effective graph-based approach for time series data augmentation that preserves data properties better than existing methods, improving forecasting performance when training data is limited."}}
{"id": "2601.19672", "categories": ["cs.LG", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19672", "abs": "https://arxiv.org/abs/2601.19672", "authors": ["Waris Gill", "Ahmad Humayun", "Ali Anwar", "Muhammad Ali Gulzar"], "title": "ProToken: Token-Level Attribution for Federated Large Language Models", "comment": null, "summary": "Federated Learning (FL) enables collaborative training of Large Language Models (LLMs) across distributed data sources while preserving privacy. However, when federated LLMs are deployed in critical applications, it remains unclear which client(s) contributed to specific generated responses, hindering debugging, malicious client identification, fair reward allocation, and trust verification. We present ProToken, a novel Provenance methodology for Token-level attribution in federated LLMs that addresses client attribution during autoregressive text generation while maintaining FL privacy constraints. ProToken leverages two key insights to enable provenance at each token: (1) transformer architectures concentrate task-specific signals in later blocks, enabling strategic layer selection for computational tractability, and (2) gradient-based relevance weighting filters out irrelevant neural activations, focusing attribution on neurons that directly influence token generation. We evaluate ProToken across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding). ProToken achieves 98% average attribution accuracy in correctly localizing responsible client(s), and maintains high accuracy when the number of clients are scaled, validating its practical viability for real-world deployment settings.", "AI": {"tldr": "ProToken enables token-level client attribution in federated LLMs while preserving privacy, achieving 98% accuracy across diverse models and domains.", "motivation": "Federated LLMs lack attribution mechanisms to identify which clients contributed to specific generated responses, which hinders debugging, malicious client identification, fair reward allocation, and trust verification in critical applications.", "method": "ProToken uses two key insights: (1) transformer architectures concentrate task-specific signals in later blocks for strategic layer selection, and (2) gradient-based relevance weighting filters irrelevant neural activations to focus on neurons directly influencing token generation.", "result": "ProToken achieves 98% average attribution accuracy in correctly localizing responsible clients across 16 configurations spanning four LLM architectures (Gemma, Llama, Qwen, SmolLM) and four domains (medical, financial, mathematical, coding), maintaining high accuracy when scaling client numbers.", "conclusion": "ProToken provides a practical, privacy-preserving solution for token-level client attribution in federated LLMs, enabling debugging, malicious client identification, fair reward allocation, and trust verification in real-world deployment settings."}}
{"id": "2601.19674", "categories": ["cs.LG", "cs.AI", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.19674", "abs": "https://arxiv.org/abs/2601.19674", "authors": ["Dominic Weisser", "Chlo\u00e9 Hashimoto-Cullen", "Benjamin Guedj"], "title": "Cross-Domain Offshore Wind Power Forecasting: Transfer Learning Through Meteorological Clusters", "comment": "11 pages", "summary": "Ambitious decarbonisation targets are catalysing growth in orders of new offshore wind farms. For these newly commissioned plants to run, accurate power forecasts are needed from the onset. These allow grid stability, good reserve management and efficient energy trading. Despite machine learning models having strong performances, they tend to require large volumes of site-specific data that new farms do not yet have. To overcome this data scarcity, we propose a novel transfer learning framework that clusters power output according to covariate meteorological features. Rather than training a single, general-purpose model, we thus forecast with an ensemble of expert models, each trained on a cluster. As these pre-trained models each specialise in a distinct weather pattern, they adapt efficiently to new sites and capture transferable, climate-dependent dynamics. Through the expert models' built-in calibration to seasonal and meteorological variability, we remove the industry-standard requirement of local measurements over a year. Our contributions are two-fold - we propose this novel framework and comprehensively evaluate it on eight offshore wind farms, achieving accurate cross-domain forecasting with under five months of site-specific data. Our experiments achieve a MAE of 3.52\\%, providing empirical verification that reliable forecasts do not require a full annual cycle. Beyond power forecasting, this climate-aware transfer learning method opens new opportunities for offshore wind applications such as early-stage wind resource assessment, where reducing data requirements can significantly accelerate project development whilst effectively mitigating its inherent risks.", "AI": {"tldr": "Novel transfer learning framework for offshore wind power forecasting that clusters weather patterns and uses expert models to overcome data scarcity at new wind farms, achieving accurate forecasts with under 5 months of site data.", "motivation": "New offshore wind farms need accurate power forecasts from the onset for grid stability and energy trading, but lack sufficient site-specific data for traditional ML models which require large volumes of historical data.", "method": "Proposes a transfer learning framework that clusters power output according to meteorological features, then uses an ensemble of expert models (each trained on a specific weather cluster) rather than a single general-purpose model. This allows models to specialize in distinct weather patterns and adapt efficiently to new sites.", "result": "Achieved accurate cross-domain forecasting with under five months of site-specific data across eight offshore wind farms, with MAE of 3.52%. Removed the industry-standard requirement of local measurements over a full annual cycle.", "conclusion": "The climate-aware transfer learning method enables reliable power forecasting without needing a full year of data, opening opportunities for early-stage wind resource assessment and accelerating offshore wind project development while mitigating risks."}}
{"id": "2601.19675", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19675", "abs": "https://arxiv.org/abs/2601.19675", "authors": ["Hongyaoxing Gu", "Lijuan Hu", "Liye Yu", "Haowei Li", "Fangfang Liu"], "title": "LoPRo: Enhancing Low-Rank Quantization via Permuted Block-Wise Rotation", "comment": null, "summary": "Post-training quantization (PTQ) enables effective model compression while preserving relatively high accuracy. Current weight-only PTQ methods primarily focus on the challenging sub-3-bit regime, where approaches often suffer significant accuracy degradation, typically requiring fine-tuning to achieve competitive performance. In this work, we revisit the fundamental characteristics of weight quantization and analyze the challenges in quantizing the residual matrix under low-rank approximation. We propose LoPRo, a novel fine-tuning-free PTQ algorithm that enhances residual matrix quantization by applying block-wise permutation and Walsh-Hadamard transformations to rotate columns of similar importance, while explicitly preserving the quantization accuracy of the most salient column blocks. Furthermore, we introduce a mixed-precision fast low-rank decomposition based on rank-1 sketch (R1SVD) to further minimize quantization costs. Experiments demonstrate that LoPRo outperforms existing fine-tuning-free PTQ methods at both 2-bit and 3-bit quantization, achieving accuracy comparable to fine-tuning baselines. Specifically, LoPRo achieves state-of-the-art quantization accuracy on LLaMA-2 and LLaMA-3 series models while delivering up to a 4$\\times$ speedup. In the MoE model Mixtral-8x7B, LoPRo completes quantization within 2.5 hours, simultaneously reducing perplexity by 0.4$\\downarrow$ and improving accuracy by 8\\%$\\uparrow$. Moreover, compared to other low-rank quantization methods, LoPRo achieves superior accuracy with a significantly lower rank, while maintaining high inference efficiency and minimal additional latency.", "AI": {"tldr": "LoPRo is a fine-tuning-free post-training quantization method that uses block-wise permutation and Walsh-Hadamard transformations to improve weight quantization, achieving state-of-the-art 2-3 bit quantization with high efficiency.", "motivation": "Current weight-only PTQ methods struggle with significant accuracy degradation in sub-3-bit regimes and often require fine-tuning to achieve competitive performance. There's a need for fine-tuning-free methods that can maintain high accuracy while being computationally efficient.", "method": "LoPRo enhances residual matrix quantization through block-wise permutation and Walsh-Hadamard transformations to rotate columns of similar importance, while preserving quantization accuracy of most salient column blocks. It also uses mixed-precision fast low-rank decomposition based on rank-1 sketch (R1SVD) to minimize quantization costs.", "result": "LoPRo outperforms existing fine-tuning-free PTQ methods at both 2-bit and 3-bit quantization, achieving accuracy comparable to fine-tuning baselines. It achieves state-of-the-art quantization accuracy on LLaMA-2 and LLaMA-3 models with up to 4\u00d7 speedup. For Mixtral-8x7B, it completes quantization within 2.5 hours while reducing perplexity by 0.4 and improving accuracy by 8%.", "conclusion": "LoPRo provides an effective fine-tuning-free PTQ solution that achieves superior accuracy with lower rank compared to other low-rank quantization methods, while maintaining high inference efficiency and minimal additional latency."}}
{"id": "2601.19700", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.19700", "abs": "https://arxiv.org/abs/2601.19700", "authors": ["Jiajie Su", "Haoyuan Wang", "Xiaohua Feng", "Yunshan Ma", "Xiaobo Xia", "Yuyuan Li", "Xiaolin Zheng", "Jianmao Xiao", "Chaochao Chen"], "title": "Out-of-Distribution Generalization via Invariant Trajectories for Multimodal Large Language Model Editing", "comment": null, "summary": "Knowledge editing emerges as a crucial technique for efficiently correcting incorrect or outdated knowledge in large language models (LLM). Existing editing methods for unimodal LLM rely on a rigid parameter-to-output mapping, which causes causal-underfit and causal-overfit in cascaded reasoning for Multimodal LLM (MLLM). In this paper, we reformulate MLLM editing as an out-of-distribution (OOD) generalization problem, where the goal is to discern semantic shift with factual shift and thus achieve robust editing among diverse cross-modal prompting. The key challenge of this OOD problem lies in identifying invariant causal trajectories that generalize accurately while suppressing spurious correlations. To address it, we propose ODEdit, a plug-and-play invariant learning based framework that optimizes the tripartite OOD risk objective to simultaneously enhance editing reliability, locality, and generality.We further introduce an edit trajectory invariant learning method, which integrates a total variation penalty into the risk minimization objective to stabilize edit trajectories against environmental variations. Theoretical analysis and extensive experiments demonstrate the effectiveness of ODEdit.", "AI": {"tldr": "ODEdit is a plug-and-play invariant learning framework for multimodal LLM knowledge editing that treats editing as an out-of-distribution generalization problem to handle cross-modal prompting variations.", "motivation": "Existing unimodal LLM editing methods fail for multimodal LLMs due to rigid parameter-to-output mapping causing causal-underfit and causal-overfit in cascaded reasoning, especially with diverse cross-modal prompting.", "method": "ODEdit reformulates MLLM editing as OOD generalization, uses invariant learning to identify causal trajectories, optimizes tripartite OOD risk objective for reliability/locality/generality, and adds total variation penalty to stabilize edit trajectories.", "result": "Theoretical analysis and extensive experiments demonstrate ODEdit's effectiveness in robust knowledge editing across diverse cross-modal prompts.", "conclusion": "Treating MLLM editing as OOD generalization with invariant learning (ODEdit) successfully addresses the limitations of existing methods and enables robust knowledge correction in multimodal contexts."}}
{"id": "2601.19718", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19718", "abs": "https://arxiv.org/abs/2601.19718", "authors": ["Kaifeng Zhang", "Kai Ming Ting", "Tianrun Liang", "Qiuran Zhao"], "title": "Rethinking Divisive Hierarchical Clustering from a Distributional Perspective", "comment": null, "summary": "We uncover that current objective-based Divisive Hierarchical Clustering (DHC) methods produce a dendrogram that does not have three desired properties i.e., no unwarranted splitting, group similar clusters into a same subset, ground-truth correspondence. This shortcoming has their root cause in using a set-oriented bisecting assessment criterion. We show that this shortcoming can be addressed by using a distributional kernel, instead of the set-oriented criterion; and the resultant clusters achieve a new distribution-oriented objective to maximize the total similarity of all clusters (TSC). Our theoretical analysis shows that the resultant dendrogram guarantees a lower bound of TSC. The empirical evaluation shows the effectiveness of our proposed method on artificial and Spatial Transcriptomics (bioinformatics) datasets. Our proposed method successfully creates a dendrogram that is consistent with the biological regions in a Spatial Transcriptomics dataset, whereas other contenders fail.", "AI": {"tldr": "The paper identifies flaws in current divisive hierarchical clustering methods and proposes a distributional kernel approach to fix them, ensuring better dendrogram properties and theoretical guarantees.", "motivation": "Current objective-based Divisive Hierarchical Clustering methods produce dendrograms lacking three desired properties: no unwarranted splitting, grouping similar clusters together, and ground-truth correspondence. This stems from using set-oriented bisecting assessment criteria.", "method": "Proposes using a distributional kernel instead of set-oriented criteria, resulting in clusters that maximize total similarity of all clusters (TSC). The approach creates dendrograms with theoretical guarantees.", "result": "Theoretical analysis shows the dendrogram guarantees a lower bound of TSC. Empirical evaluation on artificial and Spatial Transcriptomics datasets demonstrates effectiveness. The method successfully creates dendrograms consistent with biological regions where other methods fail.", "conclusion": "Distributional kernel approach addresses shortcomings of current DHC methods, providing better dendrogram properties with theoretical guarantees and practical effectiveness on real-world bioinformatics data."}}
{"id": "2601.19720", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19720", "abs": "https://arxiv.org/abs/2601.19720", "authors": ["Gong Gao", "Weidong Zhao", "Xianhui Liu", "Ning Jia"], "title": "Improving Policy Exploitation in Online Reinforcement Learning with Instant Retrospect Action", "comment": null, "summary": "Existing value-based online reinforcement learning (RL) algorithms suffer from slow policy exploitation due to ineffective exploration and delayed policy updates. To address these challenges, we propose an algorithm called Instant Retrospect Action (IRA). Specifically, we propose Q-Representation Discrepancy Evolution (RDE) to facilitate Q-network representation learning, enabling discriminative representations for neighboring state-action pairs. In addition, we adopt an explicit method to policy constraints by enabling Greedy Action Guidance (GAG). This is achieved through backtracking historical actions, which effectively enhances the policy update process. Our proposed method relies on providing the learning algorithm with accurate $k$-nearest-neighbor action value estimates and learning to design a fast-adaptable policy through policy constraints. We further propose the Instant Policy Update (IPU) mechanism, which enhances policy exploitation by systematically increasing the frequency of policy updates. We further discover that the early-stage training conservatism of the IRA method can alleviate the overestimation bias problem in value-based RL. Experimental results show that IRA can significantly improve the learning efficiency and final performance of online RL algorithms on eight MuJoCo continuous control tasks.", "AI": {"tldr": "IRA algorithm improves online RL efficiency by combining representation learning, action backtracking, and frequent policy updates to address slow exploitation and delayed updates.", "motivation": "Existing value-based online RL algorithms suffer from slow policy exploitation due to ineffective exploration and delayed policy updates, limiting learning efficiency.", "method": "Proposes IRA with three key components: 1) Q-Representation Discrepancy Evolution (RDE) for discriminative representations, 2) Greedy Action Guidance (GAG) using historical action backtracking for policy constraints, and 3) Instant Policy Update (IPU) mechanism for frequent policy updates.", "result": "IRA significantly improves learning efficiency and final performance on eight MuJoCo continuous control tasks, and early-stage training conservatism helps alleviate overestimation bias.", "conclusion": "IRA effectively addresses slow exploitation and delayed updates in online RL through integrated representation learning, policy constraints, and frequent updates, demonstrating superior performance on continuous control benchmarks."}}
{"id": "2601.19730", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19730", "abs": "https://arxiv.org/abs/2601.19730", "authors": ["Hongxu Chen", "Ke Wei", "Xiaoming Yuan", "Luo Luo"], "title": "Stability and Generalization of Nonconvex Optimization with Heavy-Tailed Noise", "comment": null, "summary": "The empirical evidence indicates that stochastic optimization with heavy-tailed gradient noise is more appropriate to characterize the training of machine learning models than that with standard bounded gradient variance noise. Most existing works on this phenomenon focus on the convergence of optimization errors, while the analysis for generalization bounds under the heavy-tailed gradient noise remains limited. In this paper, we develop a general framework for establishing generalization bounds under heavy-tailed noise. Specifically, we introduce a truncation argument to achieve the generalization error bound based on the algorithmic stability under the assumption of bounded $p$th centered moment with $p\\in(1,2]$. Building on this framework, we further provide the stability and generalization analysis for several popular stochastic algorithms under heavy-tailed noise, including clipped and normalized stochastic gradient descent, as well as their mini-batch and momentum variants.", "AI": {"tldr": "Develops generalization bounds for stochastic optimization under heavy-tailed gradient noise using algorithmic stability with truncation argument.", "motivation": "Heavy-tailed gradient noise better characterizes ML training than bounded variance, but generalization analysis under such noise remains limited despite existing convergence studies.", "method": "Introduces truncation argument to achieve generalization error bounds via algorithmic stability, assuming bounded p-th centered moment (p\u2208(1,2]). Applies framework to clipped/normalized SGD and their mini-batch/momentum variants.", "result": "Develops general framework for establishing generalization bounds under heavy-tailed noise, providing stability and generalization analysis for several popular stochastic algorithms.", "conclusion": "Provides systematic approach to analyze generalization of stochastic optimization algorithms under heavy-tailed gradient noise, addressing gap between convergence and generalization analysis."}}
{"id": "2601.19745", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19745", "abs": "https://arxiv.org/abs/2601.19745", "authors": ["Shuyue Wei", "Wantong Chen", "Tongyu Wei", "Chen Gong", "Yongxin Tong", "Lizhen Cui"], "title": "GraphDLG: Exploring Deep Leakage from Gradients in Federated Graph Learning", "comment": null, "summary": "Federated graph learning (FGL) has recently emerged as a promising privacy-preserving paradigm that enables distributed graph learning across multiple data owners. A critical privacy concern in federated learning is whether an adversary can recover raw data from shared gradients, a vulnerability known as deep leakage from gradients (DLG). However, most prior studies on the DLG problem focused on image or text data, and it remains an open question whether graphs can be effectively recovered, particularly when the graph structure and node features are uniquely entangled in GNNs. In this work, we first theoretically analyze the components in FGL and derive a crucial insight: once the graph structure is recovered, node features can be obtained through a closed-form recursive rule. Building on this analysis, we propose GraphDLG, a novel approach to recover raw training graphs from shared gradients in FGL, which can utilize randomly generated graphs or client-side training graphs as auxiliaries to enhance recovery. Extensive experiments demonstrate that GraphDLG outperforms existing solutions by successfully decoupling the graph structure and node features, achieving improvements of over 5.46% (by MSE) for node feature reconstruction and over 25.04% (by AUC) for graph structure reconstruction.", "AI": {"tldr": "GraphDLG: A novel method to recover raw training graphs from shared gradients in federated graph learning, achieving significant improvements over existing solutions.", "motivation": "Address the privacy vulnerability in federated graph learning where adversaries could potentially recover raw graph data from shared gradients, which has been studied for image/text data but remains unexplored for graph data with unique structure-feature entanglement in GNNs.", "method": "First theoretically analyze FGL components to derive insight that graph structure recovery enables node feature recovery via closed-form recursive rule. Then propose GraphDLG approach that uses randomly generated graphs or client-side training graphs as auxiliaries to enhance recovery.", "result": "GraphDLG outperforms existing solutions by successfully decoupling graph structure and node features, achieving improvements of over 5.46% (by MSE) for node feature reconstruction and over 25.04% (by AUC) for graph structure reconstruction.", "conclusion": "Graphs can be effectively recovered from gradients in federated graph learning, demonstrating significant privacy vulnerabilities in FGL systems that need to be addressed."}}
{"id": "2601.19756", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19756", "abs": "https://arxiv.org/abs/2601.19756", "authors": ["Yunwei Ren", "Yatin Dandi", "Florent Krzakala", "Jason D. Lee"], "title": "Provable Learning of Random Hierarchy Models and Hierarchical Shallow-to-Deep Chaining", "comment": null, "summary": "The empirical success of deep learning is often attributed to deep networks' ability to exploit hierarchical structure in data, constructing increasingly complex features across layers. Yet despite substantial progress in deep learning theory, most optimization results sill focus on networks with only two or three layers, leaving the theoretical understanding of hierarchical learning in genuinely deep models limited. This leads to a natural question: can we prove that deep networks, trained by gradient-based methods, can efficiently exploit hierarchical structure?\n  In this work, we consider Random Hierarchy Models -- a hierarchical context-free grammar introduced by arXiv:2307.02129 and conjectured to separate deep and shallow networks. We prove that, under mild conditions, a deep convolutional network can be efficiently trained to learn this function class. Our proof builds on a general observation: if intermediate layers can receive clean signal from the labels and the relevant features are weakly identifiable, then layerwise training each individual layer suffices to hierarchically learn the target function.", "AI": {"tldr": "Deep convolutional networks can be efficiently trained to learn hierarchical functions through layerwise training when intermediate layers receive clean signal from labels and features are weakly identifiable.", "motivation": "Despite empirical success of deep learning in exploiting hierarchical structure, most theoretical optimization results focus on shallow networks (2-3 layers), leaving limited understanding of hierarchical learning in genuinely deep models. The paper aims to prove whether deep networks trained by gradient methods can efficiently exploit hierarchical structure.", "method": "The authors use Random Hierarchy Models (a hierarchical context-free grammar) as a test case. They prove that under mild conditions, deep convolutional networks can be efficiently trained through layerwise training, where each individual layer is trained separately. The key insight is that if intermediate layers receive clean signal from labels and relevant features are weakly identifiable, this approach suffices.", "result": "The paper proves that deep convolutional networks can be efficiently trained to learn hierarchical functions from Random Hierarchy Models. The theoretical result demonstrates that layerwise training is sufficient for hierarchical learning when the specified conditions are met.", "conclusion": "Deep networks trained by gradient-based methods can indeed efficiently exploit hierarchical structure, as demonstrated through the theoretical analysis of Random Hierarchy Models. The layerwise training approach provides a viable method for hierarchical learning when intermediate layers receive clean signal and features are weakly identifiable."}}
{"id": "2601.19766", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19766", "abs": "https://arxiv.org/abs/2601.19766", "authors": ["Allyson Hahn", "Krishnan Raghavan"], "title": "The Effect of Architecture During Continual Learning", "comment": null, "summary": "Continual learning is a challenge for models with static architecture, as they fail to adapt to when data distributions evolve across tasks. We introduce a mathematical framework that jointly models architecture and weights in a Sobolev space, enabling a rigorous investigation into the role of neural network architecture in continual learning and its effect on the forgetting loss. We derive necessary conditions for the continual learning solution and prove that learning only model weights is insufficient to mitigate catastrophic forgetting under distribution shifts. Consequently, we prove that by learning the architecture and weights simultaneously at each task, we can reduce catastrophic forgetting.\n  To learn weights and architecture simultaneously, we formulate continual learning as a bilevel optimization problem: the upper level selects an optimal architecture for a given task, while the lower level computes optimal weights via dynamic programming over all tasks. To solve the upper level problem, we introduce a derivative-free direct search algorithm to determine the optimal architecture. Once found, we must transfer knowledge from the current architecture to the optimal one. However, the optimal architecture will result in a weights parameter space different from the current architecture (i.e., dimensions of weights matrices will not match). To bridge the dimensionality gap, we develop a low-rank transfer mechanism to map knowledge across architectures of mismatched dimensions. Empirical studies across regression and classification problems, including feedforward, convolutional, and graph neural networks, demonstrate that learning the optimal architecture and weights simultaneously yields substantially improved performance (up to two orders of magnitude), reduced forgetting, and enhanced robustness to noise compared with static architecture approaches.", "AI": {"tldr": "The paper proposes a novel continual learning framework that jointly optimizes neural network architecture and weights to mitigate catastrophic forgetting, proving that weight-only learning is insufficient and introducing a bilevel optimization approach with low-rank knowledge transfer.", "motivation": "Static neural network architectures fail to adapt to evolving data distributions in continual learning, leading to catastrophic forgetting. The authors aim to mathematically demonstrate that learning only weights is insufficient and that architecture adaptation is necessary for effective continual learning.", "method": "1) Mathematical framework modeling architecture and weights in Sobolev space; 2) Bilevel optimization: upper level selects optimal architecture via derivative-free direct search, lower level computes optimal weights via dynamic programming; 3) Low-rank transfer mechanism to map knowledge across architectures with mismatched dimensions.", "result": "Empirical studies across regression/classification problems with feedforward, convolutional, and graph neural networks show: up to two orders of magnitude performance improvement, significantly reduced forgetting, and enhanced robustness to noise compared to static architecture approaches.", "conclusion": "Simultaneous learning of architecture and weights is essential for effective continual learning, as proven mathematically and demonstrated empirically. The proposed framework provides a rigorous solution to catastrophic forgetting through architecture adaptation and knowledge transfer mechanisms."}}
{"id": "2601.19788", "categories": ["cs.LG", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.19788", "abs": "https://arxiv.org/abs/2601.19788", "authors": ["Sixing Tan", "Xianmin Liu"], "title": "Knowledge-Aware Evolution for Streaming Federated Continual Learning with Category Overlap and without Task Identifiers", "comment": null, "summary": "Federated Continual Learning (FCL) leverages inter-client collaboration to balance new knowledge acquisition and prior knowledge retention in non-stationary data. However, existing batch-based FCL methods lack adaptability to streaming scenarios featuring category overlap between old and new data and absent task identifiers, leading to indistinguishability of old and new knowledge, uncertain task assignments for samples, and knowledge confusion.To address this, we propose streaming federated continual learning setting: per federated learning (FL) round, clients process streaming data with disjoint samples and potentially overlapping categories without task identifiers, necessitating sustained inference capability for all prior categories after each FL round.Next, we introduce FedKACE: 1) an adaptive inference model switching mechanism that enables unidirectional switching from local model to global model to achieve a trade-off between personalization and generalization; 2) a adaptive gradient-balanced replay scheme that reconciles new knowledge learning and old knowledge retention under overlapping-class scenarios; 3) a kernel spectral boundary buffer maintenance that preserves high-information and high-boundary-influence samples to optimize cross-round knowledge retention. Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE.", "AI": {"tldr": "FedKACE is a streaming federated continual learning method that handles overlapping categories without task identifiers through adaptive model switching, gradient-balanced replay, and kernel spectral boundary buffer maintenance.", "motivation": "Existing batch-based federated continual learning methods fail in streaming scenarios with overlapping categories and no task identifiers, causing knowledge confusion and uncertain task assignments.", "method": "FedKACE introduces: 1) adaptive inference model switching (local to global) for personalization-generalization trade-off; 2) adaptive gradient-balanced replay for overlapping-class scenarios; 3) kernel spectral boundary buffer maintenance for preserving high-information boundary samples.", "result": "Experiments across multiple scenarios and regret analysis demonstrate the effectiveness of FedKACE in streaming federated continual learning settings.", "conclusion": "FedKACE successfully addresses the challenges of streaming federated continual learning with overlapping categories and no task identifiers through its three key components."}}
{"id": "2601.19791", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.19791", "abs": "https://arxiv.org/abs/2601.19791", "authors": ["Mingyue Xu", "Gal Vardi", "Itay Safran"], "title": "To Grok Grokking: Provable Grokking in Ridge Regression", "comment": null, "summary": "We study grokking, the onset of generalization long after overfitting, in a classical ridge regression setting. We prove end-to-end grokking results for learning over-parameterized linear regression models using gradient descent with weight decay. Specifically, we prove that the following stages occur: (i) the model overfits the training data early during training; (ii) poor generalization persists long after overfitting has manifested; and (iii) the generalization error eventually becomes arbitrarily small. Moreover, we show, both theoretically and empirically, that grokking can be amplified or eliminated in a principled manner through proper hyperparameter tuning. To the best of our knowledge, these are the first rigorous quantitative bounds on the generalization delay (which we refer to as the \"grokking time\") in terms of training hyperparameters. Lastly, going beyond the linear setting, we empirically demonstrate that our quantitative bounds also capture the behavior of grokking on non-linear neural networks. Our results suggest that grokking is not an inherent failure mode of deep learning, but rather a consequence of specific training conditions, and thus does not require fundamental changes to the model architecture or learning algorithm to avoid.", "AI": {"tldr": "The paper provides rigorous analysis of grokking phenomenon in ridge regression, proving three-stage training dynamics and deriving quantitative bounds for grokking time.", "motivation": "To understand grokking - the delayed generalization that occurs long after overfitting - in a mathematically rigorous framework, particularly in ridge regression settings.", "method": "Theoretical analysis of over-parameterized linear regression with gradient descent and weight decay, proving end-to-end grokking results with quantitative bounds on generalization delay.", "result": "Proved three-stage training dynamics: early overfitting, prolonged poor generalization, and eventual excellent generalization. Derived quantitative bounds for grokking time in terms of hyperparameters, showing grokking can be amplified or eliminated through hyperparameter tuning.", "conclusion": "Grokking is not an inherent failure mode of deep learning but a consequence of specific training conditions, requiring no fundamental changes to model architecture or learning algorithm to avoid."}}
{"id": "2601.19794", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.19794", "abs": "https://arxiv.org/abs/2601.19794", "authors": ["Ganesh Sundaram", "Jonas Ulmen", "Daniel G\u00f6rges"], "title": "Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation", "comment": "8 pages, Submitted to the 2026 IFAC World Congress", "summary": "The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to capture functional significance. This paper introduces a component-aware pruning framework that utilizes gradient information to compute three distinct importance metrics during training: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty. Experimental results with an autoencoder and a TD-MPC agent demonstrate that the proposed framework reveals critical structural dependencies and dynamic shifts in importance that static heuristics often miss, supporting more informed compression decisions.", "AI": {"tldr": "A component-aware pruning framework using gradient-based importance metrics (Gradient Accumulation, Fisher Information, Bayesian Uncertainty) to better identify critical structural dependencies in multi-component neural architectures than static norm-based methods.", "motivation": "Multi-component neural architectures have high computational complexity, and conventional model compression techniques (like norm-based pruning) fail to capture functional significance and structural dependencies between components.", "method": "Proposes a component-aware pruning framework that uses gradient information during training to compute three importance metrics: Gradient Accumulation, Fisher Information, and Bayesian Uncertainty to assess parameter group importance.", "result": "Experimental results with an autoencoder and TD-MPC agent show the framework reveals critical structural dependencies and dynamic importance shifts that static heuristics miss, enabling more informed compression decisions.", "conclusion": "Gradient-based importance metrics provide better insights into component relationships than static norm-based methods, supporting more effective pruning decisions for complex multi-component neural architectures."}}
{"id": "2601.19818", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.19818", "abs": "https://arxiv.org/abs/2601.19818", "authors": ["Kazuaki Tanaka", "Kohei Yatabe"], "title": "Learn and Verify: A Framework for Rigorous Verification of Physics-Informed Neural Networks", "comment": "13 pages, 10 figures", "summary": "The numerical solution of differential equations using neural networks has become a central topic in scientific computing, with Physics-Informed Neural Networks (PINNs) emerging as a powerful paradigm for both forward and inverse problems. However, unlike classical numerical methods that offer established convergence guarantees, neural network-based approximations typically lack rigorous error bounds. Furthermore, the non-deterministic nature of their optimization makes it difficult to mathematically certify their accuracy. To address these challenges, we propose a \"Learn and Verify\" framework that provides computable, mathematically rigorous error bounds for the solutions of differential equations. By combining a novel Doubly Smoothed Maximum (DSM) loss for training with interval arithmetic for verification, we compute rigorous a posteriori error bounds as machine-verifiable proofs. Numerical experiments on nonlinear Ordinary Differential Equations (ODEs), including problems with time-varying coefficients and finite-time blow-up, demonstrate that the proposed framework successfully constructs rigorous enclosures of the true solutions, establishing a foundation for trustworthy scientific machine learning.", "AI": {"tldr": "A \"Learn and Verify\" framework that provides mathematically rigorous error bounds for neural network solutions of differential equations using Doubly Smoothed Maximum loss and interval arithmetic verification.", "motivation": "Neural network solutions for differential equations (like PINNs) lack rigorous error bounds and convergence guarantees compared to classical numerical methods, making it difficult to mathematically certify their accuracy due to non-deterministic optimization.", "method": "Proposes a framework combining: 1) Novel Doubly Smoothed Maximum (DSM) loss for training neural networks, and 2) Interval arithmetic for verification to compute rigorous a posteriori error bounds as machine-verifiable proofs.", "result": "Numerical experiments on nonlinear ODEs (including problems with time-varying coefficients and finite-time blow-up) demonstrate successful construction of rigorous enclosures of true solutions.", "conclusion": "The framework establishes a foundation for trustworthy scientific machine learning by providing computable, mathematically rigorous error bounds for neural network solutions of differential equations."}}
{"id": "2601.19831", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19831", "abs": "https://arxiv.org/abs/2601.19831", "authors": ["Michael Y. Hu", "Jane Pan", "Ayush Rajesh Jhaveri", "Nicholas Lourie", "Kyunghyun Cho"], "title": "Neural Neural Scaling Laws", "comment": null, "summary": "Neural scaling laws predict how language model performance improves with increased compute. While aggregate metrics like validation loss can follow smooth power-law curves, individual downstream tasks exhibit diverse scaling behaviors: some improve monotonically, others plateau, and some even degrade with scale. We argue that predicting downstream performance from validation perplexity suffers from two limitations: averaging token-level losses obscures signal, and no simple parametric family can capture the full spectrum of scaling behaviors. To address this, we propose Neural Neural Scaling Laws (NeuNeu), a neural network that frames scaling law prediction as time-series extrapolation. NeuNeu combines temporal context from observed accuracy trajectories with token-level validation losses, learning to predict future performance without assuming any bottleneck or functional form. Trained entirely on open-source model checkpoints from HuggingFace, NeuNeu achieves 2.04% mean absolute error in predicting model accuracy on 66 downstream tasks -- a 38% reduction compared to logistic scaling laws (3.29% MAE). Furthermore, NeuNeu generalizes zero-shot to unseen model families, parameter counts, and downstream tasks. Our work suggests that predicting downstream scaling laws directly from data outperforms parametric alternatives.", "AI": {"tldr": "NeuNeu uses neural networks to predict downstream task performance from validation losses, outperforming traditional parametric scaling laws with 38% lower error.", "motivation": "Current scaling law predictions have limitations: validation perplexity averaging obscures signal, and no simple parametric family captures diverse scaling behaviors (monotonic improvement, plateauing, degradation).", "method": "Propose Neural Neural Scaling Laws (NeuNeu) - a neural network that frames scaling law prediction as time-series extrapolation, combining temporal context from observed accuracy trajectories with token-level validation losses.", "result": "Achieves 2.04% mean absolute error on 66 downstream tasks (38% reduction vs logistic scaling laws), generalizes zero-shot to unseen model families, parameter counts, and tasks.", "conclusion": "Predicting downstream scaling laws directly from data using neural networks outperforms parametric alternatives."}}
{"id": "2601.19833", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19833", "abs": "https://arxiv.org/abs/2601.19833", "authors": ["Padmaksha Roy", "Lamine Mili", "Almuatazbellah Boker"], "title": "A Multi-directional Meta-Learning Framework for Class-Generalizable Anomaly Detection", "comment": null, "summary": "In this paper, we address the problem of class-generalizable anomaly detection, where the objective is to develop a unified model by focusing our learning on the available normal data and a small amount of anomaly data in order to detect the completely unseen anomalies, also referred to as the out-of-distribution (OOD) classes. Adding to this challenge is the fact that the anomaly data is rare and costly to label. To achieve this, we propose a multidirectional meta-learning algorithm -- at the inner level, the model aims to learn the manifold of the normal data (representation); at the outer level, the model is meta-tuned with a few anomaly samples to maximize the softmax confidence margin between the normal and anomaly samples (decision surface calibration), treating normals as in-distribution (ID) and anomalies as out-of-distribution (OOD). By iteratively repeating this process over multiple episodes of predominantly normal and a small number of anomaly samples, we realize a multidirectional meta-learning framework. This two-level optimization, enhanced by multidirectional training, enables stronger generalization to unseen anomaly classes.", "AI": {"tldr": "A multidirectional meta-learning framework for class-generalizable anomaly detection that learns from normal data and few anomaly samples to detect unseen anomaly classes.", "motivation": "Addressing the challenge of class-generalizable anomaly detection where anomaly data is rare and costly to label, and the model needs to detect completely unseen anomaly classes (OOD).", "method": "Proposes a multidirectional meta-learning algorithm with two-level optimization: inner level learns the manifold of normal data (representation learning), outer level meta-tunes with few anomaly samples to maximize softmax confidence margin between normal and anomaly samples (decision surface calibration).", "result": "The framework enables stronger generalization to unseen anomaly classes through iterative multidirectional training over episodes of predominantly normal and few anomaly samples.", "conclusion": "The multidirectional meta-learning approach effectively addresses class-generalizable anomaly detection by learning from limited anomaly data while maintaining strong generalization to unseen anomaly classes."}}
{"id": "2601.19862", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.19862", "abs": "https://arxiv.org/abs/2601.19862", "authors": ["Yuqing Kong", "Mingyu Song", "Yizhou Wang", "Yifan Wu"], "title": "Calibration without Ground Truth", "comment": null, "summary": "Villalobos et al. [2024] predict that publicly available human text will be exhausted within the next decade. Thus, improving models without access to ground-truth labels becomes increasingly important. We propose a label-free post-processing framework that improves a strong but miscalibrated model using a weaker yet better-calibrated reference. Our framework guarantees a strict performance improvement under any proper loss. Our approach is based on a characterization of when strict improvement is possible: when the strong and reference models are not mutually calibrated. We formalize this condition, connect it to arbitrage and no-trade results from economics, and develop an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels. Experiments on representative LLMs across varying scales demonstrate that our label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.", "AI": {"tldr": "A label-free post-processing framework that improves strong but miscalibrated models using weaker but better-calibrated reference models, guaranteeing strict performance improvement under any proper loss without needing ground-truth labels.", "motivation": "With predictions that publicly available human text will be exhausted within the next decade, improving models without access to ground-truth labels becomes increasingly important as labeled data becomes scarce.", "method": "Proposes a label-free post-processing framework that leverages a weaker but better-calibrated reference model to improve a strong but miscalibrated model. The approach is based on characterizing when strict improvement is possible (when models are not mutually calibrated), connects to arbitrage and no-trade results from economics, and uses an efficient Bregman projection algorithm that guarantees worst-case loss reduction without labels.", "result": "Experiments on representative LLMs across varying scales demonstrate that the label-free method significantly reduces proper losses and calibration errors, achieving performance competitive with supervised baselines.", "conclusion": "The proposed framework provides a practical solution for model improvement in label-scarce scenarios, offering guaranteed performance improvement under proper losses without requiring ground-truth labels, which is crucial as human-generated text becomes increasingly scarce."}}
{"id": "2601.19867", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19867", "abs": "https://arxiv.org/abs/2601.19867", "authors": ["Tareq Si Salem"], "title": "Bandits in Flux: Adversarial Constraints in Dynamic Environments", "comment": "Accepted to AISTATS 2026", "summary": "We investigate the challenging problem of adversarial multi-armed bandits operating under time-varying constraints, a scenario motivated by numerous real-world applications. To address this complex setting, we propose a novel primal-dual algorithm that extends online mirror descent through the incorporation of suitable gradient estimators and effective constraint handling. We provide theoretical guarantees establishing sublinear dynamic regret and sublinear constraint violation for our proposed policy. Our algorithm achieves state-of-the-art performance in terms of both regret and constraint violation. Empirical evaluations demonstrate the superiority of our approach.", "AI": {"tldr": "Novel primal-dual algorithm for adversarial multi-armed bandits with time-varying constraints achieves sublinear dynamic regret and constraint violation with state-of-the-art performance.", "motivation": "Addressing the challenging problem of adversarial multi-armed bandits under time-varying constraints, motivated by numerous real-world applications where constraints change over time.", "method": "Proposes a novel primal-dual algorithm that extends online mirror descent with suitable gradient estimators and effective constraint handling mechanisms.", "result": "Theoretical guarantees establish sublinear dynamic regret and sublinear constraint violation. Algorithm achieves state-of-the-art performance in both metrics.", "conclusion": "The proposed approach demonstrates superiority through empirical evaluations and provides an effective solution for adversarial bandits with time-varying constraints."}}
{"id": "2601.19876", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19876", "abs": "https://arxiv.org/abs/2601.19876", "authors": ["Yiying Sheng", "Wenhao Ding", "Dylan Roi", "Leonard Leong Litt Yeo", "Hwa Liang Leo", "Choon Hwai Yap"], "title": "RHSIA: Real-time Hemodynamics Surrogation for Non-idealized Intracranial Aneurysms", "comment": null, "summary": "Extensive studies suggested that fluid mechanical markers of intracranial aneurysms (IAs) derived from Computational Fluid Dynamics (CFD) can indicate disease progression risks, but to date this has not been translated clinically. This is because CFD requires specialized expertise and is time-consuming and low throughput, making it difficult to support clinical trials. A deep learning model that maps IA morphology to biomechanical markers can address this, enabling physicians to obtain these markers in real time without performing CFD. Here, we show that a Graph Transformer model that incorporates temporal information, which is supervised by large CFD data, can accurately predict Wall Shear Stress (WSS) across the cardiac cycle from IA surface meshes. The model effectively captures the temporal variations of the WSS pattern, achieving a Structural Similarity Index (SSIM) of up to 0.981 and a maximum-based relative L2 error of 2.8%. Ablation studies and SOTA comparison confirmed its optimality. Further, as pulsatile CFD data is computationally expensive to generate and sample sizes are limited, we engaged a strategy of injecting a large amount of steady-state CFD data, which are extremely low-cost to generate, as augmentation. This approach enhances network performance substantially when pulsatile CFD data sample size is small. Our study provides a proof of concept that temporal sequences cardiovascular fluid mechanical parameters can be computed in real time using a deep learning model from the geometric mesh, and this is achievable even with small pulsatile CFD sample size. Our approach is likely applicable to other cardiovascular scenarios.", "AI": {"tldr": "Deep learning model predicts cardiac cycle Wall Shear Stress from aneurysm geometry, enabling real-time CFD-like analysis without actual CFD simulations.", "motivation": "CFD-derived fluid mechanical markers can indicate intracranial aneurysm progression risks but haven't been clinically translated due to CFD's complexity, time requirements, and low throughput. A deep learning alternative could provide real-time biomechanical markers without CFD expertise.", "method": "Graph Transformer model incorporating temporal information, supervised by large CFD data, predicts WSS across cardiac cycle from IA surface meshes. Uses steady-state CFD data augmentation to overcome limited pulsatile CFD data availability.", "result": "Model accurately captures temporal WSS variations with SSIM up to 0.981 and maximum-based relative L2 error of 2.8%. Ablation studies confirm optimality. Steady-state data augmentation substantially enhances performance with small pulsatile data samples.", "conclusion": "Proof of concept that temporal cardiovascular fluid mechanical parameters can be computed in real-time from geometric meshes using deep learning, even with limited pulsatile CFD data. Approach likely applicable to other cardiovascular scenarios."}}
{"id": "2601.19895", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.19895", "abs": "https://arxiv.org/abs/2601.19895", "authors": ["Chen Chen", "Lai Wei"], "title": "Post-LayerNorm Is Back: Stable, ExpressivE, and Deep", "comment": null, "summary": "Large language model (LLM) scaling is hitting a wall. Widening models yields diminishing returns, and extending context length does not improve fundamental expressivity. In contrast, depth scaling offers theoretically superior expressivity, yet current Transformer architectures struggle to train reliably at extreme depths. We revisit the Post-LayerNorm (Post-LN) formulation, whose instability at scale caused its replacement by Pre-LN in modern LLMs. We show that the central failure mode of Post-LN arises from the ResNet-style residual pathway, which introduces gradient vanishing in deep networks. We present Keel, a Post-LN Transformer that replaces this residual path with a Highway-style connection. This modification preserves the gradient flow through the residual branch, preventing signal vanishing from the top layers to the bottom. Unlike prior methods, Keel enables stable training at extreme depths without requiring specialized initialization or complex optimization tricks. Keel trains robustly at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN. These findings indicate that Post-LN, when paired with a Highway-style connection, provides a simple and effective foundation for building deeply scalable LLMs, opening the possibility for future infinite-depth architectures.", "AI": {"tldr": "Keel replaces Post-LN's ResNet-style residual with Highway-style connections to enable stable training of extremely deep Transformers (1000+ layers), overcoming gradient vanishing issues that plague current depth scaling approaches.", "motivation": "LLM scaling faces limitations: width scaling has diminishing returns, context length extension doesn't improve fundamental expressivity, while depth scaling offers superior theoretical expressivity but current Transformers (especially Post-LN) fail to train reliably at extreme depths due to gradient vanishing problems.", "method": "Keel modifies the Post-LayerNorm (Post-LN) Transformer by replacing the ResNet-style residual pathway with a Highway-style connection. This preserves gradient flow through the residual branch, preventing signal vanishing from top to bottom layers. The approach requires no specialized initialization or complex optimization tricks.", "result": "Keel enables stable training at depths exceeding 1000 layers and consistently improves perplexity and depth-scaling characteristics over Pre-LN Transformers. It demonstrates robust training without the instability issues that previously caused Post-LN to be replaced by Pre-LN in modern LLMs.", "conclusion": "Post-LN with Highway-style connections provides a simple, effective foundation for building deeply scalable LLMs, potentially enabling future infinite-depth architectures and overcoming current scaling limitations."}}
{"id": "2601.19897", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.19897", "abs": "https://arxiv.org/abs/2601.19897", "authors": ["Idan Shenfeld", "Mehul Damani", "Jonas H\u00fcbotter", "Pulkit Agrawal"], "title": "Self-Distillation Enables Continual Learning", "comment": null, "summary": "Continual learning, enabling models to acquire new skills and knowledge without degrading existing capabilities, remains a fundamental challenge for foundation models. While on-policy reinforcement learning can reduce forgetting, it requires explicit reward functions that are often unavailable. Learning from expert demonstrations, the primary alternative, is dominated by supervised fine-tuning (SFT), which is inherently off-policy. We introduce Self-Distillation Fine-Tuning (SDFT), a simple method that enables on-policy learning directly from demonstrations. SDFT leverages in-context learning by using a demonstration-conditioned model as its own teacher, generating on-policy training signals that preserve prior capabilities while acquiring new skills. Across skill learning and knowledge acquisition tasks, SDFT consistently outperforms SFT, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning experiments, SDFT enables a single model to accumulate multiple skills over time without performance regression, establishing on-policy distillation as a practical path to continual learning from demonstrations.", "AI": {"tldr": "SDFT enables on-policy continual learning from demonstrations by using demonstration-conditioned models as their own teachers, outperforming supervised fine-tuning in both new skill acquisition and forgetting reduction.", "motivation": "Continual learning for foundation models faces challenges: on-policy RL requires explicit rewards (often unavailable), while supervised fine-tuning (the primary alternative) is off-policy and leads to forgetting. There's a need for on-policy learning directly from demonstrations.", "method": "Self-Distillation Fine-Tuning (SDFT) leverages in-context learning by using a demonstration-conditioned model as its own teacher. The model generates on-policy training signals that preserve prior capabilities while acquiring new skills from demonstrations.", "result": "SDFT consistently outperforms SFT across skill learning and knowledge acquisition tasks, achieving higher new-task accuracy while substantially reducing catastrophic forgetting. In sequential learning, SDFT enables accumulation of multiple skills over time without performance regression.", "conclusion": "On-policy distillation via SDFT provides a practical path to continual learning from demonstrations, enabling models to acquire new skills while preserving existing capabilities without requiring explicit reward functions."}}
