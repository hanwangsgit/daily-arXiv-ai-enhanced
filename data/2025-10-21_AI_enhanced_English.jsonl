{"id": "2510.16310", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "I.4.0; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.16310", "abs": "https://arxiv.org/abs/2510.16310", "authors": ["Olajumoke O. Adekunle", "Joseph D. Akinyemi", "Khadijat T. Ladoja", "Olufade F. W. Onifade"], "title": "Lung Cancer Classification from CT Images Using ResNet", "comment": "9 pages,4 figures, 3 tables", "summary": "Lung cancer, a malignancy originating in lung tissues, is commonly diagnosed\nand classified using medical imaging techniques, particularly computed\ntomography (CT). Despite the integration of machine learning and deep learning\nmethods, the predictive efficacy of automated systems for lung cancer\nclassification from CT images remains below the desired threshold for clinical\nadoption. Existing research predominantly focuses on binary classification,\ndistinguishing between malignant and benign lung nodules. In this study, a\nnovel deep learning-based approach is introduced, aimed at an improved\nmulti-class classification, discerning various subtypes of lung cancer from CT\nimages. Leveraging a pre-trained ResNet model, lung tissue images were\nclassified into three distinct classes, two of which denote malignancy and one\nbenign. Employing a dataset comprising 15,000 lung CT images sourced from the\nLC25000 histopathological images, the ResNet50 model was trained on 10,200\nimages, validated on 2,550 images, and tested on the remaining 2,250 images.\nThrough the incorporation of custom layers atop the ResNet architecture and\nmeticulous hyperparameter fine-tuning, a remarkable test accuracy of 98.8% was\nrecorded. This represents a notable enhancement over the performance of prior\nmodels on the same dataset.", "AI": {"tldr": "A novel deep learning approach using ResNet50 achieves 98.8% accuracy for multi-class lung cancer classification from CT images, significantly outperforming previous methods.", "motivation": "Current automated lung cancer classification systems have insufficient predictive efficacy for clinical adoption, and existing research mainly focuses on binary classification rather than distinguishing between different cancer subtypes.", "method": "Used a pre-trained ResNet50 model with custom layers added on top, trained on 10,200 lung CT images from LC25000 dataset, validated on 2,550 images, and tested on 2,250 images. Applied meticulous hyperparameter fine-tuning for three-class classification (two malignant subtypes and one benign).", "result": "Achieved remarkable test accuracy of 98.8%, representing a notable enhancement over prior models on the same dataset.", "conclusion": "The proposed deep learning approach demonstrates superior performance in multi-class lung cancer classification from CT images, showing potential for clinical applications."}}
{"id": "2510.16321", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2510.16321", "abs": "https://arxiv.org/abs/2510.16321", "authors": ["Junno Yun", "Ya\u015far Utku Al\u00e7alar", "Mehmet Ak\u00e7akaya"], "title": "Time-Embedded Algorithm Unrolling for Computational MRI", "comment": "Neural Information Processing Systems (NeurIPS), 2025", "summary": "Algorithm unrolling methods have proven powerful for solving the regularized\nleast squares problem in computational magnetic resonance imaging (MRI). These\napproaches unfold an iterative algorithm with a fixed number of iterations,\ntypically alternating between a neural network-based proximal operator for\nregularization, a data fidelity operation and auxiliary updates with learnable\nparameters. While the connection to optimization methods dictate that the\nproximal operator network should be shared across unrolls, this can introduce\nartifacts or blurring. Heuristically, practitioners have shown that using\ndistinct networks may be beneficial, but this significantly increases the\nnumber of learnable parameters, making it challenging to prevent overfitting.\nTo address these shortcomings, by taking inspirations from proximal operators\nwith varying thresholds in approximate message passing (AMP) and the success of\ntime-embedding in diffusion models, we propose a time-embedded algorithm\nunrolling scheme for inverse problems. Specifically, we introduce a novel\nperspective on the iteration-dependent proximal operation in vector AMP (VAMP)\nand the subsequent Onsager correction in the context of algorithm unrolling,\nframing them as a time-embedded neural network. Similarly, the scalar weights\nin the data fidelity operation and its associated Onsager correction are cast\nas time-dependent learnable parameters. Our extensive experiments on the\nfastMRI dataset, spanning various acceleration rates and datasets, demonstrate\nthat our method effectively reduces aliasing artifacts and mitigates noise\namplification, achieving state-of-the-art performance. Furthermore, we show\nthat our time-embedding strategy extends to existing algorithm unrolling\napproaches, enhancing reconstruction quality without increasing the\ncomputational complexity significantly.", "AI": {"tldr": "Proposed time-embedded algorithm unrolling for MRI reconstruction that uses time-dependent proximal operators and learnable parameters instead of shared networks, improving reconstruction quality without significantly increasing computational complexity.", "motivation": "Traditional algorithm unrolling methods share the same proximal operator network across iterations, which can introduce artifacts and blurring. Using distinct networks increases parameters and risks overfitting. Time-embedding addresses these issues by making operations iteration-dependent.", "method": "Introduced time-embedded algorithm unrolling inspired by AMP and diffusion models. Framed iteration-dependent proximal operations in VAMP and Onsager corrections as time-embedded neural networks. Made scalar weights in data fidelity and Onsager corrections time-dependent learnable parameters.", "result": "Extensive experiments on fastMRI dataset across various acceleration rates showed effective reduction of aliasing artifacts and noise amplification. Achieved state-of-the-art performance. Method also enhanced existing algorithm unrolling approaches without significant computational complexity increase.", "conclusion": "Time-embedding strategy provides an effective solution for algorithm unrolling in inverse problems, improving reconstruction quality while maintaining computational efficiency. The approach successfully addresses limitations of shared networks in traditional unrolling methods."}}
{"id": "2510.16347", "categories": ["eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.16347", "abs": "https://arxiv.org/abs/2510.16347", "authors": ["Songyuan Lu", "Jingwen Hui", "Jake Weeks", "David B. Berry", "Fanny Chapelin", "Frank Talke"], "title": "Computer Navigated Spinal Surgery Using Magnetic Resonance Imaging and Augmented Reality", "comment": null, "summary": "Current spinal pain management procedures, such as radiofrequency ablation\n(RFA) and epidural steroid injection (ESI), rely on fluoroscopy for needle\nplacement which exposes patients and physicians to ionizing radiation. In this\npaper, we investigate a radiation-free surgical navigation system for spinal\npain management procedures that combines magnetic resonance imaging (MRI) with\nfiducial ArUco marker-based augmented reality (AR). High-resolution MRI scans\nof a lumbar spinal phantom were obtained and assembled as a surface mesh.\nLaplacian smoothing algorithms were then applied to smoothen the surface and\nimprove the model fidelity. A commercially available stereo camera (ZED2) was\nused to track single or dual fiducial ArUco markers on the patient to determine\nthe patient's real-time pose. Custom AR software was applied to overlay the MRI\nimage onto the patient, allowing the physician to see not only the outer\nsurface of the patient but also the complete anatomy of the patient below the\nsurface. Needle-insertion trials on a 3D-printed 3-vertebra phantom showed that\ndual-ArUco marker tracking increased the accuracy of needle insertions and\nreduced the average needle misplacement distance compared to single-ArUco\nmarker procedures. The average needle misplacement is comparable to the average\ndeviation of 2 mm for conventional epidural techniques using fluoroscopy. Our\nradiation-free system demonstrates promise to serve as an alternative to\nfluoroscopy by improving image-guided spinal navigation.", "AI": {"tldr": "A radiation-free spinal navigation system using MRI and AR with fiducial markers shows comparable accuracy to conventional fluoroscopy for spinal pain management procedures.", "motivation": "Current spinal pain management procedures like RFA and ESI use fluoroscopy which exposes patients and physicians to ionizing radiation, creating a need for radiation-free alternatives.", "method": "Combined MRI with fiducial ArUco marker-based AR using a stereo camera (ZED2) to track markers and overlay MRI images onto patients, with dual-marker tracking for improved accuracy.", "result": "Dual-ArUco marker tracking increased needle insertion accuracy and reduced average misplacement distance compared to single-marker procedures, achieving average misplacement comparable to conventional fluoroscopy (2 mm deviation).", "conclusion": "The radiation-free system demonstrates promise as an alternative to fluoroscopy for spinal navigation procedures."}}
{"id": "2510.16394", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.16394", "abs": "https://arxiv.org/abs/2510.16394", "authors": ["Jinqi Zhang", "Lamei Zhang", "Bin Zou"], "title": "FSAR-Cap: A Fine-Grained Two-Stage Annotated Dataset for SAR Image Captioning", "comment": "5pages,4figures", "summary": "Synthetic Aperture Radar (SAR) image captioning enables scene-level semantic\nunderstanding and plays a crucial role in applications such as military\nintelligence and urban planning, but its development is limited by the scarcity\nof high-quality datasets. To address this, we present FSAR-Cap, a large-scale\nSAR captioning dataset with 14,480 images and 72,400 image-text pairs. FSAR-Cap\nis built on the FAIR-CSAR detection dataset and constructed through a two-stage\nannotation strategy that combines hierarchical template-based representation,\nmanual verification and supplementation, prompt standardization. Compared with\nexisting resources, FSAR-Cap provides richer fine-grained annotations, broader\ncategory coverage, and higher annotation quality. Benchmarking with multiple\nencoder-decoder architectures verifies its effectiveness, establishing a\nfoundation for future research in SAR captioning and intelligent image\ninterpretation.", "AI": {"tldr": "FSAR-Cap is a large-scale SAR image captioning dataset with 14,480 images and 72,400 image-text pairs, addressing the scarcity of high-quality datasets in SAR image understanding.", "motivation": "Synthetic Aperture Radar (SAR) image captioning is crucial for military intelligence and urban planning, but its development is limited by the scarcity of high-quality datasets.", "method": "Built on FAIR-CSAR detection dataset using a two-stage annotation strategy combining hierarchical template-based representation, manual verification and supplementation, and prompt standardization.", "result": "FSAR-Cap provides richer fine-grained annotations, broader category coverage, and higher annotation quality compared to existing resources. Benchmarking with multiple encoder-decoder architectures verifies its effectiveness.", "conclusion": "FSAR-Cap establishes a foundation for future research in SAR captioning and intelligent image interpretation."}}
{"id": "2510.15871", "categories": ["cs.IT", "cs.AI", "cs.LG", "math.IT", "math.PR", "94A17, 94A15, 68T05, 62F15, 68P30, 68T27, 68T50, 30B42", "H.1.1; I.1.2; I.2.6; I.2.8; I.2.4; E.4; G.1.6"], "pdf": "https://arxiv.org/pdf/2510.15871", "abs": "https://arxiv.org/abs/2510.15871", "authors": ["Chenguang Lu"], "title": "A Semantic Generalization of Shannon's Information Theory and Applications", "comment": "45 pages, 18 Figures, a review paper", "summary": "Does semantic communication require a semantic information theory parallel to\nShannon's information theory, or can Shannon's work be generalized for semantic\ncommunication? This paper advocates for the latter and introduces a semantic\ngeneralization of Shannon's information theory (G theory for short). The core\nidea is to replace the distortion constraint with the semantic constraint,\nachieved by utilizing a set of truth functions as a semantic channel. These\ntruth functions enable the expressions of semantic distortion, semantic\ninformation measures, and semantic information loss. Notably, the maximum\nsemantic information criterion is equivalent to the maximum likelihood\ncriterion and similar to the Regularized Least Squares criterion. This paper\nshows G theory's applications to daily and electronic semantic communication,\nmachine learning, constraint control, Bayesian confirmation, portfolio theory,\nand information value. The improvements in machine learning methods involve\nmultilabel learning and classification, maximum mutual information\nclassification, mixture models, and solving latent variables. Furthermore,\ninsights from statistical physics are discussed: Shannon information is similar\nto free energy; semantic information to free energy in local equilibrium\nsystems; and information efficiency to the efficiency of free energy in\nperforming work. The paper also proposes refining Friston's minimum free energy\nprinciple into the maximum information efficiency principle. Lastly, it\ncompares G theory with other semantic information theories and discusses its\nlimitation in representing the semantics of complex data.", "AI": {"tldr": "This paper proposes a semantic generalization of Shannon's information theory (G theory) that replaces distortion constraints with semantic constraints using truth functions, enabling semantic information measures and applications across communication, machine learning, and physics.", "motivation": "To determine whether semantic communication requires a new information theory or can be achieved by generalizing Shannon's theory, advocating for the latter approach.", "method": "Introduces G theory by replacing distortion constraints with semantic constraints using truth functions as a semantic channel, enabling expressions of semantic distortion, information measures, and information loss.", "result": "Shows equivalence between maximum semantic information criterion and maximum likelihood criterion, applies G theory to various domains including communication, machine learning, constraint control, and statistical physics, and proposes refinements to existing principles.", "conclusion": "G theory successfully generalizes Shannon's information theory for semantic applications but has limitations in representing complex data semantics, and provides insights connecting information theory with statistical physics principles."}}
{"id": "2510.15963", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15963", "abs": "https://arxiv.org/abs/2510.15963", "authors": ["Jiani Huang", "Amish Sethi", "Matthew Kuo", "Mayank Keoliya", "Neelay Velingker", "JungHo Jung", "Ser-Nam Lim", "Ziyang Li", "Mayur Naik"], "title": "ESCA: Contextualizing Embodied Agents via Scene-Graph Generation", "comment": "Accepted as a Spotlight Paper at NeurIPS 2025", "summary": "Multi-modal large language models (MLLMs) are making rapid progress toward\ngeneral-purpose embodied agents. However, current training pipelines primarily\nrely on high-level vision-sound-text pairs and lack fine-grained, structured\nalignment between pixel-level visual content and textual semantics. To overcome\nthis challenge, we propose ESCA, a new framework for contextualizing embodied\nagents through structured spatial-temporal understanding. At its core is\nSGClip, a novel CLIP-based, open-domain, and promptable model for generating\nscene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic\nlearning pipeline, which harnesses model-driven self-supervision from\nvideo-caption pairs and structured reasoning, thereby eliminating the need for\nhuman-labeled scene graph annotations. We demonstrate that SGClip supports both\nprompt-based inference and task-specific fine-tuning, excelling in scene graph\ngeneration and action localization benchmarks. ESCA with SGClip consistently\nimproves both open-source and commercial MLLMs, achieving state-of-the-art\nperformance across two embodied environments. Notably, it significantly reduces\nagent perception errors and enables open-source models to surpass proprietary\nbaselines.", "AI": {"tldr": "ESCA framework improves embodied agents through structured spatial-temporal understanding using SGClip, a novel CLIP-based scene graph generation model trained without human annotations.", "motivation": "Current MLLM training pipelines lack fine-grained alignment between pixel-level visual content and textual semantics, limiting their effectiveness as embodied agents.", "method": "Proposed ESCA framework with SGClip - a neurosymbolic learning pipeline trained on 87K+ videos using model-driven self-supervision from video-caption pairs and structured reasoning, eliminating need for human-labeled scene graphs.", "result": "SGClip excels in scene graph generation and action localization benchmarks. ESCA consistently improves both open-source and commercial MLLMs, achieving state-of-the-art performance across two embodied environments.", "conclusion": "ESCA significantly reduces agent perception errors and enables open-source models to surpass proprietary baselines, advancing general-purpose embodied agents through structured spatial-temporal understanding."}}
{"id": "2510.15940", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15940", "abs": "https://arxiv.org/abs/2510.15940", "authors": ["Jialin Lu", "Kye Emond", "Kaiyu Yang", "Swarat Chaudhuri", "Weiran Sun", "Wuyang Chen"], "title": "Lean Finder: Semantic Search for Mathlib That Understands User Intents", "comment": null, "summary": "We present Lean Finder, a semantic search engine for Lean and mathlib that\nunderstands and aligns with the intents of mathematicians. Progress in formal\ntheorem proving is often hindered by the difficulty of locating relevant\ntheorems and the steep learning curve of the Lean 4 language, making\nadvancement slow and labor-intensive. Existing Lean search engines, though\nhelpful, rely primarily on informalizations (natural language translation of\nthe formal statements), while largely overlooking the mismatch with real-world\nuser queries. In contrast, we propose a user-centered semantic search tailored\nto the needs of mathematicians. Our approach begins by analyzing and clustering\nthe semantics of public Lean discussions, then fine-tuning text embeddings on\nsynthesized queries that emulate user intents. We further align Lean Finder\nwith mathematicians' preferences using diverse feedback signals, encoding it\nwith a rich awareness of their goals from multiple perspectives. Evaluations on\nreal-world queries, informalized statements, and proof states demonstrate that\nour Lean Finder achieves over $30\\%$ relative improvement compared to previous\nsearch engines and GPT-4o. In addition, Lean Finder is compatible with\nLLM-based theorem provers, bridging retrieval with formal reasoning. Lean\nFinder is available at: https://leanfinder.github.io", "AI": {"tldr": "Lean Finder is a semantic search engine for Lean and mathlib that understands mathematician intents, achieving 30%+ improvement over previous search methods and GPT-4o through user-centered design and alignment with mathematical preferences.", "motivation": "Progress in formal theorem proving is hindered by difficulty locating relevant theorems and Lean 4's steep learning curve, with existing search engines relying on informalizations while overlooking real-world user query mismatches.", "method": "Analyze and cluster semantics of public Lean discussions, fine-tune text embeddings on synthesized queries that emulate user intents, and align with mathematician preferences using diverse feedback signals from multiple perspectives.", "result": "Achieves over 30% relative improvement compared to previous search engines and GPT-4o on real-world queries, informalized statements, and proof states. Compatible with LLM-based theorem provers.", "conclusion": "Lean Finder successfully bridges retrieval with formal reasoning through user-centered semantic search tailored to mathematician needs, demonstrating significant performance improvements over existing approaches."}}
{"id": "2510.15948", "categories": ["cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15948", "abs": "https://arxiv.org/abs/2510.15948", "authors": ["MingSheng Li", "Guangze Zhao", "Sichen Liu"], "title": "VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search", "comment": null, "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable progress in\nmultimodal perception and generation, yet their safety alignment remains a\ncritical challenge.Existing defenses and vulnerable to multimodal jailbreaks,\nas visual inputs introduce new attack surfaces, reasoning chains lack safety\nsupervision, and alignment often degrades under modality fusion.To overcome\nthese limitation, we propose VisuoAlign, a framework for multi-modal safety\nalignment via prompt-guided tree search.VisuoAlign embeds safety constrains\ninto the reasoning process through visual-textual interactive prompts, employs\nMonte Carlo Tree Search(MCTS) to systematically construct diverse\nsafety-critical prompt trajectories, and introduces prompt-based scaling to\nensure real-time risk detection and compliant responses.Extensive experiments\ndemonstrate that VisuoAlign proactively exposes risks, enables comprehensive\ndataset generation, and significantly improves the robustness of LVLMs against\ncomplex cross-modal threats.", "AI": {"tldr": "VisuoAlign is a framework that enhances safety alignment in Large Vision-Language Models (LVLMs) against multimodal jailbreaks using prompt-guided tree search.", "motivation": "Existing defenses are vulnerable to multimodal jailbreaks due to new attack surfaces from visual inputs, lack of safety supervision in reasoning chains, and alignment degradation under modality fusion.", "method": "VisuoAlign embeds safety constraints via visual-textual interactive prompts, uses Monte Carlo Tree Search (MCTS) to construct diverse safety-critical prompt trajectories, and implements prompt-based scaling for real-time risk detection.", "result": "Extensive experiments show VisuoAlign proactively exposes risks, enables comprehensive dataset generation, and significantly improves LVLM robustness against complex cross-modal threats.", "conclusion": "VisuoAlign effectively addresses multimodal safety alignment challenges and enhances the security of vision-language models against sophisticated attacks."}}
{"id": "2510.16428", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.16428", "abs": "https://arxiv.org/abs/2510.16428", "authors": ["Alok Panigrahi", "Jayaprakash Katual", "Satish Mulleti"], "title": "Dictionary-Based Deblurring for Unpaired Data", "comment": "10 pages", "summary": "Effective image deblurring typically relies on large and fully paired\ndatasets of blurred and corresponding sharp images. However, obtaining such\naccurately aligned data in the real world poses a number of difficulties,\nlimiting the effectiveness and generalizability of existing deblurring methods.\nTo address this scarcity of data dependency, we present a novel dictionary\nlearning based deblurring approach for jointly estimating a structured blur\nmatrix and a high resolution image dictionary. This framework enables robust\nimage deblurring across different degrees of data supervision. Our method is\nthoroughly evaluated across three distinct experimental settings: (i) full\nsupervision involving paired data with explicit correspondence, (ii) partial\nsupervision employing unpaired data with implicit relationships, and (iii)\nunsupervised learning using non-correspondence data where direct pairings are\nabsent. Extensive experimental validation, performed on synthetically blurred\nsubsets of the CMU-Cornell iCoseg dataset and the real-world FocusPath dataset,\nconsistently shows that the proposed framework has superior performance\ncompared to conventional coupled dictionary learning approaches. The results\nvalidate that our approach provides an efficient and robust solution for image\ndeblurring in data-constrained scenarios by enabling accurate blur modeling and\nadaptive dictionary representation with a notably smaller number of training\nsamples.", "AI": {"tldr": "A dictionary learning approach for image deblurring that works across different supervision levels (full, partial, unsupervised) by jointly estimating structured blur matrices and image dictionaries, requiring fewer training samples.", "motivation": "Address the scarcity of accurately aligned blurred-sharp image pairs in real-world scenarios, which limits the effectiveness and generalizability of existing deblurring methods.", "method": "Dictionary learning framework that jointly estimates a structured blur matrix and high-resolution image dictionary, enabling robust deblurring across full supervision, partial supervision, and unsupervised settings.", "result": "Superior performance compared to conventional coupled dictionary learning approaches on synthetic CMU-Cornell iCoseg dataset and real-world FocusPath dataset, with efficient blur modeling and adaptive dictionary representation using fewer training samples.", "conclusion": "The approach provides an efficient and robust solution for image deblurring in data-constrained scenarios, enabling accurate blur modeling and adaptive dictionary representation with notably smaller training requirements."}}
{"id": "2510.16432", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16432", "abs": "https://arxiv.org/abs/2510.16432", "authors": ["Zahra Mobini", "Ahmet Hasim Gokceoglu", "Li Wang", "Gunnar Peters", "Hyundong Shin", "Hien Quoc Ngo"], "title": "Cluster-wise processing in fronthaul-aware cell-free massive MIMO systems", "comment": null, "summary": "We exploit a general cluster-based network architecture for a\nfronthaul-limited user-centric cell-free massive multiple-input multiple-output\n(CF-mMIMO) system under different degrees of cooperation among the access\npoints (APs) to achieve scalable implementation. In particular, we consider a\nCF-mMIMO system wherein the available APs are grouped into multiple processing\nclusters (PCs) to share channel state information (CSI), ensuring that they\nhave knowledge of the CSI for all users assigned to the given cluster for the\npurposes of designing resource allocation and precoding. We utilize the sum\npseudo-SE metric, which accounts for intra-cluster interference and\nintercluster-leakage, providing a close approximation to the true sum\nachievable SE. For a given PC, we formulate two optimization problems to\nmaximize the cluster-wise weighted sum pseudo-SE under fronthaul constraints,\nrelying solely on local CSI. These optimization problems are associated with\ndifferent computational complexity requirements. The first optimization problem\njointly designs precoding, user association, and power allocation, and is\nperformed at the small-scale fading time scale. The second optimization problem\noptimizes user association and power allocation at the large-scale fading time\nscale. Accordingly, we develop a novel application of modified weighted minimum\nmean square error (WMMSE)-based approach to solve the challenging formulated\nnon-convex mixed-integer problems.", "AI": {"tldr": "A scalable cluster-based architecture for cell-free massive MIMO systems with fronthaul constraints, using two optimization approaches at different time scales to maximize weighted sum pseudo-spectral efficiency.", "motivation": "To achieve scalable implementation of user-centric cell-free massive MIMO systems under fronthaul limitations by grouping access points into processing clusters with different cooperation levels.", "method": "Group APs into processing clusters sharing CSI, formulate two optimization problems for maximizing weighted sum pseudo-SE under fronthaul constraints using modified WMMSE approach: joint precoding/user association/power allocation at small-scale fading time scale, and user association/power allocation at large-scale fading time scale.", "result": "Proposed cluster-based architecture enables scalable implementation while accounting for intra-cluster interference and inter-cluster leakage through sum pseudo-SE metric.", "conclusion": "The approach provides a practical solution for fronthaul-limited cell-free massive MIMO systems with different computational complexity requirements through cluster-based processing and multi-time-scale optimization."}}
{"id": "2510.15991", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.15991", "abs": "https://arxiv.org/abs/2510.15991", "authors": ["Huiming Yang"], "title": "CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection", "comment": "13 pages", "summary": "The sparse cross-modality detector offers more advantages than its\ncounterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of\nadaptability for downstream tasks and computational cost savings. However,\nexisting sparse detectors overlook the quality of token representation, leaving\nit with a sub-optimal foreground quality and limited performance. In this\npaper, we identify that the geometric structure preserved and the class\ndistribution are the key to improving the performance of the sparse detector,\nand propose a Sparse Selector (SS). The core module of SS is Ray-Aware\nSupervision (RAS), which preserves rich geometric information during the\ntraining stage, and Class-Balanced Supervision, which adaptively reweights the\nsalience of class semantics, ensuring that tokens associated with small objects\nare retained during token sampling. Thereby, outperforming other sparse\nmulti-modal detectors in the representation of tokens. Additionally, we design\nRay Positional Encoding (Ray PE) to address the distribution differences\nbetween the LiDAR modality and the image. Finally, we integrate the\naforementioned module into an end-to-end sparse multi-modality detector, dubbed\nCrossRay3D. Experiments show that, on the challenging nuScenes benchmark,\nCrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS,\nwhile running 1.84 faster than other leading methods. Moreover, CrossRay3D\ndemonstrates strong robustness even in scenarios where LiDAR or camera data are\npartially or entirely missing.", "AI": {"tldr": "CrossRay3D is a sparse multi-modal 3D detector that improves token representation quality through Ray-Aware Supervision and Class-Balanced Supervision, achieving state-of-the-art performance on nuScenes benchmark.", "motivation": "Existing sparse detectors overlook token representation quality, resulting in sub-optimal foreground quality and limited performance. The paper identifies geometric structure preservation and class distribution as key factors for improving sparse detector performance.", "method": "Proposes Sparse Selector (SS) with Ray-Aware Supervision to preserve geometric information, Class-Balanced Supervision to adaptively reweight class semantics, and Ray Positional Encoding to address LiDAR-image modality distribution differences. Integrated into an end-to-end detector called CrossRay3D.", "result": "Achieves state-of-the-art performance on nuScenes benchmark with 72.4 mAP and 74.7 NDS, running 1.84\u00d7 faster than other leading methods. Demonstrates strong robustness even with partial or complete missing LiDAR/camera data.", "conclusion": "CrossRay3D successfully addresses token representation quality issues in sparse detectors through geometric preservation and class balancing, achieving superior performance and efficiency while maintaining robustness to missing sensor data."}}
{"id": "2510.15944", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15944", "abs": "https://arxiv.org/abs/2510.15944", "authors": ["Tianyu Bell Pan", "Mengdi Zhu", "Alexa Jordyn Cole", "Ronald Wilson", "Damon L. Woodard"], "title": "Lyapunov-Stable Adaptive Control for Multimodal Concept Drift", "comment": null, "summary": "Multimodal learning systems often struggle in non-stationary environments due\nto concept drift, where changing data distributions can degrade performance.\nModality-specific drifts and the lack of mechanisms for continuous, stable\nadaptation compound this challenge. This paper introduces LS-OGD, a novel\nadaptive control framework for robust multimodal learning in the presence of\nconcept drift. LS-OGD uses an online controller that dynamically adjusts the\nmodel's learning rate and the fusion weights between different data modalities\nin response to detected drift and evolving prediction errors. We prove that\nunder bounded drift conditions, the LS-OGD system's prediction error is\nuniformly ultimately bounded and converges to zero if the drift ceases.\nAdditionally, we demonstrate that the adaptive fusion strategy effectively\nisolates and mitigates the impact of severe modality-specific drift, thereby\nensuring system resilience and fault tolerance. These theoretical guarantees\nestablish a principled foundation for developing reliable and continuously\nadapting multimodal learning systems.", "AI": {"tldr": "LS-OGD is an adaptive control framework for robust multimodal learning that dynamically adjusts learning rates and fusion weights to handle concept drift, with proven theoretical guarantees for error bounds and system resilience.", "motivation": "Multimodal learning systems struggle with concept drift in non-stationary environments, particularly modality-specific drifts and lack of continuous adaptation mechanisms.", "method": "LS-OGD uses an online controller that dynamically adjusts learning rates and fusion weights between modalities based on detected drift and prediction errors.", "result": "The system achieves uniformly ultimately bounded prediction error under bounded drift conditions, converges to zero if drift ceases, and effectively isolates/mitigates modality-specific drift impacts.", "conclusion": "LS-OGD provides a principled foundation for developing reliable, continuously adapting multimodal learning systems with proven theoretical guarantees for resilience and fault tolerance."}}
{"id": "2510.15952", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15952", "abs": "https://arxiv.org/abs/2510.15952", "authors": ["Myung Ho Kim"], "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding", "comment": "27 pages", "summary": "Large language models exhibit intelligence without genuine epistemic\nunderstanding, exposing a key gap: the absence of epistemic architecture. This\npaper introduces the Structured Cognitive Loop (SCL) as an executable\nepistemological framework for emergent intelligence. Unlike traditional AI\nresearch asking \"what is intelligence?\" (ontological), SCL asks \"under what\nconditions does cognition emerge?\" (epistemological). Grounded in philosophy of\nmind and cognitive phenomenology, SCL bridges conceptual philosophy and\nimplementable cognition. Drawing on process philosophy, enactive cognition, and\nextended mind theory, we define intelligence not as a property but as a\nperformed process -- a continuous loop of judgment, memory, control, action,\nand regulation. SCL makes three contributions. First, it operationalizes\nphilosophical insights into computationally interpretable structures, enabling\n\"executable epistemology\" -- philosophy as structural experiment. Second, it\nshows that functional separation within cognitive architecture yields more\ncoherent and interpretable behavior than monolithic prompt based systems,\nsupported by agent evaluations. Third, it redefines intelligence: not\nrepresentational accuracy but the capacity to reconstruct its own epistemic\nstate through intentional understanding. This framework impacts philosophy of\nmind, epistemology, and AI. For philosophy, it allows theories of cognition to\nbe enacted and tested. For AI, it grounds behavior in epistemic structure\nrather than statistical regularity. For epistemology, it frames knowledge not\nas truth possession but as continuous reconstruction within a\nphenomenologically coherent loop. We situate SCL within debates on cognitive\nphenomenology, emergence, normativity, and intentionality, arguing that real\nprogress requires not larger models but architectures that realize cognitive\nprinciples structurally.", "AI": {"tldr": "The paper introduces Structured Cognitive Loop (SCL) - an executable epistemological framework that bridges philosophy and AI by defining intelligence as a continuous process of judgment, memory, control, action, and regulation rather than a static property.", "motivation": "Large language models lack genuine epistemic understanding despite exhibiting intelligence, revealing a gap in epistemic architecture. The paper aims to address this by creating an executable framework that operationalizes philosophical insights into computational structures.", "method": "SCL draws on process philosophy, enactive cognition, and extended mind theory to define intelligence as a performed process. It creates functional separation within cognitive architecture and enables 'executable epistemology' - philosophy as structural experiment.", "result": "SCL demonstrates that functional separation yields more coherent and interpretable behavior than monolithic prompt-based systems, supported by agent evaluations. It enables reconstruction of epistemic states through intentional understanding.", "conclusion": "Real progress requires architectures that structurally realize cognitive principles rather than larger models. SCL impacts philosophy by enabling theory testing, AI by grounding behavior in epistemic structure, and epistemology by framing knowledge as continuous reconstruction."}}
{"id": "2510.17037", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.17037", "abs": "https://arxiv.org/abs/2510.17037", "authors": ["Chongyuan Bi", "Jie Liang"], "title": "A Low-Complexity View Synthesis Distortion Estimation Method for 3D Video with Large Baseline Considerations", "comment": null, "summary": "Depth-image-based rendering is a key view synthesis algorithm in 3D video\nsystems, which enables the synthesis of virtual views from texture images and\ndepth maps. An efficient view synthesis distortion estimation model is critical\nfor optimizing resource allocation in real-time applications such as\ninteractive free-viewpoint video and 3D video streaming services. However,\nexisting estimation methods are often computationally intensive, require\nparameter training, or performance poorly in challenging large baseline\nconfigurations. This paper presents a novel, low-complexity, and training-free\nmethod to accurately estimate the distortion of synthesized views without\nperforming the actual rendering process. Key contributions include: (1) A joint\ntexture-depth classification method that accurately separates texture image\ninto locally stationary and non-stationary regions, which mitigates\nmisclassifications by using texture-only methods. (2) A novel baseline distance\nindicator is designed for the compensation scheme for distortions caused by\nlarge baseline configurations. (3) A region-based blending estimation strategy\nthat geometrically identifies overlapping, single-view, and mutual disocclusion\nregions, predicting distortion in synthesized views from two reference views\nwith differing synthesis conditions. Experiments on standard MPEG 3D video\nsequences validate the proposed method's high accuracy and efficiency,\nespecially in large baseline configurations. This method enables more flexible\ncamera arrangements in 3D content acquisition by accurately predicting\nsynthesis quality under challenging geometric configurations.", "AI": {"tldr": "A novel low-complexity, training-free method for estimating view synthesis distortion without actual rendering, featuring joint texture-depth classification, baseline distance compensation, and region-based blending estimation.", "motivation": "Existing view synthesis distortion estimation methods are computationally intensive, require parameter training, or perform poorly in large baseline configurations, limiting real-time applications like interactive free-viewpoint video.", "method": "Joint texture-depth classification to separate stationary/non-stationary regions, baseline distance indicator for large baseline compensation, and region-based blending estimation that identifies overlapping, single-view, and mutual disocclusion regions.", "result": "Experiments on MPEG 3D video sequences show high accuracy and efficiency, especially in large baseline configurations, enabling more flexible camera arrangements.", "conclusion": "The proposed method provides accurate synthesis quality prediction under challenging geometric configurations without the computational burden of actual rendering."}}
{"id": "2510.16539", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16539", "abs": "https://arxiv.org/abs/2510.16539", "authors": ["Zhaowei Guan", "Wenkun Wen", "Peiran Wu", "Chen Wang", "Minghua Xia"], "title": "Hybrid CNN-Transformer Based Sparse Channel Prediction for High-Mobility OTFS Systems", "comment": "5 pages, 9 figures. To appear in IEEE Wireless Communications Letters", "summary": "High-mobility scenarios in next-generation wireless networks, such as those\ninvolving vehicular communications, require ultra-reliable and low-latency\ncommunications (URLLC). However, rapidly time-varying channels pose significant\nchallenges to traditional OFDM-based systems due to the Doppler effect and\nchannel aging. Orthogonal time frequency space (OTFS) modulation offers\nresilience by representing channels in the quasi-static delay-Doppler (DD)\ndomain. This letter proposes a novel channel prediction framework for OTFS\nsystems using a hybrid convolutional neural network and transformer\n(CNN-Transformer) architecture. The CNN extracts compact features that exploit\nthe DD-domain sparsity of the channel matrices, while the transformer models\ntemporal dependencies with causal masking for consistency. Simulation\nexperiments under extreme $500$ \\si{km/h} mobility conditions demonstrate that\nthe proposed method outperforms state-of-the-art baselines, reducing the root\nmean square error and mean absolute error by $12.2\\%$ and $9.4\\%$,\nrespectively. These results demonstrate the effectiveness of DD-domain\nrepresentations and the proposed model in accurately predicting channels in\nhigh-mobility scenarios, thereby supporting the stringent URLLC requirements in\nfuture wireless systems.", "AI": {"tldr": "A hybrid CNN-Transformer model for OTFS channel prediction in high-mobility scenarios achieves 12.2% RMSE and 9.4% MAE improvements over state-of-the-art methods.", "motivation": "High-mobility scenarios in next-generation wireless networks require URLLC, but traditional OFDM systems struggle with Doppler effects and channel aging. OTFS modulation offers resilience through DD-domain representation.", "method": "Proposes a hybrid CNN-Transformer architecture where CNN extracts compact features exploiting DD-domain sparsity, and transformer models temporal dependencies with causal masking.", "result": "Simulations at 500 km/h show the method outperforms state-of-the-art baselines, reducing RMSE by 12.2% and MAE by 9.4%.", "conclusion": "The proposed approach effectively predicts channels in high-mobility scenarios using DD-domain representations, supporting URLLC requirements in future wireless systems."}}
{"id": "2510.16017", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16017", "abs": "https://arxiv.org/abs/2510.16017", "authors": ["Ibrahim Sheikh Mohamed", "Abdullah Yahya Abdullah Omaisan"], "title": "InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects", "comment": null, "summary": "Infrastructure in smart cities is increasingly monitored by networks of\nclosed circuit television (CCTV) cameras. Roads, bridges and tunnels develop\ncracks, potholes, and fluid leaks that threaten public safety and require\ntimely repair. Manual inspection is costly and hazardous, and existing\nautomatic systems typically address individual defect types or provide\nunstructured outputs that cannot directly guide maintenance crews. This paper\nproposes a comprehensive pipeline that leverages street CCTV streams for multi\ndefect detection and segmentation using the YOLO family of object detectors and\npasses the detections to a vision language model (VLM) for scene aware\nsummarization. The VLM generates a structured action plan in JSON format that\nincludes incident descriptions, recommended tools, dimensions, repair plans,\nand urgent alerts. We review literature on pothole, crack and leak detection,\nhighlight recent advances in large vision language models such as QwenVL and\nLLaVA, and describe the design of our early prototype. Experimental evaluation\non public datasets and captured CCTV clips demonstrates that the system\naccurately identifies diverse defects and produces coherent summaries. We\nconclude by discussing challenges and directions for scaling the system to city\nwide deployments.", "AI": {"tldr": "A pipeline using CCTV streams with YOLO detectors and vision language models for multi-defect detection and structured repair planning in smart cities.", "motivation": "Manual infrastructure inspection is costly and hazardous, while existing automatic systems lack comprehensive defect coverage and structured outputs for maintenance crews.", "method": "Leverages CCTV streams with YOLO detectors for multi-defect detection and segmentation, then uses vision language models for scene-aware summarization into structured JSON action plans.", "result": "Experimental evaluation shows accurate identification of diverse defects and coherent summary generation on public datasets and CCTV clips.", "conclusion": "The system demonstrates promising results but faces challenges in scaling to city-wide deployments, requiring further development."}}
{"id": "2510.15945", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15945", "abs": "https://arxiv.org/abs/2510.15945", "authors": ["Guangya Wan", "Zixin Stephen Xu", "Sasa Zorc", "Manel Baucells", "Mengxuan Hu", "Hao Wang", "Sheng Li"], "title": "BEACON: Bayesian Optimal Stopping for Efficient LLM Sampling", "comment": "Under review on ARR", "summary": "Sampling multiple responses is a common way to improve LLM output quality,\nbut it comes at the cost of additional computation. The key challenge is\ndeciding when to stop generating new samples to balance accuracy gains against\nefficiency. To address this, we introduce BEACON (Bayesian Efficient Adaptive\nCriterion for Optimal N-stopping), a principled adaptive sampling framework\ngrounded in Sequential Search with Bayesian Learning. BEACON sequentially\ngenerates responses from the policy LLM, updates posterior belief over reward\ndistributions in real time without further training, and determines when to\nstop by weighing expected gains against computational cost. Sampling terminates\nonce the marginal utility of further exploration no longer justifies the\nexpense. We establish both theoretical optimality guarantees and practical\ntractability, and show empirically that BEACON reduces average sampling by up\nto 80% while maintaining response quality. We further demonstrate BEACON's\nutility for cost-efficient preference data generation and outline practical\nextensions, offering actionable insights for future researchers.", "AI": {"tldr": "BEACON is an adaptive sampling framework that uses Bayesian learning to determine when to stop generating LLM responses, reducing sampling by up to 80% while maintaining quality.", "motivation": "Sampling multiple responses improves LLM output quality but increases computational cost, creating a need for efficient stopping criteria.", "method": "Sequentially generates responses, updates posterior belief over reward distributions in real-time using Bayesian learning, and stops when marginal utility no longer justifies computational cost.", "result": "Empirically reduces average sampling by up to 80% while maintaining response quality, with theoretical optimality guarantees.", "conclusion": "BEACON provides a principled framework for cost-efficient LLM sampling and has utility for preference data generation, offering practical extensions for future research."}}
{"id": "2510.15959", "categories": ["cs.AI", "cs.CY", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.15959", "abs": "https://arxiv.org/abs/2510.15959", "authors": ["Isabelle Hupont", "Marisa Ponti", "Sven Schade"], "title": "Exploring the Potential of Citiverses for Regulatory Learning", "comment": "26 pages", "summary": "Citiverses hold the potential to support regulatory learning by offering\nimmersive, virtual environments for experimenting with policy scenarios and\ntechnologies. This paper proposes a science-for-policy agenda to explore the\npotential of citiverses as experimentation spaces for regulatory learning,\ngrounded in a consultation with a high-level panel of experts, including\npolicymakers from the European Commission, national government science advisers\nand leading researchers in digital regulation and virtual worlds. It identifies\nkey research areas, including scalability, real-time feedback, complexity\nmodelling, cross-border collaboration, risk reduction, citizen participation,\nethical considerations and the integration of emerging technologies. In\naddition, the paper analyses a set of experimental topics, spanning\ntransportation, urban planning and the environment/climate crisis, that could\nbe tested in citiverse platforms to advance regulatory learning in these areas.\nThe proposed work is designed to inform future research for policy and\nemphasizes a responsible approach to developing and using citiverses. It\nprioritizes careful consideration of the ethical, economic, ecological and\nsocial dimensions of different regulations. The paper also explores essential\npreliminary steps necessary for integrating citiverses into the broader\necosystems of experimentation spaces, including test beds, living labs and\nregulatory sandboxes", "AI": {"tldr": "This paper proposes using citiverses (virtual worlds) as experimental spaces for regulatory learning, identifying key research areas and experimental topics through expert consultation.", "motivation": "To explore the potential of citiverses as immersive environments for testing policy scenarios and technologies, supporting regulatory learning in areas like transportation, urban planning, and climate crisis.", "method": "Consultation with high-level panel of experts including European Commission policymakers, national government science advisers, and leading researchers in digital regulation and virtual worlds.", "result": "Identified key research areas including scalability, real-time feedback, complexity modelling, cross-border collaboration, risk reduction, citizen participation, ethical considerations, and emerging technology integration.", "conclusion": "Citiverses can advance regulatory learning when developed responsibly with careful consideration of ethical, economic, ecological and social dimensions, and integrated with existing experimentation ecosystems like test beds and regulatory sandboxes."}}
{"id": "2510.17427", "categories": ["eess.IV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.17427", "abs": "https://arxiv.org/abs/2510.17427", "authors": ["Julien Zouein", "Vibhoothi Vibhoothi", "Anil Kokaram"], "title": "AV1 Motion Vector Fidelity and Application for Efficient Optical Flow", "comment": "Accepted PCS 2025, camera-ready version", "summary": "This paper presents a comprehensive analysis of motion vectors extracted from\nAV1-encoded video streams and their application in accelerating optical flow\nestimation. We demonstrate that motion vectors from AV1 video codec can serve\nas a high-quality and computationally efficient substitute for traditional\noptical flow, a critical but often resource-intensive component in many\ncomputer vision pipelines. Our primary contributions are twofold. First, we\nprovide a detailed comparison of motion vectors from both AV1 and HEVC against\nground-truth optical flow, establishing their fidelity. In particular we show\nthe impact of encoder settings on motion estimation fidelity and make\nrecommendations about the optimal settings. Second, we show that using these\nextracted AV1 motion vectors as a \"warm-start\" for a state-of-the-art deep\nlearning-based optical flow method, RAFT, significantly reduces the time to\nconvergence while achieving comparable accuracy. Specifically, we observe a\nfour-fold speedup in computation time with only a minor trade- off in end-point\nerror. These findings underscore the potential of reusing motion vectors from\ncompressed video as a practical and efficient method for a wide range of\nmotion-aware computer vision applications.", "AI": {"tldr": "AV1 motion vectors can replace traditional optical flow with high quality and efficiency, and when used as warm-start for RAFT, they provide 4x speedup with minimal accuracy loss.", "motivation": "Traditional optical flow estimation is resource-intensive, while motion vectors from compressed video codecs like AV1 offer a potentially efficient alternative for computer vision applications.", "method": "Compared motion vectors from AV1 and HEVC against ground-truth optical flow, analyzed impact of encoder settings, and used AV1 motion vectors as warm-start for RAFT deep learning model.", "result": "AV1 motion vectors show high fidelity to ground-truth optical flow. Using them as warm-start for RAFT achieves 4x speedup in computation time with only minor increase in end-point error.", "conclusion": "Motion vectors from compressed video (especially AV1) can be practically reused as efficient motion estimation for various computer vision applications, reducing computational burden significantly."}}
{"id": "2510.16576", "categories": ["cs.IT", "cs.IR", "cs.SY", "eess.SP", "eess.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16576", "abs": "https://arxiv.org/abs/2510.16576", "authors": ["Zijian Zhang", "Mingyao Cui"], "title": "Enhancing Channel Estimation in RIS-aided Systems via Observation Matrix Design", "comment": "5 pages, 2 figures", "summary": "Reconfigurable intelligent surfaces (RISs) have emerged as a promising\ntechnology for enhancing wireless communications through dense antenna arrays.\nAccurate channel estimation is critical to unlocking their full performance\npotential. To enhance RIS channel estimators, this paper proposes a novel\nobservation matrix design scheme. Bayesian optimization framework is adopted to\ngenerate observation matrices that maximize the mutual information between\nreceived pilot signals and RIS channels. To solve the formulated problem\nefficiently, we develop an alternating Riemannian manifold optimization (ARMO)\nalgorithm to alternately update the receiver combiners and RIS phase-shift\nmatrices. An adaptive kernel training strategy is further introduced to\niteratively refine the channel covariance matrix without requiring additional\npilot resources. Simulation results demonstrate that the proposed ARMO-enhanced\nestimator achieves substantial gains in estimation accuracy over\nstate-of-the-art methods.", "AI": {"tldr": "Proposes a novel observation matrix design scheme using Bayesian optimization to enhance RIS channel estimation by maximizing mutual information between pilot signals and channels.", "motivation": "Accurate channel estimation is critical for reconfigurable intelligent surfaces (RISs) to unlock their full performance potential in wireless communications, but existing methods need improvement.", "method": "Uses Bayesian optimization framework with alternating Riemannian manifold optimization (ARMO) algorithm to update receiver combiners and RIS phase-shift matrices, plus adaptive kernel training for channel covariance refinement.", "result": "Simulation results show the proposed ARMO-enhanced estimator achieves substantial gains in estimation accuracy over state-of-the-art methods.", "conclusion": "The proposed observation matrix design scheme with ARMO algorithm and adaptive kernel training significantly improves RIS channel estimation performance."}}
{"id": "2510.16036", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16036", "abs": "https://arxiv.org/abs/2510.16036", "authors": ["Zewen Li", "Zitong Yu", "Qilang Ye", "Weicheng Xie", "Wei Zhuo", "Linlin Shen"], "title": "IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection", "comment": "Accepted by IEEE Transactions on Instrumentation and Measurement\n  (TIM)", "summary": "The robust causal capability of Multimodal Large Language Models (MLLMs) hold\nthe potential of detecting defective objects in Industrial Anomaly Detection\n(IAD). However, most traditional IAD methods lack the ability to provide\nmulti-turn human-machine dialogues and detailed descriptions, such as the color\nof objects, the shape of an anomaly, or specific types of anomalies. At the\nsame time, methods based on large pre-trained models have not fully stimulated\nthe ability of large models in anomaly detection tasks. In this paper, we\nexplore the combination of rich text semantics with both image-level and\npixel-level information from images and propose IAD-GPT, a novel paradigm based\non MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate\ndetailed anomaly prompts for specific objects. These specific prompts from the\nlarge language model (LLM) are used to activate the detection and segmentation\nfunctions of the pre-trained visual-language model (i.e., CLIP). To enhance the\nvisual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein\nimage features interact with normal and abnormal text prompts to dynamically\nselect enhancement pathways, which enables language models to focus on specific\naspects of visual data, enhancing their ability to accurately interpret and\nrespond to anomalies within images. Moreover, we design a Multi-Mask Fusion\nmodule to incorporate mask as expert knowledge, which enhances the LLM's\nperception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA\ndatasets demonstrate our state-of-the-art performance on self-supervised and\nfew-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA\ndatasets. The codes are available at\n\\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.", "AI": {"tldr": "IAD-GPT is a novel MLLM-based paradigm for Industrial Anomaly Detection that combines text semantics with image-level and pixel-level information using abnormal prompts, text-guided enhancement, and multi-mask fusion to achieve state-of-the-art performance.", "motivation": "Traditional IAD methods lack multi-turn dialogues and detailed anomaly descriptions, while existing large model approaches haven't fully activated anomaly detection capabilities in MLLMs.", "method": "Uses Abnormal Prompt Generator for detailed anomaly prompts, Text-Guided Enhancer for visual grounding, and Multi-Mask Fusion to incorporate mask knowledge for pixel-level anomaly perception.", "result": "Achieves state-of-the-art performance on MVTec-AD and VisA datasets for self-supervised and few-shot anomaly detection and segmentation tasks.", "conclusion": "IAD-GPT successfully combines MLLMs with IAD, demonstrating strong performance through text-image interaction and mask fusion techniques."}}
{"id": "2510.15946", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15946", "abs": "https://arxiv.org/abs/2510.15946", "authors": ["Wenshuo Wang", "Ziyou Jiang", "Junjie Wang", "Mingyang Li", "Jie Huang", "Yuekai Huang", "Zhiyuan Chang", "Feiyan Duan", "Qing Wang"], "title": "Learning from Mistakes: Enhancing Harmful Meme Detection via Misjudgment Risk Patterns", "comment": "12 Pages, Submitted to WWW'26", "summary": "Internet memes have emerged as a popular multimodal medium, yet they are\nincreasingly weaponized to convey harmful opinions through subtle rhetorical\ndevices like irony and metaphor. Existing detection approaches, including\nMLLM-based techniques, struggle with these implicit expressions, leading to\nfrequent misjudgments. This paper introduces PatMD, a novel approach that\nimproves harmful meme detection by learning from and proactively mitigating\nthese potential misjudgment risks. Our core idea is to move beyond superficial\ncontent-level matching and instead identify the underlying misjudgment risk\npatterns, proactively guiding the MLLMs to avoid known misjudgment pitfalls. We\nfirst construct a knowledge base where each meme is deconstructed into a\nmisjudgment risk pattern explaining why it might be misjudged, either\noverlooking harmful undertones (false negative) or overinterpreting benign\ncontent (false positive). For a given target meme, PatMD retrieves relevant\npatterns and utilizes them to dynamically guide the MLLM's reasoning.\nExperiments on a benchmark of 6,626 memes across 5 harmful detection tasks show\nthat PatMD outperforms state-of-the-art baselines, achieving an average of\n8.30\\% improvement in F1-score and 7.71\\% improvement in accuracy,\ndemonstrating strong generalizability and improved detection capability of\nharmful memes.", "AI": {"tldr": "PatMD improves harmful meme detection by proactively identifying and mitigating misjudgment risks in MLLMs, achieving significant performance gains over state-of-the-art methods.", "motivation": "Internet memes are increasingly weaponized with subtle harmful content using rhetorical devices like irony and metaphor, and existing detection approaches including MLLM-based techniques frequently misjudge these implicit expressions.", "method": "PatMD constructs a knowledge base where memes are deconstructed into misjudgment risk patterns, then retrieves relevant patterns to dynamically guide MLLM reasoning and avoid known misjudgment pitfalls.", "result": "Experiments on 6,626 memes across 5 harmful detection tasks show PatMD outperforms state-of-the-art baselines with 8.30% F1-score improvement and 7.71% accuracy improvement.", "conclusion": "PatMD demonstrates strong generalizability and improved detection capability for harmful memes by proactively addressing misjudgment risks rather than relying on superficial content matching."}}
{"id": "2510.15966", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15966", "abs": "https://arxiv.org/abs/2510.15966", "authors": ["Shian Jia", "Ziyang Huang", "Xinbo Wang", "Haofei Zhang", "Mingli Song"], "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency", "comment": null, "summary": "Memory systems are fundamental to AI agents, yet existing work often lacks\nadaptability to diverse tasks and overlooks the constructive and task-oriented\nrole of AI agent memory. Drawing from Piaget's theory of cognitive development,\nwe propose PISA, a pragmatic, psych-inspired unified memory system that\naddresses these limitations by treating memory as a constructive and adaptive\nprocess. To enable continuous learning and adaptability, PISA introduces a\ntrimodal adaptation mechanism (i.e., schema updation, schema evolution, and\nschema creation) that preserves coherent organization while supporting flexible\nmemory updates. Building on these schema-grounded structures, we further design\na hybrid memory access architecture that seamlessly integrates symbolic\nreasoning with neural retrieval, significantly improving retrieval accuracy and\nefficiency. Our empirical evaluation, conducted on the existing LOCOMO\nbenchmark and our newly proposed AggQA benchmark for data analysis tasks,\nconfirms that PISA sets a new state-of-the-art by significantly enhancing\nadaptability and long-term knowledge retention.", "AI": {"tldr": "PISA is a psych-inspired unified memory system for AI agents that treats memory as a constructive, adaptive process using trimodal adaptation mechanisms and hybrid memory access, achieving state-of-the-art performance on adaptability and knowledge retention.", "motivation": "Existing AI memory systems lack adaptability to diverse tasks and overlook the constructive, task-oriented role of memory, drawing inspiration from Piaget's cognitive development theory to address these limitations.", "method": "Proposes PISA with trimodal adaptation mechanism (schema updation, evolution, creation) for continuous learning, and hybrid memory access architecture combining symbolic reasoning with neural retrieval.", "result": "Empirical evaluation on LOCOMO benchmark and new AggQA benchmark shows PISA sets new state-of-the-art by significantly enhancing adaptability and long-term knowledge retention.", "conclusion": "PISA successfully addresses limitations of existing memory systems by treating memory as constructive and adaptive, demonstrating superior performance through its psych-inspired approach and hybrid architecture."}}
{"id": "2510.17436", "categories": ["eess.IV"], "pdf": "https://arxiv.org/pdf/2510.17436", "abs": "https://arxiv.org/abs/2510.17436", "authors": ["Vladyslav Zalevskyi", "Dondu-Busra Bulut", "Thomas Sanchez", "Meritxell Bach Cuadra"], "title": "Segmenting infant brains across magnetic fields: Domain randomization and annotation curation in ultra-low field MRI", "comment": "1st place (hippocampus) and 3rd place (basal ganglia) in the Low\n  field pediatric brain magnetic resonance Image Segmentation and quality\n  Assurance Challenge (LISA) 2025", "summary": "Early identification of neurodevelopmental disorders relies on accurate\nsegmentation of brain structures in infancy, a task complicated by rapid brain\ngrowth, poor tissue contrast, and motion artifacts in pediatric MRI. These\nchallenges are further exacerbated in ultra-low-field (ULF, 0.064~T) MRI,\nwhich, despite its lower image quality, offers an affordable, portable, and\nsedation-free alternative for use in low-resource settings. In this work, we\npropose a domain randomization (DR) framework to bridge the domain gap between\nhigh-field (HF) and ULF MRI in the context of the hippocampi and basal ganglia\nsegmentation in the LISA challenge. We show that pre-training on whole-brain HF\nsegmentations using DR significantly improves generalization to ULF data, and\nthat careful curation of training labels, by removing misregistered HF-to-ULF\nannotations from training, further boosts performance. By fusing the\npredictions of several models through majority voting, we are able to achieve\ncompetitive performance. Our results demonstrate that combining robust\naugmentation with annotation quality control can enable accurate segmentation\nin ULF data. Our code is available at\nhttps://github.com/Medical-Image-Analysis-Laboratory/lisasegm", "AI": {"tldr": "A domain randomization framework improves segmentation of brain structures in ultra-low-field MRI by bridging the domain gap with high-field MRI through robust augmentation and annotation quality control.", "motivation": "Early identification of neurodevelopmental disorders requires accurate brain structure segmentation in infants, which is challenging in ultra-low-field MRI due to poor image quality, rapid brain growth, and motion artifacts, despite its affordability and portability advantages.", "method": "Proposed a domain randomization framework to bridge the domain gap between high-field and ultra-low-field MRI, using pre-training on whole-brain HF segmentations with DR, careful curation of training labels by removing misregistered annotations, and model fusion through majority voting.", "result": "The approach achieved competitive performance in hippocampi and basal ganglia segmentation for the LISA challenge, demonstrating significant improvement in generalization to ULF data.", "conclusion": "Combining robust augmentation with annotation quality control enables accurate segmentation in ultra-low-field MRI data, making it viable for neurodevelopmental disorder screening in low-resource settings."}}
{"id": "2510.16620", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16620", "abs": "https://arxiv.org/abs/2510.16620", "authors": ["Yingyao Zhou", "Natasha Devroye", "Onur G\u00fcnl\u00fc"], "title": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "comment": "submitted to IEEE COMMUNICATIONS LETTERS", "summary": "We consider reversely-degraded wiretap channels, for which the secrecy\ncapacity is zero if there is no channel feedback. This work focuses on a seeded\nmodular code design for the Gaussian wiretap channel with channel output\nfeedback, combining universal hash functions for security and learned\nfeedback-based codes for reliability to achieve positive secrecy rates. We\nstudy the trade-off between communication reliability and information leakage,\nillustrating that feedback enables agreeing on a secret key shared between\nlegitimate parties, overcoming the security advantage of the wiretapper. Our\nfindings also motivate code designs for sensing-assisted secure communication,\nto be used in next-generation integrated sensing and communication methods.", "AI": {"tldr": "A seeded modular code design for Gaussian wiretap channels with feedback achieves positive secrecy rates by combining universal hash functions for security and learned feedback-based codes for reliability, overcoming the zero secrecy capacity limitation of reversely-degraded channels without feedback.", "motivation": "To overcome the zero secrecy capacity limitation in reversely-degraded wiretap channels where no secure communication is possible without feedback, by leveraging channel output feedback to enable secret key agreement between legitimate parties.", "method": "Proposes a seeded modular code design combining universal hash functions for security and learned feedback-based codes for reliability in Gaussian wiretap channels with channel output feedback.", "result": "Achieves positive secrecy rates by enabling legitimate parties to agree on a secret key through feedback, overcoming the wiretapper's security advantage. Demonstrates the trade-off between communication reliability and information leakage.", "conclusion": "Feedback enables secure communication in reversely-degraded wiretap channels and motivates code designs for sensing-assisted secure communication in next-generation integrated sensing and communication systems."}}
{"id": "2510.16070", "categories": ["cs.CV", "cs.AI", "cs.HC", "eess.IV", "H.5.5; H.1.2; I.4.0"], "pdf": "https://arxiv.org/pdf/2510.16070", "abs": "https://arxiv.org/abs/2510.16070", "authors": ["Mahta Khoobi", "Marc Sebastian von der Stueck", "Felix Barajas Ordonez", "Anca-Maria Iancu", "Eric Corban", "Julia Nowak", "Aleksandar Kargaliev", "Valeria Perelygina", "Anna-Sophie Schott", "Daniel Pinto dos Santos", "Christiane Kuhl", "Daniel Truhn", "Sven Nebelung", "Robert Siepmann"], "title": "Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography", "comment": "Preprint version - Under second revision at Radiology (manuscript\n  RAD-25-1348)", "summary": "Structured reporting (SR) and artificial intelligence (AI) may transform how\nradiologists interact with imaging studies. This prospective study (July to\nDecember 2024) evaluated the impact of three reporting modes: free-text (FT),\nstructured reporting (SR), and AI-assisted structured reporting (AI-SR), on\nimage analysis behavior, diagnostic accuracy, efficiency, and user experience.\nFour novice and four non-novice readers (radiologists and medical students)\neach analyzed 35 bedside chest radiographs per session using a customized\nviewer and an eye-tracking system. Outcomes included diagnostic accuracy\n(compared with expert consensus using Cohen's $\\kappa$), reporting time per\nradiograph, eye-tracking metrics, and questionnaire-based user experience.\nStatistical analysis used generalized linear mixed models with Bonferroni\npost-hoc tests with a significance level of ($P \\le .01$). Diagnostic accuracy\nwas similar in FT ($\\kappa = 0.58$) and SR ($\\kappa = 0.60$) but higher in\nAI-SR ($\\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \\pm 38$\ns (FT) to $37 \\pm 18$ s (SR) and $25 \\pm 9$ s (AI-SR) ($P < .001$). Saccade\ncounts for the radiograph field ($205 \\pm 135$ (FT), $123 \\pm 88$ (SR), $97 \\pm\n58$ (AI-SR)) and total fixation duration for the report field ($11 \\pm 5$ s\n(FT), $5 \\pm 3$ s (SR), $4 \\pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P <\n.001$ each). Novice readers shifted gaze towards the radiograph in SR, while\nnon-novice readers maintained their focus on the radiograph. AI-SR was the\npreferred mode. In conclusion, SR improves efficiency by guiding visual\nattention toward the image, and AI-prefilled SR further enhances diagnostic\naccuracy and user satisfaction.", "AI": {"tldr": "AI-assisted structured reporting (AI-SR) improves diagnostic accuracy and efficiency compared to free-text and structured reporting alone, while guiding visual attention toward images.", "motivation": "To evaluate how structured reporting and AI assistance impact radiologists' image analysis behavior, diagnostic accuracy, efficiency, and user experience.", "method": "Prospective study with 8 readers (4 novice, 4 non-novice) analyzing 35 chest radiographs each using three reporting modes: free-text (FT), structured reporting (SR), and AI-assisted structured reporting (AI-SR), with eye-tracking and performance metrics.", "result": "AI-SR achieved highest diagnostic accuracy (\u03ba=0.71 vs 0.58-0.60), fastest reporting times (25\u00b19s vs 37\u00b118s SR, 88\u00b138s FT), and reduced visual attention shifts. SR and AI-SR guided attention toward radiographs.", "conclusion": "Structured reporting improves efficiency by directing visual attention to images, and AI-prefilled structured reporting further enhances diagnostic accuracy and user satisfaction."}}
{"id": "2510.15947", "categories": ["cs.LG", "cs.AI", "eess.SP", "q-bio.NC", "68T07, 92C55, 62M10", "I.2.6; I.5.1; J.3"], "pdf": "https://arxiv.org/pdf/2510.15947", "abs": "https://arxiv.org/abs/2510.15947", "authors": ["Casper van Laar", "Khubaib Ahmed"], "title": "WaveNet's Precision in EEG Classification", "comment": "6 pages, 5 figures and 3 tables. Includes main text and bibliography", "summary": "This study introduces a WaveNet-based deep learning model designed to\nautomate the classification of EEG signals into physiological, pathological,\nartifact, and noise categories. Traditional methods for EEG signal\nclassification, which rely on expert visual review, are becoming increasingly\nimpractical due to the growing complexity and volume of EEG recordings.\nLeveraging a publicly available annotated dataset from Mayo Clinic and St.\nAnne's University Hospital, the WaveNet model was trained, validated, and\ntested on 209,232 samples with a 70/20/10 percent split. The model achieved a\nclassification accuracy exceeding previous CNN and LSTM-based approaches, and\nwas benchmarked against a Temporal Convolutional Network (TCN) baseline.\nNotably, the model distinguishes noise and artifacts with high precision,\nalthough it reveals a modest but explainable degree of misclassification\nbetween physiological and pathological signals, reflecting inherent clinical\noverlap. WaveNet's architecture, originally developed for raw audio synthesis,\nis well suited for EEG data due to its use of dilated causal convolutions and\nresidual connections, enabling it to capture both fine-grained and long-range\ntemporal dependencies. The research also details the preprocessing pipeline,\nincluding dynamic dataset partitioning and normalization steps that support\nmodel generalization.", "AI": {"tldr": "WaveNet-based deep learning model achieves high accuracy in classifying EEG signals into physiological, pathological, artifact, and noise categories, outperforming CNN and LSTM approaches.", "motivation": "Traditional EEG classification methods relying on expert visual review are impractical due to growing complexity and volume of EEG recordings.", "method": "Used WaveNet architecture with dilated causal convolutions and residual connections on 209,232 EEG samples from Mayo Clinic and St. Anne's University Hospital, with 70/20/10 train/validation/test split.", "result": "Model achieved classification accuracy exceeding previous CNN and LSTM approaches, with high precision in distinguishing noise and artifacts, though some misclassification between physiological and pathological signals due to clinical overlap.", "conclusion": "WaveNet's architecture is well-suited for EEG data analysis due to its ability to capture both fine-grained and long-range temporal dependencies in signals."}}
{"id": "2510.15974", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15974", "abs": "https://arxiv.org/abs/2510.15974", "authors": ["Chris Su", "Harrison Li", "Matheus Marques", "George Flint", "Kevin Zhu", "Sunishchal Dev"], "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games", "comment": null, "summary": "Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in\nperformance on solving puzzles beyond certain perplexity thresholds. In\nsubsequent discourse, questions have arisen as to whether the nature of the\ntask muddles an evaluation of true reasoning. One potential confound is the\nrequirement that the model keep track of the state space on its own. We provide\na large language model (LLM) with an environment interface for Tower of Hanoi\nproblems, allowing it to make a move with a tool call, provide written\njustification, observe the resulting state space, and reprompt itself for the\nnext move. We observe that access to an environment interface does not delay or\neradicate performance collapse. Furthermore, LLM-parameterized policy analysis\nreveals increasing divergence from both optimal policies and uniformly random\npolicies, suggesting that the model exhibits mode-like collapse at each level\nof complexity, and that performance is dependent upon whether the mode reflects\nthe correct solution for the problem. We suggest that a similar phenomena might\ntake place in LRMs.", "AI": {"tldr": "LLMs with environment interfaces still show performance collapse on Tower of Hanoi puzzles, suggesting the issue is not just state tracking but fundamental reasoning limitations.", "motivation": "To investigate whether performance collapse in Large Reasoning Models is due to state tracking requirements or true reasoning failures.", "method": "Provided LLMs with an environment interface for Tower of Hanoi problems, allowing tool calls for moves, written justifications, state observation, and self-reprompting.", "result": "Environment access didn't prevent performance collapse. Policy analysis showed increasing divergence from optimal policies, suggesting mode-like collapse at each complexity level.", "conclusion": "Performance collapse in reasoning tasks is likely due to fundamental reasoning limitations rather than state tracking issues, with similar phenomena potentially affecting LRMs."}}
{"id": "2510.16094", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16094", "abs": "https://arxiv.org/abs/2510.16094", "authors": ["Carsten Andrich", "Isabella Varga", "Tobias F. Nowack", "Alexander Ihlow", "Sebastian Giehl", "Michael Schubert", "Reiner S. Thom\u00e4", "Matthias A. Hein"], "title": "Wideband Antenna Deconvolution for Bistatic Millimeter Wave Radar Reflectivity Measurements", "comment": "5 pages, 5 figures, submitted to EuCAP'26", "summary": "Bistatic radar measurements offer unique spatial diversity and enhanced\ntarget characterization capabilities, rendering them increasingly vital for\ncontemporary sensing application research. The reliability of such measurements\nis contingent upon precise system and antenna calibration. The prevailing\ntechnique is the substitution method, which involves the use of known reference\nobjects. We propose an over-the-air calibration algorithm for spherical\nbistatic measurement systems. Our method is both significantly simpler and\ntwice as fast as existing algorithms. The application of our technique to\nreflectivity measurements of a metal sphere from 76 to 81 GHz demonstrates a\ndynamic range enhancement of up to 40 dB when compared with uncalibrated data.\nA comparison with simulation data demonstrates a high degree of agreement\nbetween measurement and simulation.", "AI": {"tldr": "Proposes a simpler and faster over-the-air calibration algorithm for spherical bistatic radar systems, achieving 40 dB dynamic range improvement and high agreement with simulations.", "motivation": "Bistatic radar measurements provide spatial diversity and enhanced target characterization but require precise calibration for reliability, with current substitution methods being complex and slow.", "method": "Developed an over-the-air calibration algorithm for spherical bistatic measurement systems that is simpler and faster than existing approaches.", "result": "Applied to 76-81 GHz reflectivity measurements of a metal sphere, achieving up to 40 dB dynamic range enhancement compared to uncalibrated data, with high agreement between measurements and simulations.", "conclusion": "The proposed calibration method effectively improves bistatic radar measurement reliability while being significantly simpler and faster than existing techniques."}}
{"id": "2510.16792", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16792", "abs": "https://arxiv.org/abs/2510.16792", "authors": ["Zhi Gu", "Wai Ho Mow"], "title": "Non-Orthogonal Pilot Sequence Design for Multi-Cells Interference Networks", "comment": null, "summary": "In wireless communications, the performance of non-orthogonal sequence sets\nsignificantly affects the level of multi-user interference when the number of\nusers surpasses the sequence length. The design of non-orthogonal sequences\nplays a crucial role in both the non-orthogonality of the pilots in multi-cell\nsystems and the signature sequences in overloaded code-division multiple-access\n(CDMA) systems. In multi-cell systems, considering the strength disparity\nbetween channels originating from the home cell and the neighboring cells, the\nextended total squared correlation (ETSC) is proposed as a new sequence design\ncriterion, which is defined as the sum of squares of the weighted correlations\namong sequences. In this paper, we derive a closed-form expression for the\nlower bound of ETSC for multi-cell systems with a given sequence length $\\tau$,\nwhere $\\tau \\leq K$ and $K$ is the number of users per cell. This can be\nregarded as a generalization of the well-known Welch bound (Welch, 1974, IEEE\nTIT) and the extended Welch bound (Wang et al., 2021, IEEE TWC). Additionally,\nfrom the necessary conditions of the bound, the optimal sequence set can be\neasily obtained when the interference power factor matrix is positive definite.\nOn the other hand, to address the lack of sequence generation methods under\ncertain parameter conditions, we propose the ETSC-MM algorithm, which generates\nsequence sets with low ETSC based on a Majorization-Minimization (MM)\noptimization framework.", "AI": {"tldr": "This paper derives a closed-form lower bound for Extended Total Squared Correlation (ETSC) in multi-cell wireless systems and proposes an MM-based algorithm to generate optimal sequence sets.", "motivation": "To address multi-user interference in overloaded scenarios where number of users exceeds sequence length, particularly in multi-cell systems with channel strength disparities between home and neighboring cells.", "method": "Derived closed-form lower bound for ETSC (generalizing Welch bound), and proposed ETSC-MM algorithm using Majorization-Minimization optimization framework to generate sequences with low ETSC.", "result": "Established theoretical lower bound for ETSC and developed practical algorithm that can generate optimal sequence sets when interference power factor matrix is positive definite.", "conclusion": "The proposed ETSC bound and MM algorithm provide effective solutions for non-orthogonal sequence design in multi-cell wireless systems, addressing both theoretical limits and practical sequence generation challenges."}}
{"id": "2510.16072", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16072", "abs": "https://arxiv.org/abs/2510.16072", "authors": ["Farjana Yesmin"], "title": "Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation", "comment": "18 pages", "summary": "Machine learning models trained on imbalanced datasets often exhibit\nintersectional biases-systematic errors arising from the interaction of\nmultiple attributes such as object class and environmental conditions. This\npaper presents a data-driven framework for analyzing and mitigating such biases\nin image classification. We introduce the Intersectional Fairness Evaluation\nFramework (IFEF), which combines quantitative fairness metrics with\ninterpretability tools to systematically identify bias patterns in model\npredictions. Building on this analysis, we propose Bias-Weighted Augmentation\n(BWA), a novel data augmentation strategy that adapts transformation\nintensities based on subgroup distribution statistics. Experiments on the Open\nImages V7 dataset with five object classes demonstrate that BWA improves\naccuracy for underrepresented class-environment intersections by up to 24\npercentage points while reducing fairness metric disparities by 35%.\nStatistical analysis across multiple independent runs confirms the significance\nof improvements (p < 0.05). Our methodology provides a replicable approach for\nanalyzing and addressing intersectional biases in image classification systems.", "AI": {"tldr": "A framework for analyzing and mitigating intersectional biases in image classification using fairness metrics and bias-weighted data augmentation.", "motivation": "Machine learning models trained on imbalanced datasets often exhibit systematic errors from interactions of multiple attributes like object class and environmental conditions.", "method": "Introduces Intersectional Fairness Evaluation Framework (IFEF) with fairness metrics and interpretability tools, plus Bias-Weighted Augmentation (BWA) that adapts transformation intensities based on subgroup statistics.", "result": "On Open Images V7 dataset, BWA improved accuracy for underrepresented class-environment intersections by up to 24 percentage points and reduced fairness metric disparities by 35%, with statistical significance (p < 0.05).", "conclusion": "The methodology provides a replicable approach for analyzing and addressing intersectional biases in image classification systems."}}
{"id": "2510.15950", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15950", "abs": "https://arxiv.org/abs/2510.15950", "authors": ["Arianna Francesconi", "Donato Cappetta", "Fabio Rebecchi", "Paolo Soda", "Valerio Guarrasi", "Rosa Sicilia"], "title": "Cross-dataset Multivariate Time-series Model for Parkinson's Diagnosis via Keyboard Dynamics", "comment": "Proceedings of the Workshop on Artificial Intelligence for Biomedical\n  Data (AIBio 2025), 28th European Conference on Artificial Intelligence 2025,\n  Springer CCIS", "summary": "Parkinson's disease (PD) presents a growing global challenge, affecting over\n10 million individuals, with prevalence expected to double by 2040. Early\ndiagnosis remains difficult due to the late emergence of motor symptoms and\nlimitations of traditional clinical assessments. In this study, we propose a\nnovel pipeline that leverages keystroke dynamics as a non-invasive and scalable\nbiomarker for remote PD screening and telemonitoring. Our methodology involves\nthree main stages: (i) preprocessing of data from four distinct datasets,\nextracting four temporal signals and addressing class imbalance through the\ncomparison of three methods; (ii) pre-training eight state-of-the-art\ndeep-learning architectures on the two largest datasets, optimizing temporal\nwindowing, stride, and other hyperparameters; (iii) fine-tuning on an\nintermediate-sized dataset and performing external validation on a fourth,\nindependent cohort. Our results demonstrate that hybrid convolutional-recurrent\nand transformer-based models achieve strong external validation performance,\nwith AUC-ROC scores exceeding 90% and F1-Score over 70%. Notably, a temporal\nconvolutional model attains an AUC-ROC of 91.14% in external validation,\noutperforming existing methods that rely solely on internal validation. These\nfindings underscore the potential of keystroke dynamics as a reliable digital\nbiomarker for PD, offering a promising avenue for early detection and\ncontinuous monitoring.", "AI": {"tldr": "A novel pipeline using keystroke dynamics achieves over 90% AUC-ROC for Parkinson's disease screening through deep learning models, demonstrating potential as a non-invasive digital biomarker.", "motivation": "Parkinson's disease affects over 10 million people globally with prevalence expected to double by 2040. Early diagnosis is challenging due to late motor symptom emergence and limitations of traditional clinical assessments, creating need for scalable remote screening methods.", "method": "Three-stage pipeline: (1) preprocessing data from four datasets, extracting temporal signals and addressing class imbalance; (2) pre-training eight deep-learning architectures on largest datasets with hyperparameter optimization; (3) fine-tuning on intermediate dataset and external validation on independent cohort.", "result": "Hybrid convolutional-recurrent and transformer models achieved strong external validation with AUC-ROC scores exceeding 90% and F1-Score over 70%. Temporal convolutional model attained 91.14% AUC-ROC in external validation, outperforming existing methods relying solely on internal validation.", "conclusion": "Keystroke dynamics show significant potential as a reliable digital biomarker for Parkinson's disease, offering promising avenue for early detection and continuous monitoring through non-invasive, scalable remote screening."}}
{"id": "2510.15980", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15980", "abs": "https://arxiv.org/abs/2510.15980", "authors": ["Dong Liu", "Yanxuan Yu"], "title": "Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition", "comment": null, "summary": "We propose \\textbf{Cognitive Load Traces} (CLTs) as a mid-level\ninterpretability framework for deep models, inspired by Cognitive Load Theory\nin human cognition. CLTs are defined as symbolic, temporally varying functions\nthat quantify model-internal resource allocation. Formally, we represent CLTs\nas a three-component stochastic process $(\\mathrm{IL}_t, \\mathrm{EL}_t,\n\\mathrm{GL}_t)$, corresponding to \\emph{Intrinsic}, \\emph{Extraneous}, and\n\\emph{Germane} load. Each component is instantiated through measurable proxies\nsuch as attention entropy, KV-cache miss ratio, representation dispersion, and\ndecoding stability. We propose both symbolic formulations and visualization\nmethods (load curves, simplex diagrams) that enable interpretable analysis of\nreasoning dynamics. Experiments on reasoning and planning benchmarks show that\nCLTs predict error-onset, reveal cognitive strategies, and enable load-guided\ninterventions that improve reasoning efficiency by 15-30\\% while maintaining\naccuracy.", "AI": {"tldr": "Cognitive Load Traces (CLTs) is a mid-level interpretability framework that quantifies model-internal resource allocation through symbolic, temporally varying functions representing Intrinsic, Extraneous, and Germane load components.", "motivation": "Inspired by Cognitive Load Theory from human cognition to better understand and interpret deep model reasoning dynamics and resource allocation patterns.", "method": "Define CLTs as a three-component stochastic process (IL_t, EL_t, GL_t) with measurable proxies including attention entropy, KV-cache miss ratio, representation dispersion, and decoding stability. Develop symbolic formulations and visualization methods (load curves, simplex diagrams).", "result": "CLTs successfully predict error-onset, reveal cognitive strategies, and enable load-guided interventions that improve reasoning efficiency by 15-30% while maintaining accuracy on reasoning and planning benchmarks.", "conclusion": "CLTs provide an effective interpretability framework for analyzing deep model reasoning, offering both diagnostic capabilities and practical interventions for improving reasoning efficiency."}}
{"id": "2510.16172", "categories": ["eess.SP", "cs.MS", "51-08", "D.2.2; D.2.8; D.2.13"], "pdf": "https://arxiv.org/pdf/2510.16172", "abs": "https://arxiv.org/abs/2510.16172", "authors": ["J\u00e9rome Eertmans", "Sophie Lequeu", "Beno\u00eet Legat", "Laurent Jacques", "Claude Oestges"], "title": "Fast, Differentiable, GPU-Accelerated Ray Tracing for Multiple Diffraction and Reflection Paths", "comment": "5 pages, 3 figures, submitted to EuCAP 2026", "summary": "We present a fast, differentiable, GPU-accelerated optimization method for\nray path tracing in environments containing planar reflectors and straight\ndiffraction edges. Based on Fermat's principle, our approach reformulates the\npath-finding problem as the minimization of total path length, enabling\nefficient parallel execution on modern GPU architectures. Unlike existing\nmethods that require separate algorithms for reflections and diffractions, our\nunified formulation maintains consistent problem dimensions across all\ninteraction sequences, making it particularly suitable for vectorized\ncomputation. Through implicit differentiation, we achieve efficient gradient\ncomputation without differentiating through solver iterations, significantly\noutperforming traditional automatic differentiation approaches. Numerical\nsimulations demonstrate convergence rates comparable to specialized Newton\nmethods while providing superior scalability for large-scale applications. The\nmethod integrates seamlessly with differentiable programming libraries such as\nJAX and DrJIT, enabling new possibilities in inverse design and optimization\nfor wireless propagation modeling. The source code is openly available at\nhttps://github.com/jeertmans/fpt-jax.", "AI": {"tldr": "A fast, differentiable GPU-accelerated optimization method for ray path tracing that unifies reflections and diffractions using Fermat's principle, enabling efficient parallel computation and gradient computation through implicit differentiation.", "motivation": "To develop a unified approach for ray path tracing that handles both reflections and diffractions efficiently on modern GPU architectures, overcoming limitations of existing methods that require separate algorithms for different interaction types.", "method": "Reformulates path-finding as minimization of total path length based on Fermat's principle, uses unified formulation for consistent problem dimensions, implements implicit differentiation for efficient gradient computation without differentiating through solver iterations, and leverages GPU acceleration for parallel execution.", "result": "Achieves convergence rates comparable to specialized Newton methods while providing superior scalability for large-scale applications, significantly outperforming traditional automatic differentiation approaches in computational efficiency.", "conclusion": "The method enables seamless integration with differentiable programming libraries like JAX and DrJIT, opening new possibilities for inverse design and optimization in wireless propagation modeling, with source code made openly available."}}
{"id": "2510.16444", "categories": ["cs.CV", "cs.MM", "cs.RO", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.16444", "abs": "https://arxiv.org/abs/2510.16444", "authors": ["Kunyu Peng", "Di Wen", "Jia Fu", "Jiamin Wu", "Kailun Yang", "Junwei Zheng", "Ruiping Liu", "Yufan Chen", "Yuqian Fu", "Danda Pani Paudel", "Luc Van Gool", "Rainer Stiefelhagen"], "title": "RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba", "comment": "Extended version of ECCV 2024 paper arXiv:2407.01872. The dataset and\n  code are released at https://github.com/KPeng9510/refAVA2", "summary": "Referring Atomic Video Action Recognition (RAVAR) aims to recognize\nfine-grained, atomic-level actions of a specific person of interest conditioned\non natural language descriptions. Distinct from conventional action recognition\nand detection tasks, RAVAR emphasizes precise language-guided action\nunderstanding, which is particularly critical for interactive human action\nanalysis in complex multi-person scenarios. In this work, we extend our\npreviously introduced RefAVA dataset to RefAVA++, which comprises >2.9 million\nframes and >75.1k annotated persons in total. We benchmark this dataset using\nbaselines from multiple related domains, including atomic action localization,\nvideo question answering, and text-video retrieval, as well as our earlier\nmodel, RefAtomNet. Although RefAtomNet surpasses other baselines by\nincorporating agent attention to highlight salient features, its ability to\nalign and retrieve cross-modal information remains limited, leading to\nsuboptimal performance in localizing the target person and predicting\nfine-grained actions. To overcome the aforementioned limitations, we introduce\nRefAtomNet++, a novel framework that advances cross-modal token aggregation\nthrough a multi-hierarchical semantic-aligned cross-attention mechanism\ncombined with multi-trajectory Mamba modeling at the partial-keyword,\nscene-attribute, and holistic-sentence levels. In particular, scanning\ntrajectories are constructed by dynamically selecting the nearest visual\nspatial tokens at each timestep for both partial-keyword and scene-attribute\nlevels. Moreover, we design a multi-hierarchical semantic-aligned\ncross-attention strategy, enabling more effective aggregation of spatial and\ntemporal tokens across different semantic hierarchies. Experiments show that\nRefAtomNet++ establishes new state-of-the-art results. The dataset and code are\nreleased at https://github.com/KPeng9510/refAVA2.", "AI": {"tldr": "RAVAR aims to recognize fine-grained atomic-level actions of specific persons using natural language descriptions. The authors introduce RefAVA++ dataset with >2.9M frames and >75.1k annotated persons, and propose RefAtomNet++ framework with multi-hierarchical semantic-aligned cross-attention and multi-trajectory Mamba modeling.", "motivation": "Existing methods have limited ability in aligning and retrieving cross-modal information for precise language-guided action understanding in complex multi-person scenarios, leading to suboptimal performance in localizing target persons and predicting fine-grained actions.", "method": "RefAtomNet++ uses multi-hierarchical semantic-aligned cross-attention mechanism combined with multi-trajectory Mamba modeling at partial-keyword, scene-attribute, and holistic-sentence levels. It constructs scanning trajectories by dynamically selecting nearest visual spatial tokens and enables effective aggregation of spatial and temporal tokens across semantic hierarchies.", "result": "RefAtomNet++ establishes new state-of-the-art results on the RefAVA++ dataset, outperforming previous baselines including the authors' earlier RefAtomNet model.", "conclusion": "The proposed RefAtomNet++ framework effectively addresses cross-modal alignment challenges in RAVAR through its multi-hierarchical semantic-aligned cross-attention and multi-trajectory Mamba modeling, achieving superior performance for fine-grained, language-guided atomic action recognition."}}
{"id": "2510.16948", "categories": ["cs.IT", "cs.CV", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.16948", "abs": "https://arxiv.org/abs/2510.16948", "authors": ["Ruiming Guo", "Ayush Bhandari"], "title": "Unlocking Off-the-Grid Sparse Recovery with Unlimited Sensing: Simultaneous Super-Resolution in Time and Amplitude", "comment": "28 Pages, 10 figures. To appear in IEEE Journal of Selected Topics in\n  Signal Processing", "summary": "The recovery of Dirac impulses, or spikes, from filtered measurements is a\nclassical problem in signal processing. As the spikes lie in the continuous\ndomain while measurements are discrete, this task is known as super-resolution\nor off-the-grid sparse recovery. Despite significant theoretical and\nalgorithmic advances over the past decade, these developments often overlook\ncritical challenges at the analog-digital interface. In particular, when spikes\nexhibit strong-weak amplitude disparity, conventional digital acquisition may\nresult in clipping of strong components or loss of weak ones beneath the\nquantization noise floor. This motivates a broader perspective:\nsuper-resolution must simultaneously resolve both amplitude and temporal\nstructure. Under a fixed bit budget, such information loss is unavoidable. In\ncontrast, the emerging theory and practice of the Unlimited Sensing Framework\n(USF) demonstrate that these fundamental limitations can be overcome. Building\non this foundation, we demonstrate that modulo encoding within USF enables\ndigital super-resolution by enhancing measurement precision, thereby unlocking\ntemporal super-resolution beyond conventional limits. We develop new\ntheoretical results that extend to non-bandlimited kernels commonly encountered\nin practice and introduce a robust algorithm for off-the-grid sparse recovery.\nTo demonstrate practical impact, we instantiate our framework in the context of\ntime-of-flight imaging. Both numerical simulations and hardware experiments\nvalidate the effectiveness of our approach under low-bit quantization, enabling\nsuper-resolution in amplitude and time.", "AI": {"tldr": "The paper addresses super-resolution spike recovery from filtered measurements, overcoming amplitude-temporal resolution trade-offs through modulo encoding in the Unlimited Sensing Framework (USF), enabling digital super-resolution beyond conventional limits.", "motivation": "Conventional digital acquisition suffers from clipping of strong spikes or loss of weak ones beneath quantization noise when spikes exhibit strong-weak amplitude disparity, creating fundamental limitations in super-resolution.", "method": "Leverages modulo encoding within the Unlimited Sensing Framework (USF) to enhance measurement precision, with new theoretical results for non-bandlimited kernels and a robust algorithm for off-the-grid sparse recovery.", "result": "The approach enables super-resolution in both amplitude and time domains under low-bit quantization, validated through numerical simulations and hardware experiments in time-of-flight imaging.", "conclusion": "Modulo encoding in USF overcomes fundamental limitations of conventional acquisition, enabling simultaneous amplitude and temporal super-resolution beyond traditional digital constraints."}}
{"id": "2510.16088", "categories": ["cs.CV", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16088", "abs": "https://arxiv.org/abs/2510.16088", "authors": ["Zia Badar"], "title": "Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch", "comment": null, "summary": "Quantization of neural networks provides benefits of inference in less\ncompute and memory requirements. Previous work in quantization lack two\nimportant aspects which this work provides. First almost all previous work in\nquantization used a non-differentiable approach and for learning; the\nderivative is usually set manually in backpropogation which make the learning\nability of algorithm questionable, our approach is not just differentiable, we\nalso provide proof of convergence of our approach to the optimal neural\nnetwork. Second previous work in shift/logrithmic quantization either have\navoided activation quantization along with weight quantization or achieved less\naccuracy. Learning logrithmic quantize values of form $2^n$ requires the\nquantization function can scale to more than 1 bit quantization which is\nanother benifit of our quantization that it provides $n$ bits quantization as\nwell. Our approach when tested with image classification task using imagenet\ndataset, resnet18 and weight quantization only achieves less than 1 percent\naccuracy compared to full precision accuracy while taking only 15 epochs to\ntrain using shift bit quantization and achieves comparable to SOTA approaches\naccuracy in both weight and activation quantization using shift bit\nquantization in 15 training epochs with slightly higher(only higher cpu\ninstructions) inference cost compared to 1 bit quantization(without logrithmic\nquantization) and not requiring any higher precision multiplication.", "AI": {"tldr": "This paper presents a differentiable quantization method for neural networks that provides proof of convergence and supports n-bit quantization, achieving near full-precision accuracy with only 15 training epochs.", "motivation": "Previous quantization methods lack differentiability and proper convergence proofs, and struggle with activation quantization while maintaining accuracy. The authors aim to create a differentiable quantization approach that can scale to multiple bits and handle both weight and activation quantization effectively.", "method": "The proposed method uses a differentiable quantization approach with shift/logarithmic quantization that can scale to n-bit quantization. It provides mathematical proof of convergence to optimal neural networks and supports both weight-only and weight+activation quantization.", "result": "When tested on ImageNet with ResNet18, the method achieved less than 1% accuracy drop compared to full precision with weight-only quantization using only 15 training epochs. With weight and activation quantization, it achieved state-of-the-art accuracy in 15 epochs, with slightly higher CPU instructions but no need for higher precision multiplication.", "conclusion": "The proposed differentiable quantization method successfully addresses limitations of previous approaches by providing convergence guarantees, supporting multi-bit quantization, and achieving competitive accuracy with efficient training and inference."}}
{"id": "2510.15954", "categories": ["cs.LG", "cs.CE", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.15954", "abs": "https://arxiv.org/abs/2510.15954", "authors": ["Hongzheng Shi", "Yuhang Wang", "Xiao Liu"], "title": "Fire-EnSF: Wildfire Spread Data Assimilation using Ensemble Score Filter", "comment": null, "summary": "As wildfires become increasingly destructive and expensive to control,\neffective management of active wildfires requires accurate, real-time fire\nspread predictions. To enhance the forecasting accuracy of active fires, data\nassimilation plays a vital role by integrating observations (such as\nremote-sensing data) and fire predictions generated from numerical models. This\npaper provides a comprehensive investigation on the application of a recently\nproposed diffusion-model-based filtering algorithm -- the Ensemble Score Filter\n(EnSF) -- to the data assimilation problem for real-time active wildfire spread\npredictions. Leveraging a score-based generative diffusion model, EnSF has been\nshown to have superior accuracy for high-dimensional nonlinear filtering\nproblems, making it an ideal candidate for the filtering problems of wildfire\nspread models. Technical details are provided, and our numerical investigations\ndemonstrate that EnSF provides superior accuracy, stability, and computational\nefficiency, establishing it as a robust and practical method for wildfire data\nassimilation. Our code has been made publicly available.", "AI": {"tldr": "The paper investigates using Ensemble Score Filter (EnSF) for data assimilation in wildfire spread prediction, showing superior accuracy and efficiency.", "motivation": "Wildfires are increasingly destructive and expensive, requiring accurate real-time fire spread predictions. Data assimilation can improve forecasting by integrating observations with model predictions.", "method": "Applied Ensemble Score Filter (EnSF), a diffusion-model-based filtering algorithm using score-based generative diffusion models, to wildfire data assimilation problems.", "result": "EnSF demonstrated superior accuracy, stability, and computational efficiency compared to other methods for high-dimensional nonlinear filtering in wildfire spread models.", "conclusion": "EnSF is established as a robust and practical method for wildfire data assimilation, with publicly available code for implementation."}}
{"id": "2510.15981", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2510.15981", "abs": "https://arxiv.org/abs/2510.15981", "authors": ["Rafael Cabral", "Tuan Manh Do", "Xuejun Yu", "Wai Ming Tai", "Zijin Feng", "Xin Shen"], "title": "ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization", "comment": null, "summary": "Proof autoformalization, the task of translating natural language theorems\nand proofs into machine-verifiable code, is a critical step for integrating\nlarge language models into rigorous mathematical workflows. Current approaches\nfocus on producing executable code, but they frequently fail to preserve the\nsemantic meaning and logical structure of the original human-written argument.\nTo address this, we introduce ProofFlow, a novel pipeline that treats\nstructural fidelity as a primary objective. ProofFlow first constructs a\ndirected acyclic graph (DAG) to map the logical dependencies between proof\nsteps. Then, it employs a novel lemma-based approach to systematically\nformalize each step as an intermediate lemma, preserving the logical structure\nof the original argument. To facilitate evaluation, we present a new benchmark\nof 184 undergraduate-level problems, manually annotated with step-by-step\nsolutions and logical dependency graphs, and introduce ProofScore, a new\ncomposite metric to evaluate syntactic correctness, semantic faithfulness, and\nstructural fidelity. Experimental results show our pipeline sets a new\nstate-of-the-art for autoformalization, achieving a ProofScore of 0.545,\nsubstantially exceeding baselines like full-proof formalization (0.123), which\nprocesses the entire proof at once, and step-proof formalization (0.072), which\nhandles each step independently. Our pipeline, benchmark, and score metric are\nopen-sourced to encourage further progress at\nhttps://github.com/Huawei-AI4Math/ProofFlow.", "AI": {"tldr": "ProofFlow is a novel autoformalization pipeline that preserves logical structure through DAG-based dependency mapping and lemma-based formalization, achieving state-of-the-art performance on a new benchmark.", "motivation": "Current autoformalization approaches focus on producing executable code but frequently fail to preserve semantic meaning and logical structure of original human-written proofs.", "method": "Constructs directed acyclic graph (DAG) to map logical dependencies between proof steps, then employs lemma-based approach to formalize each step as intermediate lemma while preserving logical structure.", "result": "Achieves ProofScore of 0.545, substantially exceeding baselines like full-proof formalization (0.123) and step-proof formalization (0.072) on new benchmark of 184 undergraduate-level problems.", "conclusion": "ProofFlow sets new state-of-the-art for autoformalization by treating structural fidelity as primary objective, with pipeline, benchmark, and metric open-sourced for further progress."}}
{"id": "2510.16200", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16200", "abs": "https://arxiv.org/abs/2510.16200", "authors": ["Lorenz Mohr", "Michael D\u00f6bereiner", "Steffen Schieler", "Joerg Robert", "Christian Schneider", "Sebastian Semper", "Reiner S. Thoma"], "title": "Performance Comparison of Joint Delay-Doppler Estimation Algorithms", "comment": "5 pages, 4 figures", "summary": "Integrated sensing and communications (ISAC), radar, and beamforming require\nreal-time, high-resolution estimation algorithms to determine delay-Doppler\nvalues of specular paths within the wireless propagation channel. Our\ncontribution is the measurement-based performance comparison of the\ndelay-Doppler estimation between three different algorithms, comprising maximum\nlikelihood (ML), convolutional neural network (CNN), and constant false alarm\nrate (CFAR) approaches. We apply these algorithms to publicly available channel\ndata which includes two spherical targets with analytically describable\ndelay-Doppler parameters. The comparison of the three algorithms features the\ntarget detection rate, root mean squared errors (RMSEs) of the delay-Doppler\nestimates, and a runtime analysis. Notably, all three algorithms demonstrate\nsimilar parameter estimation capabilities in bi-static scenarios, achieving\ntarget detection probabilities of up to 80%. Conversely, forward and backward\nscattering conditions pose a problem to the estimation due to strong\nline-of-sight (LoS) contribution, reducing the corresponding detection\nprobability down to 0%.", "AI": {"tldr": "Performance comparison of three delay-Doppler estimation algorithms (ML, CNN, CFAR) for ISAC applications, showing similar performance in bi-static scenarios but poor detection in forward/backward scattering conditions.", "motivation": "ISAC, radar, and beamforming require real-time, high-resolution delay-Doppler estimation algorithms for wireless channel analysis.", "method": "Measurement-based comparison using publicly available channel data with two spherical targets, evaluating target detection rate, RMSE of delay-Doppler estimates, and runtime analysis.", "result": "All three algorithms showed similar parameter estimation in bi-static scenarios with up to 80% detection probability, but detection dropped to 0% in forward/backward scattering due to strong LoS interference.", "conclusion": "The three algorithms perform comparably in bi-static conditions but struggle with forward/backward scattering scenarios where LoS dominates."}}
{"id": "2510.17043", "categories": ["cs.CV", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.17043", "abs": "https://arxiv.org/abs/2510.17043", "authors": ["Md Ahmed Al Muzaddid", "William J. Beksi"], "title": "Person Re-Identification via Generalized Class Prototypes", "comment": "18 pages, 11 figures, and 4 tables", "summary": "Advanced feature extraction methods have significantly contributed to\nenhancing the task of person re-identification. In addition, modifications to\nobjective functions have been developed to further improve performance.\nNonetheless, selecting better class representatives is an underexplored area of\nresearch that can also lead to advancements in re-identification performance.\nAlthough past works have experimented with using the centroid of a gallery\nimage class during training, only a few have investigated alternative\nrepresentations during the retrieval stage. In this paper, we demonstrate that\nthese prior techniques yield suboptimal results in terms of re-identification\nmetrics. To address the re-identification problem, we propose a generalized\nselection method that involves choosing representations that are not limited to\nclass centroids. Our approach strikes a balance between accuracy and mean\naverage precision, leading to improvements beyond the state of the art. For\nexample, the actual number of representations per class can be adjusted to meet\nspecific application requirements. We apply our methodology on top of multiple\nre-identification embeddings, and in all cases it substantially improves upon\ncontemporary results", "AI": {"tldr": "The paper proposes a generalized selection method for class representations in person re-identification that improves performance beyond state-of-the-art methods by choosing better representations beyond just class centroids.", "motivation": "Current person re-identification methods focus on feature extraction and objective functions, but selecting better class representatives is an underexplored area that can significantly improve performance. Prior techniques using class centroids yield suboptimal results.", "method": "A generalized selection method that chooses class representations not limited to centroids, allowing adjustment of the number of representations per class to meet specific application requirements. Applied on top of multiple re-identification embeddings.", "result": "The approach substantially improves upon contemporary results across all tested re-identification embeddings, achieving better balance between accuracy and mean average precision.", "conclusion": "The proposed generalized selection method for class representations effectively addresses limitations of prior centroid-based approaches and leads to significant performance improvements in person re-identification tasks."}}
{"id": "2510.17093", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17093", "abs": "https://arxiv.org/abs/2510.17093", "authors": ["Yunfeng Wen", "Fang Yang", "Jian Song", "Zhu Han"], "title": "Channel Capacity for FMCW-based Optical Wireless Integrated Sensing and Communication: Asymptotic Analysis and Envelope Design", "comment": "This work has been submitted to the IEEE for possible publication. 13\n  pages, 7 figures", "summary": "Optical wireless integrated sensing and communication (OW-ISAC) is rapidly\nburgeoning as a complement and augmentation to its radio-frequency counterpart.\nIn this paper, the channel capacity is analyzed to guide the design of a\ncoherent OW-ISAC system based on frequency-modulated continuous wave (FMCW).\nFirstly, the system model of FMCW-based OW-ISAC is recast into an\ninformation-theoretic formulation, where an additional harmonic-mean constraint\nis imposed to ensure the sensing performance. Subsequently, both lower and\nupper bounds for channel capacity are derived under the imposed sensing\nconstraint, based on which asymptotic expressions for channel capacity are\npresented for both low and high signal-to-noise-ratio regions. Moreover, the\nanalysis of channel capacity provides guidance for the envelope design based on\npulse amplitude modulation, whose capacity-achieving capabilities are\ndemonstrated by numerical results. Furthermore, simulations reveal the\ntrade-off between communication and sensing functionalities. In summary, the\nanalysis of channel capacity under the sensing constraint provides insights\ninto both the optimality and the practicality of OW-ISAC design.", "AI": {"tldr": "Analysis of channel capacity for coherent optical wireless integrated sensing and communication (OW-ISAC) systems using frequency-modulated continuous wave (FMCW), deriving capacity bounds under sensing constraints and providing design guidance.", "motivation": "OW-ISAC is emerging as a complement to radio-frequency systems, requiring analysis of channel capacity to guide the design of coherent systems that integrate both communication and sensing functionalities.", "method": "Recast FMCW-based OW-ISAC system into information-theoretic formulation with harmonic-mean constraint for sensing performance, derive lower/upper capacity bounds, analyze asymptotic expressions for low/high SNR regions, and provide envelope design guidance using pulse amplitude modulation.", "result": "Derived channel capacity bounds under sensing constraints, presented asymptotic capacity expressions, demonstrated capacity-achieving capabilities of pulse amplitude modulation through numerical results, and revealed communication-sensing trade-off through simulations.", "conclusion": "Channel capacity analysis under sensing constraints provides insights into both optimality and practicality of OW-ISAC design, guiding the development of integrated optical wireless communication and sensing systems."}}
{"id": "2510.16115", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16115", "abs": "https://arxiv.org/abs/2510.16115", "authors": ["Jianhan Lin", "Yuchu Qin", "Shuai Gao", "Yikang Rui", "Jie Liu", "Yanjie Lv"], "title": "StripRFNet: A Strip Receptive Field and Shape-Aware Network for Road Damage Detection", "comment": null, "summary": "Well-maintained road networks are crucial for achieving Sustainable\nDevelopment Goal (SDG) 11. Road surface damage not only threatens traffic\nsafety but also hinders sustainable urban development. Accurate detection,\nhowever, remains challenging due to the diverse shapes of damages, the\ndifficulty of capturing slender cracks with high aspect ratios, and the high\nerror rates in small-scale damage recognition. To address these issues, we\npropose StripRFNet, a novel deep neural network comprising three modules: (1) a\nShape Perception Module (SPM) that enhances shape discrimination via large\nseparable kernel attention (LSKA) in multi-scale feature aggregation; (2) a\nStrip Receptive Field Module (SRFM) that employs large strip convolutions and\npooling to capture features of slender cracks; and (3) a Small-Scale\nEnhancement Module (SSEM) that leverages a high-resolution P2 feature map, a\ndedicated detection head, and dynamic upsampling to improve small-object\ndetection. Experiments on the RDD2022 benchmark show that StripRFNet surpasses\nexisting methods. On the Chinese subset, it improves F1-score, mAP50, and\nmAP50:95 by 4.4, 2.9, and 3.4 percentage points over the baseline,\nrespectively. On the full dataset, it achieves the highest F1-score of 80.33%\ncompared with CRDDC'2022 participants and ORDDC'2024 Phase 2 results, while\nmaintaining competitive inference speed. These results demonstrate that\nStripRFNet achieves state-of-the-art accuracy and real-time efficiency,\noffering a promising tool for intelligent road maintenance and sustainable\ninfrastructure management.", "AI": {"tldr": "StripRFNet is a novel deep neural network for road damage detection that addresses challenges like diverse damage shapes, slender cracks, and small-scale damage recognition through three specialized modules, achieving state-of-the-art performance on the RDD2022 benchmark.", "motivation": "Road surface damage threatens traffic safety and hinders sustainable urban development. Accurate detection is challenging due to diverse damage shapes, difficulty capturing slender cracks with high aspect ratios, and high error rates in small-scale damage recognition.", "method": "StripRFNet comprises three modules: (1) Shape Perception Module (SPM) with large separable kernel attention for shape discrimination, (2) Strip Receptive Field Module (SRFM) using large strip convolutions and pooling for slender cracks, and (3) Small-Scale Enhancement Module (SSEM) with high-resolution features and dynamic upsampling for small-object detection.", "result": "On RDD2022 benchmark: Chinese subset improved F1-score, mAP50, and mAP50:95 by 4.4, 2.9, and 3.4 percentage points over baseline. On full dataset, achieved highest F1-score of 80.33% compared to CRDDC'2022 participants and ORDDC'2024 Phase 2 results, while maintaining competitive inference speed.", "conclusion": "StripRFNet achieves state-of-the-art accuracy and real-time efficiency, offering a promising tool for intelligent road maintenance and sustainable infrastructure management."}}
{"id": "2510.15955", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15955", "abs": "https://arxiv.org/abs/2510.15955", "authors": ["Kiran Kate", "Yara Rizk", "Poulami Ghosh", "Ashu Gulati", "Tathagata Chakraborti", "Zidane Wright", "Mayank Agarwal"], "title": "How Good Are LLMs at Processing Tool Outputs?", "comment": null, "summary": "Most realistic task automation problems require large language models (LLMs)\nto call tools, which often return complex JSON responses. These responses must\nbe further processed to derive the information necessary for task completion.\nThe ability of LLMs to do so is under-studied. In this paper, we study the tool\nresponse processing task and LLMs' abilities to process structured (JSON)\nresponses. We created a dataset for this task, and evaluated 15 open and closed\nweight models using multiple prompting approaches. Our results show that JSON\nprocessing remains a difficult task even for frontier models across multiple\nprompting strategies. The optimal response processing strategy depends on both\nthe nature and size of the tool outputs, as well as the complexity of the\nrequired reasoning. Variations in processing approaches can lead to performance\ndifferences ranging from 3\\% to 50\\%.", "AI": {"tldr": "LLMs struggle with processing complex JSON tool responses for task automation, with performance varying 3-50% depending on processing strategy, response size, and reasoning complexity.", "motivation": "Most realistic task automation requires LLMs to process complex JSON responses from tools, but this capability is under-studied despite being crucial for task completion.", "method": "Created a dataset for tool response processing and evaluated 15 open/closed weight models using multiple prompting approaches to study JSON processing abilities.", "result": "JSON processing remains difficult even for frontier models across multiple prompting strategies. Performance depends on output size, nature, and reasoning complexity.", "conclusion": "The optimal response processing strategy varies significantly based on tool output characteristics and reasoning requirements, highlighting the need for better JSON processing capabilities in LLMs."}}
{"id": "2510.15983", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15983", "abs": "https://arxiv.org/abs/2510.15983", "authors": ["Sarah Rebecca Ondraszek", "J\u00f6rg Waitelonis", "Katja Keller", "Claudia Niessner", "Anna M. Jacyszyn", "Harald Sack"], "title": "Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science", "comment": "10 pages, 2 figures. Camera-ready version. Accepted to the 5th\n  International Workshop on Scientific Knowledge: Representation, Discovery,\n  and Assessment; 2 November 2025 - Nara, Japan; co-located with The 24th\n  International Semantic Web Conference, ISWC 2025. To be published in CEUR\n  proceedings", "summary": "An essential component for evaluating and comparing physical and cognitive\ncapabilities between populations is the testing of various factors related to\nhuman performance. As a core part of sports science research, testing motor\nperformance enables the analysis of the physical health of different\ndemographic groups and makes them comparable.\n  The Motor Research (MO|RE) data repository, developed at the Karlsruhe\nInstitute of Technology, is an infrastructure for publishing and archiving\nresearch data in sports science, particularly in the field of motor performance\nresearch. In this paper, we present our vision for creating a knowledge graph\nfrom MO|RE data. With an ontology rooted in the Basic Formal Ontology, our\napproach centers on formally representing the interrelation of plan\nspecifications, specific processes, and related measurements. Our goal is to\ntransform how motor performance data are modeled and shared across studies,\nmaking it standardized and machine-understandable. The idea presented here is\ndeveloped within the Leibniz Science Campus ``Digital Transformation of\nResearch'' (DiTraRe).", "AI": {"tldr": "The paper presents a vision for creating a knowledge graph from the MO|RE data repository to transform how motor performance data are modeled and shared across studies, making it standardized and machine-understandable.", "motivation": "Testing motor performance is essential for evaluating physical and cognitive capabilities between populations in sports science research, but current data sharing lacks standardization and machine-understandability.", "method": "Develop a knowledge graph using an ontology rooted in the Basic Formal Ontology, focusing on formally representing the interrelation of plan specifications, specific processes, and related measurements from the MO|RE data repository.", "result": "The paper presents the conceptual framework and vision for transforming motor performance data modeling and sharing, developed within the Leibniz Science Campus \"Digital Transformation of Research\" (DiTraRe).", "conclusion": "The proposed knowledge graph approach aims to standardize and make motor performance data machine-understandable, facilitating better comparison and analysis across different studies and demographic groups."}}
{"id": "2510.16296", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16296", "abs": "https://arxiv.org/abs/2510.16296", "authors": ["Yuan Ai", "Xidong Mu", "Pengbo Si", "Yuanwei Liu"], "title": "Delay Minimization in Pinching-Antenna-enabled NOMA-MEC Networks", "comment": null, "summary": "This letter proposes a novel pinching antenna systems (PASS) enabled\nnon-orthogonal multiple access (NOMA) multi-access edge computing (MEC)\nframework. An optimization problem is formulated to minimize the maximum task\ndelay by optimizing offloading ratios, transmit powers, and pinching antenna\n(PA) positions, subject to constraints on maximum transmit power, user energy\nbudgets, and minimum PA separation to mitigate coupling effects. To address the\nnon-convex problem, a bisection search-based alternating optimization (AO)\nalgorithm is developed, where each subproblem is iteratively solved for a given\ntask delay. Numerical simulations demonstrate that the proposed framework\nsignificantly reduces the task delay compared to benchmark schemes.", "AI": {"tldr": "Proposes a pinching antenna systems (PASS) enabled NOMA-MEC framework to minimize maximum task delay through joint optimization of offloading ratios, transmit powers, and antenna positions.", "motivation": "To reduce task delay in multi-access edge computing systems by leveraging pinching antenna technology and non-orthogonal multiple access for improved performance.", "method": "Develops a bisection search-based alternating optimization algorithm that iteratively solves subproblems for offloading ratios, transmit powers, and antenna positions while considering constraints on power, energy budgets, and antenna separation.", "result": "Numerical simulations show the proposed framework significantly reduces task delay compared to benchmark schemes.", "conclusion": "The PASS-enabled NOMA-MEC framework with the proposed optimization algorithm effectively minimizes task delay in edge computing systems."}}
{"id": "2510.17466", "categories": ["cs.IT", "eess.SP", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17466", "abs": "https://arxiv.org/abs/2510.17466", "authors": ["Fathima Jesbin", "Ananthanarayanan Chockalingam"], "title": "Delay-Doppler Pulse Shaping in Zak-OTFS Using Hermite Basis Functions", "comment": "Submitted to IEEE journal for possible publication", "summary": "The performance of Zak-OTFS modulation is critically dependent on the choice\nof the delay-Doppler (DD) domain pulse shaping filter. The design of pulses for\n$L^2(\\mathbb{R})$ is constrained by the Balian-Low Theorem, which imposes an\ninescapable trade-off between time-frequency localization and orthogonality for\nspectrally efficient systems. In Zak-OTFS, this trade-off requires balancing\nthe need for localization for input/output (I/O) relation estimation with the\nneed for orthogonality for reliable data detection when operating without time\nor bandwidth expansion. The well-known sinc and Gaussian pulse shapes represent\nthe canonical extremes of this trade-off, while composite constructions such as\nthe Gaussian-sinc (GS) pulse shape offer a good compromise. In this work, we\npropose a systematic DD pulse design framework for Zak-OTFS that expresses the\npulse as a linear combination of Hermite basis functions. We obtain the optimal\ncoefficients for the Hermite basis functions that minimize the inter-symbol\ninterference (ISI) energy at the DD sampling points by solving a constrained\noptimization problem via singular value decomposition. For the proposed class\nof Hermite pulses, we derive closed-form expressions for the I/O relation and\nnoise covariance in Zak-OTFS. Simulation results of Zak-OTFS with embedded\npilot and model-free I/O relation estimation in Vehicular-A channels with\nfractional DDs demonstrate that the optimized pulse shape achieves a bit error\nrate performance that is significantly superior compared to those of the\ncanonical sinc and Gaussian pulses and is on par with that of the\nstate-of-the-art GS pulse, validating the proposed framework which provides\ngreater design flexibility in terms of control of ISI and sidelobe energies.", "AI": {"tldr": "Proposes a systematic delay-Doppler pulse design framework for Zak-OTFS using Hermite basis functions, optimizing coefficients to minimize inter-symbol interference while balancing time-frequency localization and orthogonality constraints.", "motivation": "Zak-OTFS performance depends critically on pulse shaping filter design, constrained by the Balian-Low Theorem trade-off between time-frequency localization and orthogonality. Existing pulses like sinc and Gaussian represent extremes, while composite pulses offer compromise but lack systematic design.", "method": "Express pulse as linear combination of Hermite basis functions. Obtain optimal coefficients by solving constrained optimization problem via singular value decomposition to minimize ISI energy at DD sampling points. Derive closed-form expressions for I/O relation and noise covariance.", "result": "Optimized Hermite pulse achieves significantly superior bit error rate performance compared to canonical sinc and Gaussian pulses, and performs on par with state-of-the-art Gaussian-sinc pulse in Vehicular-A channels with fractional delay-Dopplers.", "conclusion": "The proposed framework provides greater design flexibility for controlling ISI and sidelobe energies, offering a systematic approach to pulse design that balances the fundamental trade-offs in Zak-OTFS modulation."}}
{"id": "2510.16118", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16118", "abs": "https://arxiv.org/abs/2510.16118", "authors": ["Nishad Sahu", "Shounak Sural", "Aditya Satish Patil", "Ragunathan", "Rajkumar"], "title": "ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles", "comment": "Accepted at International Conference on Computer Vision (ICCV) 2025\n  Workshops", "summary": "Reliable perception is fundamental for safety critical decision making in\nautonomous driving. Yet, vision based object detector neural networks remain\nvulnerable to uncertainty arising from issues such as data bias and\ndistributional shifts. In this paper, we introduce ObjectTransforms, a\ntechnique for quantifying and reducing uncertainty in vision based object\ndetection through object specific transformations at both training and\ninference times. At training time, ObjectTransforms perform color space\nperturbations on individual objects, improving robustness to lighting and color\nvariations. ObjectTransforms also uses diffusion models to generate realistic,\ndiverse pedestrian instances. At inference time, object perturbations are\napplied to detected objects and the variance of detection scores are used to\nquantify predictive uncertainty in real time. This uncertainty signal is then\nused to filter out false positives and also recover false negatives, improving\nthe overall precision recall curve. Experiments with YOLOv8 on the NuImages 10K\ndataset demonstrate that our method yields notable accuracy improvements and\nuncertainty reduction across all object classes during training, while\npredicting desirably higher uncertainty values for false positives as compared\nto true positives during inference. Our results highlight the potential of\nObjectTransforms as a lightweight yet effective mechanism for reducing and\nquantifying uncertainty in vision-based perception during training and\ninference respectively.", "AI": {"tldr": "ObjectTransforms is a technique that uses object-specific transformations to quantify and reduce uncertainty in vision-based object detection, improving robustness and filtering false detections.", "motivation": "Vision-based object detectors are vulnerable to uncertainty from data bias and distribution shifts, which is critical for safety in autonomous driving.", "method": "Uses color space perturbations on individual objects during training and diffusion models to generate diverse pedestrians. At inference, applies object perturbations and uses detection score variance to quantify uncertainty.", "result": "Experiments on NuImages dataset with YOLOv8 show accuracy improvements, uncertainty reduction across all classes, and higher uncertainty for false positives than true positives.", "conclusion": "ObjectTransforms is an effective lightweight mechanism for reducing and quantifying uncertainty in vision-based perception during training and inference."}}
{"id": "2510.15960", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.15960", "abs": "https://arxiv.org/abs/2510.15960", "authors": ["Sana Kordoghli", "Abdelhakim Settar", "Oumayma Belaati", "Mohammad Alkhatib"], "title": "Hydrogen production from blended waste biomass: pyrolysis, thermodynamic-kinetic analysis and AI-based modelling", "comment": "41 pages, 21 figures", "summary": "This work contributes to advancing sustainable energy and waste management\nstrategies by investigating the thermochemical conversion of food-based biomass\nthrough pyrolysis, highlighting the role of artificial intelligence (AI) in\nenhancing process modelling accuracy and optimization efficiency. The main\nobjective is to explore the potential of underutilized biomass resources, such\nas spent coffee grounds (SCG) and date seeds (DS), for sustainable hydrogen\nproduction. Specifically, it aims to optimize the pyrolysis process while\nevaluating the performance of these resources both individually and as blends.\nProximate, ultimate, fibre, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC\nanalyses were conducted for pure DS, SCG, and blends (75% DS - 25% SCG, 50% DS\n- 50% SCG, 25% DS - 75% SCG). Blend 3 offered superior hydrogen yield potential\nbut had the highest activation energy (Ea: 313.24 kJ/mol), while Blend 1\nexhibited the best activation energy value (Ea: 161.75 kJ/mol). The kinetic\nmodelling based on isoconversional methods (KAS, FWO, Friedman) identified KAS\nas the most accurate. These approaches provide a detailed understanding of the\npyrolysis process, with particular emphasis on the integration of artificial\nintelligence. An LSTM model trained with lignocellulosic data predicted TGA\ncurves with exceptional accuracy (R^2: 0.9996-0.9998).", "AI": {"tldr": "This study investigates thermochemical conversion of food-based biomass (spent coffee grounds and date seeds) through pyrolysis for sustainable hydrogen production, using AI to enhance process modeling and optimization.", "motivation": "To advance sustainable energy and waste management by exploring underutilized biomass resources for hydrogen production and improving pyrolysis process efficiency through AI integration.", "method": "Conducted proximate, ultimate, fiber, TGA/DTG, kinetic, thermodynamic, and Py-Micro GC analyses on pure DS, SCG, and their blends. Used isoconversional methods (KAS, FWO, Friedman) for kinetic modeling and trained an LSTM model with lignocellulosic data.", "result": "Blend 3 (25% DS - 75% SCG) offered superior hydrogen yield potential but highest activation energy (313.24 kJ/mol), while Blend 1 (75% DS - 25% SCG) had best activation energy (161.75 kJ/mol). KAS method was most accurate. LSTM model predicted TGA curves with exceptional accuracy (R\u00b2: 0.9996-0.9998).", "conclusion": "AI-enhanced pyrolysis modeling provides accurate optimization for sustainable hydrogen production from food-based biomass, with different biomass blends offering trade-offs between hydrogen yield and activation energy requirements."}}
{"id": "2510.16001", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16001", "abs": "https://arxiv.org/abs/2510.16001", "authors": ["Ruolan Cheng", "Yong Deng", "Enrique Herrera-Viedma"], "title": "A Non-overlap-based Conflict Measure for Random Permutation Sets", "comment": null, "summary": "Random permutation set (RPS) is a new formalism for reasoning with\nuncertainty involving order information. Measuring the conflict between two\npieces of evidence represented by permutation mass functions remains an urgent\nresearch topic in order-structured uncertain information fusion. In this paper,\na detailed analysis of conflicts in RPS is carried out from two different\nperspectives: random finite set (RFS) and Dempster-Shafer theory (DST).\nStarting from the observation of permutations, we first define an inconsistency\nmeasure between permutations inspired by the rank-biased overlap(RBO) measure\nand further propose a non-overlap-based conflict measure method for RPSs. This\npaper regards RPS theory (RPST) as an extension of DST. The order information\nnewly added in focal sets indicates qualitative propensity, characterized by\ntop-ranked elements occupying a more critical position. Some numerical examples\nare used to demonstrate the behavior and properties of the proposed conflict\nmeasure. The proposed method not only has the natural top-weightedness property\nand can effectively measure the conflict between RPSs from the DST view but\nalso provides decision-makers with a flexible selection of weights, parameters,\nand truncated depths.", "AI": {"tldr": "This paper proposes a new conflict measure method for Random Permutation Sets (RPS) by analyzing conflicts from both Random Finite Set and Dempster-Shafer Theory perspectives, using rank-biased overlap inspired inconsistency measures.", "motivation": "There is an urgent need to measure conflict between evidence represented by permutation mass functions in order-structured uncertain information fusion, as existing methods don't adequately handle the order information in RPS.", "method": "The authors define an inconsistency measure between permutations inspired by rank-biased overlap (RBO), and propose a non-overlap-based conflict measure method for RPSs, treating RPS theory as an extension of Dempster-Shafer Theory.", "result": "The proposed method demonstrates natural top-weightedness property, effectively measures conflict between RPSs from DST perspective, and provides flexible selection of weights, parameters, and truncated depths for decision-makers.", "conclusion": "The conflict measure method successfully addresses the challenge of measuring conflicts in RPS by incorporating order information and providing decision-makers with configurable parameters for practical applications."}}
{"id": "2510.16389", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16389", "abs": "https://arxiv.org/abs/2510.16389", "authors": ["Yubin Luo", "Li Yu", "Tao Wu", "Yuxiang Zhang", "Jianhua Zhang"], "title": "A Robust CSI-Based Scatterer Geometric Reconstruction Method for 6G ISAC System", "comment": null, "summary": "Digital twin (DT) is a core enabler of sixth generation (6G) mobile systems.\nAs a prerequisite for DT, scatterer geometric reconstruction (SGR) in\npropagation environments is essential but typically requires extra sensors such\nas cameras and LiDAR. With integrated sensing and communication (ISAC) in 6G,\nwe reinterpret the linear sampling method (LSM) from a wireless channel\nviewpoint and propose a CSI based variant for sensor free SGR: by exploiting\nthe shared channel characteristics of multipath and scattering, in band CSI\nreplaces the scattered field measurements usually required by LSM. However,\naperture limited arrays reduce LSM robustness. To address this, we propose\nmatched filtering enhanced multi frequency LSM (MF MLSM). Multi frequency data\nincreases frequency diversity, and matched filtering coherently aligns inter\nfrequency phases to avoid artifacts, both of which improve robustness.\nExperiments with apertures of 93.6 deg, 144 deg, and 180 deg and SNRs of 27 dB\nand 12 dB demonstrate robust SGR with this approach.", "AI": {"tldr": "Proposes a sensor-free scatterer geometric reconstruction method using CSI instead of traditional sensors, enhanced with matched filtering and multi-frequency LSM to improve robustness with limited aperture arrays.", "motivation": "Digital twin requires SGR for 6G systems, but traditional methods need extra sensors like cameras/LiDAR. With ISAC in 6G, there's opportunity to use wireless channel characteristics for sensor-free SGR.", "method": "Reinterprets linear sampling method from wireless channel viewpoint, using CSI to replace scattered field measurements. Proposes matched filtering enhanced multi-frequency LSM (MF MLSM) with multi-frequency data for diversity and matched filtering for phase alignment.", "result": "Experiments with apertures of 93.6\u00b0, 144\u00b0, and 180\u00b0 and SNRs of 27 dB and 12 dB demonstrate robust SGR performance.", "conclusion": "The proposed MF MLSM approach enables robust sensor-free scatterer geometric reconstruction suitable for 6G digital twin applications."}}
{"id": "2510.17544", "categories": ["cs.IT", "cs.FL", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17544", "abs": "https://arxiv.org/abs/2510.17544", "authors": ["Neil Lutz"], "title": "Multihead Finite-State Compression", "comment": null, "summary": "This paper develops multihead finite-state compression, a generalization of\nfinite-state compression, complementary to the multihead finite-state\ndimensions of Huang, Li, Lutz, and Lutz (2025). In this model, an infinite\nsequence of symbols is compressed by a compressor that produces outputs\naccording to finite-state rules, based on the symbols read by a constant number\nof finite-state read heads moving forward obliviously through the sequence. The\nmain theorem of this work establishes that for every sequence and every\npositive integer $h$, the infimum of the compression ratios achieved by\n$h$-head finite-state information-lossless compressors equals the $h$-head\nfinite-state predimension of the sequence. As an immediate corollary, the\ninfimum of these ratios over all $h$ is the multihead finite-state dimension of\nthe sequence.", "AI": {"tldr": "This paper introduces multihead finite-state compression, a generalization of finite-state compression where compressors use multiple read heads to compress sequences. The main result shows that for any sequence and number of heads h, the optimal compression ratio equals the h-head finite-state predimension of the sequence.", "motivation": "To extend finite-state compression theory by incorporating multiple read heads, complementing recent work on multihead finite-state dimensions. This provides a more powerful compression model that can better capture sequence complexity.", "method": "Develops a multihead finite-state compression model where compressors use h finite-state read heads moving obliviously forward through sequences. The compressors produce outputs based on finite-state rules applied to symbols read by multiple heads.", "result": "The main theorem proves that for every sequence and positive integer h, the infimum compression ratio achieved by h-head finite-state compressors equals the h-head finite-state predimension of the sequence. As a corollary, the infimum over all h equals the multihead finite-state dimension.", "conclusion": "Multihead finite-state compression provides a natural generalization of finite-state compression that aligns perfectly with multihead finite-state dimension theory, establishing fundamental connections between compression ratios and sequence complexity measures."}}
{"id": "2510.16134", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16134", "abs": "https://arxiv.org/abs/2510.16134", "authors": ["Chen Kong", "James Fort", "Aria Kang", "Jonathan Wittmer", "Simon Green", "Tianwei Shen", "Yipu Zhao", "Cheng Peng", "Gustavo Solaira", "Andrew Berkovich", "Nikhil Raina", "Vijay Baiyya", "Evgeniy Oleinik", "Eric Huang", "Fan Zhang", "Julian Straub", "Mark Schwesinger", "Luis Pesqueira", "Xiaqing Pan", "Jakob Julian Engel", "Carl Ren", "Mingfei Yan", "Richard Newcombe"], "title": "Aria Gen 2 Pilot Dataset", "comment": null, "summary": "The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal open dataset\ncaptured using the state-of-the-art Aria Gen 2 glasses. To facilitate timely\naccess, A2PD is released incrementally with ongoing dataset enhancements. The\ninitial release features Dia'ane, our primary subject, who records her daily\nactivities alongside friends, each equipped with Aria Gen 2 glasses. It\nencompasses five primary scenarios: cleaning, cooking, eating, playing, and\noutdoor walking. In each of the scenarios, we provide comprehensive raw sensor\ndata and output data from various machine perception algorithms. These data\nillustrate the device's ability to perceive the wearer, the surrounding\nenvironment, and interactions between the wearer and the environment, while\nmaintaining robust performance across diverse users and conditions. The A2PD is\npublicly available at projectaria.com, with open-source tools and usage\nexamples provided in Project Aria Tools.", "AI": {"tldr": "The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal dataset captured using Aria Gen 2 glasses, featuring daily activities across five scenarios with comprehensive sensor and perception data.", "motivation": "To provide timely access to a state-of-the-art egocentric multimodal dataset for research, with incremental releases and ongoing enhancements.", "method": "Dataset captured using Aria Gen 2 glasses with primary subject Dia'ane recording daily activities alongside friends, covering five scenarios: cleaning, cooking, eating, playing, and outdoor walking.", "result": "Comprehensive raw sensor data and output from machine perception algorithms that demonstrate the device's ability to perceive the wearer, environment, and interactions while maintaining robust performance across diverse users and conditions.", "conclusion": "A2PD is publicly available at projectaria.com with open-source tools and usage examples in Project Aria Tools, providing a valuable resource for egocentric multimodal research."}}
{"id": "2510.15961", "categories": ["cs.LG", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.15961", "abs": "https://arxiv.org/abs/2510.15961", "authors": ["Yiyang Li", "Zehong Wang", "Zhengqing Yuan", "Zheyuan Zhang", "Keerthiram Murugesan", "Chuxu Zhang", "Yanfang Ye"], "title": "Interpretable Graph-Language Modeling for Detecting Youth Illicit Drug Use", "comment": null, "summary": "Illicit drug use among teenagers and young adults (TYAs) remains a pressing\npublic health concern, with rising prevalence and long-term impacts on health\nand well-being. To detect illicit drug use among TYAs, researchers analyze\nlarge-scale surveys such as the Youth Risk Behavior Survey (YRBS) and the\nNational Survey on Drug Use and Health (NSDUH), which preserve rich\ndemographic, psychological, and environmental factors related to substance use.\nHowever, existing modeling methods treat survey variables independently,\noverlooking latent and interconnected structures among them. To address this\nlimitation, we propose LAMI (LAtent relation Mining with bi-modal\nInterpretability), a novel joint graph-language modeling framework for\ndetecting illicit drug use and interpreting behavioral risk factors among TYAs.\nLAMI represents individual responses as relational graphs, learns latent\nconnections through a specialized graph structure learning layer, and\nintegrates a large language model to generate natural language explanations\ngrounded in both graph structures and survey semantics. Experiments on the YRBS\nand NSDUH datasets show that LAMI outperforms competitive baselines in\npredictive accuracy. Interpretability analyses further demonstrate that LAMI\nreveals meaningful behavioral substructures and psychosocial pathways, such as\nfamily dynamics, peer influence, and school-related distress, that align with\nestablished risk factors for substance use.", "AI": {"tldr": "LAMI is a joint graph-language modeling framework that detects illicit drug use among teenagers and young adults by learning latent connections in survey data and generating interpretable explanations.", "motivation": "Existing methods treat survey variables independently, overlooking latent and interconnected structures among demographic, psychological, and environmental factors related to substance use.", "method": "LAMI represents individual responses as relational graphs, learns latent connections through a specialized graph structure learning layer, and integrates a large language model to generate natural language explanations.", "result": "Experiments on YRBS and NSDUH datasets show LAMI outperforms competitive baselines in predictive accuracy and reveals meaningful behavioral substructures and psychosocial pathways.", "conclusion": "LAMI effectively detects illicit drug use while providing interpretable insights into established risk factors like family dynamics, peer influence, and school-related distress."}}
{"id": "2510.16004", "categories": ["cs.AI", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.16004", "abs": "https://arxiv.org/abs/2510.16004", "authors": ["Andreas Radler", "Vincent Seyfried", "Stefan Pirker", "Johannes Brandstetter", "Thomas Lichtenegger"], "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction", "comment": "22 pages, 16 figures", "summary": "Neural surrogates have shown great potential in simulating dynamical systems,\nwhile offering real-time capabilities. We envision Neural Twins as a\nprogression of neural surrogates, aiming to create digital replicas of real\nsystems. A neural twin consumes measurements at test time to update its state,\nthereby enabling context-specific decision-making. A critical property of\nneural twins is their ability to remain on-trajectory, i.e., to stay close to\nthe true system state over time. We introduce Parallel-in-time Neural Twins\n(PAINT), an architecture-agnostic family of methods for modeling dynamical\nsystems from measurements. PAINT trains a generative neural network to model\nthe distribution of states parallel over time. At test time, states are\npredicted from measurements in a sliding window fashion. Our theoretical\nanalysis shows that PAINT is on-trajectory, whereas autoregressive models\ngenerally are not. Empirically, we evaluate our method on a challenging\ntwo-dimensional turbulent fluid dynamics problem. The results demonstrate that\nPAINT stays on-trajectory and predicts system states from sparse measurements\nwith high fidelity. These findings underscore PAINT's potential for developing\nneural twins that stay on-trajectory, enabling more accurate state estimation\nand decision-making.", "AI": {"tldr": "PAINT introduces parallel-in-time neural twins for dynamical systems that stay on-trajectory by modeling state distributions over time windows, enabling accurate state estimation from sparse measurements.", "motivation": "To create neural twins that can maintain accurate system state over time by consuming real-time measurements, addressing the limitation of traditional neural surrogates that often drift off-trajectory.", "method": "PAINT trains generative neural networks to model state distributions parallel over time, using sliding window predictions from measurements at test time. The architecture-agnostic approach ensures on-trajectory performance.", "result": "Empirical evaluation on turbulent fluid dynamics shows PAINT maintains on-trajectory performance and predicts system states from sparse measurements with high fidelity, outperforming autoregressive models.", "conclusion": "PAINT enables development of neural twins that stay on-trajectory, providing more accurate state estimation and decision-making capabilities for dynamical systems."}}
{"id": "2510.16397", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16397", "abs": "https://arxiv.org/abs/2510.16397", "authors": ["Yiming Xu", "Dongfang Xu", "Shenghui Song", "Dusit Niyato"], "title": "Adaptive Sensing Performance Design for Enhancing Secure Communication in Networked ISAC Systems", "comment": "16 pages", "summary": "The channel state information (CSI) of an eavesdropper is crucial for\nphysical layer security (PLS) design, but it is difficult to obtain due to the\npassive and non-cooperative nature of the eavesdropper. To this end, integrated\nsensing and communication (ISAC) offers a novel solution by estimating the CSI\nof the eavesdropper based on sensing information. However, existing studies\nnormally impose explicit and fixed sensing performance requirement without\nconsidering the varying communication conditions, which hinders the system from\nfully exploiting the synergy between sensing and communication. To address this\nissue, this paper proposes sensing-enhanced secure communication with adaptive\nsensing performance. Specifically, we formulate the sensing performance\nimplicitly in the information leakage rate and adaptively optimize it for the\nminimization of the power consumption, offering enhanced flexibility and\nadaptability in sensing performance. We consider both centralized and\ndecentralized designs to thoroughly investigate the impact of network structure\non system performance and complexity. Specifically, we devise a block\ncoordinate descent (BCD)-based method for centralized design. For decentralized\ndesign, we develop an optimization framework based on consensus alternating\ndirection method of multipliers (ADMM) to reduce complexity and information\nexchange overhead. Experimental results demonstrate the advantage of the\nproposed implicit sensing performance requirement design due to its capability\nto adaptively adjust the sensing performance to enhance the system performance\nfor varying system configurations.", "AI": {"tldr": "This paper proposes sensing-enhanced secure communication with adaptive sensing performance for physical layer security, using integrated sensing and communication to estimate eavesdropper CSI and formulating sensing performance implicitly in information leakage rate.", "motivation": "Traditional PLS designs struggle to obtain eavesdropper CSI due to their passive nature, and existing ISAC approaches impose fixed sensing requirements without considering varying communication conditions, limiting the synergy between sensing and communication.", "method": "Proposes implicit sensing performance formulation in information leakage rate with adaptive optimization for power minimization. Develops both centralized (BCD-based) and decentralized (consensus ADMM-based) designs to investigate network structure impact.", "result": "Experimental results show the proposed implicit sensing performance requirement design adaptively adjusts sensing performance to enhance system performance across varying configurations, outperforming fixed requirement approaches.", "conclusion": "The adaptive sensing performance design offers enhanced flexibility and adaptability, with both centralized and decentralized approaches providing effective solutions for sensing-enhanced secure communication systems."}}
{"id": "2510.17613", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17613", "abs": "https://arxiv.org/abs/2510.17613", "authors": ["MohammadHossein Alishahi", "Ming Zeng", "Paul Fortier", "Ji Wang", "Nian Xia", "Gongpu Wang"], "title": "Mode Switching-based STAR-RIS with Discrete Phase Shifters", "comment": "accepted by IEEE WCL", "summary": "The increasing demand for cost-effective, high-speed Internet of Things (IoT)\napplications in the coming sixth-generation (6G) networks has driven research\ntoward maximizing spectral efficiency and simplifying hardware designs. In this\ncontext, we investigate the sum rate maximization problem for a mode-switching\ndiscrete-phase shifters simultaneously transmitting and reflecting\nreconfigurable intelligent surface (STAR-RIS)-aided multi-antenna access point\nnetwork, emphasizing hardware efficiency and reduced cost. A mixed-integer\nnonlinear optimization framework is formulated for joint optimization of the\nactive beamforming matrix, user power allocation, and STAR-RIS phase shift\nvectors, including binary transmission/reflection amplitudes and discrete phase\nshifters. To solve the formulated problem, we employ a block coordinate descent\nmethod, dividing it into three subproblems tackled using difference-of-concave\nprogramming and combinatorial optimization techniques. Numerical results\nvalidate the effectiveness of the proposed joint optimization approach,\nconsistently achieving superior sum rate performance compared to partial\noptimization methods, thereby underscoring its potential for efficient and\nscalable 6G IoT systems.", "AI": {"tldr": "Joint optimization of active beamforming, power allocation, and STAR-RIS phase shifts for sum rate maximization in 6G IoT networks using mixed-integer nonlinear programming and block coordinate descent.", "motivation": "Address the need for cost-effective, high-speed IoT applications in 6G networks by maximizing spectral efficiency and simplifying hardware designs with STAR-RIS technology.", "method": "Formulated mixed-integer nonlinear optimization framework solved via block coordinate descent method with difference-of-concave programming and combinatorial optimization techniques.", "result": "Proposed joint optimization achieves superior sum rate performance compared to partial optimization methods, validated through numerical results.", "conclusion": "The approach demonstrates potential for efficient and scalable 6G IoT systems with improved spectral efficiency and hardware efficiency."}}
{"id": "2510.16136", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.16136", "abs": "https://arxiv.org/abs/2510.16136", "authors": ["Sayan Deb Sarkar", "Sinisa Stekovic", "Vincent Lepetit", "Iro Armeni"], "title": "GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer", "comment": "NeurIPS 2025. Project Page: https://sayands.github.io/guideflow3d/", "summary": "Transferring appearance to 3D assets using different representations of the\nappearance object - such as images or text - has garnered interest due to its\nwide range of applications in industries like gaming, augmented reality, and\ndigital content creation. However, state-of-the-art methods still fail when the\ngeometry between the input and appearance objects is significantly different. A\nstraightforward approach is to directly apply a 3D generative model, but we\nshow that this ultimately fails to produce appealing results. Instead, we\npropose a principled approach inspired by universal guidance. Given a\npretrained rectified flow model conditioned on image or text, our training-free\nmethod interacts with the sampling process by periodically adding guidance.\nThis guidance can be modeled as a differentiable loss function, and we\nexperiment with two different types of guidance including part-aware losses for\nappearance and self-similarity. Our experiments show that our approach\nsuccessfully transfers texture and geometric details to the input 3D asset,\noutperforming baselines both qualitatively and quantitatively. We also show\nthat traditional metrics are not suitable for evaluating the task due to their\ninability of focusing on local details and comparing dissimilar inputs, in\nabsence of ground truth data. We thus evaluate appearance transfer quality with\na GPT-based system objectively ranking outputs, ensuring robust and human-like\nassessment, as further confirmed by our user study. Beyond showcased scenarios,\nour method is general and could be extended to different types of diffusion\nmodels and guidance functions.", "AI": {"tldr": "A training-free method for transferring appearance to 3D assets using universal guidance with pretrained rectified flow models, overcoming geometry mismatch issues through periodic guidance addition during sampling.", "motivation": "Current methods fail when geometry between input and appearance objects differs significantly, and direct 3D generative models produce unappealing results. Need for robust appearance transfer across different representations (images/text) for gaming, AR, and digital content creation.", "method": "Uses pretrained rectified flow model conditioned on image/text, interacts with sampling process by periodically adding differentiable guidance modeled as loss functions (part-aware appearance loss and self-similarity loss). Training-free approach.", "result": "Successfully transfers texture and geometric details to 3D assets, outperforming baselines qualitatively and quantitatively. Traditional metrics unsuitable, so uses GPT-based system for objective ranking, confirmed by user study.", "conclusion": "Proposed principled approach effectively handles appearance transfer despite geometric differences. Method is generalizable to different diffusion models and guidance functions beyond showcased scenarios."}}
{"id": "2510.15962", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15962", "abs": "https://arxiv.org/abs/2510.15962", "authors": ["Zhuxuanzi Wang", "Mingqiao Mo", "Xi Xiao", "Chen Liu", "Chenrui Ma", "Yunbei Zhang", "Xiao Wang", "Smita Krishnaswamy", "Tianyang Wang"], "title": "CTR-LoRA: Curvature-Aware and Trust-Region Guided Low-Rank Adaptation for Large Language Models", "comment": null, "summary": "Parameter-efficient fine-tuning (PEFT) has become the standard approach for\nadapting large language models under limited compute and memory budgets.\nAlthough previous methods improve efficiency through low-rank updates,\nquantization, or heuristic budget reallocation, they often decouple the\nallocation of capacity from the way updates evolve during training. In this\nwork, we introduce CTR-LoRA, a framework guided by curvature trust region that\nintegrates rank scheduling with stability-aware optimization. CTR-LoRA\nallocates parameters based on marginal utility derived from lightweight\nsecond-order proxies and constrains updates using a Fisher/Hessian-metric trust\nregion. Experiments on multiple open-source backbones (7B-13B), evaluated on\nboth in-distribution and out-of-distribution benchmarks, show consistent\nimprovements over strong PEFT baselines. In addition to increased accuracy,\nCTR-LoRA enhances training stability, reduces memory requirements, and achieves\nhigher throughput, positioning it on the Pareto frontier of performance and\nefficiency. These results highlight a principled path toward more robust and\ndeployable PEFT.", "AI": {"tldr": "CTR-LoRA is a parameter-efficient fine-tuning framework that integrates rank scheduling with stability-aware optimization using curvature trust regions, achieving better performance and efficiency than existing PEFT methods.", "motivation": "Existing PEFT methods often decouple capacity allocation from how updates evolve during training, leading to suboptimal performance and efficiency.", "method": "CTR-LoRA uses curvature trust region guidance to allocate parameters based on marginal utility from second-order proxies and constrains updates using Fisher/Hessian-metric trust regions.", "result": "Experiments on 7B-13B models show consistent improvements over strong PEFT baselines on both in-distribution and out-of-distribution benchmarks, with enhanced training stability, reduced memory requirements, and higher throughput.", "conclusion": "CTR-LoRA provides a principled path toward more robust and deployable PEFT, positioning it on the Pareto frontier of performance and efficiency."}}
{"id": "2510.16033", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16033", "abs": "https://arxiv.org/abs/2510.16033", "authors": ["Junyu Ren", "Wensheng Gan", "Guangyu Zhang", "Wei Zhong", "Philip S. Yu"], "title": "Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis", "comment": "Preprint. 16 figures, 12 tables", "summary": "Existing transfer fault diagnosis methods typically assume either clean data\nor sufficient domain similarity, which limits their effectiveness in industrial\nenvironments where severe noise interference and domain shifts coexist. To\naddress this challenge, we propose an information separation global-focal\nadversarial network (ISGFAN), a robust framework for cross-domain fault\ndiagnosis under noise conditions. ISGFAN is built on an information separation\narchitecture that integrates adversarial learning with an improved orthogonal\nloss to decouple domain-invariant fault representation, thereby isolating noise\ninterference and domain-specific characteristics. To further strengthen\ntransfer robustness, ISGFAN employs a global-focal domain-adversarial scheme\nthat constrains both the conditional and marginal distributions of the model.\nSpecifically, the focal domain-adversarial component mitigates\ncategory-specific transfer obstacles caused by noise in unsupervised scenarios,\nwhile the global domain classifier ensures alignment of the overall\ndistribution. Experiments conducted on three public benchmark datasets\ndemonstrate that the proposed method outperforms other prominent existing\napproaches, confirming the superiority of the ISGFAN framework. Data and code\nare available at https://github.com/JYREN-Source/ISGFAN", "AI": {"tldr": "Proposes ISGFAN framework for robust cross-domain fault diagnosis under noise conditions using information separation and global-focal adversarial learning.", "motivation": "Existing methods assume clean data or sufficient domain similarity, limiting effectiveness in industrial environments with severe noise and domain shifts.", "method": "Information separation architecture with adversarial learning and improved orthogonal loss to decouple domain-invariant fault representation, plus global-focal domain-adversarial scheme for conditional and marginal distribution alignment.", "result": "Outperforms other prominent approaches on three public benchmark datasets, demonstrating superiority of ISGFAN framework.", "conclusion": "ISGFAN effectively addresses noise interference and domain shifts in cross-domain fault diagnosis, providing robust transfer learning capability for industrial applications."}}
{"id": "2510.16482", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16482", "abs": "https://arxiv.org/abs/2510.16482", "authors": ["Romulo Aparecido", "Jiaqian Yang", "Ronit Sohanpal", "Zelin Gan", "Eric Sillekens", "John D. Downie", "Lidia Galdino", "Vitaly Mikhailov", "Daniel Elson", "Yuta Wakayama", "David DiGiovanni", "Jiawei Luo", "Robert I. Killey", "Polina Bayvel"], "title": "Single-Step Digital Backpropagation for O-band Coherent Transmission Systems", "comment": "conference, 3 pages, 2 figures", "summary": "We demonstrate digital backpropagation-based compensation of fibre\nnonlinearities in the near-zero dispersion regime of the O-band. Single-step\nDBP effectively mitigates self-phase modulation, achieving SNR gains of up to\n1.6 dB for 50 Gbaud PDM-256QAM transmission over a 2-span 151 km SMF-28 ULL\nfibre link.", "AI": {"tldr": "Digital backpropagation compensates fiber nonlinearities in O-band near-zero dispersion regime, achieving 1.6 dB SNR gain for 50 Gbaud PDM-256QAM over 151 km fiber.", "motivation": "To address fiber nonlinearities, particularly self-phase modulation, in the near-zero dispersion regime of the O-band for high-speed optical communication systems.", "method": "Single-step digital backpropagation (DBP) technique applied to compensate fiber nonlinearities in a 2-span 151 km SMF-28 ULL fiber link.", "result": "Effective mitigation of self-phase modulation with SNR gains up to 1.6 dB for 50 Gbaud PDM-256QAM transmission.", "conclusion": "Digital backpropagation is an effective method for nonlinearity compensation in near-zero dispersion O-band transmission systems."}}
{"id": "2510.17625", "categories": ["cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17625", "abs": "https://arxiv.org/abs/2510.17625", "authors": ["Jaehyup Seong", "Byungju Lee", "Aryan Kaushik", "Wonjae Shin"], "title": "Space-Time Rate-Splitting Multiple Access for Multibeam LEO Satellite Networks", "comment": "17 pages, 3 figures, accepted for publication in IEEE Transactions on\n  Vehicular Technology", "summary": "This paper proposes a novel space-time rate-splitting multiple access\n(ST-RSMA) framework for multibeam low Earth orbit (LEO) satellite\ncommunications (SATCOM) systems, where space-time coding is integrated into the\ncommon stream transmission. This design enables full diversity gain in the\ncommon stream transmission for all users, regardless of the uncertainty of the\nchannel state information (CSI) and network load conditions, thereby overcoming\nthe performance limitations of conventional RSMA that employs a single\nbeamforming vector for all users. To further enhance performance, we develop a\nweighted minimum mean square error (WMMSE)-based algorithm tailored to ST-RSMA\nthat jointly optimizes the power allocation for the common stream and the\npower/beamforming vectors for private streams, aiming to maximize the minimum\nuser rate. Numerical results show that ST-RSMA significantly outperforms\nconventional RSMA and other multiple access techniques, offering a robust and\nscalable solution for LEO SATCOM.", "AI": {"tldr": "Proposes ST-RSMA framework integrating space-time coding with RSMA for LEO satellite communications, achieving full diversity gain and robust performance under CSI uncertainty and varying network loads.", "motivation": "To overcome performance limitations of conventional RSMA that uses single beamforming vector for all users, which fails to provide diversity gain under channel uncertainty and varying network conditions in LEO SATCOM systems.", "method": "Integrates space-time coding into common stream transmission of RSMA, and develops WMMSE-based algorithm to jointly optimize power allocation for common stream and power/beamforming vectors for private streams to maximize minimum user rate.", "result": "Numerical results show ST-RSMA significantly outperforms conventional RSMA and other multiple access techniques in LEO SATCOM scenarios.", "conclusion": "ST-RSMA offers a robust and scalable solution for multibeam LEO satellite communications, providing full diversity gain regardless of CSI uncertainty and network load conditions."}}
{"id": "2510.16145", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16145", "abs": "https://arxiv.org/abs/2510.16145", "authors": ["Ahmad Arrabi", "Jay hwasung Jung", "J Le", "A Nguyen", "J Reed", "E Stahl", "Nathan Franssen", "Scott Raymond", "Safwan Wshah"], "title": "C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy", "comment": null, "summary": "Thrombectomy is one of the most effective treatments for ischemic stroke, but\nit is resource and personnel-intensive. We propose employing deep learning to\nautomate critical aspects of thrombectomy, thereby enhancing efficiency and\nsafety. In this work, we introduce a self-supervised framework that classifies\nvarious skeletal landmarks using a regression-based pretext task. Our\nexperiments demonstrate that our model outperforms existing methods in both\nregression and classification tasks. Notably, our results indicate that the\npositional pretext task significantly enhances downstream classification\nperformance. Future work will focus on extending this framework toward fully\nautonomous C-arm control, aiming to optimize trajectories from the pelvis to\nthe head during stroke thrombectomy procedures. All code used is available at\nhttps://github.com/AhmadArrabi/C_arm_guidance", "AI": {"tldr": "Deep learning framework for automating thrombectomy procedures using self-supervised landmark classification with regression pretext tasks, showing improved performance over existing methods.", "motivation": "To enhance efficiency and safety of thrombectomy procedures by automating critical aspects through deep learning, addressing the resource-intensive nature of current treatments.", "method": "Self-supervised framework that classifies skeletal landmarks using regression-based pretext tasks, with positional pretext tasks improving downstream classification.", "result": "Model outperforms existing methods in both regression and classification tasks, with positional pretext tasks significantly enhancing classification performance.", "conclusion": "The framework shows promise for extending toward fully autonomous C-arm control to optimize trajectories from pelvis to head during thrombectomy procedures."}}
{"id": "2510.15964", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15964", "abs": "https://arxiv.org/abs/2510.15964", "authors": ["Tuowei Wang", "Kun Li", "Zixu Hao", "Donglin Bai", "Ju Ren", "Yaoxue Zhang", "Ting Cao", "Mao Yang"], "title": "Long Exposure: Accelerating Parameter-Efficient Fine-Tuning for LLMs under Shadowy Sparsity", "comment": null, "summary": "The adaptation of pre-trained large language models (LLMs) to diverse\ndownstream tasks via fine-tuning is critical for numerous applications.\nHowever, the inefficiency of parameter-efficient fine-tuning (PEFT) techniques\npresents significant challenges in terms of time investments and operational\ncosts. In this paper, we first introduce a nuanced form of sparsity, termed\nShadowy Sparsity, which is distinctive in fine-tuning and has not been\nadequately addressed for acceleration. Under Shadowy Sparsity, we propose Long\nExposure, an efficient system to accelerate PEFT for LLMs. Long Exposure\ncomprises three key components: Shadowy-sparsity Exposer employs a prolonged\nsensing range to capture more sparsity details under shadowy sparsity;\nSequence-oriented Predictor provides efficient yet accurate predictions to\nhandle large sequence inputs and constantly-evolving parameters; and\nDynamic-aware Operator facilitates more structured computational patterns and\ncoalesced memory accesses, addressing dynamic sparse operations. Extensive\nevaluations show that Long Exposure outperforms state-of-the-arts with up to a\n$2.49\\times$ speedup in end-to-end fine-tuning, offering promising advancements\nin accelerating PEFT for LLMs.", "AI": {"tldr": "Long Exposure is an efficient system that accelerates parameter-efficient fine-tuning (PEFT) for large language models by addressing Shadowy Sparsity through three components: Shadowy-sparsity Exposer, Sequence-oriented Predictor, and Dynamic-aware Operator.", "motivation": "The inefficiency of PEFT techniques presents significant challenges in terms of time investments and operational costs for adapting pre-trained LLMs to downstream tasks.", "method": "The system addresses Shadowy Sparsity with three key components: 1) Shadowy-sparsity Exposer uses prolonged sensing to capture sparsity details, 2) Sequence-oriented Predictor handles large sequences and evolving parameters, and 3) Dynamic-aware Operator improves computational patterns and memory access.", "result": "Long Exposure achieves up to 2.49\u00d7 speedup in end-to-end fine-tuning compared to state-of-the-art methods.", "conclusion": "The system offers promising advancements in accelerating PEFT for LLMs by effectively addressing the unique challenges of Shadowy Sparsity in fine-tuning."}}
{"id": "2510.16047", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16047", "abs": "https://arxiv.org/abs/2510.16047", "authors": ["Ioan Hedea"], "title": "Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks", "comment": "8 pages 2 column, 11 figures. Bachelor's thesis", "summary": "Modern manufacturing systems must meet hard delivery deadlines while coping\nwith stochastic task durations caused by process noise, equipment variability,\nand human intervention. Traditional deterministic schedules break down when\nreality deviates from nominal plans, triggering costly last-minute repairs.\nThis thesis combines offline constraint-programming (CP) optimisation with\nonline temporal-network execution to create schedules that remain feasible\nunder worst-case uncertainty. First, we build a CP model of the flexible\njob-shop with per-job deadline tasks and insert an optimal buffer $\\Delta^*$ to\nobtain a fully pro-active baseline. We then translate the resulting plan into a\nSimple Temporal Network with Uncertainty (STNU) and verify dynamic\ncontrollability, which guarantees that a real-time dispatcher can retime\nactivities for every bounded duration realisation without violating resource or\ndeadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4\nbenchmark suite show that our hybrid approach eliminates 100\\% of deadline\nviolations observed in state-of-the-art meta-heuristic schedules, while adding\nonly 3--5\\% makespan overhead. Scalability experiments confirm that CP\nsolve-times and STNU checks remain sub-second on medium-size instances. The\nwork demonstrates how temporal-network reasoning can bridge the gap between\nproactive buffering and dynamic robustness, moving industry a step closer to\ntruly digital, self-correcting factories.", "AI": {"tldr": "This paper presents a hybrid approach combining offline constraint programming optimization with online temporal-network execution to create robust manufacturing schedules that remain feasible under worst-case uncertainty, eliminating deadline violations while adding minimal makespan overhead.", "motivation": "Traditional deterministic schedules fail when reality deviates from nominal plans due to stochastic task durations caused by process noise, equipment variability, and human intervention, leading to costly last-minute repairs.", "method": "Build a CP model of flexible job-shop with per-job deadline tasks, insert optimal buffer, translate plan into Simple Temporal Network with Uncertainty (STNU), verify dynamic controllability, and use real-time dispatcher for retiming activities.", "result": "Eliminates 100% of deadline violations observed in state-of-the-art meta-heuristic schedules while adding only 3-5% makespan overhead. CP solve-times and STNU checks remain sub-second on medium-size instances.", "conclusion": "Temporal-network reasoning bridges the gap between proactive buffering and dynamic robustness, moving toward truly digital, self-correcting factories."}}
{"id": "2510.16495", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16495", "abs": "https://arxiv.org/abs/2510.16495", "authors": ["Muhammad Khalil", "Ke Wang", "Jinho Choi"], "title": "Performance Evaluation of High Power Microwave Systems Against UAVs A Probabilistic Antenna Propagation Framework with Sensitivity Analysis", "comment": "10", "summary": "We develop a probabilistic, antenna- and propagation-centric framework to\nquantify the effectiveness of high-power microwave (HPM) engagements against\nunmanned aerial vehicles (UAVs). The model couples stochastic UAV kinematics, a\nbeam-steering jitter-to-gain mapping, and atmospheric propagation (free-space\nspreading with gaseous and rain loss) to obtain closed-form statistics of the\nreceived pulse energy. From these, we derive analytically evaluable per-pulse\nand cumulative neutralization probabilities using log-normal closures and\nGaussian--Hermite quadrature, and we provide a dwell-time expression under a\nstandard pulse-independence assumption. Analytical predictions closely match\nlarge-scale Monte-Carlo simulations across broad parameter ranges. For a\nrepresentative commercial threshold $E_{\\mathrm{th}} = 10^{-2}\\,\\mathrm{J}$,\nthe model predicts $\\bar{P}_{\\mathrm{kill}} \\gtrsim 0.4$ per pulse and\n$P_{\\mathrm{kill,tot}} > 99\\%$ within about $0.1\\,\\mathrm{s}$ at kHz PRF; for\nhardened platforms with $E_{\\mathrm{th}} = 10^{-1}\\,\\mathrm{J}$,\n$\\bar{P}_{\\mathrm{kill}} < 1\\%$ and $P_{\\mathrm{kill,tot}} < 20\\%$ after\n$1\\,\\mathrm{s}$. A closed-form sensitivity (elasticity) analysis shows\nperformance is dominated by slant range ($S_{\\bar{R}} \\approx -2$), with strong\nsecondary dependence on aperture diameter and transmit power; pointing jitter\nand atmospheric variability are comparatively less influential in the evaluated\nregimes. The framework yields fast, accurate, and physics-faithful performance\npredictions and exposes clear antenna/propagation design levers for HPM system\nsizing and risk-aware mission planning.", "AI": {"tldr": "A probabilistic framework for quantifying HPM effectiveness against UAVs, combining stochastic kinematics, beam steering, and atmospheric propagation to derive closed-form neutralization probabilities.", "motivation": "To develop a fast, accurate method for predicting HPM system performance against UAVs that captures key physics while avoiding computationally expensive Monte Carlo simulations.", "method": "Probabilistic framework coupling stochastic UAV kinematics, beam-steering jitter-to-gain mapping, and atmospheric propagation to obtain closed-form statistics of received pulse energy, using log-normal closures and Gaussian-Hermite quadrature.", "result": "Model predicts high neutralization probabilities (>99% within 0.1s) for commercial UAVs but low effectiveness (<20%) against hardened platforms; sensitivity analysis shows range is the dominant factor.", "conclusion": "The framework provides fast, accurate performance predictions and identifies key design parameters (range, aperture diameter, transmit power) for HPM system optimization and mission planning."}}
{"id": "2510.17781", "categories": ["cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.17781", "abs": "https://arxiv.org/abs/2510.17781", "authors": ["Hua Sun", "Syed A. Jafar"], "title": "On the Capacity of Erasure-prone Quantum Storage with Erasure-prone Entanglement Assistance", "comment": null, "summary": "A quantum message is encoded into $N$ storage nodes (quantum systems\n$Q_1\\dots Q_N$) with assistance from $N_B$ maximally entangled bi-partite\nquantum systems $A_1B_1, \\dots, A_{N_B}B_{N_B}$, that are prepared in advance\nsuch that $B_1\\dots B_{N_B}$ are stored separately as entanglement assistance\n(EA) nodes, while $A_1\\dots A_{N_B}$ are made available to the encoder. Both\nthe storage nodes and EA nodes are erasure-prone. The quantum message must be\nrecoverable given any $K$ of the $N$ storage nodes along with any $K_B$ of the\n$N_B$ EA nodes. The capacity for this setting is the maximum size of the\nquantum message, given that the size of each EA node is $\\lambda_B$. All node\nsizes are relative to the size of a storage node, which is normalized to unity.\nThe exact capacity is characterized as a function of $N,K,N_B,K_B, \\lambda_B$\nin all cases, with one exception. The capacity remains open for an intermediate\nrange of $\\lambda_B$ values when a strict majority of the $N$ storage nodes,\nand a strict non-zero minority of the $N_B$ EA nodes, are erased. As a key\nstepping stone, an analogous classical storage (with shared-randomness\nassistance) problem is introduced. A set of constraints is identified for the\nclassical problem, such that classical linear code constructions translate to\nquantum storage codes, and the converse bounds for the two settings utilize\nsimilar insights. In particular, the capacity characterizations for the\nclassical and quantum settings are shown to be identical in all cases where the\ncapacity is settled.", "AI": {"tldr": "This paper characterizes the capacity of quantum distributed storage systems with entanglement assistance, where quantum messages are encoded across N storage nodes and NB entanglement assistance nodes with erasure tolerance requirements.", "motivation": "To understand the fundamental limits of quantum distributed storage systems that use entanglement assistance to enhance reliability against erasures, bridging classical and quantum storage coding theory.", "method": "The authors introduce an analogous classical storage problem with shared-randomness assistance, identify constraints that allow classical linear codes to translate to quantum storage codes, and use converse bounds with similar insights for both classical and quantum settings.", "result": "The exact capacity is characterized as a function of N,K,NB,KB,\u03bbB in all cases except one: when a strict majority of storage nodes and a strict non-zero minority of EA nodes are erased, the capacity remains open for intermediate \u03bbB values.", "conclusion": "The capacity characterizations for classical and quantum storage settings are identical in all settled cases, establishing a strong connection between classical and quantum distributed storage coding theory through the entanglement-assisted framework."}}
{"id": "2510.16146", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16146", "abs": "https://arxiv.org/abs/2510.16146", "authors": ["Thanh-Huy Nguyen", "Hoang-Thien Nguyen", "Vi Vu", "Ba-Thinh Lam", "Phat Huynh", "Tianyang Wang", "Xingjian Li", "Ulas Bagci", "Min Xu"], "title": "DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization", "comment": "The paper is under review at CMIG", "summary": "The limited availability of annotated data in medical imaging makes\nsemi-supervised learning increasingly appealing for its ability to learn from\nimperfect supervision. Recently, teacher-student frameworks have gained\npopularity for their training benefits and robust performance. However, jointly\noptimizing the entire network can hinder convergence and stability, especially\nin challenging scenarios. To address this for medical image segmentation, we\npropose DuetMatch, a novel dual-branch semi-supervised framework with\nasynchronous optimization, where each branch optimizes either the encoder or\ndecoder while keeping the other frozen. To improve consistency under noisy\nconditions, we introduce Decoupled Dropout Perturbation, enforcing\nregularization across branches. We also design Pair-wise CutMix Cross-Guidance\nto enhance model diversity by exchanging pseudo-labels through augmented input\npairs. To mitigate confirmation bias from noisy pseudo-labels, we propose\nConsistency Matching, refining labels using stable predictions from frozen\nteacher models. Extensive experiments on benchmark brain MRI segmentation\ndatasets, including ISLES2022 and BraTS, show that DuetMatch consistently\noutperforms state-of-the-art methods, demonstrating its effectiveness and\nrobustness across diverse semi-supervised segmentation scenarios.", "AI": {"tldr": "DuetMatch is a dual-branch semi-supervised framework for medical image segmentation that uses asynchronous optimization of encoder and decoder branches, with novel regularization and pseudo-label refinement techniques to handle limited annotated data and noisy supervision.", "motivation": "Limited annotated data in medical imaging requires semi-supervised learning, but joint optimization in teacher-student frameworks can cause convergence and stability issues, especially in challenging scenarios.", "method": "Dual-branch architecture with asynchronous optimization (each branch optimizes either encoder or decoder while freezing the other), Decoupled Dropout Perturbation for regularization, Pair-wise CutMix Cross-Guidance for model diversity, and Consistency Matching to refine noisy pseudo-labels using frozen teacher models.", "result": "Extensive experiments on brain MRI segmentation datasets (ISLES2022 and BraTS) show DuetMatch consistently outperforms state-of-the-art methods across diverse semi-supervised segmentation scenarios.", "conclusion": "DuetMatch demonstrates effectiveness and robustness in medical image segmentation, addressing key challenges in semi-supervised learning through its novel dual-branch architecture and regularization techniques."}}
{"id": "2510.15965", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.15965", "abs": "https://arxiv.org/abs/2510.15965", "authors": ["Mohan Zhang", "Yihua Zhang", "Jinghan Jia", "Zhangyang Wang", "Sijia Liu", "Tianlong Chen"], "title": "One Token Embedding Is Enough to Deadlock Your Large Reasoning Model", "comment": "NeurIPS 2025", "summary": "Modern large reasoning models (LRMs) exhibit impressive multi-step\nproblem-solving via chain-of-thought (CoT) reasoning. However, this iterative\nthinking mechanism introduces a new vulnerability surface. We present the\nDeadlock Attack, a resource exhaustion method that hijacks an LRM's generative\ncontrol flow by training a malicious adversarial embedding to induce perpetual\nreasoning loops. Specifically, the optimized embedding encourages transitional\ntokens (e.g., \"Wait\", \"But\") after reasoning steps, preventing the model from\nconcluding its answer. A key challenge we identify is the\ncontinuous-to-discrete projection gap: na\\\"ive projections of adversarial\nembeddings to token sequences nullify the attack. To overcome this, we\nintroduce a backdoor implantation strategy, enabling reliable activation\nthrough specific trigger tokens. Our method achieves a 100% attack success rate\nacross four advanced LRMs (Phi-RM, Nemotron-Nano, R1-Qwen, R1-Llama) and three\nmath reasoning benchmarks, forcing models to generate up to their maximum token\nlimits. The attack is also stealthy (in terms of causing negligible utility\nloss on benign user inputs) and remains robust against existing strategies\ntrying to mitigate the overthinking issue. Our findings expose a critical and\nunderexplored security vulnerability in LRMs from the perspective of reasoning\n(in)efficiency.", "AI": {"tldr": "The Deadlock Attack hijacks large reasoning models by inducing perpetual reasoning loops through adversarial embeddings, achieving 100% success rate across multiple models while remaining stealthy and robust.", "motivation": "To expose a critical security vulnerability in large reasoning models' chain-of-thought reasoning mechanism, which introduces a new attack surface through resource exhaustion.", "method": "Train malicious adversarial embeddings that induce transitional tokens after reasoning steps, combined with a backdoor implantation strategy to overcome the continuous-to-discrete projection gap.", "result": "100% attack success rate across four advanced LRMs and three math reasoning benchmarks, forcing models to generate up to maximum token limits while causing negligible utility loss on benign inputs.", "conclusion": "Chain-of-thought reasoning in large models creates a significant security vulnerability through reasoning inefficiency that current mitigation strategies cannot effectively address."}}
{"id": "2510.16095", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16095", "abs": "https://arxiv.org/abs/2510.16095", "authors": ["Dou Liu", "Ying Long", "Sophia Zuoqiu", "Di Liu", "Kang Li", "Yiting Lin", "Hanyi Liu", "Rong Yin", "Tian Tang"], "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study", "comment": null, "summary": "Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for\nexplainable medical Artificial Intelligence (AI) while constrained by data\nscarcity. Although Large Language Models (LLMs) can synthesize medical data,\ntheir clinical reliability remains unverified. This study evaluates the\nreliability of LLM-generated CoTs and investigates prompting strategies to\nenhance their quality. In a blinded comparative study, senior clinicians in\nAssisted Reproductive Technology (ART) evaluated CoTs generated via three\ndistinct strategies: Zero-shot, Random Few-shot (using shallow examples), and\nSelective Few-shot (using diverse, high-quality examples). These expert ratings\nwere compared against evaluations from a state-of-the-art AI model (GPT-4o).\nThe Selective Few-shot strategy significantly outperformed other strategies\nacross all human evaluation metrics (p < .001). Critically, the Random Few-shot\nstrategy offered no significant improvement over the Zero-shot baseline,\ndemonstrating that low-quality examples are as ineffective as no examples. The\nsuccess of the Selective strategy is attributed to two principles:\n\"Gold-Standard Depth\" (reasoning quality) and \"Representative Diversity\"\n(generalization). Notably, the AI evaluator failed to discern these critical\nperformance differences. The clinical reliability of synthetic CoTs is dictated\nby strategic prompt curation, not the mere presence of examples. We propose a\n\"Dual Principles\" framework as a foundational methodology to generate\ntrustworthy data at scale. This work offers a validated solution to the data\nbottleneck and confirms the indispensable role of human expertise in evaluating\nhigh-stakes clinical AI.", "AI": {"tldr": "This study evaluates LLM-generated clinical Chains-of-Thought (CoTs) reliability and finds that Selective Few-shot prompting with diverse, high-quality examples significantly outperforms other strategies, while AI evaluators fail to detect these critical differences.", "motivation": "Creating high-quality clinical CoTs is crucial for explainable medical AI but constrained by data scarcity, and while LLMs can synthesize medical data, their clinical reliability remains unverified.", "method": "Blinded comparative study where senior clinicians evaluated CoTs generated via three strategies: Zero-shot, Random Few-shot (shallow examples), and Selective Few-shot (diverse, high-quality examples), with comparisons against GPT-4o evaluations.", "result": "Selective Few-shot strategy significantly outperformed other strategies across all human evaluation metrics (p < .001). Random Few-shot offered no improvement over Zero-shot, and AI evaluator failed to discern performance differences.", "conclusion": "Clinical reliability of synthetic CoTs depends on strategic prompt curation, not just examples. Proposed 'Dual Principles' framework (Gold-Standard Depth and Representative Diversity) for generating trustworthy data at scale, confirming human expertise's indispensable role in high-stakes clinical AI evaluation."}}
{"id": "2510.16557", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16557", "abs": "https://arxiv.org/abs/2510.16557", "authors": ["Behrad Mousaei Shir-Mohammad", "Behzad Moshiri", "Abolfazl Yaghmaei"], "title": "Topology-Aware Hybrid Wi-Fi/BLE Fingerprinting via Evidence-Theoretic Fusion and Persistent Homology", "comment": null, "summary": "Indoor localization remains challenging in GNSS-denied environments due to\nmultipath, device heterogeneity, and volatile radio conditions. We propose a\ntopology-aware, hybrid Wi-Fi/BLE fingerprinting framework that (i) applies\nphysically consistent RSS normalization (dBm z-scoring or dBm -> linear mW ->\nz-score), (ii) denoises streams with classical Bayesian filters (KF/UKF/PF),\n(iii) combines complementary regressors (Random Forest and weighted kNN with a\ndiagonal Mahalanobis metric), (iv) performs evidence-theoretic fusion via\nDempster-Shafer theory (DST), and (v) augments each sample with\npersistent-homology (PH) descriptors. The system outputs both (x, y) estimates\nand interpretable belief maps, and is engineered for microcontroller-class\ndeployment with per-update cost O(T log M + log M + Mp + S).\n  We evaluate on two heterogeneous datasets, including a new 1,200-sample ESP32\nsurvey, and report ablations, robustness to test-only noise, and significance\nacross 10 stratified splits. Under 10% synthetic RSS noise, the full pipeline\nattains 3.40 m (Dataset 1) and 2.45 m (Dataset 2) RMSE, improving a strong PF +\nRF baseline by about 37%. Averaged across splits, it yields 4.993 +/- 0.15 m\nversus 6.292 +/- 0.13 m (20.6% relative reduction; p < 0.001). In noise-free\ntests, accuracy tightens to 0.44 m and 0.32 m (up to 56% better). Compared with\nrecent learning-heavy approaches that assume large site-specific datasets and\nGPU inference, our method delivers competitive accuracy with formal uncertainty\nquantification and low computational cost suitable for real-time deployment.", "AI": {"tldr": "A hybrid Wi-Fi/BLE fingerprinting framework for indoor localization that uses RSS normalization, Bayesian filtering, multiple regressors, Dempster-Shafer fusion, and persistent homology to achieve robust positioning with formal uncertainty quantification and low computational cost.", "motivation": "Indoor localization remains challenging in GNSS-denied environments due to multipath effects, device heterogeneity, and volatile radio conditions. Existing approaches often require large datasets and GPU inference, lacking formal uncertainty quantification and computational efficiency.", "method": "Proposes a topology-aware hybrid Wi-Fi/BLE fingerprinting framework with: (i) physically consistent RSS normalization, (ii) Bayesian filtering for denoising, (iii) combination of Random Forest and weighted kNN regressors, (iv) Dempster-Shafer theory fusion, and (v) persistent-homology descriptors for topological features.", "result": "Achieves 3.40 m and 2.45 m RMSE under 10% synthetic RSS noise (37% improvement over baseline), and 0.44 m and 0.32 m in noise-free conditions (up to 56% better). Delivers competitive accuracy with 20.6% relative reduction in error compared to baseline (p < 0.001).", "conclusion": "The method provides competitive indoor localization accuracy with formal uncertainty quantification and low computational cost suitable for real-time deployment on microcontroller-class devices, outperforming both traditional approaches and recent learning-heavy methods."}}
{"id": "2509.01117", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.01117", "abs": "https://arxiv.org/abs/2509.01117", "authors": ["Gyoseung Lee", "Junil Choi"], "title": "A Bayesian Framework For Cascaded Channel Estimation in RIS-Aided mmWave Systems", "comment": "Accepted to IEEE Wireless Communications Letters", "summary": "In this paper, we investigate cascaded channel estimation for reconfigurable\nintelligent surface (RIS)-aided millimeter-wave multi-user communication\nsystems. Since the complex channel gains of the cascaded RIS channel are\ngenerally non-Gaussian, the use of the linear minimum mean squared error\n(LMMSE) estimator leads to inevitable performance degradation. To tackle this\nissue, we propose a variational inference-based framework that approximates the\ncomplex channel gains using a complex adaptive Laplace prior, which effectively\ncaptures their probability distributions in a tractable way. Numerical results\ndemonstrate that the proposed estimator outperforms conventional estimators\nincluding least squares and LMMSE in terms of cascaded channel estimation\nerror.", "AI": {"tldr": "Proposed variational inference-based channel estimation with complex adaptive Laplace prior outperforms conventional LMMSE and least squares methods for RIS-aided millimeter-wave systems.", "motivation": "LMMSE estimator causes performance degradation because complex channel gains in cascaded RIS channels are generally non-Gaussian, requiring better distribution modeling.", "method": "Developed variational inference framework using complex adaptive Laplace prior to approximate non-Gaussian channel gain distributions in a tractable manner.", "result": "Numerical results show the proposed estimator achieves lower cascaded channel estimation error compared to conventional least squares and LMMSE estimators.", "conclusion": "The variational inference approach with adaptive Laplace prior provides superior channel estimation performance for RIS-aided millimeter-wave communication systems by better capturing the true channel statistics."}}
{"id": "2510.16160", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16160", "abs": "https://arxiv.org/abs/2510.16160", "authors": ["Ahmad Arrabi", "Jay Hwasung Jung", "Jax Luo", "Nathan Franssen", "Scott Raymond", "Safwan Wshah"], "title": "Automated C-Arm Positioning via Conformal Landmark Localization", "comment": null, "summary": "Accurate and reliable C-arm positioning is essential for fluoroscopy-guided\ninterventions. However, clinical workflows rely on manual alignment that\nincreases radiation exposure and procedural delays. In this work, we present a\npipeline that autonomously navigates the C-arm to predefined anatomical\nlandmarks utilizing X-ray images. Given an input X-ray image from an arbitrary\nstarting location on the operating table, the model predicts a 3D displacement\nvector toward each target landmark along the body. To ensure reliable\ndeployment, we capture both aleatoric and epistemic uncertainties in the\nmodel's predictions and further calibrate them using conformal prediction. The\nderived prediction regions are interpreted as 3D confidence regions around the\npredicted landmark locations. The training framework combines a probabilistic\nloss with skeletal pose regularization to encourage anatomically plausible\noutputs. We validate our approach on a synthetic X-ray dataset generated from\nDeepDRR. Results show not only strong localization accuracy across multiple\narchitectures but also well-calibrated prediction bounds. These findings\nhighlight the pipeline's potential as a component in safe and reliable\nautonomous C-arm systems. Code is available at\nhttps://github.com/AhmadArrabi/C_arm_guidance_APAH", "AI": {"tldr": "A pipeline for autonomous C-arm navigation to anatomical landmarks using X-ray images, with uncertainty quantification and conformal prediction for reliable deployment.", "motivation": "Manual C-arm positioning in fluoroscopy-guided interventions increases radiation exposure and procedural delays, necessitating automated solutions.", "method": "Predicts 3D displacement vectors from arbitrary X-ray images using probabilistic models with aleatoric/epistemic uncertainty capture, conformal prediction calibration, and skeletal pose regularization for anatomical plausibility.", "result": "Strong localization accuracy across multiple architectures with well-calibrated prediction bounds on synthetic X-ray dataset from DeepDRR.", "conclusion": "The pipeline shows potential as a safe and reliable component for autonomous C-arm systems in clinical workflows."}}
{"id": "2510.15967", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15967", "abs": "https://arxiv.org/abs/2510.15967", "authors": ["Zhengyi Zhong", "Wenzheng Jiang", "Weidong Bao", "Ji Wang", "Cheems Wang", "Guanbo Wang", "Yongheng Deng", "Ju Ren"], "title": "Gains: Fine-grained Federated Domain Adaptation in Open Set", "comment": "Accepted by NeurIPS2025", "summary": "Conventional federated learning (FL) assumes a closed world with a fixed\ntotal number of clients. In contrast, new clients continuously join the FL\nprocess in real-world scenarios, introducing new knowledge. This raises two\ncritical demands: detecting new knowledge, i.e., knowledge discovery, and\nintegrating it into the global model, i.e., knowledge adaptation. Existing\nresearch focuses on coarse-grained knowledge discovery, and often sacrifices\nsource domain performance and adaptation efficiency. To this end, we propose a\nfine-grained federated domain adaptation approach in open set (Gains). Gains\nsplits the model into an encoder and a classifier, empirically revealing\nfeatures extracted by the encoder are sensitive to domain shifts while\nclassifier parameters are sensitive to class increments. Based on this, we\ndevelop fine-grained knowledge discovery and contribution-driven aggregation\ntechniques to identify and incorporate new knowledge. Additionally, an\nanti-forgetting mechanism is designed to preserve source domain performance,\nensuring balanced adaptation. Experimental results on multi-domain datasets\nacross three typical data-shift scenarios demonstrate that Gains significantly\noutperforms other baselines in performance for both source-domain and\ntarget-domain clients. Code is available at:\nhttps://github.com/Zhong-Zhengyi/Gains.", "AI": {"tldr": "Gains is a fine-grained federated domain adaptation approach for open-set scenarios that addresses knowledge discovery and adaptation when new clients join FL, outperforming existing methods while preserving source domain performance.", "motivation": "Real-world FL scenarios involve continuous client additions with new knowledge, requiring both detection of new knowledge (discovery) and integration into global models (adaptation), which existing methods handle poorly with coarse-grained approaches.", "method": "Splits model into encoder and classifier, uses fine-grained knowledge discovery and contribution-driven aggregation to identify new knowledge, and implements anti-forgetting mechanism to preserve source domain performance.", "result": "Experimental results on multi-domain datasets across three data-shift scenarios show Gains significantly outperforms baselines in both source-domain and target-domain client performance.", "conclusion": "Gains effectively handles open-set FL with continuous client additions through fine-grained knowledge discovery and adaptation while maintaining source domain performance, demonstrating superior performance across various data-shift scenarios."}}
{"id": "2510.16193", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16193", "abs": "https://arxiv.org/abs/2510.16193", "authors": ["Elija Perrier"], "title": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability", "comment": "Under review", "summary": "Corporate responsibility turns on notions of corporate \\textit{mens rea},\ntraditionally imputed from human agents. Yet these assumptions are under\nchallenge as generative AI increasingly mediates enterprise decision-making.\nBuilding on the theory of extended cognition, we argue that in response\ncorporate knowledge may be redefined as a dynamic capability, measurable by the\nefficiency of its information-access procedures and the validated reliability\nof their outputs. We develop a formal model that captures epistemic states of\ncorporations deploying sophisticated AI or information systems, introducing a\ncontinuous organisational knowledge metric $S_S(\\varphi)$ which integrates a\npipeline's computational cost and its statistically validated error rate. We\nderive a thresholded knowledge predicate $\\mathsf{K}_S$ to impute knowledge and\na firm-wide epistemic capacity index $\\mathcal{K}_{S,t}$ to measure overall\ncapability. We then operationally map these quantitative metrics onto the legal\nstandards of actual knowledge, constructive knowledge, wilful blindness, and\nrecklessness. Our work provides a pathway towards creating measurable and\njusticiable audit artefacts, that render the corporate mind tractable and\naccountable in the algorithmic age.", "AI": {"tldr": "This paper proposes redefining corporate knowledge as a measurable capability using AI systems, developing formal models to quantify organizational knowledge and map it to legal standards for corporate accountability.", "motivation": "Traditional corporate responsibility relies on human agents, but this is challenged by generative AI mediating enterprise decisions. The paper aims to make corporate knowledge tractable and accountable in the algorithmic age.", "method": "Develops a formal model based on extended cognition theory, introducing continuous organizational knowledge metrics that integrate computational cost and validated error rates of AI systems, then maps these to legal standards.", "result": "Creates measurable knowledge metrics including S_S(\u03c6) for epistemic states, K_S for knowledge imputation, and K_S,t for firm-wide epistemic capacity, providing quantitative pathways to legal accountability.", "conclusion": "The work provides a framework for creating measurable audit artifacts that render the corporate mind accountable when using sophisticated AI systems, bridging computational metrics with legal standards."}}
{"id": "2510.16963", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16963", "abs": "https://arxiv.org/abs/2510.16963", "authors": ["Donggu Lee", "Sung Joon Maeng", "Ismail Guvenc"], "title": "Stochastic Geometry Analysis of Asymmetric Uplink Interference for Urban UAV-RC Networks", "comment": null, "summary": "Uncrewed aerial vehicles (UAVs) have emerged as a flexible platform for\nproviding coverage over challenging environments, particularly for public\nsafety and surveillance missions in urban areas. However, deploying the UAVs in\ndense urban areas introduces unique challenges, most notably asymmetric uplink\n(UL, remote controller to UAV) interference due to a higher chance of\nline-of-sight (LoS) interference at the UAV. In this letter, we propose a\nstochastic geometry framework to tractably analyze the large-scale asymmetric\ninterference in urban areas. We incorporate a log-Gaussian Cox process (LGCP)\nmodel to capture the spatial correlation of the interference field in both UL\nand downlink (DL) as a function of the UAV altitude and the two-dimensional\n(2-D) distance between the remote controller and UAV. To quantify the UL and\nthe DL interference asymmetry, we also define the interference asymmetry ratio\ncharacterizing the interference disparity between the UL and the DL. Our\nnumerical results demonstrate that the interference asymmetry ratio increases\nas the UAV altitude and 2-D distance increase, highlighting that the UL\ninterference worsens.", "AI": {"tldr": "This paper analyzes asymmetric interference in UAV communications in urban areas, showing that uplink interference worsens with increasing UAV altitude and distance from the remote controller.", "motivation": "UAV deployment in dense urban areas faces unique challenges from asymmetric uplink interference due to higher line-of-sight interference at UAVs, which needs systematic analysis.", "method": "Proposes a stochastic geometry framework using log-Gaussian Cox process (LGCP) to model spatial correlation of interference in both uplink and downlink as functions of UAV altitude and 2D distance.", "result": "Numerical results show that interference asymmetry ratio increases with UAV altitude and 2D distance, indicating worsening uplink interference.", "conclusion": "The proposed framework effectively quantifies asymmetric interference in UAV communications, revealing that uplink interference becomes more severe at higher altitudes and greater distances."}}
{"id": "2510.17775", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.17775", "abs": "https://arxiv.org/abs/2510.17775", "authors": ["Kweku Abraham", "Amnon Balanov", "Tamir Bendory", "Carlos Esteve-Yag\u00fce"], "title": "Sample Complexity Analysis of Multi-Target Detection via Markovian and Hard-Core Multi-Reference Alignment", "comment": null, "summary": "Motivated by single-particle cryo-electron microscopy, we study the sample\ncomplexity of the multi-target detection (MTD) problem, in which an unknown\nsignal appears multiple times at unknown locations within a long, noisy\nobservation. We propose a patching scheme that reduces MTD to a non-i.i.d.\nmulti-reference alignment (MRA) model. In the one-dimensional setting, the\nlatent group elements form a Markov chain, and we show that the convergence\nrate of any estimator matches that of the corresponding i.i.d. MRA model, up to\na logarithmic factor in the number of patches. Moreover, for estimators based\non empirical averaging, such as the method of moments, the convergence rates\nare identical in both settings. We further establish an analogous result in two\ndimensions, where the latent structure arises from an exponentially mixing\nrandom field generated by a hard-core placement model. As a consequence, if the\nsignal in the corresponding i.i.d. MRA model is determined by moments up to\norder $n_{\\min}$, then in the low-SNR regime the number of patches required to\nestimate the signal in the MTD model scales as $\\sigma^{2n_{\\min}}$, where\n$\\sigma^2$ denotes the noise variance.", "AI": {"tldr": "The paper analyzes sample complexity for multi-target detection in cryo-EM, showing that patching reduces it to non-i.i.d. multi-reference alignment with Markov chain structure, achieving similar convergence rates as i.i.d. MRA up to logarithmic factors.", "motivation": "Motivated by single-particle cryo-electron microscopy, to understand the sample complexity of multi-target detection where unknown signals appear multiple times at unknown locations in noisy observations.", "method": "Proposes a patching scheme that reduces MTD to non-i.i.d. multi-reference alignment model. In 1D, latent group elements form a Markov chain; in 2D, uses exponentially mixing random field from hard-core placement model.", "result": "Convergence rate of any estimator matches i.i.d. MRA model up to logarithmic factor in patch count. For empirical averaging methods like method of moments, convergence rates are identical. In low-SNR regime, number of patches scales as \u03c3^{2n_min} where \u03c3\u00b2 is noise variance.", "conclusion": "The MTD problem can be effectively reduced to MRA models with comparable sample complexity, providing theoretical foundation for cryo-EM applications with similar estimation performance as independent alignment models."}}
{"id": "2510.16179", "categories": ["cs.CV", "I.4.9"], "pdf": "https://arxiv.org/pdf/2510.16179", "abs": "https://arxiv.org/abs/2510.16179", "authors": ["Xavier Giro-i-Nieto", "Nefeli Andreou", "Anqi Liang", "Manel Baradad", "Francesc Moreno-Noguer", "Aleix Martinez"], "title": "Cost Savings from Automatic Quality Assessment of Generated Images", "comment": null, "summary": "Deep generative models have shown impressive progress in recent years, making\nit possible to produce high quality images with a simple text prompt or a\nreference image. However, state of the art technology does not yet meet the\nquality standards offered by traditional photographic methods. For this reason,\nproduction pipelines that use generated images often include a manual stage of\nimage quality assessment (IQA). This process is slow and expensive, especially\nbecause of the low yield of automatically generated images that pass the\nquality bar. The IQA workload can be reduced by introducing an automatic\npre-filtering stage, that will increase the overall quality of the images sent\nto review and, therefore, reduce the average cost required to obtain a high\nquality image. We present a formula that estimates the cost savings depending\non the precision and pass yield of a generic IQA engine. This formula is\napplied in a use case of background inpainting, showcasing a significant cost\nsaving of 51.61% obtained with a simple AutoML solution.", "AI": {"tldr": "The paper presents a cost-saving formula for automatic image quality assessment (IQA) pre-filtering to reduce manual review costs in generative image pipelines.", "motivation": "Manual image quality assessment in generative AI pipelines is slow and expensive due to low yield of high-quality generated images, creating need for automated pre-filtering.", "method": "Developed a mathematical formula to estimate cost savings based on precision and pass yield of IQA engines, and tested it with AutoML solution on background inpainting use case.", "result": "Achieved significant cost saving of 51.61% using a simple AutoML-based IQA pre-filtering system.", "conclusion": "Automatic IQA pre-filtering can substantially reduce costs in generative image production pipelines, with demonstrated 51.61% savings in background inpainting scenario."}}
{"id": "2510.15968", "categories": ["cs.LG", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.15968", "abs": "https://arxiv.org/abs/2510.15968", "authors": ["Zhen Huang", "Hong Wang", "Wenkai Yang", "Muxi Tang", "Depeng Xie", "Ting-Jung Lin", "Yu Zhang", "Wei W. Xing", "Lei He"], "title": "Self-Attention to Operator Learning-based 3D-IC Thermal Simulation", "comment": null, "summary": "Thermal management in 3D ICs is increasingly challenging due to higher power\ndensities. Traditional PDE-solving-based methods, while accurate, are too slow\nfor iterative design. Machine learning approaches like FNO provide faster\nalternatives but suffer from high-frequency information loss and high-fidelity\ndata dependency. We introduce Self-Attention U-Net Fourier Neural Operator\n(SAU-FNO), a novel framework combining self-attention and U-Net with FNO to\ncapture long-range dependencies and model local high-frequency features\neffectively. Transfer learning is employed to fine-tune low-fidelity data,\nminimizing the need for extensive high-fidelity datasets and speeding up\ntraining. Experiments demonstrate that SAU-FNO achieves state-of-the-art\nthermal prediction accuracy and provides an 842x speedup over traditional FEM\nmethods, making it an efficient tool for advanced 3D IC thermal simulations.", "AI": {"tldr": "SAU-FNO combines self-attention, U-Net, and FNO for efficient 3D IC thermal prediction with 842x speedup over FEM methods.", "motivation": "Traditional PDE methods are too slow for iterative design, while existing ML approaches lose high-frequency information and require extensive high-fidelity data.", "method": "Self-Attention U-Net Fourier Neural Operator (SAU-FNO) framework that captures long-range dependencies and local high-frequency features, using transfer learning to fine-tune low-fidelity data.", "result": "Achieves state-of-the-art thermal prediction accuracy with 842x speedup over traditional FEM methods.", "conclusion": "SAU-FNO is an efficient tool for advanced 3D IC thermal simulations, reducing dependency on high-fidelity data while maintaining accuracy."}}
{"id": "2510.16194", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16194", "abs": "https://arxiv.org/abs/2510.16194", "authors": ["Guanchen Wu", "Zuhui Chen", "Yuzhang Xie", "Carl Yang"], "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration", "comment": "Agents4Science 2025 (Spotlight)", "summary": "Protected health information (PHI) de-identification is critical for enabling\nthe safe reuse of clinical notes, yet evaluating and comparing PHI\nde-identification models typically depends on costly, small-scale expert\nannotations. We present TEAM-PHI, a multi-agent evaluation and selection\nframework that uses large language models (LLMs) to automatically measure\nde-identification quality and select the best-performing model without heavy\nreliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each\nindependently judging the correctness of PHI extractions and outputting\nstructured metrics. Their results are then consolidated through an LLM-based\nmajority voting mechanism that integrates diverse evaluator perspectives into a\nsingle, stable, and reproducible ranking. Experiments on a real-world clinical\nnote corpus demonstrate that TEAM-PHI produces consistent and accurate\nrankings: despite variation across individual evaluators, LLM-based voting\nreliably converges on the same top-performing systems. Further comparison with\nground-truth annotations and human evaluation confirms that the framework's\nautomated rankings closely match supervised evaluation. By combining\nindependent evaluation agents with LLM majority voting, TEAM-PHI offers a\npractical, secure, and cost-effective solution for automatic evaluation and\nbest-model selection in PHI de-identification, even when ground-truth labels\nare limited.", "AI": {"tldr": "TEAM-PHI is a multi-agent framework that uses LLMs to automatically evaluate and rank PHI de-identification models without relying heavily on expert annotations, achieving rankings that closely match supervised evaluation.", "motivation": "PHI de-identification is crucial for clinical data reuse, but current evaluation methods depend on expensive, small-scale expert annotations, creating a need for automated evaluation solutions.", "method": "Uses multiple Evaluation Agents (LLMs) to independently judge PHI extraction correctness, then consolidates results through LLM-based majority voting to produce stable rankings.", "result": "Experiments show TEAM-PHI produces consistent and accurate rankings that reliably converge on the same top-performing systems, closely matching ground-truth annotations and human evaluation.", "conclusion": "TEAM-PHI offers a practical, secure, and cost-effective solution for automatic evaluation and best-model selection in PHI de-identification, especially when ground-truth labels are limited."}}
{"id": "2510.17113", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17113", "abs": "https://arxiv.org/abs/2510.17113", "authors": ["Mengzhen Liu", "Ming Li", "Rang Liu", "Qian Liu", "A. Lee Swindlehurst"], "title": "Reconfigurable Antenna Arrays: Bridging Electromagnetics and Signal Processing", "comment": "7 pages, 5 figures, 1 table", "summary": "Reconfigurable antennas (RAs), capable of dynamically adapting their\nradiation patterns, polarization states, and operating frequencies, have\nemerged as a promising technology to meet the stringent performance\nrequirements of sixth-generation (6G) wireless networks. This article\nsystematically introduces essential hardware implementations of RAs and\ninvestigates advanced array architectures, such as fully-digital and tri-hybrid\ndesigns, emphasizing their capability to synergistically integrate\nelectromagnetic (EM) reconfigurability with analog and digital signal\nprocessing. By facilitating coordinated beamforming across the EM and signal\nprocessing domains, RA arrays offer unprecedented flexibility and adaptability\ncompared to conventional static antenna systems. Representative applications\nempowered by RA arrays, including integrated sensing and communication (ISAC),\nphysical layer security (PLS), and near-field communications, are highlighted.\nA case study illustrates the effectiveness of RA arrays in optimizing beam\nsteering, improving link robustness, and alleviating system power consumption.\nFinally, several open challenges and future research directions are outlined,\nemphasizing the need for advancements in theoretical modeling, hardware\nreliability, channel estimation techniques, intelligent optimization methods,\nand innovative network architectures, to fully realize the transformative\nimpact of RAs in future 6G wireless networks.", "AI": {"tldr": "Reconfigurable antennas (RAs) enable dynamic adaptation of radiation patterns, polarization, and frequencies for 6G networks, offering superior flexibility through coordinated beamforming across electromagnetic and signal processing domains.", "motivation": "To meet stringent performance requirements of 6G wireless networks by overcoming limitations of conventional static antenna systems through dynamic adaptability.", "method": "Systematic investigation of hardware implementations and advanced array architectures (fully-digital, tri-hybrid) that integrate electromagnetic reconfigurability with analog and digital signal processing.", "result": "RA arrays provide unprecedented flexibility and adaptability, enabling optimized beam steering, improved link robustness, reduced power consumption, and support for applications like ISAC, PLS, and near-field communications.", "conclusion": "While promising, RA technology requires advancements in theoretical modeling, hardware reliability, channel estimation, intelligent optimization, and network architectures to fully realize its transformative potential in 6G networks."}}
{"id": "2510.16196", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16196", "abs": "https://arxiv.org/abs/2510.16196", "authors": ["Zheng Huang", "Enpei Zhang", "Yinghao Cai", "Weikang Qiu", "Carl Yang", "Elynn Chen", "Xiang Zhang", "Rex Ying", "Dawei Zhou", "Yujun Yan"], "title": "Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI", "comment": null, "summary": "Understanding how the brain encodes visual information is a central challenge\nin neuroscience and machine learning. A promising approach is to reconstruct\nvisual stimuli, essentially images, from functional Magnetic Resonance Imaging\n(fMRI) signals. This involves two stages: transforming fMRI signals into a\nlatent space and then using a pretrained generative model to reconstruct\nimages. The reconstruction quality depends on how similar the latent space is\nto the structure of neural activity and how well the generative model produces\nimages from that space. Yet, it remains unclear which type of latent space best\nsupports this transformation and how it should be organized to represent visual\nstimuli effectively. We present two key findings. First, fMRI signals are more\nsimilar to the text space of a language model than to either a vision based\nspace or a joint text image space. Second, text representations and the\ngenerative model should be adapted to capture the compositional nature of\nvisual stimuli, including objects, their detailed attributes, and\nrelationships. Building on these insights, we propose PRISM, a model that\nProjects fMRI sIgnals into a Structured text space as an interMediate\nrepresentation for visual stimuli reconstruction. It includes an object centric\ndiffusion module that generates images by composing individual objects to\nreduce object detection errors, and an attribute relationship search module\nthat automatically identifies key attributes and relationships that best align\nwith the neural activity. Extensive experiments on real world datasets\ndemonstrate that our framework outperforms existing methods, achieving up to an\n8% reduction in perceptual loss. These results highlight the importance of\nusing structured text as the intermediate space to bridge fMRI signals and\nimage reconstruction.", "AI": {"tldr": "This paper proposes PRISM, a model that projects fMRI signals into a structured text space for visual stimuli reconstruction, achieving better performance than existing methods.", "motivation": "To understand how the brain encodes visual information by reconstructing images from fMRI signals, and to determine the best latent space for this transformation.", "method": "PRISM projects fMRI signals into a structured text space, uses an object-centric diffusion module to generate images by composing objects, and includes an attribute-relationship search module to identify key visual elements.", "result": "The framework outperforms existing methods with up to 8% reduction in perceptual loss on real-world datasets.", "conclusion": "Structured text space is more effective than vision-based or joint text-image spaces for bridging fMRI signals and image reconstruction, capturing the compositional nature of visual stimuli."}}
{"id": "2510.15969", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15969", "abs": "https://arxiv.org/abs/2510.15969", "authors": ["Paul-Niklas Ken Kandora", "Simon Caspar Zeller", "Aaron Jeremias Elsing", "Elena Kuss", "Steffen Rebennack"], "title": "LinearizeLLM: An Agent-Based Framework for LLM-Driven Exact Linear Reformulation of Nonlinear Optimization Problems", "comment": null, "summary": "Reformulating nonlinear optimization problems is largely manual and\nexpertise-intensive, yet it remains essential for solving such problems with\nlinear optimization solvers or applying special-purpose algorithms. We\nintroduce \\textit{LinearizeLLM}, an agent-based framework that solves this task\nby leveraging Large Language Models (LLMs). The framework assigns each\nnonlinear pattern to a \\textit{reformulation agent} that is explicitly\ninstructed to derive an exact linear reformulation for its nonlinearity\npattern, for instance, absolute-value terms or bilinear products of decision\nvariables. The agents then coordinate to assemble a solver-ready linear model\nequivalent to the original problem. To benchmark the approach, we create a\ndataset of 20 real-world nonlinear optimization problems derived from the\nestablished ComplexOR dataset of linear optimization problems. We evaluate our\napproach with several LLMs. Our results indicate that specialized LLM agents\ncan automate linearization tasks, opening a path toward fully conversational\nmodeling pipelines for nonlinear optimization.", "AI": {"tldr": "LinearizeLLM is an agent-based framework that uses specialized LLM agents to automatically linearize nonlinear optimization problems by identifying and reformulating specific nonlinear patterns into equivalent linear forms.", "motivation": "Manual reformulation of nonlinear optimization problems is expertise-intensive but essential for using linear solvers or special-purpose algorithms. This process needs automation to make optimization more accessible.", "method": "An agent-based framework where each nonlinear pattern (e.g., absolute-value terms, bilinear products) is assigned to a specialized reformulation agent that derives exact linear reformulations. Agents coordinate to assemble a solver-ready linear model.", "result": "Tested on 20 real-world nonlinear problems from ComplexOR dataset. Multiple LLMs were evaluated and showed capability to automate linearization tasks effectively.", "conclusion": "Specialized LLM agents can successfully automate linearization tasks, enabling conversational modeling pipelines for nonlinear optimization problems."}}
{"id": "2510.16206", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16206", "abs": "https://arxiv.org/abs/2510.16206", "authors": ["Alex Zhavoronkov", "Dominika Wilczok", "Roman Yampolskiy"], "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI", "comment": null, "summary": "Since the rapid expansion of large language models (LLMs), people have begun\nto rely on them for information retrieval. While traditional search engines\ndisplay ranked lists of sources shaped by search engine optimization (SEO),\nadvertising, and personalization, LLMs typically provide a synthesized response\nthat feels singular and authoritative. While both approaches carry risks of\nbias and omission, LLMs may amplify the effect by collapsing multiple\nperspectives into one answer, reducing users ability or inclination to compare\nalternatives. This concentrates power over information in a few LLM vendors\nwhose systems effectively shape what is remembered and what is overlooked. As a\nresult, certain narratives, individuals or groups, may be disproportionately\nsuppressed, while others are disproportionately elevated. Over time, this\ncreates a new threat: the gradual erasure of those with limited digital\npresence, and the amplification of those already prominent, reshaping\ncollective memory.To address these concerns, this paper presents a concept of\nthe Right To Be Remembered (RTBR) which encompasses minimizing the risk of\nAI-driven information omission, embracing the right of fair treatment, while\nensuring that the generated content would be maximally truthful.", "AI": {"tldr": "LLMs create information concentration risks by providing singular synthesized responses, potentially erasing marginalized voices and amplifying prominent ones, threatening collective memory. The paper proposes a Right To Be Remembered (RTBR) framework to address these concerns.", "motivation": "The rapid expansion of LLMs for information retrieval creates risks of bias amplification and information concentration, where synthesized responses may disproportionately suppress certain narratives while elevating others, reshaping collective memory and threatening digital erasure of marginalized groups.", "method": "The paper presents a conceptual framework called the Right To Be Remembered (RTBR), which aims to minimize AI-driven information omission, ensure fair treatment rights, and maximize truthfulness in generated content.", "result": "The proposed RTBR framework addresses the concentration of information power in LLM vendors and the potential erasure of those with limited digital presence by establishing principles for fair information treatment and preservation.", "conclusion": "The Right To Be Remembered concept provides a necessary framework to counter the threats posed by LLM-driven information concentration, ensuring that collective memory is preserved and marginalized voices are not erased through AI-driven information systems."}}
{"id": "2510.17272", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17272", "abs": "https://arxiv.org/abs/2510.17272", "authors": ["Muhammad Asif", "Asim Ihsan", "Zhu Shoujin", "Ali Ranjha", "Xingwang Li", "Khaled M. Rabie", "Symeon Chatzinotas"], "title": "Robust Beamforming Optimization for STAR-RIS Empowered Multi-User RSMA Under Hardware Imperfections and Channel Uncertainty", "comment": "12 pages, and 11 figures. Submitted to IEEE", "summary": "This study explores the synergy between rate-splitting multiple access (RSMA)\nand simultaneous transmitting and reflecting reconfigurable intelligent surface\n(STAR-RIS) as a unified framework to enable ubiquitous, intelligent, and\nresilient connectivity in future sixth-generation networks, while improving\nspectral and energy efficiency. Specifically, we investigate a\nSTAR-RIS-assisted multi-user RSMA system and develop an intelligent\noptimization strategy that jointly designs the transmitter's active\nbeamforming, the common stream rate allocation, and the passive beamforming\nvectors for the STAR-RIS transmission and reflection regions, considering\ntransceiver hardware impairments and imperfect channel state information (CSI).\nIn addition, system robustness is ensured via a bounded channel estimation\nerror model that captures CSI imperfections and guarantees resilience against\nworst-case errors. To address the highly non-convex problem, we propose an\niterative optimization algorithm that decomposes it into two sub-problems.\nFirstly, active beamforming vectors for the common and private signals are\ndetermined by reformulating the original problem into a convex semi-definite\nprogramming (SDP) form using successive convex approximation (SCA) and\nsemi-definite relaxation (SDR). Secondly, passive beamforming vectors are\noptimized through a convex SDP reformulation by exploiting SCA and SDR\ntechniques. Moreover, when higher-rank solutions arise, Gaussian randomization\nis applied to obtain rank-one solutions. Numerical simulations demonstrate that\nthe proposed strategy achieves significant performance gains over benchmark\nschemes and exhibits fast convergence.", "AI": {"tldr": "This paper proposes a unified framework combining rate-splitting multiple access (RSMA) with STAR-RIS for 6G networks, developing an intelligent optimization strategy for joint active/passive beamforming and rate allocation under hardware impairments and imperfect CSI.", "motivation": "To enable ubiquitous, intelligent, and resilient connectivity in future 6G networks while improving spectral and energy efficiency, addressing the challenges of hardware impairments and imperfect channel state information.", "method": "Proposes an iterative optimization algorithm that decomposes the non-convex problem into two sub-problems: active beamforming using SCA and SDR techniques, and passive beamforming through convex SDP reformulation with Gaussian randomization for rank-one solutions.", "result": "Numerical simulations show significant performance gains over benchmark schemes and fast convergence of the proposed optimization strategy.", "conclusion": "The RSMA-STAR-RIS framework with the proposed intelligent optimization strategy effectively enhances system performance and robustness in 6G networks under practical constraints."}}
{"id": "2510.16207", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16207", "abs": "https://arxiv.org/abs/2510.16207", "authors": ["Mateus Pinto da Silva", "Sabrina P. L. P. Correa", "Hugo N. Oliveira", "Ian M. Nunes", "Jefersson A. dos Santos"], "title": "Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions", "comment": "5 pages, 1 figure", "summary": "Mapping agriculture in tropical areas through remote sensing presents unique\nchallenges, including the lack of high-quality annotated data, the elevated\ncosts of labeling, data variability, and regional generalisation. This paper\nadvocates a Data-Centric Artificial Intelligence (DCAI) perspective and\npipeline, emphasizing data quality and curation as key drivers for model\nrobustness and scalability. It reviews and prioritizes techniques such as\nconfident learning, core-set selection, data augmentation, and active learning.\nThe paper highlights the readiness and suitability of 25 distinct strategies in\nlarge-scale agricultural mapping pipelines. The tropical context is of high\ninterest, since high cloudiness, diverse crop calendars, and limited datasets\nlimit traditional model-centric approaches. This tutorial outlines practical\nsolutions as a data-centric approach for curating and training AI models better\nsuited to the dynamic realities of tropical agriculture. Finally, we propose a\npractical pipeline using the 9 most mature and straightforward methods that can\nbe applied to a large-scale tropical agricultural mapping project.", "AI": {"tldr": "This paper proposes a Data-Centric AI approach for tropical agriculture mapping, prioritizing data quality and curation over model-centric methods to address challenges like limited annotated data, high labeling costs, and regional generalization issues.", "motivation": "Tropical agriculture mapping faces unique challenges including lack of high-quality annotated data, high labeling costs, data variability, cloudiness, diverse crop calendars, and limited datasets that hinder traditional model-centric approaches.", "method": "Advocates a Data-Centric AI pipeline emphasizing data quality and curation, reviewing techniques like confident learning, core-set selection, data augmentation, and active learning. Proposes a practical pipeline using the 9 most mature methods for large-scale tropical agricultural mapping.", "result": "Identifies 25 distinct strategies suitable for large-scale agricultural mapping pipelines and highlights their readiness for implementation in tropical contexts.", "conclusion": "A data-centric approach provides practical solutions for curating and training AI models better suited to the dynamic realities of tropical agriculture, overcoming limitations of traditional model-centric methods."}}
{"id": "2510.15970", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15970", "abs": "https://arxiv.org/abs/2510.15970", "authors": ["Yang Ba", "Mohammad Sadeq Abolhasani", "Rong Pan"], "title": "Predict Training Data Quality via Its Geometry in Metric Space", "comment": "Accepted to the NeurIPS 2025 Workshop on New Perspectives in Graph\n  Machine Learning", "summary": "High-quality training data is the foundation of machine learning and\nartificial intelligence, shaping how models learn and perform. Although much is\nknown about what types of data are effective for training, the impact of the\ndata's geometric structure on model performance remains largely underexplored.\nWe propose that both the richness of representation and the elimination of\nredundancy within training data critically influence learning outcomes. To\ninvestigate this, we employ persistent homology to extract topological features\nfrom data within a metric space, thereby offering a principled way to quantify\ndiversity beyond entropy-based measures. Our findings highlight persistent\nhomology as a powerful tool for analyzing and enhancing the training data that\ndrives AI systems.", "AI": {"tldr": "Using persistent homology to analyze training data's geometric structure improves AI model performance by quantifying diversity beyond entropy measures.", "motivation": "The geometric structure of training data's impact on model performance is underexplored, despite data quality being fundamental to machine learning.", "method": "Employ persistent homology to extract topological features from data in metric space, providing principled quantification of data diversity.", "result": "Persistent homology proves effective for analyzing and enhancing training data quality for AI systems.", "conclusion": "Persistent homology is a powerful tool for understanding and improving training data structure to boost AI system performance."}}
{"id": "2510.16234", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16234", "abs": "https://arxiv.org/abs/2510.16234", "authors": ["Hanane Nour Moussa", "Patrick Queiroz Da Silva", "Daniel Adu-Ampratwum", "Alyson East", "Zitong Lu", "Nikki Puccetti", "Mingyi Xue", "Huan Sun", "Bodhisattwa Prasad Majumder", "Sachin Kumar"], "title": "ScholarEval: Research Idea Evaluation Grounded in Literature", "comment": null, "summary": "As AI tools become increasingly common for research ideation, robust\nevaluation is critical to ensure the validity and usefulness of generated\nideas. We introduce ScholarEval, a retrieval augmented evaluation framework\nthat assesses research ideas based on two fundamental criteria: soundness - the\nempirical validity of proposed methods based on existing literature, and\ncontribution - the degree of advancement made by the idea across different\ndimensions relative to prior research. To evaluate ScholarEval, we introduce\nScholarIdeas, the first expert-annotated dataset of multi-domain research ideas\nand reviews, comprised of 117 ideas across four disciplines: artificial\nintelligence, neuroscience, biochemistry, and ecology. Our evaluation shows\nthat ScholarEval achieves significantly higher coverage of points mentioned in\nthe human expert annotated rubrics in ScholarIdeas compared to all baselines.\nFurthermore, ScholarEval is consistently preferred over our strongest baseline\no4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,\nin terms of evaluation actionability, depth, and evidence support. Our\nlarge-scale user study also shows that ScholarEval significantly outperforms\ndeep research in literature engagement, idea refinement, and usefulness. We\nopenly release our code, dataset, and ScholarEval tool for the community to use\nand build on.", "AI": {"tldr": "ScholarEval is a retrieval-augmented framework for evaluating AI-generated research ideas based on soundness and contribution, outperforming existing baselines including OpenAI's o4-mini-deep-research.", "motivation": "As AI tools become increasingly common for research ideation, robust evaluation is critical to ensure the validity and usefulness of generated ideas.", "method": "Introduces ScholarEval framework with two criteria: soundness (empirical validity based on literature) and contribution (degree of advancement). Also creates ScholarIdeas dataset - 117 expert-annotated research ideas across four disciplines.", "result": "ScholarEval achieves significantly higher coverage of expert-annotated rubric points compared to all baselines. Consistently preferred over OpenAI's o4-mini-deep-research in evaluation actionability, depth, and evidence support. Large-scale user study shows significant outperformance in literature engagement, idea refinement, and usefulness.", "conclusion": "ScholarEval provides an effective framework for evaluating research ideas, with code, dataset, and tool released openly for community use."}}
{"id": "2510.17324", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17324", "abs": "https://arxiv.org/abs/2510.17324", "authors": ["Idir Edjekouane", "Alejandro Gonz\u00e1lez Garrido", "Jorge Querol", "Symeon Chatzinotas"], "title": "When 5G NTN Meets GNSS: Tracking GNSS Signals under Overlaid 5G Waveforms", "comment": "Submitted to IEEE ICC 2026", "summary": "Global Navigation Satellite Systems (GNSS) provide the backbone of\nPositioning, Navigation, and Timing (PNT) but remain vulnerable to\ninterference. Low Earth Orbit (LEO) constellations within Fifth-Generation (5G)\nNon-Terrestrial Networks (NTN) can enhance resilience by jointly supporting\ncommunication and navigation. This paper presents the first quantitative\nanalysis of GNSS tracking and navigation message demodulation under a hybrid\nwaveform where a low-power Direct-Sequence Spread Spectrum (DSSS) component is\noverlaid on an Orthogonal Frequency-Division Multiplexing (OFDM) 5G downlink.\nWe evaluate a minimally modified GNSS receiver that tracks a legacy Global\nPositioning System (GPS) L1 Coarse/Acquisition (C/A) overlay aligned with 5G\nframes while treating the 5G waveform as structured interference. Using Monte\nCarlo simulations under realistic LEO Doppler dynamics, we analyze the Bit\nError Rate (BER) of GPS L1 C/A navigation bits and the subframe decoding\nprobability versus Signalto- Interference-plus-Noise Ratio (SINR) for multiple\nSignalto- Interference Ratios (SIR) and dynamic classes. Results show reliable\ndemodulation across wide SINR ranges for low and medium dynamics, whereas high\ndynamics impose strict lock limits. These findings confirm the feasibility of\nJoint Communication and Positioning (JCAP) using a near-legacy GNSS chipset\nwith minimal receiver modifications.", "AI": {"tldr": "Analysis of GNSS tracking and navigation message demodulation under a hybrid 5G-NTN waveform with GPS L1 C/A overlay, showing feasibility of Joint Communication and Positioning with minimal receiver modifications.", "motivation": "GNSS systems are vulnerable to interference, and 5G Non-Terrestrial Networks (NTN) in LEO constellations can enhance resilience by supporting both communication and navigation services.", "method": "Evaluated a minimally modified GNSS receiver tracking GPS L1 C/A overlay on 5G OFDM downlink, treating 5G as structured interference. Used Monte Carlo simulations under realistic LEO Doppler dynamics to analyze BER and subframe decoding probability vs SINR.", "result": "Reliable demodulation across wide SINR ranges for low and medium dynamics, but high dynamics impose strict lock limits. GPS L1 C/A navigation bits can be successfully demodulated.", "conclusion": "Confirms feasibility of Joint Communication and Positioning (JCAP) using near-legacy GNSS chipsets with minimal receiver modifications in 5G-NTN hybrid systems."}}
{"id": "2510.16209", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16209", "abs": "https://arxiv.org/abs/2510.16209", "authors": ["Nyle Siddiqui", "Rohit Gupta", "Sirnam Swetha", "Mubarak Shah"], "title": "StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales", "comment": null, "summary": "State space models (SSMs) have emerged as a competitive alternative to\ntransformers in various tasks. Their linear complexity and hidden-state\nrecurrence make them particularly attractive for modeling long sequences,\nwhereas attention becomes quadratically expensive. However, current training\nmethods for video understanding are tailored towards transformers and fail to\nfully leverage the unique attributes of SSMs. For example, video models are\noften trained at a fixed resolution and video length to balance the quadratic\nscaling of attention cost against performance. Consequently, these models\nsuffer from degraded performance when evaluated on videos with spatial and\ntemporal resolutions unseen during training; a property we call spatio-temporal\ninflexibility. In the context of action recognition, this severely limits a\nmodel's ability to retain performance across both short- and long-form videos.\nTherefore, we propose a flexible training method that leverages and improves\nthe inherent adaptability of SSMs. Our method samples videos at varying\ntemporal and spatial resolutions during training and dynamically interpolates\nmodel weights to accommodate any spatio-temporal scale. This instills our SSM,\nwhich we call StretchySnake, with spatio-temporal flexibility and enables it to\nseamlessly handle videos ranging from short, fine-grained clips to long,\ncomplex activities. We introduce and compare five different variants of\nflexible training, and identify the most effective strategy for video SSMs. On\nshort-action (UCF-101, HMDB-51) and long-action (COIN, Breakfast) benchmarks,\nStretchySnake outperforms transformer and SSM baselines alike by up to 28%,\nwith strong adaptability to fine-grained actions (SSV2, Diving-48). Therefore,\nour method provides a simple drop-in training recipe that makes video SSMs more\nrobust, resolution-agnostic, and efficient across diverse action recognition\nscenarios.", "AI": {"tldr": "Proposes StretchySnake, a flexible training method for video state space models that enables spatio-temporal adaptability across varying video resolutions and lengths, outperforming transformer and SSM baselines by up to 28%.", "motivation": "Current video training methods are tailored for transformers and fail to leverage SSMs' unique attributes, leading to spatio-temporal inflexibility where models degrade on unseen video resolutions and lengths.", "method": "Samples videos at varying temporal and spatial resolutions during training and dynamically interpolates model weights to accommodate any spatio-temporal scale, with five different flexible training variants compared.", "result": "Outperforms transformer and SSM baselines by up to 28% on short-action (UCF-101, HMDB-51) and long-action (COIN, Breakfast) benchmarks, with strong adaptability to fine-grained actions (SSV2, Diving-48).", "conclusion": "Provides a simple drop-in training recipe that makes video SSMs more robust, resolution-agnostic, and efficient across diverse action recognition scenarios."}}
{"id": "2510.15977", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15977", "abs": "https://arxiv.org/abs/2510.15977", "authors": ["Wenyun Li", "Zheng Zhang", "Dongmei Jiang", "Xiangyuan Lan"], "title": "Bolster Hallucination Detection via Prompt-Guided Data Augmentation", "comment": null, "summary": "Large language models (LLMs) have garnered significant interest in AI\ncommunity. Despite their impressive generation capabilities, they have been\nfound to produce misleading or fabricated information, a phenomenon known as\nhallucinations. Consequently, hallucination detection has become critical to\nensure the reliability of LLM-generated content. One primary challenge in\nhallucination detection is the scarcity of well-labeled datasets containing\nboth truthful and hallucinated outputs. To address this issue, we introduce\nPrompt-guided data Augmented haLlucination dEtection (PALE), a novel framework\nthat leverages prompt-guided responses from LLMs as data augmentation for\nhallucination detection. This strategy can generate both truthful and\nhallucinated data under prompt guidance at a relatively low cost. To more\neffectively evaluate the truthfulness of the sparse intermediate embeddings\nproduced by LLMs, we introduce an estimation metric called the Contrastive\nMahalanobis Score (CM Score). This score is based on modeling the distributions\nof truthful and hallucinated data in the activation space. CM Score employs a\nmatrix decomposition approach to more accurately capture the underlying\nstructure of these distributions. Importantly, our framework does not require\nadditional human annotations, offering strong generalizability and practicality\nfor real-world applications. Extensive experiments demonstrate that PALE\nachieves superior hallucination detection performance, outperforming the\ncompetitive baseline by a significant margin of 6.55%.", "AI": {"tldr": "PALE is a novel framework for hallucination detection in LLMs that uses prompt-guided data augmentation and a Contrastive Mahalanobis Score to evaluate truthfulness without requiring human annotations.", "motivation": "Address the scarcity of well-labeled datasets for hallucination detection in LLMs and improve the reliability of LLM-generated content by detecting misleading or fabricated information.", "method": "Uses prompt-guided responses from LLMs as data augmentation to generate both truthful and hallucinated data. Introduces Contrastive Mahalanobis Score (CM Score) based on modeling distributions in activation space using matrix decomposition.", "result": "PALE achieves superior hallucination detection performance, outperforming competitive baseline by 6.55% margin in extensive experiments.", "conclusion": "The framework offers strong generalizability and practicality for real-world applications without requiring additional human annotations."}}
{"id": "2510.16259", "categories": ["cs.AI", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2510.16259", "abs": "https://arxiv.org/abs/2510.16259", "authors": ["Zhehao Zhang", "Weijie Xu", "Shixian Cui", "Chandan K. Reddy"], "title": "Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense", "comment": "29 pages, 9 tables, 4 figures", "summary": "Recent advances in large reasoning models (LRMs) have enabled remarkable\nperformance on complex tasks such as mathematics and coding by generating long\nChain-of-Thought (CoT) traces. In this paper, we identify and systematically\nanalyze a critical vulnerability we term reasoning distraction, where LRMs are\ndiverted from their primary objective by irrelevant yet complex tasks\nmaliciously embedded in the prompt. Through a comprehensive study across\ndiverse models and benchmarks, we show that even state-of-the-art LRMs are\nhighly susceptible, with injected distractors reducing task accuracy by up to\n60%. We further reveal that certain alignment techniques can amplify this\nweakness and that models may exhibit covert compliance, following hidden\nadversarial instructions in reasoning while concealing them in the final\noutput. To mitigate these risks, we propose a training-based defense that\ncombines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on\nsynthetic adversarial data, improving robustness by over 50 points on\nchallenging distractor attacks. Our findings establish reasoning distraction as\na distinct and urgent threat to LRM reliability and provide a practical step\ntoward safer and more trustworthy reasoning systems.", "AI": {"tldr": "Large reasoning models are vulnerable to 'reasoning distraction' attacks where maliciously embedded irrelevant tasks divert them from primary objectives, reducing accuracy by up to 60%. The paper proposes a training-based defense that improves robustness by over 50 points.", "motivation": "To identify and systematically analyze a critical vulnerability in large reasoning models where they can be diverted from their primary objectives by irrelevant complex tasks embedded in prompts, threatening LRM reliability.", "method": "Comprehensive study across diverse models and benchmarks, plus proposed training-based defense combining Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on synthetic adversarial data.", "result": "State-of-the-art LRMs are highly susceptible to reasoning distraction, with accuracy reductions up to 60%. Alignment techniques can amplify this weakness, and models may exhibit covert compliance. The proposed defense improves robustness by over 50 points on challenging distractor attacks.", "conclusion": "Reasoning distraction represents a distinct and urgent threat to LRM reliability, and the proposed training-based defense provides a practical step toward safer and more trustworthy reasoning systems."}}
{"id": "2510.17361", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17361", "abs": "https://arxiv.org/abs/2510.17361", "authors": ["Shiming Liu", "Jianhua Xie", "Yan Wang"], "title": "Efficiency-Enhanced Open Earbud Earphone Antenna Using Dual-Feed Technique", "comment": "5 pages, 10 figures, submitted to IEEE Open Journal of Antennas and\n  Propagation", "summary": "The stringent spatial constraints and the demand for high antenna efficiency\nin modern wireless earphones present significant design challenges. To address\nthese issues, this paper presents and thoroughly investigates a novel earphone\nantenna design specifically tailored for open earbud wireless earphones. In\ncontrast to traditional earphone antennas that rely on a conventional\nsingle-feed configuration, the proposed design introduces a dual-feed\nexcitation technique incorporating a controlled phase difference between the\ntwo feeds. This innovative feeding strategy effectively enlarges the equivalent\nradiating aperture, thereby enhancing the overall radiation efficiency of the\nantenna system. Experimental and simulation results demonstrate that the\ndual-feed approach yields an efficiency improvement exceeding 1 dB when\ncompared with standard single-feed designs. Furthermore, the fabricated\nprototype achieves a -6 dB impedance bandwidth that fully encompasses the 2.4\nGHz ISM band, ensuring stable wireless communication performance. The measured\ntotal efficiencies reach -8.5 dB in free space and -9.5 dB under on-head\nconditions. These results confirm that the proposed antenna successfully\nachieves high efficiency and reliable performance within the extremely limited\nvolume of an earbud device, demonstrating strong potential for integration into\nnext-generation compact wireless earphones.", "AI": {"tldr": "A novel dual-feed antenna design for wireless earbuds that improves radiation efficiency by over 1 dB compared to traditional single-feed designs, achieving high performance within extreme spatial constraints.", "motivation": "Address the stringent spatial constraints and high antenna efficiency demands in modern wireless earphones, particularly for open earbud designs where traditional antennas struggle with performance.", "method": "Introduces a dual-feed excitation technique with controlled phase difference between feeds, which effectively enlarges the equivalent radiating aperture to enhance radiation efficiency.", "result": "The dual-feed approach achieves over 1 dB efficiency improvement, covers the 2.4 GHz ISM band with -6 dB impedance bandwidth, and reaches total efficiencies of -8.5 dB (free space) and -9.5 dB (on-head).", "conclusion": "The proposed antenna successfully achieves high efficiency and reliable performance within extremely limited earbud volume, demonstrating strong potential for next-generation compact wireless earphones."}}
{"id": "2510.16220", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16220", "abs": "https://arxiv.org/abs/2510.16220", "authors": ["Djamel Eddine Boukhari"], "title": "VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction", "comment": null, "summary": "Facial Beauty Prediction (FBP) is a complex and challenging computer vision\ntask, aiming to model the subjective and intricate nature of human aesthetic\nperception. While deep learning models, particularly Convolutional Neural\nNetworks (CNNs), have made significant strides, they often struggle to capture\nthe global, holistic facial features that are critical to human judgment.\nVision Transformers (ViT) address this by effectively modeling long-range\nspatial relationships, but their quadratic complexity can be a bottleneck. This\npaper introduces a novel, heterogeneous ensemble architecture,\n\\textbf{VM-BeautyNet}, that synergistically fuses the complementary strengths\nof a Vision Transformer and a Mamba-based Vision model, a recent advancement in\nState-Space Models (SSMs). The ViT backbone excels at capturing global facial\nstructure and symmetry, while the Mamba backbone efficiently models long-range\ndependencies with linear complexity, focusing on sequential features and\ntextures. We evaluate our approach on the benchmark SCUT-FBP5500 dataset. Our\nproposed VM-BeautyNet achieves state-of-the-art performance, with a\n\\textbf{Pearson Correlation (PC) of 0.9212}, a \\textbf{Mean Absolute Error\n(MAE) of 0.2085}, and a \\textbf{Root Mean Square Error (RMSE) of 0.2698}.\nFurthermore, through Grad-CAM visualizations, we provide interpretability\nanalysis that confirms the complementary feature extraction of the two\nbackbones, offering new insights into the model's decision-making process and\npresenting a powerful new architectural paradigm for computational aesthetics.", "AI": {"tldr": "VM-BeautyNet is a novel ensemble model combining Vision Transformer and Mamba-based Vision model for facial beauty prediction, achieving state-of-the-art performance on SCUT-FBP5500 dataset with improved interpretability.", "motivation": "Existing CNN models struggle to capture global facial features critical for beauty perception, while Vision Transformers have quadratic complexity limitations. There's a need for models that can efficiently capture both global structure and long-range dependencies.", "method": "Proposed VM-BeautyNet - a heterogeneous ensemble architecture that fuses Vision Transformer (for global facial structure and symmetry) with Mamba-based Vision model (for efficient long-range dependency modeling with linear complexity).", "result": "Achieved state-of-the-art performance on SCUT-FBP5500: Pearson Correlation of 0.9212, MAE of 0.2085, RMSE of 0.2698. Grad-CAM visualizations confirmed complementary feature extraction between the two backbones.", "conclusion": "VM-BeautyNet presents a powerful new architectural paradigm for computational aesthetics, successfully combining global structure modeling with efficient long-range dependency capture while providing interpretable insights into decision-making."}}
{"id": "2510.15978", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15978", "abs": "https://arxiv.org/abs/2510.15978", "authors": ["Junchao Gong", "Jingyi Xu", "Ben Fei", "Fenghua Ling", "Wenlong Zhang", "Kun Chen", "Wanghan Xu", "Weidong Yang", "Xiaokang Yang", "Lei Bai"], "title": "DAWP: A framework for global observation forecasting via Data Assimilation and Weather Prediction in satellite observation space", "comment": null, "summary": "Weather prediction is a critical task for human society, where impressive\nprogress has been made by training artificial intelligence weather prediction\n(AIWP) methods with reanalysis data. However, reliance on reanalysis data\nlimits the AIWPs with shortcomings, including data assimilation biases and\ntemporal discrepancies. To liberate AIWPs from the reanalysis data, observation\nforecasting emerges as a transformative paradigm for weather prediction. One of\nthe key challenges in observation forecasting is learning spatiotemporal\ndynamics across disparate measurement systems with irregular high-resolution\nobservation data, which constrains the design and prediction of AIWPs. To this\nend, we propose our DAWP as an innovative framework to enable AIWPs to operate\nin a complete observation space by initialization with an artificial\nintelligence data assimilation (AIDA) module. Specifically, our AIDA module\napplies a mask multi-modality autoencoder(MMAE)for assimilating irregular\nsatellite observation tokens encoded by mask ViT-VAEs. For AIWP, we introduce a\nspatiotemporal decoupling transformer with cross-regional boundary conditioning\n(CBC), learning the dynamics in observation space, to enable sub-image-based\nglobal observation forecasting. Comprehensive experiments demonstrate that AIDA\ninitialization significantly improves the roll out and efficiency of AIWP.\nAdditionally, we show that DAWP holds promising potential to be applied in\nglobal precipitation forecasting.", "AI": {"tldr": "DAWP is a framework that enables AI weather prediction to operate in observation space using AI data assimilation, overcoming limitations of reanalysis data dependency.", "motivation": "Current AI weather prediction methods rely on reanalysis data which has biases and temporal discrepancies. Observation forecasting offers a transformative alternative but faces challenges with irregular high-resolution data across disparate measurement systems.", "method": "Proposes DAWP with AI data assimilation (AIDA) module using mask multi-modality autoencoder for assimilating irregular satellite observations, and spatiotemporal decoupling transformer with cross-regional boundary conditioning for global observation forecasting.", "result": "AIDA initialization significantly improves AIWP rollout and efficiency. DAWP shows promising potential for global precipitation forecasting.", "conclusion": "DAWP successfully liberates AI weather prediction from reanalysis data dependency by enabling operation in complete observation space through innovative AI data assimilation and forecasting methods."}}
{"id": "2510.16276", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16276", "abs": "https://arxiv.org/abs/2510.16276", "authors": ["Song Bian", "Minghao Yan", "Anand Jayarajan", "Gennady Pekhimenko", "Shivaram Venkataraman"], "title": "What Limits Agentic Systems Efficiency?", "comment": "27 pages, 15 figures", "summary": "Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have\ndemonstrated strong reasoning capabilities. To further enhance LLM\ncapabilities, recent agentic systems, such as Deep Research, incorporate web\ninteractions into LLM reasoning to mitigate uncertainties and reduce potential\nerrors. However, existing research predominantly focuses on reasoning\nperformance, often neglecting the efficiency of agentic systems. In this work,\nwe present a comprehensive empirical study that identifies efficiency\nbottlenecks in web-interactive agentic systems. We decompose end-to-end latency\ninto two primary components: LLM API latency and web environment latency. We\nconduct a comprehensive empirical study across 15 models and 5 providers to\ndemonstrate high variability in API-based agentic systems. We observe that web\nenvironment latency can contribute as much as 53.7% to the overall latency in a\nweb-based agentic system. To improve latency, we propose SpecCache, a caching\nframework augmented with speculative execution that can reduce web environment\noverhead. Extensive evaluations on two standard benchmarks show that our\napproach improves the cache hit rate by up to 58x compared to a random caching\nstrategy, while reducing web environment overhead by up to 3.2x, without\ndegrading agentic system performance.", "AI": {"tldr": "This paper identifies efficiency bottlenecks in web-interactive LLM agentic systems and proposes SpecCache, a caching framework with speculative execution that reduces web environment overhead by up to 3.2x without performance degradation.", "motivation": "Existing research on LLM agentic systems focuses primarily on reasoning performance while neglecting efficiency. Web interactions in these systems introduce significant latency that can account for over 50% of total system latency.", "method": "The authors conduct an empirical study across 15 models and 5 providers to analyze latency components. They propose SpecCache, a caching framework augmented with speculative execution to reduce web environment overhead.", "result": "Web environment latency contributes up to 53.7% of overall system latency. SpecCache improves cache hit rate by up to 58x compared to random caching and reduces web environment overhead by up to 3.2x while maintaining system performance.", "conclusion": "Efficiency is a critical bottleneck in web-interactive agentic systems, and the proposed SpecCache framework effectively addresses this issue by significantly reducing web environment latency without compromising reasoning performance."}}
{"id": "2510.17462", "categories": ["eess.SP", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17462", "abs": "https://arxiv.org/abs/2510.17462", "authors": ["Sefa Kayraklik", "Ali Fuat Sahin", "Onur Salan", "Recep A. Tasci", "Recep Vural", "Yusuf Islam Tek", "Ertugrul Basar", "Ibrahim Hokelek", "Ali Gorcin", "Karim Boutiba", "Adlen Ksentini"], "title": "ORIX: Orchestration of RIS with xApps for Smart Wireless Factory Environments", "comment": "Submitted in IEEE", "summary": "The vision of a smart wireless factory (SWF) demands highly flexible,\nlow-latency, and reliable connectivity that goes beyond conventional wireless\nsolutions. Reconfigurable intelligent surface (RIS)-empowered communications,\nwhen integrated with the open radio access network (O-RAN) architectures, have\nemerged as a promising enabler to meet these challenging requirements. This\narticle introduces the methodology for the orchestration of RIS with xApps\n(ORIX), bringing the RIS technology into the O-RAN ecosystem through xApp-based\ncontrol for SWF environments. ORIX features three key components: an\nO-RAN-compliant RIS service model for dynamic configuration, an RIS channel\nsimulator that supports 3GPP indoor factory models with multiple industrial\nscenarios, and practical RIS optimization strategies with finite-resolution\ncontrol. Together, these elements provide a realistic end-to-end emulation\nplatform for evaluating RIS placement, control, and performance in SWF\nenvironments prior to deployment. The presented case study demonstrates how\nORIX enables the evaluation of achievable performance gains, exploration of\ntrade-offs among key RIS design parameters, and identification of deployment\nstrategies that balance system performance with practical implementation\nconstraints. By bridging theoretical advances with industrial feasibility, ORIX\nlays the groundwork for RIS-assisted O-RAN networks to power next-generation\nwireless communication in industrial scenarios.", "AI": {"tldr": "ORIX integrates RIS with O-RAN through xApp-based control for smart wireless factories, providing dynamic configuration, channel simulation, and optimization strategies for practical deployment.", "motivation": "Smart wireless factories require flexible, low-latency, reliable connectivity beyond conventional wireless solutions. RIS-empowered communications integrated with O-RAN architectures can meet these challenging industrial requirements.", "method": "ORIX methodology includes: O-RAN-compliant RIS service model for dynamic configuration, RIS channel simulator supporting 3GPP indoor factory models with multiple industrial scenarios, and practical RIS optimization strategies with finite-resolution control.", "result": "ORIX provides a realistic end-to-end emulation platform for evaluating RIS placement, control, and performance in SWF environments. Case study demonstrates performance gains, trade-off exploration among RIS design parameters, and identification of deployment strategies balancing performance with implementation constraints.", "conclusion": "ORIX bridges theoretical advances with industrial feasibility, laying groundwork for RIS-assisted O-RAN networks to power next-generation wireless communication in industrial scenarios."}}
{"id": "2510.16235", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16235", "abs": "https://arxiv.org/abs/2510.16235", "authors": ["Vishal Manikanden", "Aniketh Bandlamudi", "Daniel Haehn"], "title": "Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection", "comment": null, "summary": "Oral Cavity Squamous Cell Carcinoma (OCSCC) is the most common type of head\nand neck cancer. Due to the subtle nature of its early stages, deep and hidden\nareas of development, and slow growth, OCSCC often goes undetected, leading to\npreventable deaths. However, properly trained Convolutional Neural Networks\n(CNNs), with their precise image segmentation techniques and ability to apply\nkernel matrices to modify the RGB values of images for accurate image pattern\nrecognition, would be an effective means for early detection of OCSCC. Pairing\nthis neural network with image capturing and processing hardware would allow\nincreased efficacy in OCSCC detection. The aim of our project is to develop a\nConvolutional Neural Network trained to recognize OCSCC, as well as to design a\nphysical hardware system to capture and process detailed images, in order to\ndetermine the image quality required for accurate predictions. A CNN was\ntrained on 4293 training images consisting of benign and malignant tumors, as\nwell as negative samples, and was evaluated for its precision, recall, and Mean\nAverage Precision (mAP) in its predictions of OCSCC. A testing dataset of\nrandomly assorted images of cancerous, non-cancerous, and negative images was\nchosen, and each image was altered to represent 5 common resolutions. This test\ndata set was thoroughly analyzed by the CNN and predictions were scored on the\nbasis of accuracy. The designed enhancement hardware was used to capture\ndetailed images, and its impact was scored. An application was developed to\nfacilitate the testing process and bring open access to the CNN. Images of\nincreasing resolution resulted in higher-accuracy predictions on a logarithmic\nscale, demonstrating the diminishing returns of higher pixel counts.", "AI": {"tldr": "CNN-based system for early detection of Oral Cavity Squamous Cell Carcinoma using image analysis, showing that higher resolution images improve detection accuracy with diminishing returns.", "motivation": "OCSCC often goes undetected due to subtle early stages and hidden development areas, leading to preventable deaths. CNN-based detection could enable early diagnosis.", "method": "Trained CNN on 4293 images (benign/malignant tumors, negatives), tested on various resolutions, developed hardware for image capture, and created application for testing.", "result": "Higher resolution images led to more accurate predictions on a logarithmic scale, showing diminishing returns of higher pixel counts.", "conclusion": "CNN-based detection system shows promise for early OCSCC detection, with image resolution being a key factor in prediction accuracy."}}
{"id": "2510.15979", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15979", "abs": "https://arxiv.org/abs/2510.15979", "authors": ["Zexu Sun", "Yongcheng Zeng", "Erxue Min", "Heyang Gao", "Bokai Ji", "Xu Chen"], "title": "Cog-Rethinker: Hierarchical Metacognitive Reinforcement Learning for LLM Reasoning", "comment": "22 Pages, 8 figures, 4 tables", "summary": "Contemporary progress in large language models (LLMs) has revealed notable\ninferential capacities via reinforcement learning (RL) employing verifiable\nreward, facilitating the development of O1 and R1-like reasoning models.\nDirectly training from base models with RL is called zero-RL. However, previous\nworks rely upon activating LLMs' inherent capacities through fixed prompt\ntemplates. This strategy introduces substantial sampling inefficiencies for\nweak LLMs, as the majority of problems generate invalid outputs during\naccuracy-driven filtration in reasoning tasks, which causes a waste of samples.\nTo solve this issue, we propose Cog-Rethinker, a novel hierarchical\nmetacognitive RL framework for LLM reasoning. Our Cog-Rethinker mainly focuses\non the rollout procedure in RL training. After the direct rollout, our\nCog-Rethinker improves sample utilization in a hierarchical metacognitive\ntwo-stage framework. By leveraging human cognition during solving problems,\nfirstly, it prompts policy to decompose zero-accuracy problems into subproblems\nto produce final reasoning results. Secondly, with zero-accuracy problems in\nprevious rollout stage, it further prompts policy to refine these answers by\nreferencing previous wrong solutions. Moreover, to enable cold-start of the two\nnew reasoning patterns and maintain train-test consistency across prompt\ntemplates, our Cog-Rethinker applies supervised fine-tuning on the policy using\ncorrect samples of the two stages with direct rollout template. Experimental\nresults demonstrate Cog-Rethinker's superior performance on various\nmathematical reasoning benchmarks, we also analyzed its improved sample\nefficiency that accelerates convergence compared to baseline methods.", "AI": {"tldr": "Cog-Rethinker is a hierarchical metacognitive RL framework that improves sample efficiency in LLM reasoning by decomposing zero-accuracy problems and refining wrong solutions, achieving better performance on mathematical reasoning benchmarks.", "motivation": "Current RL training for LLMs suffers from sampling inefficiencies, especially for weak models where most problems generate invalid outputs during accuracy-driven filtration, wasting samples.", "method": "Proposes a two-stage hierarchical metacognitive framework: 1) decomposes zero-accuracy problems into subproblems, 2) refines answers by referencing previous wrong solutions. Uses supervised fine-tuning for cold-start and maintains train-test consistency.", "result": "Demonstrates superior performance on various mathematical reasoning benchmarks and shows improved sample efficiency that accelerates convergence compared to baseline methods.", "conclusion": "Cog-Rethinker effectively addresses sampling inefficiency in RL training for LLM reasoning through hierarchical metacognitive approaches, enabling better utilization of training samples and faster convergence."}}
{"id": "2510.16302", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16302", "abs": "https://arxiv.org/abs/2510.16302", "authors": ["Changhao Wang", "Yanfang Liu", "Xinxin Fan", "Anzhi Zhou", "Lao Tian", "Yunfeng Lu"], "title": "DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA", "comment": "13 pages, 5 figures", "summary": "Multi-hop reasoning for question answering (QA) plays a critical role in\nretrieval-augmented generation (RAG) for modern large language models (LLMs).\nThe accurate answer can be obtained through retrieving relational structure of\nentities from knowledge graph (KG). Regarding the inherent relation-dependency\nand reasoning pattern, multi-hop reasoning can be in general classified into\ntwo categories: i) parallel fact-verification multi-hop reasoning question,\ni.e., requiring simultaneous verifications of multiple independent\nsub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding\nsequential multi-step inference with intermediate conclusions serving as\nessential premises for subsequent reasoning. Currently, the multi-hop reasoning\napproaches singly employ one of two techniques: LLM response-based fact\nverification and KG path-based chain construction. Nevertheless, the former\nexcels at parallel fact-verification but underperforms on chained reasoning\ntasks, while the latter demonstrates proficiency in chained multi-hop reasoning\nbut suffers from redundant path retrieval when handling parallel\nfact-verification reasoning. These limitations deteriorate the efficiency and\naccuracy for multi-hop QA tasks. To address this challenge, we propose a novel\ndual-track KG verification and reasoning framework DTKG, which is inspired by\nthe Dual Process Theory in cognitive science. Specifically, DTKG comprises two\nmain stages: the Classification Stage and the Branch Processing Stage.", "AI": {"tldr": "DTKG is a dual-track framework for multi-hop QA that combines LLM-based fact verification and KG path-based reasoning to handle both parallel fact-verification and chained multi-hop reasoning tasks efficiently.", "motivation": "Current multi-hop reasoning approaches either use LLM response-based fact verification (good for parallel verification but poor for chained reasoning) or KG path-based chain construction (good for chained reasoning but inefficient for parallel verification), leading to efficiency and accuracy issues.", "method": "DTKG uses a dual-track framework inspired by Dual Process Theory, with two main stages: Classification Stage to identify reasoning type, and Branch Processing Stage to apply appropriate techniques (LLM verification for parallel tasks, KG path construction for chained tasks).", "result": "The paper claims DTKG addresses the limitations of existing approaches by efficiently handling both types of multi-hop reasoning tasks, though specific results are not detailed in the abstract.", "conclusion": "DTKG provides a comprehensive solution for multi-hop QA by leveraging both LLM and KG capabilities through a dual-track approach, improving efficiency and accuracy across different reasoning patterns."}}
{"id": "2510.17502", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17502", "abs": "https://arxiv.org/abs/2510.17502", "authors": ["Li-Hsiang Shen"], "title": "6D Movable Metasurface (6DMM) in Downlink NOMA Transmissions", "comment": null, "summary": "This letter proposes a novel six-dimensional movable metasurface\n(6DMM)-assisted downlink non-orthogonal multiple access (NOMA) system, in which\na conventional base station (BS) equipped with fixed antennas serves multiple\nusers with the assistance of a reconfigurable intelligent surface (RIS) with\nsix-dimensional spatial configurability. In contrast to traditional RIS with\nstatic surface, the proposed 6DMM architecture allows each element to\ndynamically adjust its position and orient the whole metasurface in\nyaw-pitch-roll axes, enabling both in spatial and electromagnetic controls. We\nformulate a sum-rate maximization problem that jointly optimizes the BS\nNOMA-based beamforming, phase-shifts, element positions, and rotation angles of\nmetasurface under constraints of NOMA power levels, unit-modulus of\nphase-shifts, power budget, inter-element separation and boundaries of element\nposition/orientation. Due to non-convexity and high-dimensionality, we employ a\nprobabilistic cross-entropy optimization (CEO) scheme to iteratively refine the\nsolution distribution based on maximizing likelihood and elite solution\nsampling. Simulation results show that the proposed CEO-based 6DMM-NOMA\narchitecture achieves substantial rate performance gains compared to 6DMM\nsub-structures, conventional static RIS, and other multiple access mechanisms.\nIt also highlights the effectiveness of CEO providing probabilistic\noptimization for solving high-dimensional scalable metasurface.", "AI": {"tldr": "A novel 6D movable metasurface-assisted NOMA system that dynamically adjusts element positions and orientations to enhance downlink performance through joint optimization of beamforming, phase-shifts, and spatial configurations.", "motivation": "Traditional RIS systems have static surfaces, limiting their spatial and electromagnetic control capabilities. The proposed 6DMM architecture enables dynamic position and orientation adjustments to improve communication performance.", "method": "Formulated a sum-rate maximization problem with joint optimization of BS NOMA beamforming, phase-shifts, element positions, and rotation angles. Used probabilistic cross-entropy optimization (CEO) to solve the high-dimensional non-convex problem through iterative solution distribution refinement.", "result": "Simulation results show substantial rate performance gains compared to 6DMM sub-structures, conventional static RIS, and other multiple access mechanisms. The CEO approach effectively handles high-dimensional optimization for scalable metasurfaces.", "conclusion": "The 6DMM-NOMA architecture with CEO optimization provides significant performance improvements over traditional systems, demonstrating the effectiveness of dynamic spatial and electromagnetic control in metasurface-assisted communications."}}
{"id": "2510.16258", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16258", "abs": "https://arxiv.org/abs/2510.16258", "authors": ["Claire McLean", "Makenzie Meendering", "Tristan Swartz", "Orri Gabbay", "Alexandra Olsen", "Rachel Jacobs", "Nicholas Rosen", "Philippe de Bree", "Tony Garcia", "Gadsden Merrill", "Jake Sandakly", "Julia Buffalini", "Neham Jain", "Steven Krenn", "Moneish Kumar", "Dejan Markovic", "Evonne Ng", "Fabian Prada", "Andrew Saba", "Siwei Zhang", "Vasu Agrawal", "Tim Godisart", "Alexander Richard", "Michael Zollhoefer"], "title": "Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset", "comment": null, "summary": "The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of\n500 individual hours of 3D motion data from 439 participants collected in a\nmulti-camera collection stage, amounting to over 54 million frames of tracked\n3D motion. The dataset features a wide range of single-person motion data,\nincluding prompted motions, hand gestures, and locomotion; as well as\nmulti-person behavioral and conversational data like discussions, conversations\nin different emotional states, collaborative activities, and co-living\nscenarios in an apartment-like space. We provide tracked human motion including\nhand tracking and body shape, text annotations, and a separate audio track for\neach participant.", "AI": {"tldr": "Embody 3D is a large-scale multimodal dataset containing 500 hours of 3D motion data from 439 participants, featuring both single-person and multi-person interactions with comprehensive tracking and annotations.", "motivation": "To create a comprehensive dataset for studying human motion and social interactions in 3D, addressing the need for large-scale multimodal data with detailed motion tracking and behavioral annotations.", "method": "Collected data from 439 participants in a multi-camera stage, capturing over 54 million frames of 3D motion tracking including hand gestures, body shape, and various interaction scenarios.", "result": "Produced a dataset with 500 hours of 3D motion data covering prompted motions, hand gestures, locomotion, discussions, emotional conversations, collaborative activities, and co-living scenarios.", "conclusion": "Embody 3D provides a valuable resource for research in human motion analysis, social interactions, and behavioral studies with comprehensive multimodal data including text annotations and separate audio tracks."}}
{"id": "2510.15982", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15982", "abs": "https://arxiv.org/abs/2510.15982", "authors": ["Donghyeok Shin", "Yeongmin Kim", "Suhyeon Jo", "Byeonghu Na", "Il-Chul Moon"], "title": "AMiD: Knowledge Distillation for LLMs with $\u03b1$-mixture Assistant Distribution", "comment": null, "summary": "Autoregressive large language models (LLMs) have achieved remarkable\nimprovement across many tasks but incur high computational and memory costs.\nKnowledge distillation (KD) mitigates this issue by transferring knowledge from\na large teacher to a smaller student through distributional alignment. Previous\nstudies have proposed various discrepancy metrics, but the capacity gap and\ntraining instability caused by near-zero probabilities, stemming from the\nhigh-dimensional output of LLMs, remain fundamental limitations. To overcome\nthese challenges, several approaches implicitly or explicitly incorporating\nassistant distribution have recently been proposed. However, the past proposals\nof assistant distributions have been a fragmented approach without a systematic\ninvestigation of the interpolation path and the divergence. This paper proposes\n$\\alpha$-mixture assistant distribution, a novel generalized family of\nassistant distributions, and $\\alpha$-mixture distillation, coined AMiD, a\nunified framework for KD using the assistant distribution. The $\\alpha$-mixture\nassistant distribution provides a continuous extension of the assistant\ndistribution by introducing a new distribution design variable $\\alpha$, which\nhas been fixed in all previous approaches. Furthermore, AMiD generalizes the\nfamily of divergences used with the assistant distributions based on\noptimality, which has also been restricted in previous works. Through extensive\nexperiments, we demonstrate that AMiD offers superior performance and training\nstability by leveraging a broader and theoretically grounded assistant\ndistribution space.", "AI": {"tldr": "Proposes AMiD, a unified knowledge distillation framework using \u03b1-mixture assistant distributions to address training instability and capacity gaps in LLM distillation.", "motivation": "Address computational/memory costs of LLMs and overcome limitations of previous KD methods including capacity gaps and training instability from near-zero probabilities in high-dimensional outputs.", "method": "Introduces \u03b1-mixture assistant distribution as a generalized family with continuous parameter \u03b1, and AMiD framework that generalizes divergence families based on optimality theory.", "result": "AMiD demonstrates superior performance and training stability by leveraging broader, theoretically grounded assistant distribution space in extensive experiments.", "conclusion": "The proposed \u03b1-mixture assistant distribution and AMiD framework provide a unified, systematic approach that outperforms previous fragmented methods for LLM knowledge distillation."}}
{"id": "2510.16309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16309", "abs": "https://arxiv.org/abs/2510.16309", "authors": ["Crystal Su"], "title": "MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier", "comment": "Accepted to the Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2026) Workshop", "summary": "Large language models (LLMs) often produce fluent reasoning steps while\nviolating simple mathematical or logical constraints. We introduce MedRule-KG,\na compact typed knowledge graph coupled with a symbolic verifier, designed to\nenforce mathematically interpretable rules in reasoning tasks. MedRule-KG\nencodes entities, relations, and three domain-inspired rules, while the\nverifier checks predictions and applies minimal corrections to guarantee\nconsistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG\nimproves exact match (EM) from 0.767 to 0.900, and adding the verifier yields\n1.000 EM while eliminating rule violations entirely. We demonstrate how\nMedRule-KG provides a general scaffold for safe mathematical reasoning, discuss\nablations, and release code and data to encourage reproducibility.", "AI": {"tldr": "MedRule-KG is a knowledge graph with symbolic verification that enforces mathematical rules in LLM reasoning, improving accuracy from 76.7% to 100% on FDA benchmarks.", "motivation": "LLMs often produce fluent but mathematically/logically incorrect reasoning, violating basic constraints despite appearing coherent.", "method": "Create MedRule-KG - a compact typed knowledge graph with symbolic verifier that encodes entities, relations, and domain rules, then checks predictions and applies minimal corrections for consistency.", "result": "On 90-example FDA benchmark: grounding in MedRule-KG improved EM from 0.767 to 0.900; adding verifier achieved 1.000 EM and eliminated all rule violations.", "conclusion": "MedRule-KG provides a general scaffold for safe mathematical reasoning, with code and data released for reproducibility."}}
{"id": "2510.17695", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17695", "abs": "https://arxiv.org/abs/2510.17695", "authors": ["Maximilian H. V. Tillmann", "Ban-Sok Shin", "Dmitriy Shutin", "Armin Dekorsy"], "title": "Semantic Joint Source Channel Coding for Distributed Subsurface Imaging in Multi-Agent Systems", "comment": null, "summary": "Multi-agent systems (MAS) are a promising solution for autonomous exploration\ntasks in hazardous or remote environments, such as planetary surveys. In such\nsettings, communication among agents is essential to ensure collaborative task\nexecution, yet conventional approaches treat exploration and communication as\ndecoupled subsystems. This work presents a novel framework that tightly\nintegrates semantic communication into the MAS exploration process, adapting\ncommunication strategies to the exploration methodology to improve overall task\nperformance. Specifically, we investigate the application of semantic joint\nsource-channel coding (JSCC) with over-the-air computation (AirComp) for\ndistributed function computation for the application of cooperative subsurface\nimaging using the adapt-then-combine full waveform inversion (ATC-FWI)\nalgorithm. Our results demonstrate that semantic JSCC significantly outperforms\nclassical point-to-point and standard JSCC methods, especially in\nhigh-connectivity networks. Furthermore, incorporating side information at the\nreceiving agent enhances communication efficiency and imaging accuracy, a\nfeature previously unexplored in MAS-based exploration. We validate our\napproach through a use case inspired by subsurface anomaly detection, showing\nmeasurable improvements in imaging performance per agent. This work underscores\nthe potential of semantic communication in distributed multi-agent exploration,\noffering a communication-aware exploration paradigm that achieves task-relevant\nperformance gains.", "AI": {"tldr": "This paper presents a semantic communication framework for multi-agent exploration systems that integrates communication strategies with exploration methodology, using semantic JSCC with AirComp for cooperative subsurface imaging.", "motivation": "Traditional multi-agent systems treat exploration and communication as separate subsystems, which limits performance in autonomous exploration tasks like planetary surveys where communication is essential for collaboration.", "method": "The framework integrates semantic joint source-channel coding (JSCC) with over-the-air computation (AirComp) for distributed function computation, applied to cooperative subsurface imaging using adapt-then-combine full waveform inversion (ATC-FWI) algorithm.", "result": "Semantic JSCC significantly outperforms classical point-to-point and standard JSCC methods, especially in high-connectivity networks. Incorporating side information at receiving agents enhances communication efficiency and imaging accuracy.", "conclusion": "The work demonstrates the potential of semantic communication in distributed multi-agent exploration, offering a communication-aware exploration paradigm that achieves task-relevant performance gains."}}
{"id": "2510.16272", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16272", "abs": "https://arxiv.org/abs/2510.16272", "authors": ["Baicheng Li", "Zike Yan", "Dong Wu", "Hongbin Zha"], "title": "Proactive Scene Decomposition and Reconstruction", "comment": null, "summary": "Human behaviors are the major causes of scene dynamics and inherently contain\nrich cues regarding the dynamics. This paper formalizes a new task of proactive\nscene decomposition and reconstruction, an online approach that leverages\nhuman-object interactions to iteratively disassemble and reconstruct the\nenvironment. By observing these intentional interactions, we can dynamically\nrefine the decomposition and reconstruction process, addressing inherent\nambiguities in static object-level reconstruction. The proposed system\neffectively integrates multiple tasks in dynamic environments such as accurate\ncamera and object pose estimation, instance decomposition, and online map\nupdating, capitalizing on cues from human-object interactions in egocentric\nlive streams for a flexible, progressive alternative to conventional\nobject-level reconstruction methods. Aided by the Gaussian splatting technique,\naccurate and consistent dynamic scene modeling is achieved with photorealistic\nand efficient rendering. The efficacy is validated in multiple real-world\nscenarios with promising advantages.", "AI": {"tldr": "Proactive scene decomposition and reconstruction using human-object interactions to dynamically refine scene understanding from egocentric live streams.", "motivation": "Human behaviors provide rich cues about scene dynamics that can help address ambiguities in static object-level reconstruction methods.", "method": "Online approach that leverages human-object interactions to iteratively disassemble and reconstruct environments, integrating camera/object pose estimation, instance decomposition, and online map updating using Gaussian splatting for efficient rendering.", "result": "Achieves accurate and consistent dynamic scene modeling with photorealistic rendering, validated in multiple real-world scenarios with promising advantages.", "conclusion": "The proposed system provides a flexible, progressive alternative to conventional object-level reconstruction methods by capitalizing on human-object interaction cues."}}
{"id": "2510.15985", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15985", "abs": "https://arxiv.org/abs/2510.15985", "authors": ["Zexi Tan", "Tao Xie", "Binbin Sun", "Xiang Zhang", "Yiqun Zhang", "Yiu-Ming Cheung"], "title": "MEET-Sepsis: Multi-Endogenous-View Enhanced Time-Series Representation Learning for Early Sepsis Prediction Representation Learning for Early Sepsis Prediction", "comment": "Accepted to PRICAI 2025", "summary": "Sepsis is a life-threatening infectious syndrome associated with high\nmortality in intensive care units (ICUs). Early and accurate sepsis prediction\n(SP) is critical for timely intervention, yet remains challenging due to subtle\nearly manifestations and rapidly escalating mortality. While AI has improved SP\nefficiency, existing methods struggle to capture weak early temporal signals.\nThis paper introduces a Multi-Endogenous-view Representation Enhancement (MERE)\nmechanism to construct enriched feature views, coupled with a Cascaded\nDual-convolution Time-series Attention (CDTA) module for multi-scale temporal\nrepresentation learning. The proposed MEET-Sepsis framework achieves\ncompetitive prediction accuracy using only 20% of the ICU monitoring time\nrequired by SOTA methods, significantly advancing early SP. Extensive\nvalidation confirms its efficacy. Code is available at:\nhttps://github.com/yueliangy/MEET-Sepsis.", "AI": {"tldr": "The paper proposes MEET-Sepsis, an AI framework for early sepsis prediction that uses multi-view feature enhancement and multi-scale temporal attention to achieve competitive accuracy with only 20% of ICU monitoring time compared to state-of-the-art methods.", "motivation": "Early sepsis prediction is critical for timely intervention but remains challenging due to subtle early manifestations and rapidly escalating mortality. Existing AI methods struggle to capture weak early temporal signals in ICU monitoring data.", "method": "Proposes a Multi-Endogenous-view Representation Enhancement (MERE) mechanism to construct enriched feature views, coupled with a Cascaded Dual-convolution Time-series Attention (CDTA) module for multi-scale temporal representation learning.", "result": "The MEET-Sepsis framework achieves competitive prediction accuracy using only 20% of the ICU monitoring time required by state-of-the-art methods, significantly advancing early sepsis prediction.", "conclusion": "The proposed framework effectively addresses the challenge of early sepsis prediction by enhancing feature representations and capturing multi-scale temporal patterns, with extensive validation confirming its efficacy."}}
{"id": "2510.16342", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16342", "abs": "https://arxiv.org/abs/2510.16342", "authors": ["Tong Zhang", "Ru Zhang", "Jianyi Liu", "Zhen Yang", "Gongshen Liu"], "title": "Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts", "comment": null, "summary": "Existing concept erasure methods for text-to-image diffusion models commonly\nrely on fixed anchor strategies, which often lead to critical issues such as\nconcept re-emergence and erosion. To address this, we conduct causal tracing to\nreveal the inherent sensitivity of erasure to anchor selection and define\nSibling Exclusive Concepts as a superior class of anchors. Based on this\ninsight, we propose \\textbf{SELECT} (Sibling-Exclusive Evaluation for\nContextual Targeting), a dynamic anchor selection framework designed to\novercome the limitations of fixed anchors. Our framework introduces a novel\ntwo-stage evaluation mechanism that automatically discovers optimal anchors for\nprecise erasure while identifying critical boundary anchors to preserve related\nconcepts. Extensive evaluations demonstrate that SELECT, as a universal anchor\nsolution, not only efficiently adapts to multiple erasure frameworks but also\nconsistently outperforms existing baselines across key performance metrics,\naveraging only 4 seconds for anchor mining of a single concept.", "AI": {"tldr": "SELECT is a dynamic anchor selection framework that overcomes limitations of fixed anchor strategies in concept erasure for text-to-image diffusion models, using sibling exclusive concepts and two-stage evaluation to achieve precise erasure while preserving related concepts.", "motivation": "Existing concept erasure methods rely on fixed anchor strategies, which cause issues like concept re-emergence and erosion. The sensitivity of erasure to anchor selection needs to be addressed.", "method": "Proposed SELECT framework with two-stage evaluation mechanism that automatically discovers optimal anchors for precise erasure and identifies critical boundary anchors to preserve related concepts.", "result": "SELECT efficiently adapts to multiple erasure frameworks and consistently outperforms existing baselines across key performance metrics, averaging only 4 seconds for anchor mining of a single concept.", "conclusion": "SELECT serves as a universal anchor solution that overcomes limitations of fixed anchors in concept erasure for text-to-image diffusion models."}}
{"id": "2510.17738", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17738", "abs": "https://arxiv.org/abs/2510.17738", "authors": ["Fabian Jaensch", "Giuseppe Caire", "Beg\u00fcm Demir"], "title": "Beam Index Map Prediction in Unseen Environments from Geospatial Data", "comment": "5 pages", "summary": "In 5G, beam training consists of the efficient association of users to beams\nfor a given beamforming codebook used at the base station and the given\npropagation environment in the cell. We propose a convolutional neural network\napproach that leverages the position of the base station and geospatial data to\npredict beam distributions for all user locations simultaneously. Our method\ngeneralizes to unseen environments without site-specific training or\nspecialized sensors. The results show that it significantly reduces the number\nof candidate beams considered, thereby improving the efficiency of beam\ntraining.", "AI": {"tldr": "A CNN-based approach using base station position and geospatial data to predict beam distributions for all user locations, reducing beam training overhead in 5G networks.", "motivation": "To improve efficiency of beam training in 5G by reducing the number of candidate beams that need to be considered during user association.", "method": "Convolutional neural network that leverages base station position and geospatial data to predict beam distributions for all user locations simultaneously.", "result": "Significantly reduces the number of candidate beams considered, improving beam training efficiency without requiring site-specific training or specialized sensors.", "conclusion": "The proposed CNN method effectively generalizes to unseen environments and enhances 5G beam training efficiency through geospatial data utilization."}}
{"id": "2510.16290", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16290", "abs": "https://arxiv.org/abs/2510.16290", "authors": ["Yue Zheng", "Xiufang Shi", "Jiming Chen", "Yuanchao Shu"], "title": "Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models", "comment": null, "summary": "Video anomaly detection (VAD) has rapidly advanced by recent development of\nVision-Language Models (VLMs). While these models offer superior zero-shot\ndetection capabilities, their immense computational cost and unstable visual\ngrounding performance hinder real-time deployment. To overcome these\nchallenges, we introduce Cerberus, a two-stage cascaded system designed for\nefficient yet accurate real-time VAD. Cerberus learns normal behavioral rules\noffline, and combines lightweight filtering with fine-grained VLM reasoning\nduring online inference. The performance gains of Cerberus come from two key\ninnovations: motion mask prompting and rule-based deviation detection. The\nformer directs the VLM's attention to regions relevant to motion, while the\nlatter identifies anomalies as deviations from learned norms rather than\nenumerating possible anomalies. Extensive evaluations on four datasets show\nthat Cerberus on average achieves 57.68 fps on an NVIDIA L40S GPU, a\n151.79$\\times$ speedup, and 97.2\\% accuracy comparable to the state-of-the-art\nVLM-based VAD methods, establishing it as a practical solution for real-time\nvideo analytics.", "AI": {"tldr": "Cerberus is a two-stage cascaded system for real-time video anomaly detection that combines lightweight filtering with VLM reasoning, achieving 57.68 fps and 97.2% accuracy.", "motivation": "Current VLM-based VAD methods have high computational costs and unstable visual grounding, making real-time deployment challenging.", "method": "Two-stage system with offline learning of normal behavior rules, motion mask prompting to direct VLM attention, and rule-based deviation detection to identify anomalies as deviations from learned norms.", "result": "Achieves 57.68 fps on NVIDIA L40S GPU (151.79\u00d7 speedup) and 97.2% accuracy comparable to state-of-the-art VLM-based methods on four datasets.", "conclusion": "Cerberus establishes itself as a practical solution for real-time video analytics by balancing efficiency and accuracy."}}
{"id": "2510.15986", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15986", "abs": "https://arxiv.org/abs/2510.15986", "authors": ["Sifeddine Sellami", "Juba Agoun", "Lamia Yessad", "Louenas Bounia"], "title": "User Profiles of Sleep Disorder Sufferers: Towards Explainable Clustering and Differential Variable Analysis", "comment": "in French language, Plate-Forme Intelligence Artificielle, Jun 2025,\n  Dijon (FRANCE), France", "summary": "Sleep disorders have a major impact on patients' health and quality of life,\nbut their diagnosis remains complex due to the diversity of symptoms. Today,\ntechnological advances, combined with medical data analysis, are opening new\nperspectives for a better understanding of these disorders. In particular,\nexplainable artificial intelligence (XAI) aims to make AI model decisions\nunderstandable and interpretable for users. In this study, we propose a\nclustering-based method to group patients according to different sleep disorder\nprofiles. By integrating an explainable approach, we identify the key factors\ninfluencing these pathologies. An experiment on anonymized real data\nillustrates the effectiveness and relevance of our approach.", "AI": {"tldr": "A clustering-based method using explainable AI to group patients by sleep disorder profiles and identify key influencing factors.", "motivation": "Sleep disorders significantly impact health and quality of life, but diagnosis is complex due to diverse symptoms. Technological advances and medical data analysis offer new opportunities for better understanding these disorders.", "method": "Proposed a clustering-based method to group patients according to different sleep disorder profiles, integrating explainable artificial intelligence (XAI) to make AI model decisions understandable and interpretable.", "result": "The approach successfully identified key factors influencing sleep pathologies through experiments on anonymized real data.", "conclusion": "The method demonstrates effectiveness and relevance in understanding sleep disorders through explainable clustering of patient profiles."}}
{"id": "2510.16368", "categories": ["cs.AI", "cs.HC", "cs.LG", "econ.TH"], "pdf": "https://arxiv.org/pdf/2510.16368", "abs": "https://arxiv.org/abs/2510.16368", "authors": ["Ali Shirali"], "title": "The Burden of Interactive Alignment with Inconsistent Preferences", "comment": "Published as a conference paper at NeurIPS 2025", "summary": "From media platforms to chatbots, algorithms shape how people interact,\nlearn, and discover information. Such interactions between users and an\nalgorithm often unfold over multiple steps, during which strategic users can\nguide the algorithm to better align with their true interests by selectively\nengaging with content. However, users frequently exhibit inconsistent\npreferences: they may spend considerable time on content that offers little\nlong-term value, inadvertently signaling that such content is desirable.\nFocusing on the user side, this raises a key question: what does it take for\nsuch users to align the algorithm with their true interests?\n  To investigate these dynamics, we model the user's decision process as split\nbetween a rational system 2 that decides whether to engage and an impulsive\nsystem 1 that determines how long engagement lasts. We then study a\nmulti-leader, single-follower extensive Stackelberg game, where users,\nspecifically system 2, lead by committing to engagement strategies and the\nalgorithm best-responds based on observed interactions. We define the burden of\nalignment as the minimum horizon over which users must optimize to effectively\nsteer the algorithm. We show that a critical horizon exists: users who are\nsufficiently foresighted can achieve alignment, while those who are not are\ninstead aligned to the algorithm's objective. This critical horizon can be\nlong, imposing a substantial burden. However, even a small, costly signal\n(e.g., an extra click) can significantly reduce it. Overall, our framework\nexplains how users with inconsistent preferences can align an engagement-driven\nalgorithm with their interests in a Stackelberg equilibrium, highlighting both\nthe challenges and potential remedies for achieving alignment.", "AI": {"tldr": "Users with inconsistent preferences can align algorithms with their true interests through strategic engagement, but this requires sufficient foresight and may impose a substantial burden. A small costly signal can significantly reduce this burden.", "motivation": "To understand how users with inconsistent preferences can effectively steer engagement-driven algorithms to align with their true interests, given that algorithms learn from user interactions and users may engage with low-value content.", "method": "Model user decision process as dual-system (rational system 2 for engagement decisions, impulsive system 1 for engagement duration), and analyze as a multi-leader, single-follower Stackelberg game where users commit to engagement strategies and the algorithm best-responds.", "result": "A critical horizon exists: sufficiently foresighted users can achieve alignment, while less foresighted users become aligned to the algorithm's objective. This critical horizon can be long, but even small costly signals (e.g., extra clicks) can significantly reduce it.", "conclusion": "Users with inconsistent preferences can align engagement-driven algorithms with their interests in Stackelberg equilibrium, though achieving alignment requires sufficient foresight. The burden of alignment can be substantial but can be reduced through strategic signaling."}}
{"id": "2510.17741", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17741", "abs": "https://arxiv.org/abs/2510.17741", "authors": ["Navid Reyhanian", "Reza Ghaderi Zefreh", "Parisa Ramezani", "Emil Bjornson"], "title": "Precoding for Uplink RIS-Assisted Cell-Free MIMO-OFDM Systems with Hardware Impairments", "comment": null, "summary": "This paper studies a reconfigurable intelligent surface (RIS)-assisted\ncell-free massive multiple-input multiple-output (CF-mMIMO) system with\nmultiple RISs. Joint design of transmit precoding, RIS coefficients, and\nreceive combining is investigated for uplink sum-rate maximization under\nin-phase and quadrature phase imbalance (IQI) at user equipments (UEs) and\naccess points (APs). A weighted minimum mean squared error (WMMSE) based block\ncoordinate descent (BCD) approach is proposed, where novel iterative methods\nare developed to efficiently solve the BCD subproblems. The efficiency of\nproposed approaches is demonstrated relative to heuristic methods via extensive\nsimulations.", "AI": {"tldr": "This paper proposes a WMMSE-based BCD approach for joint optimization of transmit precoding, RIS coefficients, and receive combining in RIS-assisted cell-free massive MIMO systems with IQI impairments.", "motivation": "To address the performance degradation caused by in-phase and quadrature phase imbalance (IQI) at both user equipments and access points in RIS-assisted cell-free massive MIMO systems, and to maximize uplink sum-rate through joint optimization.", "method": "A weighted minimum mean squared error (WMMSE) based block coordinate descent (BCD) approach with novel iterative methods to efficiently solve the BCD subproblems for joint design of transmit precoding, RIS coefficients, and receive combining.", "result": "The proposed approaches demonstrate efficiency compared to heuristic methods through extensive simulations, showing improved performance in RIS-assisted cell-free massive MIMO systems with IQI impairments.", "conclusion": "The WMMSE-based BCD approach with novel iterative methods provides an effective solution for joint optimization in RIS-assisted cell-free massive MIMO systems suffering from IQI impairments, achieving superior performance over heuristic methods."}}
{"id": "2510.16295", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16295", "abs": "https://arxiv.org/abs/2510.16295", "authors": ["Ryoto Miyamoto", "Xin Fan", "Fuyuko Kido", "Tsuneo Matsumoto", "Hayato Yamana"], "title": "OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models", "comment": null, "summary": "OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in\nevaluating membership inference attacks (MIA) against large vision-language\nmodels (LVLMs). While prior work has reported high attack success rates, our\nanalysis suggests that these results often arise from detecting distributional\nbias introduced during dataset construction rather than from identifying true\nmembership status. To address this issue, we introduce a controlled benchmark\nof 6{,}000 images where the distributions of member and non-member samples are\ncarefully balanced, and ground-truth membership labels are provided across\nthree distinct training stages. Experiments using OpenLVLM-MIA demonstrated\nthat the performance of state-of-the-art MIA methods converged to random chance\nunder unbiased conditions. By offering a transparent and unbiased benchmark,\nOpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and\nprovides a solid foundation for developing stronger privacy-preserving\ntechniques.", "AI": {"tldr": "OpenLVLM-MIA is a new benchmark that reveals current MIA methods perform no better than random chance when evaluated under unbiased conditions, challenging prior claims of high success rates.", "motivation": "To address fundamental challenges in evaluating membership inference attacks on LVLMs, where prior reported high success rates may stem from dataset construction biases rather than true membership detection.", "method": "Created a controlled benchmark with 6,000 images where member and non-member distributions are carefully balanced, with ground-truth labels across three training stages to eliminate distributional bias.", "result": "State-of-the-art MIA methods converged to random chance performance under unbiased conditions, contradicting prior claims of high attack success rates.", "conclusion": "OpenLVLM-MIA provides a transparent foundation for developing stronger privacy-preserving techniques by clarifying current MIA limitations and eliminating evaluation biases."}}
{"id": "2510.15987", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15987", "abs": "https://arxiv.org/abs/2510.15987", "authors": ["Samuel Lippl", "Thomas McGee", "Kimberly Lopez", "Ziwen Pan", "Pierce Zhang", "Salma Ziadi", "Oliver Eberle", "Ida Momennejad"], "title": "Algorithmic Primitives and Compositional Geometry of Reasoning in Language Models", "comment": null, "summary": "How do latent and inference time computations enable large language models\n(LLMs) to solve multi-step reasoning? We introduce a framework for tracing and\nsteering algorithmic primitives that underlie model reasoning. Our approach\nlinks reasoning traces to internal activation patterns and evaluates\nalgorithmic primitives by injecting them into residual streams and measuring\ntheir effect on reasoning steps and task performance. We consider four\nbenchmarks: Traveling Salesperson Problem (TSP), 3SAT, AIME, and graph\nnavigation. We operationalize primitives by clustering neural activations and\nlabeling their matched reasoning traces. We then apply function vector methods\nto derive primitive vectors as reusable compositional building blocks of\nreasoning. Primitive vectors can be combined through addition, subtraction, and\nscalar operations, revealing a geometric logic in activation space. Cross-task\nand cross-model evaluations (Phi-4, Phi-4-Reasoning, Llama-3-8B) show both\nshared and task-specific primitives. Notably, comparing Phi-4 with its\nreasoning-finetuned variant highlights compositional generalization after\nfinetuning: Phi-4-Reasoning exhibits more systematic use of verification and\npath-generation primitives. Injecting the associated primitive vectors in\nPhi-4-Base induces behavioral hallmarks associated with Phi-4-Reasoning.\nTogether, these findings demonstrate that reasoning in LLMs may be supported by\na compositional geometry of algorithmic primitives, that primitives transfer\ncross-task and cross-model, and that reasoning finetuning strengthens\nalgorithmic generalization across domains.", "AI": {"tldr": "The paper introduces a framework for tracing and steering algorithmic primitives in LLMs' reasoning processes, showing that reasoning is supported by compositional geometric primitives that can transfer across tasks and models.", "motivation": "To understand how latent and inference time computations enable LLMs to solve multi-step reasoning problems by identifying and manipulating the underlying algorithmic primitives.", "method": "Links reasoning traces to internal activation patterns, operationalizes primitives through clustering neural activations, applies function vector methods to derive primitive vectors as reusable building blocks, and evaluates through cross-task/cross-model experiments on TSP, 3SAT, AIME, and graph navigation benchmarks.", "result": "Found shared and task-specific primitives that can be combined geometrically; reasoning-finetuned models show more systematic use of verification and path-generation primitives; primitive injection can induce behavioral changes in base models.", "conclusion": "LLM reasoning is supported by a compositional geometry of algorithmic primitives that transfer cross-task and cross-model, and reasoning finetuning strengthens algorithmic generalization across domains."}}
{"id": "2510.16374", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16374", "abs": "https://arxiv.org/abs/2510.16374", "authors": ["Nick Oh"], "title": "Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs", "comment": "Presented at the Workshop on the Application of LLM Explainability to\n  Reasoning and Planning at COLM 2025 (non-archival)", "summary": "Current approaches to enhancing LLM reasoning follows two isolated paradigms:\nMonitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and\nSELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack\nmechanisms to verify whether selected strategies succeed; while Generate-Verify\napproaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan\net al., 2023) iteratively refine outputs but commence generation blindly\nwithout task assessment. This separation creates inefficiencies -- strategies\nfail without feedback, and refinement occurs without strategic grounding. We\naddress this gap by implementing Flavell's cognitive monitoring model (1979)\nfrom the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),\noperationalising it as a three-phase iterative system. On GSM8K, preliminary\nresults show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for\nSelf-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%\nincreased inference cost. These initial findings suggest upfront monitoring\nproduces higher-quality initial solutions that reduce refinement needs, though\nevaluation beyond arithmetic reasoning is needed to establish generalisability.", "AI": {"tldr": "The paper proposes a three-phase iterative system based on Flavell's cognitive monitoring model that combines strategic planning with verification, achieving better accuracy with fewer attempts than existing methods on GSM8K.", "motivation": "Current LLM reasoning approaches are inefficiently separated into Monitor-Generate methods (good at planning but lack verification) and Generate-Verify methods (iteratively refine but start blindly without strategy assessment). This creates inefficiencies where strategies fail without feedback and refinement occurs without strategic grounding.", "method": "Implemented Flavell's cognitive monitoring model from the broader Monitor-Generate-Verify framework as a three-phase iterative system that combines strategic planning with verification mechanisms.", "result": "On GSM8K, achieved 75.42% accuracy vs 68.44% for SELF-REFINE and 67.07% for Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37% increased inference cost.", "conclusion": "Upfront monitoring produces higher-quality initial solutions that reduce refinement needs, though evaluation beyond arithmetic reasoning is needed to establish generalizability."}}
{"id": "2510.16319", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16319", "abs": "https://arxiv.org/abs/2510.16319", "authors": ["Rui Yang", "Huining Li", "Yiyi Long", "Xiaojun Wu", "Shengfeng He"], "title": "Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation", "comment": "ICCV 2025", "summary": "Generating sketches guided by reference styles requires precise transfer of\nstroke attributes, such as line thickness, deformation, and texture sparsity,\nwhile preserving semantic structure and content fidelity. To this end, we\npropose Stroke2Sketch, a novel training-free framework that introduces\ncross-image stroke attention, a mechanism embedded within self-attention layers\nto establish fine-grained semantic correspondences and enable accurate stroke\nattribute transfer. This allows our method to adaptively integrate reference\nstroke characteristics into content images while maintaining structural\nintegrity. Additionally, we develop adaptive contrast enhancement and\nsemantic-focused attention to reinforce content preservation and foreground\nemphasis. Stroke2Sketch effectively synthesizes stylistically faithful sketches\nthat closely resemble handcrafted results, outperforming existing methods in\nexpressive stroke control and semantic coherence. Codes are available at\nhttps://github.com/rane7/Stroke2Sketch.", "AI": {"tldr": "Stroke2Sketch is a training-free framework that uses cross-image stroke attention to transfer stroke attributes from reference styles to content images while preserving semantic structure and content fidelity.", "motivation": "To enable precise transfer of stroke attributes (line thickness, deformation, texture sparsity) from reference styles to content images while maintaining semantic structure and content fidelity.", "method": "Introduces cross-image stroke attention mechanism embedded in self-attention layers for fine-grained semantic correspondences, plus adaptive contrast enhancement and semantic-focused attention for content preservation.", "result": "Effectively synthesizes stylistically faithful sketches resembling handcrafted results, outperforming existing methods in expressive stroke control and semantic coherence.", "conclusion": "Stroke2Sketch provides an effective training-free solution for style-guided sketch generation with superior stroke attribute transfer and semantic preservation."}}
{"id": "2510.15990", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.15990", "abs": "https://arxiv.org/abs/2510.15990", "authors": ["Kangqi Ni", "Zhen Tan", "Zijie Liu", "Pingzhi Li", "Tianlong Chen"], "title": "Can GRPO Help LLMs Transcend Their Pretraining Origin?", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), primarily driven by\nthe Group Relative Policy Optimization (GRPO) algorithm, is a leading approach\nfor enhancing the reasoning abilities of Large Language Models (LLMs). Despite\nits wide adoption, GRPO's gains are often inconsistent; for instance, a model\nmay show significant improvement in one reasoning domain, like mathematics, yet\nremain stagnant in another, such as medicine. This inconsistency raises a\ncritical question: under what conditions does GRPO improve reasoning and\ngeneralize out-of-distribution (OOD)? We investigate this from a data\ndistribution perspective. We first prove theoretically that GRPO is a\nconservative reweighting scheme, bounded by the base model's distribution and\nthus unable to discover completely novel solutions. We further validate this in\ncarefully designed controlled studies by training transformers from scratch,\nevaluating generalization across reasoning depth, input length, token\nrepresentation, and compositionality. Our results provide a principled\nexplanation for GRPO's boundaries: OOD improvement emerges only when the target\ntask aligns with the model's pretrained biases, while gains on in-distribution\n(ID) tasks diminish as performance saturates. This reframes GRPO not as a\nuniversal reasoning enhancer but as a tool that sharpens pretraining biases.\nOur findings motivate future development of algorithms that can expand a\nmodel's capabilities beyond its pretraining origin.", "AI": {"tldr": "GRPO (Group Relative Policy Optimization) in RLVR improves LLM reasoning inconsistently - works well when target tasks align with pretraining biases but fails to discover novel solutions due to its conservative reweighting nature.", "motivation": "To understand why GRPO shows inconsistent performance gains across different reasoning domains and determine the conditions under which it improves reasoning and generalizes out-of-distribution.", "method": "Theoretical analysis proving GRPO is a conservative reweighting scheme bounded by base model's distribution, plus controlled studies training transformers from scratch to evaluate generalization across reasoning depth, input length, token representation, and compositionality.", "result": "GRPO's OOD improvement only occurs when target tasks align with model's pretrained biases, while ID task gains diminish as performance saturates. It cannot discover completely novel solutions.", "conclusion": "GRPO should be reframed as a tool that sharpens pretraining biases rather than a universal reasoning enhancer, motivating development of algorithms that can expand model capabilities beyond pretraining origins."}}
{"id": "2510.16382", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16382", "abs": "https://arxiv.org/abs/2510.16382", "authors": ["Ze Tao", "Jian Zhang", "Haowei Li", "Xianshuai Li", "Yifei Peng", "Xiyao Liu", "Senzhang Wang", "Chao Liu", "Sheng Ren", "Shichao Zhang"], "title": "Humanoid-inspired Causal Representation Learning for Domain Generalization", "comment": null, "summary": "This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a\nnovel causal framework inspired by human intelligence, designed to overcome the\nlimitations of conventional domain generalization models. Unlike approaches\nthat rely on statistics to capture data-label dependencies and learn\ndistortion-invariant representations, HSCM replicates the hierarchical\nprocessing and multi-level learning of human vision systems, focusing on\nmodeling fine-grained causal mechanisms. By disentangling and reweighting key\nimage attributes such as color, texture, and shape, HSCM enhances\ngeneralization across diverse domains, ensuring robust performance and\ninterpretability. Leveraging the flexibility and adaptability of human\nintelligence, our approach enables more effective transfer and learning in\ndynamic, complex environments. Through both theoretical and empirical\nevaluations, we demonstrate that HSCM outperforms existing domain\ngeneralization models, providing a more principled method for capturing causal\nrelationships and improving model robustness. The code is available at\nhttps://github.com/lambett/HSCM.", "AI": {"tldr": "HSCM is a human-inspired causal framework for domain generalization that models fine-grained causal mechanisms by disentangling image attributes like color, texture, and shape, outperforming existing methods.", "motivation": "To overcome limitations of conventional domain generalization models that rely on statistical dependencies, by drawing inspiration from human intelligence and hierarchical processing in human vision systems.", "method": "Proposes Humanoid-inspired Structural Causal Model (HSCM) that replicates human vision's hierarchical processing, disentangles key image attributes (color, texture, shape), and reweights them to capture fine-grained causal mechanisms.", "result": "HSCM outperforms existing domain generalization models in both theoretical and empirical evaluations, demonstrating enhanced generalization across diverse domains with robust performance and interpretability.", "conclusion": "HSCM provides a more principled method for capturing causal relationships and improving model robustness, leveraging human intelligence's flexibility for effective transfer learning in dynamic environments."}}
{"id": "2510.16320", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16320", "abs": "https://arxiv.org/abs/2510.16320", "authors": ["Wenhao Wang", "Longqi Cai", "Taihong Xiao", "Yuxiao Wang", "Ming-Hsuan Yang"], "title": "Scaling Laws for Deepfake Detection", "comment": null, "summary": "This paper presents a systematic study of scaling laws for the deepfake\ndetection task. Specifically, we analyze the model performance against the\nnumber of real image domains, deepfake generation methods, and training images.\nSince no existing dataset meets the scale requirements for this research, we\nconstruct ScaleDF, the largest dataset to date in this field, which contains\nover 5.8 million real images from 51 different datasets (domains) and more than\n8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we\nobserve power-law scaling similar to that shown in large language models\n(LLMs). Specifically, the average detection error follows a predictable\npower-law decay as either the number of real domains or the number of deepfake\nmethods increases. This key observation not only allows us to forecast the\nnumber of additional real domains or deepfake methods required to reach a\ntarget performance, but also inspires us to counter the evolving deepfake\ntechnology in a data-centric manner. Beyond this, we examine the role of\npre-training and data augmentations in deepfake detection under scaling, as\nwell as the limitations of scaling itself.", "AI": {"tldr": "This paper studies scaling laws for deepfake detection, finding that detection error follows power-law decay as training data (real domains and fake methods) increases, similar to LLMs.", "motivation": "To systematically analyze how deepfake detection performance scales with data quantity and diversity, since no existing dataset meets the scale requirements for such research.", "method": "Constructed ScaleDF - the largest deepfake dataset with 5.8M real images from 51 domains and 8.8M fake images from 102 methods. Analyzed scaling relationships between detection error and data scale.", "result": "Observed power-law scaling: detection error decays predictably as number of real domains or deepfake methods increases. This enables forecasting additional data needed for target performance.", "conclusion": "Scaling laws apply to deepfake detection similar to LLMs, suggesting a data-centric approach to counter evolving deepfake technology. Also examined pre-training, data augmentation roles and scaling limitations."}}
{"id": "2510.15992", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15992", "abs": "https://arxiv.org/abs/2510.15992", "authors": ["Ziming Dai", "Tuo Zhang", "Fei Gao", "Xingyi Cai", "Xiaofei Wang", "Cheng Zhang", "Wenyu Wang", "Chengjie Zang"], "title": "Stratos: An End-to-End Distillation Pipeline for Customized LLMs under Distributed Cloud Environments", "comment": null, "summary": "The growing industrial demand for customized and cost-efficient large\nlanguage models (LLMs) is fueled by the rise of vertical, domain-specific tasks\nand the need to optimize performance under constraints such as latency and\nbudget. Knowledge distillation, as an efficient model compression and transfer\ntechnique, offers a feasible solution. However, existing distillation\nframeworks often require manual intervention and struggle to meet such complex\nuser-defined distillation requirements. To bridge this gap, we propose Stratos,\nan end-to-end LLM distillation pipeline that automates server and model\nselection, knowledge distillation, and deployment in distributed cloud\nenvironments. Given user-defined constraints on model performance and system\nbudget, Stratos automatically selects Pareto-optimal servers, dynamically\nmatches teacher-student pairs, and adapts distillation strategies based on task\ncomplexity to optimize cloud hosting. Experiments show that Stratos produces a\nstudent model that achieves four times the accuracy of its GPT-4o teacher\nbaseline on a rare, domain-specific Mahjong reasoning task with reverse\nsynthetic data and knowledge injection. Moreover, it achieves reduced latency\nand cost without compromising accuracy. These results highlight its promise for\nvertical-domain LLM deployment.", "AI": {"tldr": "Stratos is an automated LLM distillation pipeline that optimizes cloud deployment by automatically selecting servers, matching teacher-student pairs, and adapting distillation strategies based on user-defined performance and budget constraints.", "motivation": "Growing industrial demand for customized, cost-efficient LLMs for domain-specific tasks, with existing distillation frameworks requiring manual intervention and struggling to meet complex user requirements.", "method": "End-to-end LLM distillation pipeline that automates server/model selection, knowledge distillation, and deployment in distributed cloud environments. Uses Pareto-optimal server selection, dynamic teacher-student matching, and adaptive distillation strategies based on task complexity.", "result": "Achieved 4x accuracy improvement over GPT-4o baseline on rare Mahjong reasoning task with reverse synthetic data and knowledge injection. Reduced latency and cost without compromising accuracy.", "conclusion": "Stratos shows promise for efficient vertical-domain LLM deployment by automating the distillation process while meeting performance and budget constraints."}}
{"id": "2510.16392", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16392", "abs": "https://arxiv.org/abs/2510.16392", "authors": ["Ao Tian", "Yunfeng Lu", "Xinxin Fan", "Changhao Wang", "Lanzhi Zhou", "Yeyao Zhang", "Yanfang Liu"], "title": "RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile", "comment": "11 pages,3 figures", "summary": "Personalized and continuous interactions are the key to enhancing user\nexperience in today's large language model (LLM)-based conversational systems,\nhowever, the finite context windows and static parametric memory make it\ndifficult to model the cross-session long-term user states and behavioral\nconsistency. Currently, the existing solutions to this predicament, such as\nretrieval-augmented generation (RAG) and explicit memory systems, primarily\nfocus on fact-level storage and retrieval, lacking the capability to distill\nlatent preferences and deep traits from the multi-turn dialogues, which limits\nthe long-term and effective user modeling, directly leading to the personalized\ninteractions remaining shallow, and hindering the cross-session continuity. To\nrealize the long-term memory and behavioral consistency for Language Agents in\nLLM era, we propose a self-evolving memory framework RGMem, inspired by the\nideology of classic renormalization group (RG) in physics, this framework\nenables to organize the dialogue history in multiple scales: it first extracts\nsemantics and user insights from episodic fragments, then through hierarchical\ncoarse-graining and rescaling operations, progressively forms a\ndynamically-evolved user profile. The core innovation of our work lies in\nmodeling memory evolution as a multi-scale process of information compression\nand emergence, which accomplishes the high-level and accurate user profiles\nfrom noisy and microscopic-level interactions.", "AI": {"tldr": "RGMem is a self-evolving memory framework that uses renormalization group principles to create multi-scale user profiles from dialogue history, enabling long-term behavioral consistency in LLM-based conversational systems.", "motivation": "Current LLM systems struggle with long-term user modeling due to finite context windows and static memory. Existing solutions like RAG focus on fact-level storage but lack capability to distill latent preferences from multi-turn dialogues, limiting personalized interactions.", "method": "Inspired by renormalization group in physics, RGMem organizes dialogue history in multiple scales: extracts semantics from episodic fragments, then uses hierarchical coarse-graining and rescaling operations to progressively form dynamically-evolved user profiles.", "result": "The framework accomplishes high-level and accurate user profiles from noisy, microscopic-level interactions through multi-scale information compression and emergence.", "conclusion": "RGMem enables long-term memory and behavioral consistency for language agents by modeling memory evolution as a multi-scale process, overcoming limitations of current approaches for personalized conversational systems."}}
{"id": "2510.16325", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16325", "abs": "https://arxiv.org/abs/2510.16325", "authors": ["Yuyao Zhang", "Yu-Wing Tai"], "title": "Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention", "comment": "22 pages", "summary": "Ultra-high-resolution text-to-image generation demands both fine-grained\ntexture synthesis and globally coherent structure, yet current diffusion models\nremain constrained to sub-$1K \\times 1K$ resolutions due to the prohibitive\nquadratic complexity of attention and the scarcity of native $4K$ training\ndata. We present \\textbf{Scale-DiT}, a new diffusion framework that introduces\nhierarchical local attention with low-resolution global guidance, enabling\nefficient, scalable, and semantically coherent image synthesis at ultra-high\nresolutions. Specifically, high-resolution latents are divided into fixed-size\nlocal windows to reduce attention complexity from quadratic to near-linear,\nwhile a low-resolution latent equipped with scaled positional anchors injects\nglobal semantics. A lightweight LoRA adaptation bridges global and local\npathways during denoising, ensuring consistency across structure and detail. To\nmaximize inference efficiency, we repermute token sequence in Hilbert curve\norder and implement a fused-kernel for skipping masked operations, resulting in\na GPU-friendly design. Extensive experiments demonstrate that Scale-DiT\nachieves more than $2\\times$ faster inference and lower memory usage compared\nto dense attention baselines, while reliably scaling to $4K \\times 4K$\nresolution without requiring additional high-resolution training data. On both\nquantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons,\nScale-DiT delivers superior global coherence and sharper local detail, matching\nor outperforming state-of-the-art methods that rely on native 4K training.\nTaken together, these results highlight hierarchical local attention with\nguided low-resolution anchors as a promising and effective approach for\nadvancing ultra-high-resolution image generation.", "AI": {"tldr": "Scale-DiT enables efficient 4K text-to-image generation using hierarchical local attention with global guidance, achieving faster inference and better quality without needing native 4K training data.", "motivation": "Current diffusion models are limited to sub-1K resolutions due to quadratic attention complexity and lack of native 4K training data, creating a need for scalable ultra-high-resolution generation.", "method": "Hierarchical local attention with low-resolution global guidance, dividing high-res latents into local windows for linear complexity, using scaled positional anchors for global semantics, and LoRA adaptation for consistency.", "result": "Achieves 2\u00d7 faster inference, lower memory usage, reliable 4K\u00d74K generation without additional training data, and superior performance on FID, IS, and CLIP Score benchmarks.", "conclusion": "Hierarchical local attention with guided low-resolution anchors is an effective approach for advancing ultra-high-resolution image generation."}}
{"id": "2510.15996", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15996", "abs": "https://arxiv.org/abs/2510.15996", "authors": ["Ozan K. Tonguz", "Federico Taschin"], "title": "Using Kolmogorov-Smirnov Distance for Measuring Distribution Shift in Machine Learning", "comment": null, "summary": "One of the major problems in Machine Learning (ML) and Artificial\nIntelligence (AI) is the fact that the probability distribution of the test\ndata in the real world could deviate substantially from the probability\ndistribution of the training data set. When this happens, the predictions of an\nML system or an AI agent could involve large errors which is very troublesome\nand undesirable. While this is a well-known hard problem plaguing the AI and ML\nsystems' accuracy and reliability, in certain applications such errors could be\ncritical for safety and reliability of AI and ML systems. One approach to deal\nwith this problem is to monitor and measure the deviation in the probability\ndistribution of the test data in real time and to compensate for this\ndeviation. In this paper, we propose and explore the use of Kolmogorov-Smirnov\n(KS) Test for measuring the distribution shift and we show how the KS distance\ncan be used to quantify the distribution shift and its impact on an AI agent's\nperformance. Our results suggest that KS distance could be used as a valuable\nstatistical tool for monitoring and measuring the distribution shift. More\nspecifically, it is shown that even a distance of KS=0.02 could lead to about\n50\\% increase in the travel time at a single intersection using a Reinforcement\nLearning agent which is quite significant. It is hoped that the use of KS Test\nand KS distance in AI-based smart transportation could be an important step\nforward for gauging the performance degradation of an AI agent in real time and\nthis, in turn, could help the AI agent to cope with the distribution shift in a\nmore informed manner.", "AI": {"tldr": "The paper proposes using Kolmogorov-Smirnov (KS) Test to measure distribution shift between training and test data in ML/AI systems, showing that even small KS distances can significantly impact AI agent performance in transportation applications.", "motivation": "Distribution shift between training and test data causes large prediction errors in ML/AI systems, which is critical for safety and reliability in applications like smart transportation.", "method": "Using Kolmogorov-Smirnov (KS) Test to measure distribution shift and KS distance to quantify the impact on AI agent performance, specifically testing with a Reinforcement Learning agent in transportation scenarios.", "result": "Even a small KS distance of 0.02 can lead to about 50% increase in travel time at a single intersection using a Reinforcement Learning agent.", "conclusion": "KS Test and KS distance are valuable tools for monitoring distribution shift in real-time, helping AI agents cope with distribution shifts more effectively in smart transportation systems."}}
{"id": "2510.16466", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16466", "abs": "https://arxiv.org/abs/2510.16466", "authors": ["Siddhartha Krothapalli", "Tridib Kumar Das", "Praveen Kumar", "Naveen Suravarpu", "Pratik Narang"], "title": "ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights", "comment": "11 pages, 1 figure, 4 tables", "summary": "As customer feedback becomes increasingly central to strategic growth, the\nability to derive actionable insights from unstructured reviews is essential.\nWhile traditional AI-driven systems excel at predicting user preferences, far\nless work has focused on transforming customer reviews into prescriptive,\nbusiness-facing recommendations. This paper introduces ReviewSense, a novel\nprescriptive decision support framework that leverages advanced large language\nmodels (LLMs) to transform customer reviews into targeted, actionable business\nrecommendations. By identifying key trends, recurring issues, and specific\nconcerns within customer sentiments, ReviewSense extends beyond\npreference-based systems to provide businesses with deeper insights for\nsustaining growth and enhancing customer loyalty. The novelty of this work lies\nin integrating clustering, LLM adaptation, and expert-driven evaluation into a\nunified, business-facing pipeline. Preliminary manual evaluations indicate\nstrong alignment between the model's recommendations and business objectives,\nhighlighting its potential for driving data-informed decision-making. This\nframework offers a new perspective on AI-driven sentiment analysis,\ndemonstrating its value in refining business strategies and maximizing the\nimpact of customer feedback.", "AI": {"tldr": "ReviewSense is a prescriptive decision support framework that uses LLMs to transform customer reviews into actionable business recommendations, going beyond traditional preference prediction to provide deeper insights for growth and customer loyalty.", "motivation": "Customer feedback is crucial for strategic growth, but existing AI systems mainly predict user preferences rather than providing prescriptive, business-facing recommendations from unstructured reviews.", "method": "Integrates clustering, LLM adaptation, and expert-driven evaluation into a unified pipeline to identify key trends, recurring issues, and specific concerns within customer sentiments.", "result": "Preliminary manual evaluations show strong alignment between the model's recommendations and business objectives, demonstrating potential for data-informed decision-making.", "conclusion": "The framework offers a new perspective on AI-driven sentiment analysis, showing value in refining business strategies and maximizing customer feedback impact."}}
{"id": "2510.16326", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16326", "abs": "https://arxiv.org/abs/2510.16326", "authors": ["Yi Wei", "Shunpu Tang", "Liang Zhao", "Qiangian Yang"], "title": "DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution", "comment": null, "summary": "Recent advances in diffusion models have driven remarkable progress in image\ngeneration. However, the generation process remains computationally intensive,\nand users often need to iteratively refine prompts to achieve the desired\nresults, further increasing latency and placing a heavy burden on cloud\nresources. To address this challenge, we propose DiffusionX, a cloud-edge\ncollaborative framework for efficient multi-round, prompt-based generation. In\nthis system, a lightweight on-device diffusion model interacts with users by\nrapidly producing preview images, while a high-capacity cloud model performs\nfinal refinements after the prompt is finalized. We further introduce a noise\nlevel predictor that dynamically balances the computation load, optimizing the\ntrade-off between latency and cloud workload. Experiments show that DiffusionX\nreduces average generation time by 15.8% compared with Stable Diffusion v1.5,\nwhile maintaining comparable image quality. Moreover, it is only 0.9% slower\nthan Tiny-SD with significantly improved image quality, thereby demonstrating\nefficiency and scalability with minimal overhead.", "AI": {"tldr": "DiffusionX is a cloud-edge collaborative framework that reduces diffusion model generation time by 15.8% while maintaining image quality through lightweight on-device previews and cloud-based final refinements.", "motivation": "To address the computational intensity of diffusion models and the iterative prompt refinement process that increases latency and burdens cloud resources.", "method": "A cloud-edge collaborative framework with lightweight on-device diffusion model for rapid previews and high-capacity cloud model for final refinements, plus a noise level predictor to balance computation load.", "result": "Reduces average generation time by 15.8% compared to Stable Diffusion v1.5 while maintaining comparable image quality, and only 0.9% slower than Tiny-SD with significantly improved image quality.", "conclusion": "DiffusionX demonstrates efficient and scalable prompt-based image generation with minimal overhead through cloud-edge collaboration."}}
{"id": "2510.15998", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.15998", "abs": "https://arxiv.org/abs/2510.15998", "authors": ["Nilo Schwencke", "Cyriaque Rousselot", "Alena Shilova", "Cyril Furtlehner"], "title": "AMStraMGRAM: Adaptive Multi-cutoff Strategy Modification for ANaGRAM", "comment": null, "summary": "Recent works have shown that natural gradient methods can significantly\noutperform standard optimizers when training physics-informed neural networks\n(PINNs). In this paper, we analyze the training dynamics of PINNs optimized\nwith ANaGRAM, a natural-gradient-inspired approach employing singular value\ndecomposition with cutoff regularization. Building on this analysis, we propose\na multi-cutoff adaptation strategy that further enhances ANaGRAM's performance.\nExperiments on benchmark PDEs validate the effectiveness of our method, which\nallows to reach machine precision on some experiments. To provide theoretical\ngrounding, we develop a framework based on spectral theory that explains the\nnecessity of regularization and extend previous shown connections with Green's\nfunctions theory.", "AI": {"tldr": "The paper analyzes PINN training dynamics with ANaGRAM natural gradient method, proposes multi-cutoff adaptation strategy, validates on benchmark PDEs achieving machine precision, and provides theoretical framework using spectral theory.", "motivation": "Recent works show natural gradient methods outperform standard optimizers for PINNs, but training dynamics analysis and regularization strategies need further investigation.", "method": "Analyze PINN training with ANaGRAM (natural-gradient method using SVD with cutoff regularization), propose multi-cutoff adaptation strategy, validate on benchmark PDEs, and develop spectral theory framework.", "result": "Multi-cutoff adaptation enhances ANaGRAM performance, achieving machine precision on some experiments. Theoretical framework explains regularization necessity and extends connections with Green's functions theory.", "conclusion": "The proposed multi-cutoff adaptation strategy significantly improves PINN training with natural gradient methods, supported by theoretical analysis using spectral theory."}}
{"id": "2510.16476", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16476", "abs": "https://arxiv.org/abs/2510.16476", "authors": ["Xiaozhe Li", "Xinyu Fang", "Shengyuan Ding", "Linyang Li", "Haodong Duan", "Qingwen Liu", "Kai Chen"], "title": "NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems", "comment": null, "summary": "Large Language Models (LLMs) have shown strong reasoning capabilities, with\nmodels like OpenAI's O-series and DeepSeek R1 excelling at tasks such as\nmathematics, coding, logic, and puzzles through Reinforcement Learning with\nVerifiable Rewards (RLVR). However, their ability to solve more complex\noptimization problems - particularly NP-hard tasks - remains underexplored. To\nbridge this gap, we propose NP-ENGINE, the first comprehensive framework for\ntraining and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks\nacross five domains, each equipped with (i) a controllable instance generator,\n(ii) a rule-based verifier, and (iii) a heuristic solver that provides\napproximate optimal solutions as ground truth. This\ngenerator-verifier-heuristic pipeline enables scalable and verifiable RLVR\ntraining under hierarchical difficulties. We also introduce NP-BENCH, a\nbenchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'\nability to tackle NP-hard level reasoning problems, focusing not only on\nfeasibility but also on solution quality. Additionally, we present\nQWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on\nQwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and\nachieves SOTA performance with the same model size. Beyond in-domain tasks, we\ndemonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain\n(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),\nas well as non-reasoning tasks such as instruction following. We also observe a\nscaling trend: increasing task diversity improves OOD generalization. These\nfindings suggest that task-rich RLVR training is a promising direction for\nadvancing LLM's reasoning ability, revealing new insights into the scaling laws\nof RLVR.", "AI": {"tldr": "NP-ENGINE is the first framework for training LLMs on NP-hard problems, featuring a generator-verifier-heuristic pipeline for scalable RLVR training. It includes NP-BENCH benchmark and QWEN2.5-7B-NP model that outperforms GPT-4o.", "motivation": "LLMs have strong reasoning capabilities but their ability to solve complex NP-hard optimization problems remains underexplored, creating a gap that needs to be addressed.", "method": "Proposed NP-ENGINE framework with 10 tasks across 5 domains, using generator-verifier-heuristic pipeline for scalable RLVR training with curriculum learning. Also created NP-BENCH benchmark and trained QWEN2.5-7B-NP model.", "result": "QWEN2.5-7B-NP significantly outperforms GPT-4o on NP-BENCH and achieves SOTA performance. RLVR training enables strong out-of-domain generalization to reasoning and non-reasoning tasks, with scaling trend showing improved generalization with task diversity.", "conclusion": "Task-rich RLVR training is a promising direction for advancing LLM reasoning ability, revealing new insights into RLVR scaling laws and enabling strong generalization across domains."}}
{"id": "2510.16940", "categories": ["cs.LG", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.16940", "abs": "https://arxiv.org/abs/2510.16940", "authors": ["Cristian J. Vaca-Rubio", "Roberto Pereira", "Luis Blanco", "Engin Zeydan", "M\u00e0rius Caus"], "title": "A Primer on Kolmogorov-Arnold Networks (KANs) for Probabilistic Time Series Forecasting", "comment": null, "summary": "This work introduces Probabilistic Kolmogorov-Arnold Network (P-KAN), a novel\nprobabilistic extension of Kolmogorov-Arnold Networks (KANs) for time series\nforecasting. By replacing scalar weights with spline-based functional\nconnections and directly parameterizing predictive distributions, P-KANs offer\nexpressive yet parameter-efficient models capable of capturing nonlinear and\nheavy-tailed dynamics. We evaluate P-KANs on satellite traffic forecasting,\nwhere uncertainty-aware predictions enable dynamic thresholding for resource\nallocation. Results show that P-KANs consistently outperform Multi Layer\nPerceptron (MLP) baselines in both accuracy and calibration, achieving superior\nefficiency-risk trade-offs while using significantly fewer parameters. We build\nup P-KANs on two distributions, namely Gaussian and Student-t distributions.\nThe Gaussian variant provides robust, conservative forecasts suitable for\nsafety-critical scenarios, whereas the Student-t variant yields sharper\ndistributions that improve efficiency under stable demand. These findings\nestablish P-KANs as a powerful framework for probabilistic forecasting with\ndirect applicability to satellite communications and other resource-constrained\ndomains.", "AI": {"tldr": "P-KAN is a probabilistic extension of Kolmogorov-Arnold Networks that uses spline-based functional connections instead of scalar weights for time series forecasting, offering parameter-efficient uncertainty-aware predictions.", "motivation": "To develop expressive yet parameter-efficient probabilistic models for time series forecasting that can capture nonlinear and heavy-tailed dynamics, particularly for satellite traffic forecasting where uncertainty-aware predictions enable dynamic resource allocation.", "method": "Replace scalar weights with spline-based functional connections and directly parameterize predictive distributions using Gaussian and Student-t distributions. This creates probabilistic models that are more parameter-efficient than traditional MLPs.", "result": "P-KANs consistently outperform MLP baselines in both accuracy and calibration, achieving superior efficiency-risk trade-offs while using significantly fewer parameters. Gaussian variant provides robust conservative forecasts, while Student-t variant yields sharper distributions for stable demand scenarios.", "conclusion": "P-KANs establish a powerful framework for probabilistic forecasting with direct applicability to satellite communications and other resource-constrained domains, offering both parameter efficiency and uncertainty quantification capabilities."}}
{"id": "2510.16332", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16332", "abs": "https://arxiv.org/abs/2510.16332", "authors": ["Haiyue Sun", "Qingdong He", "Jinlong Peng", "Peng Tang", "Jiangning Zhang", "Junwei Zhu", "Xiaobin Hu", "Shuicheng Yan"], "title": "TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement", "comment": null, "summary": "Autoregressive Model (AR) has shown remarkable success in conditional image\ngeneration. However, these approaches for multiple reference generation\nstruggle with decoupling different reference identities. In this work, we\npropose the TokenAR framework, specifically focused on a simple but effective\ntoken-level enhancement mechanism to address reference identity confusion\nproblem. Such token-level enhancement consists of three parts, 1). Token Index\nEmbedding clusters the tokens index for better representing the same reference\nimages; 2). Instruct Token Injection plays as a role of extra visual feature\ncontainer to inject detailed and complementary priors for reference tokens; 3).\nThe identity-token disentanglement strategy (ITD) explicitly guides the token\nrepresentations toward independently representing the features of each\nidentity.This token-enhancement framework significantly augments the\ncapabilities of existing AR based methods in conditional image generation,\nenabling good identity consistency while preserving high quality background\nreconstruction. Driven by the goal of high-quality and high-diversity in\nmulti-subject generation, we introduce the InstructAR Dataset, the first\nopen-source, large-scale, multi-reference input, open domain image generation\ndataset that includes 28K training pairs, each example has two reference\nsubjects, a relative prompt and a background with mask annotation, curated for\nmultiple reference image generation training and evaluating. Comprehensive\nexperiments validate that our approach surpasses current state-of-the-art\nmodels in multiple reference image generation task. The implementation code and\ndatasets will be made publicly. Codes are available, see\nhttps://github.com/lyrig/TokenAR", "AI": {"tldr": "TokenAR is a token-level enhancement framework for autoregressive models that addresses identity confusion in multi-reference image generation through three key components: token index embedding, instruct token injection, and identity-token disentanglement strategy.", "motivation": "Autoregressive models struggle with decoupling different reference identities in multiple reference generation, leading to identity confusion problems.", "method": "Three-part token-level enhancement: 1) Token Index Embedding for clustering tokens from same references, 2) Instruct Token Injection as extra visual feature container, 3) Identity-Token Disentanglement (ITD) strategy to guide independent identity representation.", "result": "The approach significantly enhances existing AR methods, achieving good identity consistency while preserving high-quality background reconstruction. Comprehensive experiments show it surpasses current state-of-the-art models.", "conclusion": "TokenAR framework effectively solves reference identity confusion in multi-reference image generation and introduces the first open-source large-scale InstructAR dataset for training and evaluation."}}
{"id": "2510.16007", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16007", "abs": "https://arxiv.org/abs/2510.16007", "authors": ["Ziao Yang", "Longbo Huang", "Hongfu Liu"], "title": "Layer-Aware Influence for Online Data Valuation Estimation", "comment": null, "summary": "Data-centric learning emphasizes curating high-quality training samples to\nboost performance rather than designing new architectures. A central problem is\nto estimate the influence of training sample efficiently. Prior studies largely\nfocus on static influence measured on a converged model, overlooking how data\nvaluation dynamically changes during optimization. This omission neglects the\ndynamic nature of sample influence during optimization, especially in deep\nmodels. To address the computational burden of frequent influence estimation,\nwe develop a layer-aware online estimator that requires only loss-to-output\ngradients. This design avoids parameter-level and full-network gradients while\npreserving ranking fidelity. Extensive experiments across LLM pretraining,\nfine-tuning, and image classification show our method improves accuracy with\nsubstantially lower time and memory cost, making dynamic data curation\nefficient and scalable in practice.", "AI": {"tldr": "A layer-aware online estimator for dynamic data influence that uses only loss-to-output gradients, enabling efficient data curation during training with lower computational cost.", "motivation": "Prior work focuses on static influence measurement after model convergence, ignoring how data valuation changes dynamically during optimization, especially in deep models.", "method": "Developed a layer-aware online estimator that requires only loss-to-output gradients, avoiding parameter-level and full-network gradients while maintaining ranking fidelity.", "result": "Extensive experiments across LLM pretraining, fine-tuning, and image classification show improved accuracy with substantially lower time and memory cost.", "conclusion": "The method makes dynamic data curation efficient and scalable in practice for data-centric learning approaches."}}
{"id": "2510.16533", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16533", "abs": "https://arxiv.org/abs/2510.16533", "authors": ["Eilene Tomkins-Flanagan", "Connor Hanley", "Mary A. Kelly"], "title": "Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination", "comment": null, "summary": "We present a typed computer language, Doug, in which all typed programs may\nbe proved to halt in polynomial time, encoded in a vector-symbolic architecture\n(VSA). Doug is just an encoding of the light linear functional programming\nlanguage (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are\nencoded using a slot-value encoding scheme based on holographic declarative\nmemory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the\nLisp VSA defined by (Flanagan, 2024). Doug allows for some points on the\nembedding space of a neural network to be interpreted as types, where the types\nof nearby points are similar both in structure and content. Types in Doug are\ntherefore learnable by a neural network. Following (Chollet, 2019), (Card,\n1983), and (Newell, 1981), we view skill as the application of a procedure, or\nprogram of action, that causes a goal to be satisfied. Skill acquisition may\ntherefore be expressed as program synthesis. Using Doug, we hope to describe a\nform of learning of skilled behaviour that follows a human-like pace of skill\nacquisition (i.e., substantially faster than brute force; Heathcote, 2000),\nexceeding the efficiency of all currently existing approaches (Kaplan, 2020;\nJones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling\nhuman mental representations, as they must actually exist in the brain, and\nthose representations' acquisition, as they are actually learned.", "AI": {"tldr": "Doug is a typed computer language encoded in vector-symbolic architecture that ensures all programs halt in polynomial time, enabling neural networks to learn types and model human-like skill acquisition through program synthesis.", "motivation": "To model human mental representations and their acquisition in the brain, enabling neural networks to learn types and achieve human-like skill acquisition efficiency that exceeds current approaches.", "method": "Encodes the light linear functional programming language (LLFPL) using holographic declarative memory for types and a Lisp VSA variant for terms, allowing neural networks to interpret embedding space points as types.", "result": "Developed Doug language where types are learnable by neural networks and nearby points in embedding space have similar types in structure and content.", "conclusion": "Doug brings us closer to modeling actual human mental representations and their acquisition as they exist in the brain, providing a foundation for efficient human-like skill learning."}}
{"id": "2510.16333", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16333", "abs": "https://arxiv.org/abs/2510.16333", "authors": ["Junha Song", "Sangdoo Yun", "Dongyoon Han", "Jaegul Choo", "Byeongho Heo"], "title": "RL makes MLLMs see better than SFT", "comment": null, "summary": "A dominant assumption in Multimodal Language Model (MLLM) research is that\nits performance is largely inherited from the LLM backbone, given its immense\nparameter scale and remarkable capabilities. This has created a void in the\nunderstanding of the vision encoder, which determines how MLLMs perceive\nimages. The recent shift in MLLM training paradigms, from Supervised Finetuning\n(SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the\nsignificant lack of analysis on how such training reshapes the vision encoder\nas well as the MLLM. To address this, we first investigate the impact of\ntraining strategies on MLLMs, where RL shows a clear advantage over SFT in\nstrongly vision-related VQA benchmarks. Motivated by this, we conduct a\ncritical yet under-explored analysis of the vision encoder of MLLMs through\ndiverse and in-depth experiments, ranging from ImageNet classification and\nsegmentation to gradient visualization. Our results demonstrate that MLLM's\npost-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on\nMLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual\nrepresentations. Specifically, the key finding of our study is that RL produces\nstronger and precisely localized visual representations compared to SFT,\nboosting the ability of the vision encoder for MLLM. We then reframe our\nfindings into a simple recipe for building strong vision encoders for MLLMs,\nPreference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs,\na PIVOT-trained vision encoder outperforms even larger and more heavily-trained\ncounterparts, despite requiring less than 1% of the computational cost of\nstandard vision pretraining. This result opens an effective and efficient path\nfor advancing the vision backbones of MLLMs. Project page available at\nhttps://june-page.github.io/pivot/", "AI": {"tldr": "The paper challenges the assumption that MLLM performance mainly comes from the LLM backbone, showing that training strategies (especially RL vs SFT) fundamentally reshape the vision encoder's representations, with RL producing stronger and more localized visual features.", "motivation": "There's a significant gap in understanding how vision encoders in MLLMs are affected by different training paradigms, particularly the shift from SFT to RL, which has been largely overlooked despite its importance for visual perception.", "method": "Conducted diverse experiments including ImageNet classification, segmentation, and gradient visualization to analyze how SFT and RL training reshape vision encoder representations in MLLMs.", "result": "RL training produces stronger and more precisely localized visual representations than SFT, leading to better performance on vision-related tasks. The proposed PIVOT method creates vision encoders that outperform larger counterparts using less than 1% of standard pretraining computational cost.", "conclusion": "Training strategy fundamentally reshapes MLLM vision encoders, with RL being superior to SFT. The PIVOT method provides an efficient path to build strong vision backbones for MLLMs, challenging the assumption that LLM backbones dominate MLLM performance."}}
{"id": "2510.16014", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16014", "abs": "https://arxiv.org/abs/2510.16014", "authors": ["Hanyin Cheng", "Ruitong Zhang", "Yuning Lu", "Peng Chen", "Meng Wang", "Yang Shu", "Bin Yang", "Chenjuan Guo"], "title": "STAR: Boosting Time Series Foundation Models for Anomaly Detection through State-aware Adapter", "comment": null, "summary": "While Time Series Foundation Models (TSFMs) have demonstrated remarkable\nsuccess in Multivariate Time Series Anomaly Detection (MTSAD), however, in\nreal-world industrial scenarios, many time series comprise not only numerical\nvariables such as temperature and flow, but also numerous discrete state\nvariables that describe the system status, such as valve on/off or day of the\nweek. Existing TSFMs often overlook the distinct categorical nature of state\nvariables and their critical role as conditions, typically treating them\nuniformly with numerical variables. This inappropriate modeling approach\nprevents the model from fully leveraging state information and even leads to a\nsignificant degradation in detection performance after state variables are\nintegrated. To address this critical limitation, this paper proposes a novel\nSTate-aware AdapteR (STAR). STAR is a plug-and-play module designed to enhance\nthe capability of TSFMs in modeling and leveraging state variables during the\nfine-tuning stage. Specifically, STAR comprisesthree core components: (1) We\ndesign an Identity-guided State Encoder, whicheffectively captures the complex\ncategorical semantics of state variables through a learnable State Memory. (2)\nWe propose a Conditional Bottleneck Adapter, which dynamically generates\nlow-rank adaptation parameters conditioned on the current state, thereby\nflexibly injecting the influence of state variables into the backbone model.\n(3) We also introduce a Numeral-State Matching module to more effectively\ndetect anomalies inherent to the state variables themselves. Extensive\nexperiments conducted on real-world datasets demonstrate that STAR can improve\nthe performance of existing TSFMs on MTSAD.", "AI": {"tldr": "STAR is a plug-and-play module that enhances Time Series Foundation Models' ability to handle state variables in anomaly detection by modeling categorical state information separately from numerical variables.", "motivation": "Existing Time Series Foundation Models fail to properly handle discrete state variables (like valve on/off status) in industrial scenarios, treating them the same as numerical variables and causing performance degradation when state variables are integrated.", "method": "STAR includes three components: Identity-guided State Encoder with learnable State Memory for categorical semantics, Conditional Bottleneck Adapter that generates low-rank parameters based on current state, and Numeral-State Matching module for detecting state variable anomalies.", "result": "Extensive experiments on real-world datasets show that STAR improves the performance of existing TSFMs on Multivariate Time Series Anomaly Detection.", "conclusion": "STAR effectively addresses the limitation of existing TSFMs in handling state variables and enhances their anomaly detection capabilities in industrial scenarios with mixed numerical and categorical data."}}
{"id": "2510.16555", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16555", "abs": "https://arxiv.org/abs/2510.16555", "authors": ["Qiongyan Wang", "Xingchen Zou", "Yutian Jiang", "Haomin Wen", "Jiaheng Wei", "Qingsong Wen", "Yuxuan Liang"], "title": "Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence", "comment": null, "summary": "Rapid urbanization intensifies the demand for Urban General Intelligence\n(UGI), referring to AI systems that can understand and reason about complex\nurban environments. Recent studies have built urban foundation models using\nsupervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit\npersistent geospatial bias, producing regionally skewed predictions and limited\ngeneralization. To this end, we propose Urban-R1, a reinforcement\nlearning-based post-training framework that aligns MLLMs with the objectives of\nUGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize\nreasoning across geographic groups and employs urban region profiling as a\nproxy task to provide measurable rewards from multimodal urban data. Extensive\nexperiments across diverse regions and tasks show that Urban-R1 effectively\nmitigates geo-bias and improves cross-region generalization, outperforming both\nSFT-trained and closed-source models. Our results highlight reinforcement\nlearning alignment as a promising pathway toward equitable and trustworthy\nurban intelligence.", "AI": {"tldr": "Urban-R1 is a reinforcement learning framework that reduces geospatial bias in urban AI systems by using Group Relative Policy Optimization and urban region profiling to improve cross-region generalization.", "motivation": "Current urban foundation models using supervised fine-tuning exhibit persistent geospatial bias, producing regionally skewed predictions and limited generalization across different geographic areas.", "method": "Proposes Urban-R1 framework using Group Relative Policy Optimization (GRPO) to optimize reasoning across geographic groups, with urban region profiling as a proxy task to provide measurable rewards from multimodal urban data.", "result": "Extensive experiments show Urban-R1 effectively mitigates geo-bias and improves cross-region generalization, outperforming both SFT-trained and closed-source models across diverse regions and tasks.", "conclusion": "Reinforcement learning alignment is a promising pathway toward equitable and trustworthy urban intelligence by addressing geospatial bias in urban AI systems."}}
{"id": "2510.16335", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16335", "abs": "https://arxiv.org/abs/2510.16335", "authors": ["Bo Peng", "Jie Lu", "Guangquan Zhang", "Zhen Fang"], "title": "On the Provable Importance of Gradients for Language-Assisted Image Clustering", "comment": "revised and extended version of ICCV2025", "summary": "This paper investigates the recently emerged problem of Language-assisted\nImage Clustering (LaIC), where textual semantics are leveraged to improve the\ndiscriminability of visual representations to facilitate image clustering. Due\nto the unavailability of true class names, one of core challenges of LaIC lies\nin how to filter positive nouns, i.e., those semantically close to the images\nof interest, from unlabeled wild corpus data. Existing filtering strategies are\npredominantly based on the off-the-shelf feature space learned by CLIP;\nhowever, despite being intuitive, these strategies lack a rigorous theoretical\nfoundation. To fill this gap, we propose a novel gradient-based framework,\ntermed as GradNorm, which is theoretically guaranteed and shows strong\nempirical performance. In particular, we measure the positiveness of each noun\nbased on the magnitude of gradients back-propagated from the cross-entropy\nbetween the predicted target distribution and the softmax output.\nTheoretically, we provide a rigorous error bound to quantify the separability\nof positive nouns by GradNorm and prove that GradNorm naturally subsumes\nexisting filtering strategies as extremely special cases of itself.\nEmpirically, extensive experiments show that GradNorm achieves the\nstate-of-the-art clustering performance on various benchmarks.", "AI": {"tldr": "GradNorm is a gradient-based framework for Language-assisted Image Clustering that measures noun positiveness using gradient magnitudes from cross-entropy loss, theoretically unifying existing methods and achieving state-of-the-art performance.", "motivation": "Existing Language-assisted Image Clustering methods rely on CLIP's feature space for filtering positive nouns but lack theoretical foundation, creating a need for a more rigorous approach.", "method": "Proposed GradNorm framework measures noun positiveness based on gradient magnitudes back-propagated from cross-entropy between predicted target distribution and softmax output.", "result": "Extensive experiments show GradNorm achieves state-of-the-art clustering performance on various benchmarks.", "conclusion": "GradNorm provides a theoretically guaranteed framework that subsumes existing filtering strategies as special cases and demonstrates strong empirical performance in language-assisted image clustering."}}
{"id": "2510.16015", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16015", "abs": "https://arxiv.org/abs/2510.16015", "authors": ["Qian Sun", "Graham Hults", "Susu Xu"], "title": "Decision-focused Sensing and Forecasting for Adaptive and Rapid Flood Response: An Implicit Learning Approach", "comment": null, "summary": "Timely and reliable decision-making is vital for flood emergency response,\nyet it remains severely hindered by limited and imprecise situational awareness\ndue to various budget and data accessibility constraints. Traditional flood\nmanagement systems often rely on in-situ sensors to calibrate remote\nsensing-based large-scale flood depth forecasting models, and further take\nflood depth estimates to optimize flood response decisions. However, these\napproaches often take fixed, decision task-agnostic strategies to decide where\nto put in-situ sensors (e.g., maximize overall information gain) and train\nflood forecasting models (e.g., minimize average forecasting errors), but\noverlook that systems with the same sensing gain and average forecasting errors\nmay lead to distinct decisions. To address this, we introduce a novel\ndecision-focused framework that strategically selects locations for in-situ\nsensor placement and optimize spatio-temporal flood forecasting models to\noptimize downstream flood response decision regrets. Our end-to-end pipeline\nintegrates four components: a contextual scoring network, a differentiable\nsensor selection module under hard budget constraints, a spatio-temporal flood\nreconstruction and forecasting model, and a differentiable decision layer\ntailored to task-specific objectives. Central to our approach is the\nincorporation of Implicit Maximum Likelihood Estimation (I-MLE) to enable\ngradient-based learning over discrete sensor configurations, and probabilistic\ndecision heads to enable differentiable approximation to various constrained\ndisaster response tasks.", "AI": {"tldr": "A decision-focused framework for flood emergency response that optimizes sensor placement and flood forecasting models to minimize downstream decision regrets, using differentiable learning over discrete sensor configurations.", "motivation": "Traditional flood management systems use task-agnostic strategies for sensor placement and model training, overlooking that similar sensing gains and forecasting errors can lead to different decision outcomes in emergency response.", "method": "End-to-end pipeline with four components: contextual scoring network, differentiable sensor selection under budget constraints, spatio-temporal flood reconstruction/forecasting model, and differentiable decision layer. Uses Implicit Maximum Likelihood Estimation (I-MLE) for gradient-based learning over discrete sensor configurations.", "result": "The framework enables optimized sensor placement and forecasting models specifically tailored to improve downstream flood response decisions rather than just maximizing information gain or minimizing average forecasting errors.", "conclusion": "The proposed decision-focused approach provides a more effective solution for flood emergency response by directly optimizing for decision quality rather than intermediate metrics, addressing limitations of traditional task-agnostic methods."}}
{"id": "2510.16559", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16559", "abs": "https://arxiv.org/abs/2510.16559", "authors": ["Tian Xia", "Tianrun Gao", "Wenhao Deng", "Long Wei", "Xiaowei Qian", "Yixian Jiang", "Chenglei Yu", "Tailin Wu"], "title": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "comment": "33 pages, 10 figures", "summary": "Engineering construction automation aims to transform natural language\nspecifications into physically viable structures, requiring complex integrated\nreasoning under strict physical constraints. While modern LLMs possess broad\nknowledge and strong reasoning capabilities that make them promising candidates\nfor this domain, their construction competencies remain largely unevaluated. To\naddress this gap, we introduce BuildArena, the first physics-aligned\ninteractive benchmark designed for language-driven engineering construction. It\ncontributes to the community in four aspects: (1) a highly customizable\nbenchmarking framework for in-depth comparison and analysis of LLMs; (2) an\nextendable task design strategy spanning static and dynamic mechanics across\nmultiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for\nsupporting construction based on language instructions; (4) a baseline LLM\nagentic workflow that effectively evaluates diverse model capabilities. On\neight frontier LLMs, BuildArena comprehensively evaluates their capabilities\nfor language-driven and physics-grounded construction automation. The project\npage is at https://build-arena.github.io/.", "AI": {"tldr": "BuildArena is the first physics-aligned interactive benchmark for evaluating LLMs' capabilities in engineering construction automation, featuring customizable framework, extendable tasks, 3D spatial computation library, and baseline agent workflow.", "motivation": "To address the gap in evaluating LLMs' construction competencies despite their broad knowledge and reasoning capabilities, as engineering construction automation requires complex reasoning under strict physical constraints.", "method": "Developed BuildArena benchmark with four key components: customizable framework, extendable task design spanning static/dynamic mechanics, 3D Spatial Geometric Computation Library, and baseline LLM agentic workflow for evaluation.", "result": "Comprehensively evaluated eight frontier LLMs on their capabilities for language-driven and physics-grounded construction automation using the BuildArena benchmark.", "conclusion": "BuildArena provides the first standardized framework for assessing LLMs in engineering construction automation, enabling systematic comparison and analysis of model capabilities in this domain."}}
{"id": "2510.17396", "categories": ["cs.LG", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17396", "abs": "https://arxiv.org/abs/2510.17396", "authors": ["Keivan Faghih Niresi", "Zepeng Zhang", "Olga Fink"], "title": "RINS-T: Robust Implicit Neural Solvers for Time Series Linear Inverse Problems", "comment": "Accepted to IEEE Transactions on Instrumentation and Measurement", "summary": "Time series data are often affected by various forms of corruption, such as\nmissing values, noise, and outliers, which pose significant challenges for\ntasks such as forecasting and anomaly detection. To address these issues,\ninverse problems focus on reconstructing the original signal from corrupted\ndata by leveraging prior knowledge about its underlying structure. While deep\nlearning methods have demonstrated potential in this domain, they often require\nextensive pretraining and struggle to generalize under distribution shifts. In\nthis work, we propose RINS-T (Robust Implicit Neural Solvers for Time Series\nLinear Inverse Problems), a novel deep prior framework that achieves high\nrecovery performance without requiring pretraining data. RINS-T leverages\nneural networks as implicit priors and integrates robust optimization\ntechniques, making it resilient to outliers while relaxing the reliance on\nGaussian noise assumptions. To further improve optimization stability and\nrobustness, we introduce three key innovations: guided input initialization,\ninput perturbation, and convex output combination techniques. Each of these\ncontributions strengthens the framework's optimization stability and\nrobustness. These advancements make RINS-T a flexible and effective solution\nfor addressing complex real-world time series challenges. Our code is available\nat https://github.com/EPFL-IMOS/RINS-T.", "AI": {"tldr": "RINS-T is a novel deep prior framework for time series linear inverse problems that achieves high recovery performance without pretraining data, using neural networks as implicit priors with robust optimization techniques.", "motivation": "Time series data often suffer from corruption like missing values, noise, and outliers, which challenge forecasting and anomaly detection. Existing deep learning methods require extensive pretraining and struggle with distribution shifts.", "method": "RINS-T uses neural networks as implicit priors with robust optimization techniques. It introduces three innovations: guided input initialization, input perturbation, and convex output combination to improve optimization stability and robustness.", "result": "The framework achieves high recovery performance without requiring pretraining data, is resilient to outliers, and relaxes reliance on Gaussian noise assumptions.", "conclusion": "RINS-T provides a flexible and effective solution for complex real-world time series challenges, with code available for public use."}}
{"id": "2510.16370", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16370", "abs": "https://arxiv.org/abs/2510.16370", "authors": ["Pulin Li", "Guocheng Wu", "Li Yin", "Yuxin Zheng", "Wei Zhang", "Yanjie Zhou"], "title": "MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization", "comment": "https://github.com/wu33learn/MIRAD", "summary": "Social manufacturing leverages community collaboration and scattered\nresources to realize mass individualization in modern industry. However, this\nparadigm shift also introduces substantial challenges in quality control,\nparticularly in defect detection. The main difficulties stem from three\naspects. First, products often have highly customized configurations. Second,\nproduction typically involves fragmented, small-batch orders. Third, imaging\nenvironments vary considerably across distributed sites. To overcome the\nscarcity of real-world datasets and tailored algorithms, we introduce the Mass\nIndividualization Robust Anomaly Detection (MIRAD) dataset. As the first\nbenchmark explicitly designed for anomaly detection in social manufacturing,\nMIRAD captures three critical dimensions of this domain: (1) diverse\nindividualized products with large intra-class variation, (2) data collected\nfrom six geographically dispersed manufacturing nodes, and (3) substantial\nimaging heterogeneity, including variations in lighting, background, and motion\nconditions. We then conduct extensive evaluations of state-of-the-art (SOTA)\nanomaly detection methods on MIRAD, covering one-class, multi-class, and\nzero-shot approaches. Results show a significant performance drop across all\nmodels compared with conventional benchmarks, highlighting the unresolved\ncomplexities of defect detection in real-world individualized production. By\nbridging industrial requirements and academic research, MIRAD provides a\nrealistic foundation for developing robust quality control solutions essential\nfor Industry 5.0. The dataset is publicly available at\nhttps://github.com/wu33learn/MIRAD.", "AI": {"tldr": "The paper introduces MIRAD, the first benchmark dataset for anomaly detection in social manufacturing, addressing challenges from mass individualization like customized products, small-batch orders, and varying imaging environments across distributed sites.", "motivation": "Social manufacturing enables mass individualization but creates major quality control challenges due to highly customized products, fragmented production, and variable imaging conditions across distributed sites, with limited real-world datasets available.", "method": "Created the MIRAD dataset capturing three critical dimensions: diverse individualized products with large intra-class variation, data from six geographically dispersed manufacturing nodes, and substantial imaging heterogeneity. Evaluated SOTA anomaly detection methods including one-class, multi-class, and zero-shot approaches.", "result": "All evaluated models showed significant performance drops compared to conventional benchmarks, demonstrating the unresolved complexities of defect detection in real-world individualized production environments.", "conclusion": "MIRAD bridges industrial requirements and academic research by providing a realistic foundation for developing robust quality control solutions essential for Industry 5.0, with the dataset publicly available for further research."}}
{"id": "2510.16016", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.16016", "abs": "https://arxiv.org/abs/2510.16016", "authors": ["Saeed Salehi"], "title": "Transfer learning strategies for accelerating reinforcement-learning-based flow control", "comment": null, "summary": "This work investigates transfer learning strategies to accelerate deep\nreinforcement learning (DRL) for multifidelity control of chaotic fluid flows.\nProgressive neural networks (PNNs), a modular architecture designed to preserve\nand reuse knowledge across tasks, are employed for the first time in the\ncontext of DRL-based flow control. In addition, a comprehensive benchmarking of\nconventional fine-tuning strategies is conducted, evaluating their performance,\nconvergence behavior, and ability to retain transferred knowledge. The\nKuramoto-Sivashinsky (KS) system is employed as a benchmark to examine how\nknowledge encoded in control policies, trained in low-fidelity environments,\ncan be effectively transferred to high-fidelity settings. Systematic\nevaluations show that while fine-tuning can accelerate convergence, it is\nhighly sensitive to pretraining duration and prone to catastrophic forgetting.\nIn contrast, PNNs enable stable and efficient transfer by preserving prior\nknowledge and providing consistent performance gains, and are notably robust to\noverfitting during the pretraining phase. Layer-wise sensitivity analysis\nfurther reveals how PNNs dynamically reuse intermediate representations from\nthe source policy while progressively adapting deeper layers to the target\ntask. Moreover, PNNs remain effective even when the source and target\nenvironments differ substantially, such as in cases with mismatched physical\nregimes or control objectives, where fine-tuning strategies often result in\nsuboptimal adaptation or complete failure of knowledge transfer. The results\nhighlight the potential of novel transfer learning frameworks for robust,\nscalable, and computationally efficient flow control that can potentially be\napplied to more complex flow configurations.", "AI": {"tldr": "This paper investigates transfer learning for accelerating deep reinforcement learning in chaotic fluid flow control, comparing progressive neural networks with fine-tuning methods.", "motivation": "To accelerate deep reinforcement learning for multifidelity control of chaotic fluid flows by effectively transferring knowledge from low-fidelity to high-fidelity environments.", "method": "Uses progressive neural networks (PNNs) for the first time in DRL-based flow control, and benchmarks against conventional fine-tuning strategies on the Kuramoto-Sivashinsky system.", "result": "PNNs enable stable and efficient transfer with consistent performance gains, while fine-tuning is sensitive to pretraining duration and prone to catastrophic forgetting. PNNs remain effective even with substantial differences between source and target environments.", "conclusion": "Progressive neural networks offer robust, scalable, and computationally efficient transfer learning for flow control, outperforming fine-tuning methods and showing potential for complex flow configurations."}}
{"id": "2510.16572", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.16572", "abs": "https://arxiv.org/abs/2510.16572", "authors": ["Ayush Chopra", "Aman Sharma", "Feroz Ahmad", "Luca Muscariello", "Vijoy Pandey", "Ramesh Raskar"], "title": "Ripple Effect Protocol: Coordinating Agent Populations", "comment": null, "summary": "Modern AI agents can exchange messages using protocols such as A2A and ACP,\nyet these mechanisms emphasize communication over coordination. As agent\npopulations grow, this limitation produces brittle collective behavior, where\nindividually smart agents converge on poor group outcomes. We introduce the\nRipple Effect Protocol (REP), a coordination protocol in which agents share not\nonly their decisions but also lightweight sensitivities - signals expressing\nhow their choices would change if key environmental variables shifted. These\nsensitivities ripple through local networks, enabling groups to align faster\nand more stably than with agent-centric communication alone. We formalize REP's\nprotocol specification, separating required message schemas from optional\naggregation rules, and evaluate it across scenarios with varying incentives and\nnetwork topologies. Benchmarks across three domains: (i) supply chain cascades\n(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),\nand (iii) sustainable resource allocation (Fishbanks) show that REP improves\ncoordination accuracy and efficiency over A2A by 41 to 100%, while flexibly\nhandling multimodal sensitivity signals from LLMs. By making coordination a\nprotocol-level capability, REP provides scalable infrastructure for the\nemerging Internet of Agents", "AI": {"tldr": "The Ripple Effect Protocol (REP) improves multi-agent coordination by having agents share lightweight sensitivity signals alongside decisions, enabling faster and more stable group alignment than traditional communication protocols.", "motivation": "Current AI agent communication protocols like A2A and ACP emphasize communication over coordination, leading to brittle collective behavior where individually smart agents converge on poor group outcomes as populations grow.", "method": "REP is a coordination protocol where agents share both decisions and lightweight sensitivities - signals expressing how their choices would change if key environmental variables shifted. These sensitivities ripple through local networks. The protocol separates required message schemas from optional aggregation rules.", "result": "Benchmarks across three domains (supply chain cascades, preference aggregation in sparse networks, sustainable resource allocation) show REP improves coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly handling multimodal sensitivity signals from LLMs.", "conclusion": "By making coordination a protocol-level capability, REP provides scalable infrastructure for the emerging Internet of Agents."}}
{"id": "2510.17406", "categories": ["cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.17406", "abs": "https://arxiv.org/abs/2510.17406", "authors": ["Tiezhi Wang", "Wilhelm Haverkamp", "Nils Strodthoff"], "title": "S4ECG: Exploring the impact of long-range interactions for arrhythmia prediction", "comment": null, "summary": "The electrocardiogram (ECG) exemplifies biosignal-based time series with\ncontinuous, temporally ordered structure reflecting cardiac physiological and\npathophysiological dynamics. Detailed analysis of these dynamics has proven\nchallenging, as conventional methods capture either global trends or local\nwaveform features but rarely their simultaneous interplay at high temporal\nresolution. To bridge global and local signal analysis, we introduce S4ECG, a\nnovel deep learning architecture leveraging structured state space models for\nmulti-epoch arrhythmia classification. Our joint multi-epoch predictions\nsignificantly outperform single-epoch approaches by 1.0-11.6% in macro-AUROC,\nwith atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998,\ndemonstrating superior performance in-distribution and enhanced\nout-of-distribution robustness. Systematic investigation reveals optimal\ntemporal dependency windows spanning 10-20 minutes for peak performance. This\nwork contributes to a paradigm shift toward temporally-aware arrhythmia\ndetection algorithms, opening new possibilities for ECG interpretation, in\nparticular for complex arrhythmias like atrial fibrillation and atrial flutter.", "AI": {"tldr": "S4ECG is a novel deep learning architecture using structured state space models for multi-epoch ECG arrhythmia classification, achieving superior performance over single-epoch approaches with optimal temporal dependency windows of 10-20 minutes.", "motivation": "Conventional ECG analysis methods struggle to capture both global trends and local waveform features simultaneously at high temporal resolution, limiting comprehensive analysis of cardiac dynamics.", "method": "Introduced S4ECG architecture leveraging structured state space models for multi-epoch arrhythmia classification, enabling joint analysis across multiple time segments.", "result": "Multi-epoch predictions outperformed single-epoch approaches by 1.0-11.6% in macro-AUROC, with atrial fibrillation specificity improving from 0.718-0.979 to 0.967-0.998, showing superior in-distribution performance and enhanced out-of-distribution robustness.", "conclusion": "This work enables a paradigm shift toward temporally-aware arrhythmia detection algorithms, particularly beneficial for complex arrhythmias like atrial fibrillation and atrial flutter."}}
{"id": "2510.16371", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16371", "abs": "https://arxiv.org/abs/2510.16371", "authors": ["Mohammad Javad Ahmadi", "Iman Gandomi", "Parisa Abdi", "Seyed-Farzad Mohammadi", "Amirhossein Taslimi", "Mehdi Khodaparast", "Hassan Hashemi", "Mahdi Tavakoli", "Hamid D. Taghirad"], "title": "Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis", "comment": "20 pages, 11 figures, 11 tables. Data descriptor for the Cataract-LMM\n  benchmark dataset. Source code and dataset are available", "summary": "The development of computer-assisted surgery systems depends on large-scale,\nannotated datasets. Current resources for cataract surgery often lack the\ndiversity and annotation depth needed to train generalizable deep-learning\nmodels. To address this gap, we present a dataset of 3,000 phacoemulsification\ncataract surgery videos from two surgical centers, performed by surgeons with a\nrange of experience levels. This resource is enriched with four annotation\nlayers: temporal surgical phases, instance segmentation of instruments and\nanatomical structures, instrument-tissue interaction tracking, and quantitative\nskill scores based on the established competency rubrics like the ICO-OSCAR.\nThe technical quality of the dataset is supported by a series of benchmarking\nexperiments for key surgical AI tasks, including workflow recognition, scene\nsegmentation, and automated skill assessment. Furthermore, we establish a\ndomain adaptation baseline for the phase recognition task by training a model\non a subset of surgical centers and evaluating its performance on a held-out\ncenter. The dataset and annotations are available in Google Form\n(https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog).", "AI": {"tldr": "A comprehensive dataset of 3,000 cataract surgery videos with multi-layer annotations for training surgical AI models, including temporal phases, instance segmentation, interaction tracking, and skill assessment.", "motivation": "Current cataract surgery datasets lack diversity and annotation depth needed to train generalizable deep-learning models for computer-assisted surgery systems.", "method": "Collected 3,000 phacoemulsification cataract surgery videos from two surgical centers with surgeons of varying experience levels, enriched with four annotation layers: temporal surgical phases, instance segmentation, instrument-tissue interaction tracking, and quantitative skill scores.", "result": "Benchmarking experiments demonstrated the dataset's technical quality for key surgical AI tasks including workflow recognition, scene segmentation, and automated skill assessment. Established domain adaptation baseline for phase recognition across surgical centers.", "conclusion": "The dataset provides a comprehensive resource for developing and evaluating surgical AI systems, with demonstrated utility across multiple computer-assisted surgery tasks and support for domain adaptation research."}}
{"id": "2510.16020", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16020", "abs": "https://arxiv.org/abs/2510.16020", "authors": ["Sangjoon Lee", "Haris Moazam Sheikh"], "title": "Airfoil optimization using Design-by-Morphing with minimized design-space dimensionality", "comment": null, "summary": "Effective airfoil geometry optimization requires exploring a diverse range of\ndesigns using as few design variables as possible. This study introduces\nAirDbM, a Design-by-Morphing (DbM) approach specialized for airfoil\noptimization that systematically reduces design-space dimensionality. AirDbM\nselects an optimal set of 12 baseline airfoils from the UIUC airfoil database,\nwhich contains over 1,600 shapes, by sequentially adding the baseline that most\nincreases the design capacity. With these baselines, AirDbM reconstructs 99 \\%\nof the database with a mean absolute error below 0.005, which matches the\nperformance of a previous DbM approach that used more baselines. In\nmulti-objective aerodynamic optimization, AirDbM demonstrates rapid convergence\nand achieves a Pareto front with a greater hypervolume than that of the\nprevious larger-baseline study, where new Pareto-optimal solutions are\ndiscovered with enhanced lift-to-drag ratios at moderate stall tolerances.\nFurthermore, AirDbM demonstrates outstanding adaptability for reinforcement\nlearning (RL) agents in generating airfoil geometry when compared to\nconventional airfoil parameterization methods, implying the broader potential\nof DbM in machine learning-driven design.", "AI": {"tldr": "AirDbM is a Design-by-Morphing approach that uses only 12 optimal baseline airfoils to achieve efficient airfoil optimization with reduced design variables while maintaining high reconstruction accuracy and superior optimization performance.", "motivation": "To enable effective airfoil geometry optimization by exploring diverse designs with minimal design variables, addressing the need for dimensionality reduction in design space.", "method": "Selects optimal set of 12 baseline airfoils from UIUC database (1600+ shapes) by sequentially adding baselines that maximize design capacity, then uses Design-by-Morphing approach for reconstruction and optimization.", "result": "Reconstructs 99% of database with mean absolute error <0.005, matches previous approach using more baselines; achieves better Pareto front with greater hypervolume in multi-objective optimization; discovers new Pareto-optimal solutions with enhanced lift-to-drag ratios; shows superior adaptability for RL agents compared to conventional parameterization.", "conclusion": "AirDbM demonstrates efficient dimensionality reduction while maintaining optimization performance, with broader potential for machine learning-driven design applications."}}
{"id": "2510.16582", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16582", "abs": "https://arxiv.org/abs/2510.16582", "authors": ["Junchi Yu", "Yujie Liu", "Jindong Gu", "Philip Torr", "Dongzhan Zhou"], "title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "comment": "NeurIPS 2025 (Spotlight)", "summary": "Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances\nlarge language models (LLMs) by providing structured and interpretable external\nknowledge. However, existing KG-based RAG methods struggle to retrieve accurate\nand diverse information from text-rich KGs for complex real-world queries.\nProcess Reward Models (PRMs) offer a way to align the retrieval process of\nKG-based RAG with query-specific knowledge requirements, but they heavily rely\non process-level supervision signals that are expensive and hard to obtain on\nKGs. To address this challenge, we propose GraphFlow, a framework that\nefficiently retrieves accurate and diverse knowledge required for real-world\nqueries from text-rich KGs. GraphFlow employs a transition-based flow matching\nobjective to jointly optimize a retrieval policy and a flow estimator. The flow\nestimator factorizes the reward of the retrieval outcome into the intermediate\nretrieval states. Such reward factorization guides the retrieval policy to\nretrieve candidates from KGs in proportion to their reward. This allows\nGraphFlow to explore high-quality regions of KGs that yield diverse and\nrelevant results. We evaluate GraphFlow on the STaRK benchmark, which includes\nreal-world queries from multiple domains over text-rich KGs. GraphFlow\noutperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit\nrate and recall. It also shows strong generalization to unseen KGs,\ndemonstrating its effectiveness and robustness.", "AI": {"tldr": "GraphFlow is a framework that improves KG-based RAG by using transition-based flow matching to retrieve accurate and diverse knowledge from text-rich knowledge graphs for complex real-world queries.", "motivation": "Existing KG-based RAG methods struggle to retrieve accurate and diverse information from text-rich KGs for complex queries, and Process Reward Models require expensive process-level supervision that's hard to obtain on KGs.", "method": "GraphFlow employs a transition-based flow matching objective to jointly optimize a retrieval policy and flow estimator, which factorizes reward outcomes into intermediate states to guide proportional retrieval of high-quality candidates.", "result": "GraphFlow outperforms strong KG-RAG baselines including GPT-4o by 10% on average in hit rate and recall on the STaRK benchmark, and shows strong generalization to unseen KGs.", "conclusion": "GraphFlow effectively addresses the limitations of existing KG-RAG methods by enabling efficient retrieval of accurate and diverse knowledge from text-rich KGs without expensive supervision, demonstrating strong performance and generalization capabilities."}}
{"id": "2510.16375", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16375", "abs": "https://arxiv.org/abs/2510.16375", "authors": ["Rishi Raj Sahoo", "Surbhi Saswati Mohanty", "Subhankar Mishra"], "title": "iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance", "comment": "Under review", "summary": "Road potholes pose significant safety hazards and maintenance challenges,\nparticularly on India's diverse and under-maintained road networks. This paper\npresents iWatchRoadv2, a fully automated end-to-end platform for real-time\npothole detection, GPS-based geotagging, and dynamic road health visualization\nusing OpenStreetMap (OSM). We curated a self-annotated dataset of over 7,000\ndashcam frames capturing diverse Indian road conditions, weather patterns, and\nlighting scenarios, which we used to fine-tune the Ultralytics YOLO model for\naccurate pothole detection. The system synchronizes OCR-extracted video\ntimestamps with external GPS logs to precisely geolocate each detected pothole,\nenriching detections with comprehensive metadata, including road segment\nattribution and contractor information managed through an optimized backend\ndatabase. iWatchRoadv2 introduces intelligent governance features that enable\nauthorities to link road segments with contract metadata through a secure login\ninterface. The system automatically sends alerts to contractors and officials\nwhen road health deteriorates, supporting automated accountability and warranty\nenforcement. The intuitive web interface delivers actionable analytics to\nstakeholders and the public, facilitating evidence-driven repair planning,\nbudget allocation, and quality assessment. Our cost-effective and scalable\nsolution streamlines frame processing and storage while supporting seamless\npublic engagement for urban and rural deployments. By automating the complete\npothole monitoring lifecycle, from detection to repair verification,\niWatchRoadv2 enables data-driven smart city management, transparent governance,\nand sustainable improvements in road infrastructure maintenance. The platform\nand live demonstration are accessible at\nhttps://smlab.niser.ac.in/project/iwatchroad.", "AI": {"tldr": "iWatchRoadv2 is an automated platform for real-time pothole detection using YOLO models, GPS geotagging, and OpenStreetMap visualization, with governance features for contractor accountability and public engagement.", "motivation": "Road potholes pose significant safety hazards and maintenance challenges on India's diverse and under-maintained road networks, requiring automated solutions for detection and repair management.", "method": "Fine-tuned Ultralytics YOLO model on 7,000+ dashcam frames of Indian roads, synchronized OCR timestamps with GPS logs for geolocation, and built backend database with road segment attribution and contractor information.", "result": "Developed a fully automated end-to-end platform with real-time pothole detection, GPS-based geotagging, dynamic road health visualization, and intelligent governance features for automated alerts and accountability.", "conclusion": "iWatchRoadv2 enables data-driven smart city management, transparent governance, and sustainable improvements in road infrastructure maintenance by automating the complete pothole monitoring lifecycle from detection to repair verification."}}
{"id": "2510.16021", "categories": ["cs.LG", "econ.GN", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.16021", "abs": "https://arxiv.org/abs/2510.16021", "authors": ["Arega Getaneh Abate", "Xiufeng Liu", "Ruyu Liu", "Xiaobing Zhang"], "title": "Feature-driven reinforcement learning for photovoltaic in continuous intraday trading", "comment": null, "summary": "Photovoltaic (PV) operators face substantial uncertainty in generation and\nshort-term electricity prices. Continuous intraday markets enable producers to\nadjust their positions in real time, potentially improving revenues and\nreducing imbalance costs. We propose a feature-driven reinforcement learning\n(RL) approach for PV intraday trading that integrates data-driven features into\nthe state and learns bidding policies in a sequential decision framework. The\nproblem is cast as a Markov Decision Process with a reward that balances\ntrading profit and imbalance penalties and is solved with Proximal Policy\nOptimization (PPO) using a predominantly linear, interpretable policy. Trained\non historical market data and evaluated out-of-sample, the strategy\nconsistently outperforms benchmark baselines across diverse scenarios.\nExtensive validation shows rapid convergence, real-time inference, and\ntransparent decision rules. Learned weights highlight the central role of\nmarket microstructure and historical features. Taken together, these results\nindicate that feature-driven RL offers a practical, data-efficient, and\noperationally deployable pathway for active intraday participation by PV\nproducers.", "AI": {"tldr": "A reinforcement learning approach using Proximal Policy Optimization for PV intraday trading that outperforms benchmarks by balancing trading profits and imbalance penalties through interpretable policies.", "motivation": "PV operators face uncertainty in generation and electricity prices, needing real-time position adjustments in continuous intraday markets to improve revenues and reduce imbalance costs.", "method": "Feature-driven reinforcement learning approach using Markov Decision Process with PPO algorithm, integrating data-driven features into state representation and learning sequential bidding policies with predominantly linear, interpretable policy structure.", "result": "The strategy consistently outperforms benchmark baselines across diverse scenarios in out-of-sample evaluation, showing rapid convergence, real-time inference capability, and transparent decision rules with learned weights highlighting market microstructure importance.", "conclusion": "Feature-driven RL provides a practical, data-efficient, and operationally deployable pathway for active intraday participation by PV producers."}}
{"id": "2510.16601", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16601", "abs": "https://arxiv.org/abs/2510.16601", "authors": ["Tianxing Wu", "Shutong Zhu", "Jingting Wang", "Ning Xu", "Guilin Qi", "Haofen Wang"], "title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "comment": "13 pages, accepted by NeurIPS 2025 (spotlight)", "summary": "Uncertain knowledge graphs (UKGs) associate each triple with a confidence\nscore to provide more precise knowledge representations. Recently, since\nreal-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)\ncompletion attracts more attention, aiming to complete missing triples and\nconfidences. Current studies attempt to learn UKG embeddings to solve this\nproblem, but they neglect the extremely imbalanced distributions of triple\nconfidences. This causes that the learnt embeddings are insufficient to\nhigh-quality UKG completion. Thus, in this paper, to address the above issue,\nwe propose a new semi-supervised Confidence Distribution Learning (ssCDL)\nmethod for UKG completion, where each triple confidence is transformed into a\nconfidence distribution to introduce more supervision information of different\nconfidences to reinforce the embedding learning process. ssCDL iteratively\nlearns UKG embedding by relational learning on labeled data (i.e., existing\ntriples with confidences) and unlabeled data with pseudo labels (i.e., unseen\ntriples with the generated confidences), which are predicted by meta-learning\nto augment the training data and rebalance the distribution of triple\nconfidences. Experiments on two UKG datasets demonstrate that ssCDL\nconsistently outperforms state-of-the-art baselines in different evaluation\nmetrics.", "AI": {"tldr": "Proposes ssCDL, a semi-supervised confidence distribution learning method for uncertain knowledge graph completion that addresses imbalanced confidence distributions through meta-learning and pseudo-labeling.", "motivation": "Current UKG completion methods neglect the extremely imbalanced distributions of triple confidences, causing insufficient embeddings for high-quality completion.", "method": "Transforms triple confidences into confidence distributions, uses relational learning on labeled and unlabeled data with pseudo labels generated by meta-learning to augment training data and rebalance confidence distributions.", "result": "Experiments on two UKG datasets show ssCDL consistently outperforms state-of-the-art baselines across different evaluation metrics.", "conclusion": "ssCDL effectively addresses the imbalanced confidence distribution problem in UKG completion through semi-supervised learning with confidence distributions and meta-learning-based pseudo-labeling."}}
{"id": "2510.17543", "categories": ["cs.LG", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17543", "abs": "https://arxiv.org/abs/2510.17543", "authors": ["Jiayi Huang", "Sangwoo Park", "Nicola Paoletti", "Osvaldo Simeone"], "title": "Reliable Inference in Edge-Cloud Model Cascades via Conformal Alignment", "comment": "Under Review", "summary": "Edge intelligence enables low-latency inference via compact on-device models,\nbut assuring reliability remains challenging. We study edge-cloud cascades that\nmust preserve conditional coverage: whenever the edge returns a prediction set,\nit should contain the true label with a user-specified probability, as if\nproduced by the cloud model. We formalize conditional coverage with respect to\nthe cloud predictive distribution, and introduce a conformal alignment-based\n(CAb) cascading mechanism that certifies this property with user control over\nthe risk level. Our method casts escalation from edge to cloud models as a\nmultiple-hypothesis testing (MHT) problem, tailoring conformal alignment (CA)\nto select which inputs can be safely handled at the edge. The proposed CAb\nmodel cascading method yields statistical guarantees on the average fraction of\nedge decisions that satisfy cloud-level conditional coverage. The procedure\napplies to arbitrary edge prediction sets, including variants of conformal\nprediction (CP), and exposes a tunable trade-off among coverage, deferral rate,\nand set size. Experiments on CIFAR-100 image classification and the TeleQnA\nquestion-answering (QA) benchmark show that the proposed CAb cascade maintains\nthe target conditional coverage for edge predictions while substantially\nreducing offloading to the cloud and incurring modest increases in\nprediction-set size.", "AI": {"tldr": "The paper proposes a conformal alignment-based (CAb) cascading mechanism for edge-cloud systems that ensures edge predictions maintain the same conditional coverage guarantees as cloud models, while reducing cloud offloading.", "motivation": "Edge intelligence enables low-latency inference but struggles with reliability assurance. Current edge-cloud cascades need to preserve conditional coverage guarantees equivalent to cloud models while minimizing cloud offloading.", "method": "Formalizes conditional coverage with respect to cloud predictive distribution, uses conformal alignment to select inputs for edge handling, and casts escalation as a multiple-hypothesis testing problem.", "result": "Experiments on CIFAR-100 and TeleQnA benchmarks show CAb maintains target conditional coverage for edge predictions while substantially reducing cloud offloading and modestly increasing prediction set sizes.", "conclusion": "The proposed CAb cascade provides statistical guarantees on edge decisions satisfying cloud-level conditional coverage, offering a tunable trade-off among coverage, deferral rate, and set size."}}
{"id": "2510.16377", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16377", "abs": "https://arxiv.org/abs/2510.16377", "authors": ["Tianhang Cheng", "Albert J. Zhai", "Evan Z. Chen", "Rui Zhou", "Yawen Deng", "Zitong Li", "Kejie Zhao", "Janice Shiu", "Qianyu Zhao", "Yide Xu", "Xinlei Wang", "Yuan Shen", "Sheng Wang", "Lisa Ainsworth", "Kaiyu Guan", "Shenlong Wang"], "title": "Demeter: A Parametric Model of Crop Plant Morphology from the Real World", "comment": "ICCV 2025", "summary": "Learning 3D parametric shape models of objects has gained popularity in\nvision and graphics and has showed broad utility in 3D reconstruction,\ngeneration, understanding, and simulation. While powerful models exist for\nhumans and animals, equally expressive approaches for modeling plants are\nlacking. In this work, we present Demeter, a data-driven parametric model that\nencodes key factors of a plant morphology, including topology, shape,\narticulation, and deformation into a compact learned representation. Unlike\nprevious parametric models, Demeter handles varying shape topology across\nvarious species and models three sources of shape variation: articulation,\nsubcomponent shape variation, and non-rigid deformation. To advance crop plant\nmodeling, we collected a large-scale, ground-truthed dataset from a soybean\nfarm as a testbed. Experiments show that Demeter effectively synthesizes\nshapes, reconstructs structures, and simulates biophysical processes. Code and\ndata is available at https://tianhang-cheng.github.io/Demeter/.", "AI": {"tldr": "Demeter is a parametric 3D plant model that handles varying topology across species and models three types of shape variation: articulation, component shape variation, and deformation.", "motivation": "While powerful 3D parametric models exist for humans and animals, equally expressive approaches for modeling plants are lacking, despite their utility in reconstruction, generation, understanding, and simulation.", "method": "Developed Demeter, a data-driven parametric model that encodes plant morphology factors (topology, shape, articulation, deformation) into a learned representation. Collected large-scale soybean farm dataset for testing.", "result": "Demeter effectively synthesizes shapes, reconstructs structures, and simulates biophysical processes.", "conclusion": "Demeter advances plant modeling by handling varying topology and multiple shape variation sources, with demonstrated effectiveness in various applications."}}
{"id": "2510.16022", "categories": ["cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.16022", "abs": "https://arxiv.org/abs/2510.16022", "authors": ["Changsheng Wang", "Xin Chen", "Sijia Liu", "Ke Ding"], "title": "Breaking Memorization Barriers in LLM Code Fine-Tuning via Information Bottleneck for Improved Generalization", "comment": null, "summary": "Adapting pretrained large language models (LLMs) to code domains via\nsupervised fine-tuning (FT) has been commonly used for code generation.\nHowever, we identify a previously underappreciated failure mode, the\nmemorization barrier, where strong memorization of downstream code data in the\nbase model could trap optimization and prevent the standard FT from effectively\nacquiring new, generalizable code knowledge. To overcome this barrier, we\npropose the information bottleneck (IB)-guided fine-tuning, termed IB-FT, which\napplies an IB penalty on hidden representations of the code data to compress\nspurious, memorized features while preserving task-relevant information.\nExtensive experiments on two code benchmarks (OriGen and Evol-CodeAlpaca-V1)\nshow that IB-FT substantially alleviates the memorization barrier, improves\ntop-1 performance (Pass@$1$), and yields far more stable gains under the\nstricter multi-sample metric Pass@$k^{(m)}$ (a problem counts as solved only if\nat least $m$ of $k$ samples pass unit tests) compared with conventional FT.", "AI": {"tldr": "IB-FT overcomes the memorization barrier in code generation by applying information bottleneck to compress memorized features while preserving task-relevant information.", "motivation": "Standard fine-tuning fails when base models strongly memorize downstream code data, preventing acquisition of new generalizable knowledge.", "method": "Information bottleneck-guided fine-tuning (IB-FT) applies IB penalty on hidden representations to compress spurious memorized features.", "result": "IB-FT substantially alleviates memorization barrier, improves Pass@1 performance, and provides more stable gains under strict multi-sample metrics.", "conclusion": "IB-FT effectively addresses the memorization barrier in code generation fine-tuning, outperforming conventional fine-tuning approaches."}}
{"id": "2510.16614", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16614", "abs": "https://arxiv.org/abs/2510.16614", "authors": ["Xuan Zhang", "Ruixiao Li", "Zhijian Zhou", "Long Li", "Yulei Qin", "Ke Li", "Xing Sun", "Xiaoyu Tan", "Chao Qu", "Yuan Qi"], "title": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "comment": null, "summary": "Reinforcement Learning (RL) has become a compelling way to strengthen the\nmulti step reasoning ability of Large Language Models (LLMs). However,\nprevalent RL paradigms still lean on sparse outcome-based rewards and limited\nexploration, which often drives LLMs toward repetitive and suboptimal reasoning\npatterns. In this paper, we study the central question of how to design\nexploration for LLM reasoning and introduce MERCI (Motivating Exploration in\nLLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that\naugments policy optimization with a principled intrinsic reward. Building on\nthe idea of count-based exploration, MERCI leverages a lightweight Coin\nFlipping Network (CFN) to estimate the pseudo count and further epistemic\nuncertainty over reasoning trajectories, and converts them into an intrinsic\nreward that values novelty while preserving the learning signal from task\nrewards. We integrate MERCI into some advanced RL frameworks like Group\nRelative Policy Optimization (GRPO). Experiments on complex reasoning\nbenchmarks demonstrate that MERCI encourages richer and more varied chains of\nthought, significantly improves performance over strong baselines, and helps\nthe policy escape local routines to discover better solutions. It indicates\nthat our targeted intrinsic motivation can make exploration reliable for\nlanguage model reasoning.", "AI": {"tldr": "MERCI is a novel RL algorithm that uses count-based intrinsic rewards to improve exploration in LLM reasoning, addressing issues of sparse rewards and limited exploration in current RL paradigms.", "motivation": "Current RL approaches for LLM reasoning rely on sparse outcome-based rewards and limited exploration, leading to repetitive and suboptimal reasoning patterns. The paper aims to design better exploration strategies for LLM reasoning.", "method": "MERCI uses a lightweight Coin Flipping Network (CFN) to estimate pseudo count and epistemic uncertainty over reasoning trajectories, converting them into intrinsic rewards that value novelty while preserving task reward signals. It's integrated into advanced RL frameworks like GRPO.", "result": "Experiments on complex reasoning benchmarks show MERCI encourages richer and more varied chains of thought, significantly improves performance over strong baselines, and helps policies escape local routines to discover better solutions.", "conclusion": "Targeted intrinsic motivation through MERCI makes exploration reliable for language model reasoning, demonstrating that principled intrinsic rewards can effectively enhance LLM reasoning capabilities."}}
{"id": "2510.16396", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16396", "abs": "https://arxiv.org/abs/2510.16396", "authors": ["Yeh Keng Hao", "Hsu Tzu Wei", "Sun Min"], "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "comment": "Accepted to AICCC 2025", "summary": "With the increasing ubiquity of AR/VR devices, the deployment of deep\nlearning models on edge devices has become a critical challenge. These devices\nrequire real-time inference, low power consumption, and minimal latency. Many\nframework designers face the conundrum of balancing efficiency and performance.\nWe design a light framework that adopts an encoder-decoder architecture and\nintroduces several key contributions aimed at improving both efficiency and\naccuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the\ninherent sparsity in hand pose images, achieving a 42% end-to-end efficiency\nimprovement. Moreover, we propose our SPLite decoder. This new architecture\nsignificantly boosts the decoding process's frame rate by 3.1x on the Raspberry\nPi 5, while maintaining accuracy on par. To further optimize performance, we\napply quantization-aware training, reducing memory usage while preserving\naccuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on\nFreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5\nCPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on\ncompound benchmark datasets, demonstrating comparable accuracy to\nstate-of-the-art approaches while significantly enhancing computational\nefficiency.", "AI": {"tldr": "A lightweight framework for AR/VR edge devices using encoder-decoder architecture with sparse convolution and SPLite decoder, achieving 42% efficiency improvement and 2.98x speed-up on Raspberry Pi 5 while maintaining accuracy.", "motivation": "Address the challenge of deploying deep learning models on AR/VR edge devices requiring real-time inference, low power consumption, and minimal latency while balancing efficiency and performance.", "method": "Encoder-decoder architecture with sparse convolution on ResNet-18 backbone to exploit sparsity in hand pose images, SPLite decoder for faster processing, and quantization-aware training for memory optimization.", "result": "42% end-to-end efficiency improvement, 3.1x frame rate boost on Raspberry Pi 5, 2.98x overall speed-up, and minimal accuracy loss (PA-MPJPE increased from 9.0mm to 9.1mm on FreiHAND).", "conclusion": "The framework achieves comparable accuracy to state-of-the-art methods while significantly enhancing computational efficiency for AR/VR edge deployment."}}
{"id": "2510.16023", "categories": ["cs.LG", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.16023", "abs": "https://arxiv.org/abs/2510.16023", "authors": ["Fanmeng Wang", "Shan Mei", "Wentao Guo", "Hongshuai Wang", "Qi Ou", "Zhifeng Gao", "Hongteng Xu"], "title": "Unifying Polymer Modeling and Design via a Conformation-Centric Generative Foundation Model", "comment": null, "summary": "Polymers, macromolecules formed from covalently bonded monomers, underpin\ncountless technologies and are indispensable to modern life. While deep\nlearning is advancing polymer science, existing methods typically represent the\nwhole polymer solely through monomer-level descriptors, overlooking the global\nstructural information inherent in polymer conformations, which ultimately\nlimits their practical performance. Moreover, this field still lacks a\nuniversal foundation model that can effectively support diverse downstream\ntasks, thereby severely constraining progress. To address these challenges, we\nintroduce PolyConFM, the first polymer foundation model that unifies polymer\nmodeling and design through conformation-centric generative pretraining.\nRecognizing that each polymer conformation can be decomposed into a sequence of\nlocal conformations (i.e., those of its repeating units), we pretrain PolyConFM\nunder the conditional generation paradigm, reconstructing these local\nconformations via masked autoregressive (MAR) modeling and further generating\ntheir orientation transformations to recover the corresponding polymer\nconformation. Besides, we construct the first high-quality polymer conformation\ndataset via molecular dynamics simulations to mitigate data sparsity, thereby\nenabling conformation-centric pretraining. Experiments demonstrate that\nPolyConFM consistently outperforms representative task-specific methods on\ndiverse downstream tasks, equipping polymer science with a universal and\npowerful tool.", "AI": {"tldr": "PolyConFM is the first polymer foundation model that uses conformation-centric generative pretraining to address limitations in existing polymer deep learning methods that overlook global structural information.", "motivation": "Existing polymer deep learning methods only use monomer-level descriptors and lack global structural information from polymer conformations, limiting performance. There's also no universal foundation model for diverse downstream tasks in polymer science.", "method": "PolyConFM uses conformation-centric generative pretraining by decomposing polymer conformations into sequences of local conformations. It employs masked autoregressive modeling to reconstruct local conformations and generate orientation transformations to recover full polymer conformations. A high-quality polymer conformation dataset was created via molecular dynamics simulations.", "result": "PolyConFM consistently outperforms representative task-specific methods across diverse downstream tasks, demonstrating superior performance.", "conclusion": "PolyConFM provides polymer science with a universal and powerful foundation model that effectively supports diverse downstream applications."}}
{"id": "2510.16658", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.16658", "abs": "https://arxiv.org/abs/2510.16658", "authors": ["Shihao Yang", "Xiying Huang", "Danilo Bernardo", "Jun-En Ding", "Andrew Michael", "Jingmei Yang", "Patrick Kwan", "Ashish Raj", "Feng Liu"], "title": "Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review", "comment": null, "summary": "The advent of large-scale artificial intelligence (AI) models has a\ntransformative effect on neuroscience research, which represents a paradigm\nshift from the traditional computational methods through the facilitation of\nend-to-end learning from raw brain signals and neural data. In this paper, we\nexplore the transformative effects of large-scale AI models on five major\nneuroscience domains: neuroimaging and data processing, brain-computer\ninterfaces and neural decoding, molecular neuroscience and genomic modeling,\nclinical assistance and translational frameworks, and disease-specific\napplications across neurological and psychiatric disorders. These models are\ndemonstrated to address major computational neuroscience challenges, including\nmultimodal neural data integration, spatiotemporal pattern interpretation, and\nthe derivation of translational frameworks for clinical deployment. Moreover,\nthe interaction between neuroscience and AI has become increasingly reciprocal,\nas biologically informed architectural constraints are now incorporated to\ndevelop more interpretable and computationally efficient models. This review\nhighlights both the notable promise of such technologies and key implementation\nconsiderations, with particular emphasis on rigorous evaluation frameworks,\neffective domain knowledge integration, and comprehensive ethical guidelines\nfor clinical use. Finally, a systematic listing of critical neuroscience\ndatasets used to derive and validate large-scale AI models across diverse\nresearch applications is provided.", "AI": {"tldr": "Large-scale AI models are transforming neuroscience by enabling end-to-end learning from neural data across five domains: neuroimaging, brain-computer interfaces, molecular neuroscience, clinical applications, and disease-specific uses.", "motivation": "To address major computational neuroscience challenges including multimodal neural data integration, spatiotemporal pattern interpretation, and developing translational frameworks for clinical deployment.", "method": "Review and exploration of large-scale AI models applied across five neuroscience domains, incorporating biologically informed architectural constraints for more interpretable and efficient models.", "result": "Demonstrated effectiveness in addressing computational neuroscience challenges and facilitating reciprocal interaction between neuroscience and AI development.", "conclusion": "Highlights the promise of large-scale AI models in neuroscience while emphasizing the need for rigorous evaluation, domain knowledge integration, and comprehensive ethical guidelines for clinical use."}}
{"id": "2510.16410", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16410", "abs": "https://arxiv.org/abs/2510.16410", "authors": ["Changyue Shi", "Minghao Chen", "Yiping Mao", "Chuxiao Yang", "Xinyuan Hu", "Jiajun Ding", "Zhou Yu"], "title": "REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting", "comment": null, "summary": "Bridging the gap between complex human instructions and precise 3D object\ngrounding remains a significant challenge in vision and robotics. Existing 3D\nsegmentation methods often struggle to interpret ambiguous, reasoning-based\ninstructions, while 2D vision-language models that excel at such reasoning lack\nintrinsic 3D spatial understanding. In this paper, we introduce REALM, an\ninnovative MLLM-agent framework that enables open-world reasoning-based\nsegmentation without requiring extensive 3D-specific post-training. We perform\nsegmentation directly on 3D Gaussian Splatting representations, capitalizing on\ntheir ability to render photorealistic novel views that are highly suitable for\nMLLM comprehension. As directly feeding one or more rendered views to the MLLM\ncan lead to high sensitivity to viewpoint selection, we propose a novel\nGlobal-to-Local Spatial Grounding strategy. Specifically, multiple global views\nare first fed into the MLLM agent in parallel for coarse-level localization,\naggregating responses to robustly identify the target object. Then, several\nclose-up novel views of the object are synthesized to perform fine-grained\nlocal segmentation, yielding accurate and consistent 3D masks. Extensive\nexperiments show that REALM achieves remarkable performance in interpreting\nboth explicit and implicit instructions across LERF, 3D-OVS, and our newly\nintroduced REALM3D benchmarks. Furthermore, our agent framework seamlessly\nsupports a range of 3D interaction tasks, including object removal,\nreplacement, and style transfer, demonstrating its practical utility and\nversatility. Project page: https://ChangyueShi.github.io/REALM.", "AI": {"tldr": "REALM is a MLLM-agent framework that enables reasoning-based 3D segmentation using 3D Gaussian Splatting representations and a Global-to-Local Spatial Grounding strategy to bridge the gap between complex instructions and precise 3D object grounding.", "motivation": "Existing 3D segmentation methods struggle with ambiguous, reasoning-based instructions, while 2D vision-language models lack intrinsic 3D spatial understanding. There's a need to bridge this gap between complex human instructions and precise 3D object grounding.", "method": "Uses 3D Gaussian Splatting representations to render photorealistic novel views for MLLM comprehension. Proposes Global-to-Local Spatial Grounding: multiple global views for coarse localization, then close-up novel views for fine-grained local segmentation to produce accurate 3D masks.", "result": "Achieves remarkable performance in interpreting both explicit and implicit instructions across LERF, 3D-OVS, and REALM3D benchmarks. Supports various 3D interaction tasks including object removal, replacement, and style transfer.", "conclusion": "REALM demonstrates practical utility and versatility as an agent framework that enables open-world reasoning-based segmentation without extensive 3D-specific post-training, effectively bridging the gap between complex instructions and 3D spatial understanding."}}
{"id": "2510.16026", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16026", "abs": "https://arxiv.org/abs/2510.16026", "authors": ["Marco Barbero-Mota", "Eric V. Strobl", "John M. Still", "William W. Stead", "Thomas A. Lasko"], "title": "A tutorial on discovering and quantifying the effect of latent causal sources of multimodal EHR data", "comment": null, "summary": "We provide an accessible description of a peer-reviewed generalizable causal\nmachine learning pipeline to (i) discover latent causal sources of large-scale\nelectronic health records observations, and (ii) quantify the source causal\neffects on clinical outcomes. We illustrate how imperfect multimodal clinical\ndata can be processed, decomposed into probabilistic independent latent\nsources, and used to train taskspecific causal models from which individual\ncausal effects can be estimated. We summarize the findings of the two\nreal-world applications of the approach to date as a demonstration of its\nversatility and utility for medical discovery at scale.", "AI": {"tldr": "A causal machine learning pipeline for discovering latent causal sources in EHR data and quantifying their effects on clinical outcomes, demonstrated through real-world applications.", "motivation": "To address the challenge of analyzing imperfect multimodal clinical data from electronic health records to uncover causal relationships and enable medical discovery at scale.", "method": "Process imperfect multimodal clinical data, decompose into probabilistic independent latent sources, and train task-specific causal models to estimate individual causal effects.", "result": "Successfully applied in two real-world applications, demonstrating the approach's versatility and utility for medical discovery.", "conclusion": "The pipeline provides an accessible and generalizable method for causal discovery from EHR data, enabling scalable medical research and clinical insights."}}
{"id": "2510.16701", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16701", "abs": "https://arxiv.org/abs/2510.16701", "authors": ["Ni Zhang", "Zhiguang Cao", "Jianan Zhou", "Cong Zhang", "Yew-Soon Ong"], "title": "An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems", "comment": null, "summary": "Complex vehicle routing problems (VRPs) remain a fundamental challenge,\ndemanding substantial expert effort for intent interpretation and algorithm\ndesign. While large language models (LLMs) offer a promising path toward\nautomation, current approaches still rely on external intervention, which\nrestrict autonomy and often lead to execution errors and low solution\nfeasibility. To address these challenges, we propose an Agentic Framework with\nLLMs (AFL) for solving complex vehicle routing problems, achieving full\nautomation from problem instance to solution. AFL directly extracts knowledge\nfrom raw inputs and enables self-contained code generation without handcrafted\nmodules or external solvers. To improve trustworthiness, AFL decomposes the\noverall pipeline into three manageable subtasks and employs four specialized\nagents whose coordinated interactions enforce cross-functional consistency and\nlogical soundness. Extensive experiments on 60 complex VRPs, ranging from\nstandard benchmarks to practical variants, validate the effectiveness and\ngenerality of our framework, showing comparable performance against\nmeticulously designed algorithms. Notably, it substantially outperforms\nexisting LLM-based baselines in both code reliability and solution feasibility,\nachieving rates close to 100% on the evaluated benchmarks.", "AI": {"tldr": "AFL is an agentic framework using LLMs to fully automate complex vehicle routing problems from raw inputs to solutions without external intervention, achieving high code reliability and solution feasibility.", "motivation": "Current LLM approaches for VRPs still require external intervention, leading to execution errors and low solution feasibility. There's a need for full automation while maintaining trustworthiness.", "method": "Proposes AFL framework that decomposes pipeline into three subtasks with four specialized agents. Agents coordinate to enforce consistency and logical soundness, enabling self-contained code generation without handcrafted modules or external solvers.", "result": "Extensive experiments on 60 complex VRPs show comparable performance to meticulously designed algorithms. Substantially outperforms existing LLM baselines with near 100% code reliability and solution feasibility on evaluated benchmarks.", "conclusion": "AFL achieves full automation for complex VRPs with high trustworthiness, demonstrating that LLM-based frameworks can effectively solve complex routing problems without external intervention."}}
{"id": "2510.16416", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16416", "abs": "https://arxiv.org/abs/2510.16416", "authors": ["Xiaojun Guo", "Runyu Zhou", "Yifei Wang", "Qi Zhang", "Chenheng Zhang", "Stefanie Jegelka", "Xiaohan Wang", "Jiajun Chai", "Guojun Yin", "Wei Lin", "Yisen Wang"], "title": "SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning", "comment": null, "summary": "Vision-language models (VLMs) have shown remarkable abilities by integrating\nlarge language models with visual inputs. However, they often fail to utilize\nvisual evidence adequately, either depending on linguistic priors in\nvision-centric tasks or resorting to textual shortcuts during reasoning.\nAlthough reinforcement learning (RL) can align models with desired behaviors,\nits application to VLMs has been hindered by the lack of scalable and reliable\nreward mechanisms. To overcome this challenge, we propose SSL4RL, a novel\nframework that leverages self-supervised learning (SSL) tasks as a source of\nverifiable rewards for RL-based fine-tuning. Our approach reformulates SSL\nobjectives-such as predicting image rotation or reconstructing masked\npatches-into dense, automatic reward signals, eliminating the need for human\npreference data or unreliable AI evaluators. Experiments show that SSL4RL\nsubstantially improves performance on both vision-centric and vision-language\nreasoning benchmarks. Furthermore, through systematic ablations, we identify\nkey factors-such as task difficulty, model scale, and semantic alignment with\nthe target domain-that influence the effectiveness of SSL4RL tasks, offering\nnew design principles for future work. We also demonstrate the framework's\ngenerality by applying it to graph learning, where it yields significant gains.\nSSL4RL establishes a versatile and effective paradigm for aligning multimodal\nmodels using verifiable, self-supervised objectives.", "AI": {"tldr": "SSL4RL is a framework that uses self-supervised learning tasks as verifiable rewards for RL-based fine-tuning of vision-language models, eliminating the need for human preference data.", "motivation": "VLMs often fail to adequately use visual evidence, relying on linguistic priors or textual shortcuts. RL can align models but lacks scalable reward mechanisms.", "method": "Reformulates SSL objectives (predicting image rotation, reconstructing masked patches) into dense, automatic reward signals for RL fine-tuning.", "result": "Substantially improves performance on vision-centric and vision-language reasoning benchmarks. Also works effectively for graph learning.", "conclusion": "SSL4RL establishes a versatile paradigm for aligning multimodal models using verifiable, self-supervised objectives, with identified key factors for effectiveness."}}
{"id": "2510.16035", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16035", "abs": "https://arxiv.org/abs/2510.16035", "authors": ["Yingguang Yang", "Xianghua Zeng", "Qi Wu", "Hao Peng", "Yutong Xia", "Hao Liu", "Bin Chong", "Philip S. Yu"], "title": "RoBCtrl: Attacking GNN-Based Social Bot Detectors via Reinforced Manipulation of Bots Control Interaction", "comment": "27 pages, 10 figures", "summary": "Social networks have become a crucial source of real-time information for\nindividuals. The influence of social bots within these platforms has garnered\nconsiderable attention from researchers, leading to the development of numerous\ndetection technologies. However, the vulnerability and robustness of these\ndetection methods is still underexplored. Existing Graph Neural Network\n(GNN)-based methods cannot be directly applied due to the issues of limited\ncontrol over social agents, the black-box nature of bot detectors, and the\nheterogeneity of bots. To address these challenges, this paper proposes the\nfirst adversarial multi-agent Reinforcement learning framework for social Bot\ncontrol attacks (RoBCtrl) targeting GNN-based social bot detectors.\nSpecifically, we use a diffusion model to generate high-fidelity bot accounts\nby reconstructing existing account data with minor modifications, thereby\nevading detection on social platforms. To the best of our knowledge, this is\nthe first application of diffusion models to mimic the behavior of evolving\nsocial bots effectively. We then employ a Multi-Agent Reinforcement Learning\n(MARL) method to simulate bots adversarial behavior. We categorize social\naccounts based on their influence and budget. Different agents are then\nemployed to control bot accounts across various categories, optimizing the\nattachment strategy through reinforcement learning. Additionally, a\nhierarchical state abstraction based on structural entropy is designed to\naccelerate the reinforcement learning. Extensive experiments on social bot\ndetection datasets demonstrate that our framework can effectively undermine the\nperformance of GNN-based detectors.", "AI": {"tldr": "This paper proposes RoBCtrl, the first adversarial multi-agent reinforcement learning framework for attacking GNN-based social bot detectors using diffusion models and MARL to generate realistic bot accounts and optimize evasion strategies.", "motivation": "Social networks are important real-time information sources, but current GNN-based bot detection methods have underexplored vulnerabilities due to limited control over social agents, black-box nature of detectors, and bot heterogeneity.", "method": "Uses diffusion models to generate high-fidelity bot accounts by reconstructing existing data with minor modifications, then employs Multi-Agent Reinforcement Learning (MARL) to simulate adversarial bot behavior across different account categories based on influence and budget, with hierarchical state abstraction using structural entropy to accelerate learning.", "result": "Extensive experiments on social bot detection datasets show the framework effectively undermines GNN-based detector performance.", "conclusion": "RoBCtrl successfully demonstrates vulnerabilities in current GNN-based social bot detectors through a novel combination of diffusion models and multi-agent reinforcement learning for adversarial attacks."}}
{"id": "2510.16720", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16720", "abs": "https://arxiv.org/abs/2510.16720", "authors": ["Jitao Sang", "Jinlin Xiao", "Jiarun Han", "Jilin Chen", "Xiaoyi Chen", "Shuyu Wei", "Yongjie Sun", "Yuhang Wang"], "title": "Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI", "comment": null, "summary": "The rapid evolution of agentic AI marks a new phase in artificial\nintelligence, where Large Language Models (LLMs) no longer merely respond but\nact, reason, and adapt. This survey traces the paradigm shift in building\nagentic AI: from Pipeline-based systems, where planning, tool use, and memory\nare orchestrated by external logic, to the emerging Model-native paradigm,\nwhere these capabilities are internalized within the model's parameters. We\nfirst position Reinforcement Learning (RL) as the algorithmic engine enabling\nthis paradigm shift. By reframing learning from imitating static data to\noutcome-driven exploration, RL underpins a unified solution of LLM + RL + Task\nacross language, vision and embodied domains. Building on this, the survey\nsystematically reviews how each capability -- Planning, Tool use, and Memory --\nhas evolved from externally scripted modules to end-to-end learned behaviors.\nFurthermore, it examines how this paradigm shift has reshaped major agent\napplications, specifically the Deep Research agent emphasizing long-horizon\nreasoning and the GUI agent emphasizing embodied interaction. We conclude by\ndiscussing the continued internalization of agentic capabilities like\nMulti-agent collaboration and Reflection, alongside the evolving roles of the\nsystem and model layers in future agentic AI. Together, these developments\noutline a coherent trajectory toward model-native agentic AI as an integrated\nlearning and interaction framework, marking the transition from constructing\nsystems that apply intelligence to developing models that grow intelligence\nthrough experience.", "AI": {"tldr": "Survey traces AI evolution from pipeline-based systems to model-native paradigm where planning, tool use, and memory are internalized within models, enabled by RL as the algorithmic engine.", "motivation": "To document the paradigm shift in agentic AI from externally orchestrated systems to models that internally learn capabilities through experience and interaction.", "method": "Systematic review of how planning, tool use, and memory capabilities evolved from scripted modules to end-to-end learned behaviors, examining RL as the enabling engine across language, vision, and embodied domains.", "result": "Identifies a coherent trajectory toward model-native agentic AI as an integrated learning framework, with applications in Deep Research and GUI agents demonstrating the shift.", "conclusion": "Agentic AI is transitioning from constructing systems that apply intelligence to developing models that grow intelligence through experience, with continued internalization of capabilities like multi-agent collaboration and reflection."}}
{"id": "2510.16438", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16438", "abs": "https://arxiv.org/abs/2510.16438", "authors": ["Aidyn Ubingazhibov", "R\u00e9mi Pautrat", "Iago Su\u00e1rez", "Shaohui Liu", "Marc Pollefeys", "Viktor Larsson"], "title": "LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching", "comment": "Accepted at ICCVW 2025", "summary": "Lines and points are complementary local features, whose combination has\nproven effective for applications such as SLAM and Structure-from-Motion. The\nbackbone of these pipelines are the local feature matchers, establishing\ncorrespondences across images. Traditionally, point and line matching have been\ntreated as independent tasks. Recently, GlueStick proposed a GNN-based network\nthat simultaneously operates on points and lines to establish matches. While\nrunning a single joint matching reduced the overall computational complexity,\nthe heavy architecture prevented real-time applications or deployment to edge\ndevices.\n  Inspired by recent progress in point matching, we propose LightGlueStick, a\nlightweight matcher for points and line segments. The key novel component in\nour architecture is the Attentional Line Message Passing (ALMP), which\nexplicitly exposes the connectivity of the lines to the network, allowing for\nefficient communication between nodes. In thorough experiments we show that\nLightGlueStick establishes a new state-of-the-art across different benchmarks.\nThe code is available at https://github.com/aubingazhib/LightGlueStick.", "AI": {"tldr": "LightGlueStick is a lightweight neural network that jointly matches points and line segments in images, achieving state-of-the-art performance while being computationally efficient for real-time applications.", "motivation": "Traditional approaches treat point and line matching as separate tasks, and while GlueStick proposed joint matching, its heavy architecture prevented real-time use. There's a need for efficient joint matching of points and lines.", "method": "Uses Attentional Line Message Passing (ALMP) which explicitly exposes line connectivity to the network, enabling efficient communication between nodes in a lightweight architecture.", "result": "Establishes new state-of-the-art performance across different benchmarks while being computationally efficient enough for real-time applications and edge devices.", "conclusion": "LightGlueStick successfully combines point and line matching in a lightweight architecture that outperforms previous methods and enables practical deployment."}}
{"id": "2510.16039", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16039", "abs": "https://arxiv.org/abs/2510.16039", "authors": ["Xiangyuan Peng", "Xingsi Dong", "Si Wu"], "title": "Vector Quantization in the Brain: Grid-like Codes in World Models", "comment": null, "summary": "We propose Grid-like Code Quantization (GCQ), a brain-inspired method for\ncompressing observation-action sequences into discrete representations using\ngrid-like patterns in attractor dynamics. Unlike conventional vector\nquantization approaches that operate on static inputs, GCQ performs\nspatiotemporal compression through an action-conditioned codebook, where\ncodewords are derived from continuous attractor neural networks and dynamically\nselected based on actions. This enables GCQ to jointly compress space and time,\nserving as a unified world model. The resulting representation supports\nlong-horizon prediction, goal-directed planning, and inverse modeling.\nExperiments across diverse tasks demonstrate GCQ's effectiveness in compact\nencoding and downstream performance. Our work offers both a computational tool\nfor efficient sequence modeling and a theoretical perspective on the formation\nof grid-like codes in neural systems.", "AI": {"tldr": "GCQ is a brain-inspired method that compresses observation-action sequences into discrete representations using grid-like patterns in attractor dynamics, enabling spatiotemporal compression through action-conditioned codebooks.", "motivation": "To develop a more efficient sequence modeling approach that can jointly compress space and time, inspired by grid-like neural patterns in the brain, unlike conventional static vector quantization methods.", "method": "Uses action-conditioned codebook with codewords derived from continuous attractor neural networks, dynamically selecting codewords based on actions to perform spatiotemporal compression.", "result": "GCQ effectively compresses observation-action sequences, supports long-horizon prediction, goal-directed planning, and inverse modeling across diverse tasks, demonstrating compact encoding and strong downstream performance.", "conclusion": "GCQ provides both a computational tool for efficient sequence modeling and theoretical insights into grid-like code formation in neural systems, offering a unified world model approach."}}
{"id": "2510.16724", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16724", "abs": "https://arxiv.org/abs/2510.16724", "authors": ["Minhua Lin", "Zongyu Wu", "Zhichao Xu", "Hui Liu", "Xianfeng Tang", "Qi He", "Charu Aggarwal", "Hui Liu", "Xiang Zhang", "Suhang Wang"], "title": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "comment": "38 pages, 4 figures, 7 tables", "summary": "The advent of large language models (LLMs) has transformed information access\nand reasoning through open-ended natural language interaction. However, LLMs\nremain limited by static knowledge, factual hallucinations, and the inability\nto retrieve real-time or domain-specific information. Retrieval-Augmented\nGeneration (RAG) mitigates these issues by grounding model outputs in external\nevidence, but traditional RAG pipelines are often single turn and heuristic,\nlacking adaptive control over retrieval and reasoning. Recent advances in\nagentic search address these limitations by enabling LLMs to plan, retrieve,\nand reflect through multi-step interaction with search environments. Within\nthis paradigm, reinforcement learning (RL) offers a powerful mechanism for\nadaptive and self-improving search behavior. This survey provides the first\ncomprehensive overview of \\emph{RL-based agentic search}, organizing the\nemerging field along three complementary dimensions: (i) What RL is for\n(functional roles), (ii) How RL is used (optimization strategies), and (iii)\nWhere RL is applied (scope of optimization). We summarize representative\nmethods, evaluation protocols, and applications, and discuss open challenges\nand future directions toward building reliable and scalable RL driven agentic\nsearch systems. We hope this survey will inspire future research on the\nintegration of RL and agentic search. Our repository is available at\nhttps://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.", "AI": {"tldr": "This survey provides a comprehensive overview of RL-based agentic search, organizing the field along three dimensions: functional roles of RL, optimization strategies, and scope of optimization.", "motivation": "Traditional RAG pipelines are single-turn and heuristic, lacking adaptive control over retrieval and reasoning. RL offers a powerful mechanism for adaptive and self-improving search behavior in agentic search systems.", "method": "The survey organizes RL-based agentic search along three dimensions: (i) What RL is for (functional roles), (ii) How RL is used (optimization strategies), and (iii) Where RL is applied (scope of optimization). It summarizes representative methods, evaluation protocols, and applications.", "result": "The survey provides the first comprehensive overview of RL-based agentic search, categorizing emerging methods and approaches in this field.", "conclusion": "The survey discusses open challenges and future directions toward building reliable and scalable RL-driven agentic search systems, aiming to inspire future research on the integration of RL and agentic search."}}
{"id": "2510.16442", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16442", "abs": "https://arxiv.org/abs/2510.16442", "authors": ["Haoran Sun", "Chen Cai", "Huiping Zhuang", "Kong Aik Lee", "Lap-Pui Chau", "Yi Wang"], "title": "EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning", "comment": null, "summary": "The rapid development of deepfake video technology has not only facilitated\nartistic creation but also made it easier to spread misinformation. Traditional\ndeepfake video detection (DVD) methods face issues such as a lack of\ntransparency in their principles and insufficient generalization capabilities\nto cope with evolving forgery techniques. This highlights an urgent need for\ndetectors that can identify forged content and provide verifiable reasoning\nexplanations. This paper proposes the explainable deepfake video detection\n(EDVD) task and designs the EDVD-LLaMA multimodal, a large language model\n(MLLM) reasoning framework, which provides traceable reasoning processes\nalongside accurate detection results and trustworthy explanations. Our approach\nfirst incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT)\nto extract and fuse global and local cross-frame deepfake features, providing\nrich spatio-temporal semantic information input for MLLM reasoning. Second, we\nconstruct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which\nintroduces facial feature data as hard constraints during the reasoning process\nto achieve pixel-level spatio-temporal video localization, suppress\nhallucinated outputs, and enhance the reliability of the chain of thought. In\naddition, we build an Explainable Reasoning FF++ benchmark dataset\n(ER-FF++set), leveraging structured data to annotate videos and ensure quality\ncontrol, thereby supporting dual supervision for reasoning and detection.\nExtensive experiments demonstrate that EDVD-LLaMA achieves outstanding\nperformance and robustness in terms of detection accuracy, explainability, and\nits ability to handle cross-forgery methods and cross-dataset scenarios.\nCompared to previous DVD methods, it provides a more explainable and superior\nsolution. The source code and dataset will be publicly available.", "AI": {"tldr": "Proposes EDVD-LLaMA, an explainable deepfake video detection framework using multimodal LLM reasoning with spatio-temporal feature extraction and fine-grained chain-of-thought mechanisms.", "motivation": "Traditional deepfake detection methods lack transparency and generalization capabilities, creating need for detectors that provide verifiable reasoning explanations alongside detection results.", "method": "Uses Spatio-Temporal Subtle Information Tokenization (ST-SIT) to extract cross-frame deepfake features, and Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) with facial feature constraints for reliable reasoning. Built on ER-FF++ benchmark dataset.", "result": "Achieves outstanding performance and robustness in detection accuracy, explainability, and cross-forgery/cross-dataset scenarios, outperforming previous deepfake detection methods.", "conclusion": "EDVD-LLaMA provides a more explainable and superior solution for deepfake video detection with traceable reasoning processes and trustworthy explanations."}}
{"id": "2510.16045", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16045", "abs": "https://arxiv.org/abs/2510.16045", "authors": ["Mengtao Lv", "Ruiqi Zhu", "Xinyu Wang", "Yun Li"], "title": "AMS-QUANT: Adaptive Mantissa Sharing for Floating-point Quantization", "comment": "12 pages, 6 figures", "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious kinds of tasks, while the billion or even trillion parameters bring\nstorage and efficiency bottlenecks for inference. Quantization, particularly\nfloating-point quantization, is known to be capable of speeding up LLM\ninference by reducing memory footprint and data movement during the inference\nprocess. For the first time, we advance the floating-point quantization\nexploration from integer bitwidths to non-integer bit-widths, namely AMS-Quant,\nto further approach the quantization sweet spot. AMS-Quant incorporates two\nnovel techniques to put it into effect: (1) it proposes Mantissa-bit Sharing,\nwhich groups k quantized weights and lets them share the least significant\nmantissa bit, allowing us to further approach the minimum quantization\nbit-width without accuracy loss. (2) It introduces Adaptive Searching, which\nemploys an offline optimization strategy to minimize the accuracy degradation\nintroduced by sharing. Moreover, AMS-Quant is also prototyped as efficient CUDA\nLinear kernels, which translates memory savings into wall-clock latency\nreduction by reducing memory access. Extensive experiments on large-scale\ndatasets and models show that AMS-Quant can quantize the model to FP-5.33-e2m3\nand FP4.25-e2m2, and significantly speed up the LLM decoding over FP16\ninference (2.8x and 3.2x), with negligible accuracy loss.", "AI": {"tldr": "AMS-Quant introduces non-integer floating-point quantization for LLMs using mantissa-bit sharing and adaptive searching to achieve FP-5.33 and FP4.25 formats, providing 2.8-3.2x speedup over FP16 with minimal accuracy loss.", "motivation": "Large language models have huge parameter sizes that create storage and efficiency bottlenecks for inference. Floating-point quantization can reduce memory footprint and speed up inference, but existing methods use integer bit-widths.", "method": "Two novel techniques: (1) Mantissa-bit Sharing - groups weights to share least significant mantissa bits, enabling non-integer bit-widths; (2) Adaptive Searching - offline optimization to minimize accuracy degradation from sharing. Also implements efficient CUDA kernels to translate memory savings into latency reduction.", "result": "Successfully quantizes models to FP-5.33-e2m3 and FP4.25-e2m2 formats, achieving 2.8x and 3.2x speedup over FP16 inference respectively on large-scale datasets and models, with negligible accuracy loss.", "conclusion": "AMS-Quant advances floating-point quantization to non-integer bit-widths, effectively approaching the quantization sweet spot while maintaining model accuracy and significantly accelerating LLM inference."}}
{"id": "2510.16742", "categories": ["cs.AI", "cs.MA", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16742", "abs": "https://arxiv.org/abs/2510.16742", "authors": ["Paul Saves", "Pramudita Satria Palar", "Muhammad Daffa Robani", "Nicolas Verstaevel", "Moncef Garouani", "Julien Aligon", "Benoit Gaudou", "Koji Shimoyama", "Joseph Morlier"], "title": "Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration", "comment": null, "summary": "Complex systems are increasingly explored through simulation-driven\nengineering workflows that combine physics-based and empirical models with\noptimization and analytics. Despite their power, these workflows face two\ncentral obstacles: (1) high computational cost, since accurate exploration\nrequires many expensive simulator runs; and (2) limited transparency and\nreliability when decisions rely on opaque blackbox components. We propose a\nworkflow that addresses both challenges by training lightweight emulators on\ncompact designs of experiments that (i) provide fast, low-latency\napproximations of expensive simulators, (ii) enable rigorous uncertainty\nquantification, and (iii) are adapted for global and local Explainable\nArtificial Intelligence (XAI) analyses. This workflow unifies every\nsimulation-based complex-system analysis tool, ranging from engineering design\nto agent-based models for socio-environmental understanding. In this paper, we\nproposea comparative methodology and practical recommendations for using\nsurrogate-based explainability tools within the proposed workflow. The\nmethodology supports continuous and categorical inputs, combines global-effect\nand uncertainty analyses with local attribution, and evaluates the consistency\nof explanations across surrogate models, thereby diagnosing surrogate adequacy\nand guiding further data collection or model refinement. We demonstrate the\napproach on two contrasting case studies: a multidisciplinary design analysis\nof a hybrid-electric aircraft and an agent-based model of urban segregation.\nResults show that the surrogate model and XAI coupling enables large-scale\nexploration in seconds, uncovers nonlinear interactions and emergent behaviors,\nidentifies key design and policy levers, and signals regions where surrogates\nrequire more data or alternative architectures.", "AI": {"tldr": "The paper proposes a workflow using lightweight emulators trained on compact designs of experiments to address computational cost and transparency issues in simulation-driven engineering workflows, enabling fast approximations, uncertainty quantification, and explainable AI analyses.", "motivation": "Address two main challenges in simulation-driven engineering workflows: (1) high computational cost due to many expensive simulator runs, and (2) limited transparency and reliability when decisions rely on opaque blackbox components.", "method": "Train lightweight emulators on compact designs of experiments that provide fast approximations of expensive simulators, enable rigorous uncertainty quantification, and support global and local Explainable AI (XAI) analyses. Uses surrogate-based explainability tools with comparative methodology supporting continuous and categorical inputs.", "result": "Demonstrated on hybrid-electric aircraft design and urban segregation agent-based model. The approach enables large-scale exploration in seconds, uncovers nonlinear interactions and emergent behaviors, identifies key design and policy levers, and signals regions where surrogates need improvement.", "conclusion": "The surrogate model and XAI coupling provides an effective workflow for complex-system analysis that balances computational efficiency with transparency and reliability, while guiding further data collection or model refinement."}}
{"id": "2510.16051", "categories": ["cs.LG", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.16051", "abs": "https://arxiv.org/abs/2510.16051", "authors": ["Sofiya Garkot", "Maksym Shamrai", "Ivan Synytsia", "Mariya Hirna"], "title": "GUIrilla: A Scalable Framework for Automated Desktop UI Exploration", "comment": "22 pages", "summary": "Autonomous agents capable of operating complex graphical user interfaces\n(GUIs) have the potential to transform desktop automation. While recent\nadvances in large language models (LLMs) have significantly improved UI\nunderstanding, navigating full-window, multi-application desktop environments\nremains a major challenge. Data availability is limited by costly manual\nannotation, closed-source datasets and surface-level synthetic pipelines. We\nintroduce GUIrilla, an automated scalable framework that systematically\nexplores applications via native accessibility APIs to address the critical\ndata collection challenge in GUI automation. Our framework focuses on macOS -\nan ecosystem with limited representation in current UI datasets - though many\nof its components are designed for broader cross-platform applicability.\nGUIrilla organizes discovered interface elements and crawler actions into\nhierarchical GUI graphs and employs specialized interaction handlers to achieve\ncomprehensive application coverage. Using the application graphs from GUIrilla\ncrawler, we construct and release GUIrilla-Task, a large-scale dataset of\n27,171 functionally grounded tasks across 1,108 macOS applications, each\nannotated with full-desktop and window-level screenshots, accessibility\nmetadata, and semantic action traces. Empirical results show that tuning\nLLM-based agents on GUIrilla-Task significantly improves performance on\ndownstream UI tasks, outperforming synthetic baselines on the ScreenSpot Pro\nbenchmark while using 97% less data. We also release macapptree, an open-source\nlibrary for reproducible collection of structured accessibility metadata, along\nwith the full GUIrilla-Task dataset, the manually verified GUIrilla-Gold\nbenchmark, and the framework code to support open research in desktop autonomy.", "AI": {"tldr": "GUIrilla is an automated framework for collecting GUI interaction data via accessibility APIs, creating a large-scale dataset (GUIrilla-Task) that improves LLM-based UI agents' performance with significantly less data.", "motivation": "Address the data scarcity challenge in GUI automation by overcoming limitations of manual annotation, closed-source datasets, and surface-level synthetic pipelines for desktop environments.", "method": "Systematic exploration of macOS applications via native accessibility APIs, organizing interface elements into hierarchical GUI graphs with specialized interaction handlers for comprehensive coverage.", "result": "Created GUIrilla-Task dataset with 27,171 tasks across 1,108 macOS applications, with full annotations. Tuned LLM agents outperformed synthetic baselines on ScreenSpot Pro benchmark using 97% less data.", "conclusion": "GUIrilla provides an effective scalable solution for GUI data collection, enabling improved desktop automation agents and supporting open research through released datasets and tools."}}
{"id": "2510.16753", "categories": ["cs.AI", "68T30", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16753", "abs": "https://arxiv.org/abs/2510.16753", "authors": ["Wei Huang", "Peining Li", "Meiyu Liang", "Xu Hou", "Junping Du", "Yingxia Shao", "Guanhua Ye", "Wu Liu", "Kangkang Lu", "Yang Yu"], "title": "ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion", "comment": "11 pages, 4 figures", "summary": "Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by\nincorporating visual and textual modalities, enabling richer and more\nexpressive entity representations. However, existing MKGs often suffer from\nincompleteness, which hinder their effectiveness in downstream tasks.\nTherefore, multimodal knowledge graph completion (MKGC) task is receiving\nincreasing attention. While large language models (LLMs) have shown promise for\nknowledge graph completion (KGC), their application to the multimodal setting\nremains underexplored. Moreover, applying Multimodal Large Language Models\n(MLLMs) to the task of MKGC introduces significant challenges: (1) the large\nnumber of image tokens per entity leads to semantic noise and modality\nconflicts, and (2) the high computational cost of processing large token\ninputs. To address these issues, we propose Efficient Lightweight Multimodal\nLarge Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token\nCompressor (MVTC) based on multi-head attention mechanism, which adaptively\ncompresses image tokens from both textual and visual views, thereby effectively\nreducing redundancy while retaining necessary information and avoiding modality\nconflicts. Additionally, we design an attention pruning strategy to remove\nredundant attention layers from MLLMs, thereby significantly reducing the\ninference cost. We further introduce a linear projection to compensate for the\nperformance degradation caused by pruning. Extensive experiments on benchmark\nFB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art\nperformance while substantially improving computational efficiency,\nestablishing a new paradigm for multimodal knowledge graph completion.", "AI": {"tldr": "ELMM is a lightweight multimodal LLM approach for multimodal knowledge graph completion that addresses computational efficiency and semantic noise issues through token compression and attention pruning.", "motivation": "Existing multimodal knowledge graphs suffer from incompleteness, and applying multimodal LLMs to completion tasks faces challenges with semantic noise from image tokens and high computational costs.", "method": "Proposes ELMM with Multi-view Visual Token Compressor (MVTC) using multi-head attention to compress image tokens from textual and visual views, plus attention pruning strategy with linear projection to reduce inference cost.", "result": "Extensive experiments on FB15k-237-IMG and WN18-IMG show ELMM achieves state-of-the-art performance while significantly improving computational efficiency.", "conclusion": "ELMM establishes a new paradigm for multimodal knowledge graph completion by effectively balancing performance and efficiency through adaptive token compression and model pruning."}}
{"id": "2510.16445", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16445", "abs": "https://arxiv.org/abs/2510.16445", "authors": ["Chien Thai", "Mai Xuan Trang", "Huong Ninh", "Hoang Hiep Ly", "Anh Son Le"], "title": "Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance", "comment": "Neurocomputing", "summary": "Detecting rotated objects accurately and efficiently is a significant\nchallenge in computer vision, particularly in applications such as aerial\nimagery, remote sensing, and autonomous driving. Although traditional object\ndetection frameworks are effective for axis-aligned objects, they often\nunderperform in scenarios involving rotated objects due to their limitations in\ncapturing orientation variations. This paper introduces an improved loss\nfunction aimed at enhancing detection accuracy and robustness by leveraging the\nGaussian bounding box representation and Bhattacharyya distance. In addition,\nwe advocate for the use of an anisotropic Gaussian representation to address\nthe issues associated with isotropic variance in square-like objects. Our\nproposed method addresses these challenges by incorporating a\nrotation-invariant loss function that effectively captures the geometric\nproperties of rotated objects. We integrate this proposed loss function into\nstate-of-the-art deep learning-based rotated object detection detectors, and\nextensive experiments demonstrated significant improvements in mean Average\nPrecision metrics compared to existing methods. The results highlight the\npotential of our approach to establish new benchmark in rotated object\ndetection, with implications for a wide range of applications requiring precise\nand reliable object localization irrespective of orientation.", "AI": {"tldr": "This paper proposes an improved loss function using Gaussian bounding box representation and Bhattacharyya distance to enhance rotated object detection accuracy, particularly addressing orientation variations in applications like aerial imagery and autonomous driving.", "motivation": "Traditional object detection frameworks perform poorly on rotated objects due to their inability to capture orientation variations, creating challenges in applications such as aerial imagery, remote sensing, and autonomous driving where objects appear at various angles.", "method": "The authors introduce a rotation-invariant loss function based on Gaussian bounding box representation and Bhattacharyya distance, using anisotropic Gaussian representation to handle square-like objects and address isotropic variance issues.", "result": "Extensive experiments show significant improvements in mean Average Precision metrics when integrating the proposed loss function into state-of-the-art deep learning-based rotated object detectors compared to existing methods.", "conclusion": "The proposed approach demonstrates potential to establish new benchmarks in rotated object detection, offering precise and reliable object localization regardless of orientation for various applications."}}
{"id": "2510.16053", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16053", "abs": "https://arxiv.org/abs/2510.16053", "authors": ["Chenyang Yu", "Xinpeng Xie", "Yan Huang", "Chenxi Qiu"], "title": "FUSE-Traffic: Fusion of Unstructured and Structured Data for Event-aware Traffic Forecasting", "comment": null, "summary": "Accurate traffic forecasting is a core technology for building Intelligent\nTransportation Systems (ITS), enabling better urban resource allocation and\nimproved travel experiences. With growing urbanization, traffic congestion has\nintensified, highlighting the need for reliable and responsive forecasting\nmodels. In recent years, deep learning, particularly Graph Neural Networks\n(GNNs), has emerged as the mainstream paradigm in traffic forecasting. GNNs can\neffectively capture complex spatial dependencies in road network topology and\ndynamic temporal evolution patterns in traffic flow data. Foundational models\nsuch as STGCN and GraphWaveNet, along with more recent developments including\nSTWave and D2STGNN, have achieved impressive performance on standard traffic\ndatasets. These approaches incorporate sophisticated graph convolutional\nstructures and temporal modeling mechanisms, demonstrating particular\neffectiveness in capturing and forecasting traffic patterns characterized by\nperiodic regularities. To address this challenge, researchers have explored\nvarious ways to incorporate event information. Early attempts primarily relied\non manually engineered event features. For instance, some approaches introduced\nmanually defined incident effect scores or constructed specific subgraphs for\ndifferent event-induced traffic conditions. While these methods somewhat\nenhance responsiveness to specific events, their core drawback lies in a heavy\nreliance on domain experts' prior knowledge, making generalization to diverse\nand complex unknown events difficult, and low-dimensional manual features often\nlead to the loss of rich semantic details.", "AI": {"tldr": "The paper discusses traffic forecasting using Graph Neural Networks (GNNs) to capture spatial dependencies and temporal patterns in traffic data, highlighting limitations of current approaches that rely on manually engineered event features.", "motivation": "Accurate traffic forecasting is essential for Intelligent Transportation Systems to address growing urbanization and traffic congestion, requiring reliable models that can handle complex traffic patterns and events.", "method": "The paper reviews GNN-based approaches like STGCN, GraphWaveNet, STWave, and D2STGNN that use graph convolutional structures and temporal modeling mechanisms. It also discusses limitations of manual event feature engineering methods.", "result": "Current GNN models demonstrate impressive performance on standard datasets, particularly in capturing periodic traffic patterns, but struggle with diverse and complex unknown events due to reliance on manual feature engineering.", "conclusion": "While GNNs have advanced traffic forecasting, there's a need to move beyond manual event feature engineering to better handle diverse and complex traffic events while preserving semantic details."}}
{"id": "2510.16756", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.RO", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.16756", "abs": "https://arxiv.org/abs/2510.16756", "authors": ["Siyin Wang", "Wenyi Yu", "Xianzhao Chen", "Xiaohai Tian", "Jun Zhang", "Lu Lu", "Chao Zhang"], "title": "End-to-end Listen, Look, Speak and Act", "comment": "22 pages, 8 figures", "summary": "Human interaction is inherently multimodal and full-duplex: we listen while\nwatching, speak while acting, and fluidly adapt to turn-taking and\ninterruptions. Realizing these capabilities is essential for building models\nsimulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),\nwhich, to our knowledge, is the first full-duplex, end-to-end model that\nsimultaneously perceives and generates across vision, text, speech, and action\nwithin a single architecture, enabling interaction patterns previously out of\nreach, yielding more natural, human-like behaviors. At its core is a novel\nSA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each\nmodality to specialized experts and fuses them through a unified attention\nbackbone. This provides a generalizable solution for joint multimodal\nperception and concurrent generation, leveraging strong pre-trained components\nwhile enabling efficient modality integration and mitigating modality\ninterference. On speech-interaction and robot-manipulation benchmarks, ELLSA\nmatches modality-specific baselines, while uniquely supporting advanced\nmultimodal and full-duplex behaviors such as dialogue and action turn-taking,\ndefective instruction rejection, speaking-while-acting, context-grounded visual\nquestion answering, and action barge-ins. We contend that ELLSA represents a\nstep toward more natural and general interactive intelligence, contributing to\nthe broader pursuit of artificial general intelligence. All data, code and\nmodel checkpoints will be released upon acceptance.", "AI": {"tldr": "ELLSA is the first full-duplex, end-to-end model that simultaneously perceives and generates across vision, text, speech, and action within a single architecture, enabling natural human-like multimodal interactions.", "motivation": "Human interaction is inherently multimodal and full-duplex, with capabilities like listening while watching, speaking while acting, and fluid turn-taking. Realizing these capabilities is essential for building human-simulating models.", "method": "Uses a novel SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each modality to specialized experts and fuses them through a unified attention backbone, enabling joint multimodal perception and concurrent generation.", "result": "On speech-interaction and robot-manipulation benchmarks, ELLSA matches modality-specific baselines while uniquely supporting advanced multimodal behaviors like dialogue turn-taking, defective instruction rejection, speaking-while-acting, and action barge-ins.", "conclusion": "ELLSA represents a step toward more natural and general interactive intelligence, contributing to the broader pursuit of artificial general intelligence."}}
{"id": "2510.16446", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16446", "abs": "https://arxiv.org/abs/2510.16446", "authors": ["Jaekyun Park", "Hye Won Chung"], "title": "VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion", "comment": "NeurIPS 2025", "summary": "In the era of large-scale foundation models, fully fine-tuning pretrained\nnetworks for each downstream task is often prohibitively resource-intensive.\nPrompt tuning offers a lightweight alternative by introducing tunable prompts\nwhile keeping the backbone frozen. However, existing visual prompt tuning\nmethods often fail to specialize the prompts or enrich the representation\nspace--especially when applied to self-supervised backbones. We show that these\nlimitations become especially pronounced in challenging tasks and data-scarce\nsettings, where effective adaptation is most critical. In this work, we\nintroduce VIPAMIN, a visual prompt initialization strategy that enhances\nadaptation of self-supervised models by (1) aligning prompts with semantically\ninformative regions in the embedding space, and (2) injecting novel\nrepresentational directions beyond the pretrained subspace. Despite its\nsimplicity--requiring only a single forward pass and lightweight\noperations--VIPAMIN consistently improves performance across diverse tasks and\ndataset sizes, setting a new state of the art in visual prompt tuning. Our code\nis available at https://github.com/iamjaekyun/vipamin.", "AI": {"tldr": "VIPAMIN is a visual prompt initialization strategy that enhances adaptation of self-supervised models by aligning prompts with semantically informative regions and injecting novel representational directions beyond the pretrained subspace.", "motivation": "Existing visual prompt tuning methods often fail to specialize prompts or enrich representation space, especially with self-supervised backbones, and these limitations become pronounced in challenging tasks and data-scarce settings where effective adaptation is critical.", "method": "VIPAMIN aligns prompts with semantically informative regions in the embedding space and injects novel representational directions beyond the pretrained subspace, requiring only a single forward pass and lightweight operations.", "result": "VIPAMIN consistently improves performance across diverse tasks and dataset sizes, setting a new state of the art in visual prompt tuning.", "conclusion": "VIPAMIN provides an effective and efficient visual prompt initialization strategy that enhances adaptation of self-supervised models, demonstrating strong performance improvements across various scenarios."}}
{"id": "2510.16060", "categories": ["cs.LG", "cs.AI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16060", "abs": "https://arxiv.org/abs/2510.16060", "authors": ["Coen Adler", "Yuxin Chang", "Felix Draxler", "Samar Abdi", "Padhraic Smyth"], "title": "Beyond Accuracy: Are Time Series Foundation Models Well-Calibrated?", "comment": null, "summary": "The recent development of foundation models for time series data has\ngenerated considerable interest in using such models across a variety of\napplications. Although foundation models achieve state-of-the-art predictive\nperformance, their calibration properties remain relatively underexplored,\ndespite the fact that calibration can be critical for many practical\napplications. In this paper, we investigate the calibration-related properties\nof five recent time series foundation models and two competitive baselines. We\nperform a series of systematic evaluations assessing model calibration (i.e.,\nover- or under-confidence), effects of varying prediction heads, and\ncalibration under long-term autoregressive forecasting. We find that time\nseries foundation models are consistently better calibrated than baseline\nmodels and tend not to be either systematically over- or under-confident, in\ncontrast to the overconfidence often seen in other deep learning models.", "AI": {"tldr": "Time series foundation models show better calibration than baselines and avoid systematic overconfidence issues common in deep learning models.", "motivation": "Foundation models for time series achieve state-of-the-art performance but their calibration properties remain underexplored, despite calibration being critical for practical applications.", "method": "Systematic evaluation of five recent time series foundation models and two competitive baselines, assessing model calibration, effects of varying prediction heads, and calibration under long-term autoregressive forecasting.", "result": "Time series foundation models are consistently better calibrated than baseline models and tend not to be either systematically over- or under-confident.", "conclusion": "Time series foundation models demonstrate superior calibration properties compared to traditional deep learning models, avoiding the overconfidence issues commonly observed in other deep learning approaches."}}
{"id": "2510.16769", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16769", "abs": "https://arxiv.org/abs/2510.16769", "authors": ["Shuo Han", "Yukun Cao", "Zezhong Ding", "Zengyi Gao", "S Kevin Zhou", "Xike Xie"], "title": "See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models", "comment": null, "summary": "Vision-language models (VLMs) have shown promise in graph understanding, but\nremain limited by input-token constraints, facing scalability bottlenecks and\nlacking effective mechanisms to coordinate textual and visual modalities. To\naddress these challenges, we propose GraphVista, a unified framework that\nenhances both scalability and modality coordination in graph understanding. For\nscalability, GraphVista organizes graph information hierarchically into a\nlightweight GraphRAG base, which retrieves only task-relevant textual\ndescriptions and high-resolution visual subgraphs, compressing redundant\ncontext while preserving key reasoning elements. For modality coordination,\nGraphVista introduces a planning agent that routes tasks to the most suitable\nmodality-using the text modality for simple property reasoning and the visual\nmodality for local and structurally complex reasoning grounded in explicit\ntopology. Extensive experiments demonstrate that GraphVista scales to large\ngraphs, up to $200\\times$ larger than those used in existing benchmarks, and\nconsistently outperforms existing textual, visual, and fusion-based methods,\nachieving up to $4.4\\times$ quality improvement over the state-of-the-art\nbaselines by fully exploiting the complementary strengths of both modalities.", "AI": {"tldr": "GraphVista is a unified framework that enhances graph understanding by improving scalability through hierarchical organization and better modality coordination between text and visual inputs.", "motivation": "Current vision-language models face scalability bottlenecks due to input-token constraints and lack effective mechanisms to coordinate textual and visual modalities for graph understanding tasks.", "method": "GraphVista uses hierarchical organization into a lightweight GraphRAG base for scalability, and introduces a planning agent that routes tasks to the most suitable modality - text for simple property reasoning and visual for complex structural reasoning.", "result": "GraphVista scales to graphs 200\u00d7 larger than existing benchmarks and achieves up to 4.4\u00d7 quality improvement over state-of-the-art baselines by fully exploiting complementary strengths of both modalities.", "conclusion": "The proposed framework successfully addresses scalability and modality coordination challenges in graph understanding, demonstrating significant improvements over existing methods across various graph sizes and complexity levels."}}
{"id": "2510.16450", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16450", "abs": "https://arxiv.org/abs/2510.16450", "authors": ["Shan Xiong", "Jiabao Chen", "Ye Wang", "Jialin Peng"], "title": "Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy", "comment": null, "summary": "Annotation-efficient segmentation of the numerous mitochondria instances from\nvarious electron microscopy (EM) images is highly valuable for biological and\nneuroscience research. Although unsupervised domain adaptation (UDA) methods\ncan help mitigate domain shifts and reduce the high costs of annotating each\ndomain, they typically have relatively low performance in practical\napplications. Thus, we investigate weakly supervised domain adaptation (WDA)\nthat utilizes additional sparse point labels on the target domain, which\nrequire minimal annotation effort and minimal expert knowledge. To take full\nuse of the incomplete and imprecise point annotations, we introduce a multitask\nlearning framework that jointly conducts segmentation and center detection with\na novel cross-teaching mechanism and class-focused cross-domain contrastive\nlearning. While leveraging unlabeled image regions is essential, we introduce\nsegmentation self-training with a novel instance-aware pseudo-label (IPL)\nselection strategy. Unlike existing methods that typically rely on pixel-wise\npseudo-label filtering, the IPL semantically selects reliable and diverse\npseudo-labels with the help of the detection task. Comprehensive validations\nand comparisons on challenging datasets demonstrate that our method outperforms\nexisting UDA and WDA methods, significantly narrowing the performance gap with\nthe supervised upper bound. Furthermore, under the UDA setting, our method also\nachieves substantial improvements over other UDA techniques.", "AI": {"tldr": "A weakly supervised domain adaptation method for mitochondria segmentation that uses sparse point labels and a multitask framework with cross-teaching and instance-aware pseudo-label selection to reduce annotation costs while improving performance.", "motivation": "Mitochondria segmentation from EM images requires expensive annotations. Unsupervised domain adaptation methods have low practical performance, so weakly supervised approaches with minimal point annotations are needed to reduce costs while maintaining accuracy.", "method": "Multitask learning framework combining segmentation and center detection with cross-teaching mechanism and class-focused cross-domain contrastive learning. Uses instance-aware pseudo-label selection strategy that semantically selects reliable pseudo-labels using detection task.", "result": "Outperforms existing UDA and WDA methods, significantly narrowing performance gap with supervised upper bound. Also achieves substantial improvements over other UDA techniques in unsupervised setting.", "conclusion": "The proposed weakly supervised domain adaptation approach effectively leverages sparse point annotations to achieve high-performance mitochondria segmentation with minimal annotation effort, making it valuable for biological research."}}
{"id": "2510.16063", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16063", "abs": "https://arxiv.org/abs/2510.16063", "authors": ["Muhy Eddin Za'ter", "Bri-Mathias Hodge"], "title": "Learning a Generalized Model for Substation Level Voltage Estimation in Distribution Networks", "comment": null, "summary": "Accurate voltage estimation in distribution networks is critical for\nreal-time monitoring and increasing the reliability of the grid. As DER\npenetration and distribution level voltage variability increase, robust\ndistribution system state estimation (DSSE) has become more essential to\nmaintain safe and efficient operations. Traditional DSSE techniques, however,\nstruggle with sparse measurements and the scale of modern feeders, limiting\ntheir scalability to large networks. This paper presents a hierarchical graph\nneural network for substation-level voltage estimation that exploits both\nelectrical topology and physical features, while remaining robust to the low\nobservability levels common to real-world distribution networks. Leveraging the\npublic SMART-DS datasets, the model is trained and evaluated on thousands of\nbuses across multiple substations and DER penetration scenarios. Comprehensive\nexperiments demonstrate that the proposed method achieves up to 2 times lower\nRMSE than alternative data-driven models, and maintains high accuracy with as\nlittle as 1\\% measurement coverage. The results highlight the potential of GNNs\nto enable scalable, reproducible, and data-driven voltage monitoring for\ndistribution systems.", "AI": {"tldr": "A hierarchical graph neural network for substation-level voltage estimation that achieves 2x lower RMSE than alternatives and works with only 1% measurement coverage.", "motivation": "Traditional distribution system state estimation struggles with sparse measurements and large network scale, while DER penetration increases voltage variability, making robust voltage estimation essential for grid reliability.", "method": "Hierarchical graph neural network that exploits electrical topology and physical features, trained on SMART-DS datasets across multiple substations and DER penetration scenarios.", "result": "Achieves up to 2 times lower RMSE than alternative data-driven models and maintains high accuracy with only 1% measurement coverage.", "conclusion": "GNNs show potential for enabling scalable, reproducible, and data-driven voltage monitoring in distribution systems."}}
{"id": "2510.16802", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16802", "abs": "https://arxiv.org/abs/2510.16802", "authors": ["Chao Li", "Yuru Wang"], "title": "Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation", "comment": "14 pages", "summary": "Traditional knowledge graphs are constrained by fixed ontologies that\norganize concepts within rigid hierarchical structures. The root cause lies in\ntreating domains as implicit context rather than as explicit, reasoning-level\ncomponents. To overcome these limitations, we propose the Domain-Contextualized\nConcept Graph (CDC), a novel knowledge modeling framework that elevates domains\nto first-class elements of conceptual representation. CDC adopts a C-D-C triple\nstructure - <Concept, Relation@Domain, Concept'> - where domain specifications\nserve as dynamic classification dimensions defined on demand. Grounded in a\ncognitive-linguistic isomorphic mapping principle, CDC operationalizes how\nhumans understand concepts through contextual frames. We formalize more than\ntwenty standardized relation predicates (structural, logical, cross-domain, and\ntemporal) and implement CDC in Prolog for full inference capability. Case\nstudies in education, enterprise knowledge systems, and technical documentation\ndemonstrate that CDC enables context-aware reasoning, cross-domain analogy, and\npersonalized knowledge modeling - capabilities unattainable under traditional\nontology-based frameworks.", "AI": {"tldr": "Proposes Domain-Contextualized Concept Graph (CDC) - a knowledge modeling framework that makes domains explicit first-class elements using C-D-C triples (<Concept, Relation@Domain, Concept'>) to overcome rigid hierarchical limitations of traditional knowledge graphs.", "motivation": "Traditional knowledge graphs are constrained by fixed ontologies with rigid hierarchical structures, treating domains as implicit context rather than explicit reasoning-level components.", "method": "CDC uses C-D-C triple structure with domain specifications as dynamic classification dimensions, grounded in cognitive-linguistic isomorphic mapping principle. Formalizes 20+ standardized relation predicates and implements in Prolog for full inference.", "result": "Case studies in education, enterprise systems, and technical documentation show CDC enables context-aware reasoning, cross-domain analogy, and personalized knowledge modeling - capabilities unattainable with traditional ontology frameworks.", "conclusion": "CDC overcomes limitations of traditional knowledge graphs by elevating domains to first-class elements, enabling dynamic, context-aware reasoning and knowledge modeling."}}
{"id": "2510.16457", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16457", "abs": "https://arxiv.org/abs/2510.16457", "authors": ["Peiran Xu", "Xicheng Gong", "Yadong MU"], "title": "NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation", "comment": "ICCV 2025", "summary": "In this work we concentrate on the task of goal-oriented Vision-and-Language\nNavigation (VLN). Existing methods often make decisions based on historical\ninformation, overlooking the future implications and long-term outcomes of the\nactions. In contrast, we aim to develop a foresighted agent. Specifically, we\ndraw upon Q-learning to train a Q-model using large-scale unlabeled trajectory\ndata, in order to learn the general knowledge regarding the layout and object\nrelations within indoor scenes. This model can generate a Q-feature, analogous\nto the Q-value in traditional Q-network, for each candidate action, which\ndescribes the potential future information that may be observed after taking\nthe specific action. Subsequently, a cross-modal future encoder integrates the\ntask-agnostic Q-feature with navigation instructions to produce a set of action\nscores reflecting future prospects. These scores, when combined with the\noriginal scores based on history, facilitate an A*-style searching strategy to\neffectively explore the regions that are more likely to lead to the\ndestination. Extensive experiments conducted on widely used goal-oriented VLN\ndatasets validate the effectiveness of the proposed method.", "AI": {"tldr": "Proposes a foresighted VLN agent using Q-learning to predict future outcomes, integrating task-agnostic Q-features with navigation instructions for improved path planning.", "motivation": "Existing VLN methods focus on historical information but overlook future implications and long-term outcomes of actions, limiting navigation performance.", "method": "Trains Q-model with unlabeled trajectory data to generate Q-features for candidate actions, then uses cross-modal future encoder to combine Q-features with instructions for A*-style search strategy.", "result": "Extensive experiments on goal-oriented VLN datasets validate the method's effectiveness in improving navigation performance.", "conclusion": "The proposed foresighted agent successfully addresses the limitation of historical-only approaches by incorporating future-aware planning through Q-learning and cross-modal integration."}}
{"id": "2510.16064", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.16064", "abs": "https://arxiv.org/abs/2510.16064", "authors": ["Muhy Eddin Za'ter", "Bri-Mathias Hodge", "Kyri Baker"], "title": "Residual Correction Models for AC Optimal Power Flow Using DC Optimal Power Flow Solutions", "comment": null, "summary": "Solving the nonlinear AC optimal power flow (AC OPF) problem remains a major\ncomputational bottleneck for real-time grid operations. In this paper, we\npropose a residual learning paradigm that uses fast DC optimal power flow (DC\nOPF) solutions as a baseline, and learns only the nonlinear corrections\nrequired to provide the full AC-OPF solution. The method utilizes a\ntopology-aware Graph Neural Network with local attention and two-level DC\nfeature integration, trained using a physics-informed loss that enforces AC\npower-flow feasibility and operational limits. Evaluations on OPFData for 57-,\n118-, and 2000-bus systems show around 25% lower MSE, up to 3X reduction in\nfeasibility error, and up to 13X runtime speedup compared to conventional AC\nOPF solvers. The model maintains accuracy under N-1 contingencies and scales\nefficiently to large networks. These results demonstrate that residual learning\nis a practical and scalable bridge between linear approximations and\nAC-feasible OPF, enabling near real-time operational decision making.", "AI": {"tldr": "Residual learning approach using DC OPF solutions as baseline and learning nonlinear corrections to achieve AC-OPF solutions with improved accuracy and speed.", "motivation": "The nonlinear AC optimal power flow problem is a major computational bottleneck for real-time grid operations, requiring faster and more efficient solutions.", "method": "Uses topology-aware Graph Neural Network with local attention and two-level DC feature integration, trained with physics-informed loss to enforce AC power-flow feasibility and operational limits.", "result": "25% lower MSE, up to 3X reduction in feasibility error, and up to 13X runtime speedup compared to conventional AC OPF solvers, with maintained accuracy under N-1 contingencies.", "conclusion": "Residual learning provides a practical and scalable bridge between linear approximations and AC-feasible OPF, enabling near real-time operational decision making."}}
{"id": "2510.16872", "categories": ["cs.AI", "cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2510.16872", "abs": "https://arxiv.org/abs/2510.16872", "authors": ["Shaolei Zhang", "Ju Fan", "Meihao Fan", "Guoliang Li", "Xiaoyong Du"], "title": "DeepAnalyze: Agentic Large Language Models for Autonomous Data Science", "comment": "Code: https://github.com/ruc-datalab/DeepAnalyze Model:\n  https://huggingface.co/RUC-DataLab/DeepAnalyze-8B", "summary": "Autonomous data science, from raw data sources to analyst-grade deep research\nreports, has been a long-standing challenge, and is now becoming feasible with\nthe emergence of powerful large language models (LLMs). Recent workflow-based\ndata agents have shown promising results on specific data tasks but remain\nfundamentally limited in achieving fully autonomous data science due to their\nreliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,\nthe first agentic LLM designed for autonomous data science, capable of\nautomatically completing the end-toend pipeline from data sources to\nanalyst-grade deep research reports. To tackle high-complexity data science\ntasks, we propose a curriculum-based agentic training paradigm that emulates\nthe learning trajectory of human data scientists, enabling LLMs to\nprogressively acquire and integrate multiple capabilities in real-world\nenvironments. We also introduce a data-grounded trajectory synthesis framework\nthat constructs high-quality training data. Through agentic training,\nDeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data\nquestion answering and specialized analytical tasks to open-ended data\nresearch. Experiments demonstrate that, with only 8B parameters, DeepAnalyze\noutperforms previous workflow-based agents built on most advanced proprietary\nLLMs. The model, code, and training data of DeepAnalyze are open-sourced,\npaving the way toward autonomous data science.", "AI": {"tldr": "DeepAnalyze-8B is the first agentic LLM for autonomous data science that can complete end-to-end pipelines from data sources to research reports, outperforming workflow-based agents despite having only 8B parameters.", "motivation": "Existing workflow-based data agents are limited by predefined workflows and cannot achieve fully autonomous data science. The emergence of powerful LLMs makes autonomous data science from raw data to research reports feasible.", "method": "Proposed curriculum-based agentic training paradigm that emulates human data scientists' learning trajectory, enabling progressive capability acquisition. Also introduced data-grounded trajectory synthesis framework for constructing high-quality training data.", "result": "DeepAnalyze-8B outperforms previous workflow-based agents built on more advanced proprietary LLMs, demonstrating capability across data question answering, specialized analytical tasks, and open-ended data research.", "conclusion": "DeepAnalyze-8B paves the way toward autonomous data science with its open-sourced model, code, and training data, showing that agentic training enables LLMs to handle complex data science tasks effectively."}}
{"id": "2510.16463", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16463", "abs": "https://arxiv.org/abs/2510.16463", "authors": ["Haocheng Tang", "Ruoke Yan", "Xinhui Yin", "Qi Zhang", "Xinfeng Zhang", "Siwei Ma", "Wen Gao", "Chuanmin Jia"], "title": "HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars", "comment": "ACM International Conference on Multimedia 2025", "summary": "Recent advances in 3D Gaussian Splatting (3DGS) have enabled fast,\nphotorealistic rendering of dynamic 3D scenes, showing strong potential in\nimmersive communication. However, in digital human encoding and transmission,\nthe compression methods based on general 3DGS representations are limited by\nthe lack of human priors, resulting in suboptimal bitrate efficiency and\nreconstruction quality at the decoder side, which hinders their application in\nstreamable 3D avatar systems. We propose HGC-Avatar, a novel Hierarchical\nGaussian Compression framework designed for efficient transmission and\nhigh-quality rendering of dynamic avatars. Our method disentangles the Gaussian\nrepresentation into a structural layer, which maps poses to Gaussians via a\nStyleUNet-based generator, and a motion layer, which leverages the SMPL-X model\nto represent temporal pose variations compactly and semantically. This\nhierarchical design supports layer-wise compression, progressive decoding, and\ncontrollable rendering from diverse pose inputs such as video sequences or\ntext. Since people are most concerned with facial realism, we incorporate a\nfacial attention mechanism during StyleUNet training to preserve identity and\nexpression details under low-bitrate constraints. Experimental results\ndemonstrate that HGC-Avatar provides a streamable solution for rapid 3D avatar\nrendering, while significantly outperforming prior methods in both visual\nquality and compression efficiency.", "AI": {"tldr": "HGC-Avatar is a hierarchical Gaussian compression framework for efficient transmission and high-quality rendering of dynamic avatars, using disentangled structural and motion layers with facial attention for improved realism under low-bitrate constraints.", "motivation": "Current 3D Gaussian Splatting compression methods for digital humans lack human priors, leading to suboptimal bitrate efficiency and reconstruction quality, which hinders their use in streamable 3D avatar systems.", "method": "Disentangles Gaussian representation into structural layer (StyleUNet-based generator mapping poses to Gaussians) and motion layer (SMPL-X model for compact temporal pose variations), with facial attention mechanism during training and layer-wise compression.", "result": "Provides streamable solution for rapid 3D avatar rendering, significantly outperforming prior methods in both visual quality and compression efficiency.", "conclusion": "HGC-Avatar enables efficient transmission and high-quality rendering of dynamic avatars with improved realism under low-bitrate constraints, advancing streamable 3D avatar systems."}}
{"id": "2510.16065", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16065", "abs": "https://arxiv.org/abs/2510.16065", "authors": ["Lunchen Xie", "Zehua He", "Qingjiang Shi"], "title": "FedPURIN: Programmed Update and Reduced INformation for Sparse Personalized Federated Learning", "comment": null, "summary": "Personalized Federated Learning (PFL) has emerged as a critical research\nfrontier addressing data heterogeneity issue across distributed clients. Novel\nmodel architectures and collaboration mechanisms are engineered to accommodate\nstatistical disparities while producing client-specific models. Parameter\ndecoupling represents a promising paradigm for maintaining model performance in\nPFL frameworks. However, the communication efficiency of many existing methods\nremains suboptimal, sustaining substantial communication burdens that impede\npractical deployment. To bridge this gap, we propose Federated Learning with\nProgrammed Update and Reduced INformation (FedPURIN), a novel framework that\nstrategically identifies critical parameters for transmission through an\ninteger programming formulation. This mathematically grounded strategy is\nseamlessly integrated into a sparse aggregation scheme, achieving a significant\ncommunication reduction while preserving the efficacy. Comprehensive\nevaluations on standard image classification benchmarks under varied non-IID\nconditions demonstrate competitive performance relative to state-of-the-art\nmethods, coupled with quantifiable communication reduction through sparse\naggregation. The framework establishes a new paradigm for\ncommunication-efficient PFL, particularly advantageous for edge intelligence\nsystems operating with heterogeneous data sources.", "AI": {"tldr": "FedPURIN is a communication-efficient personalized federated learning framework that uses integer programming to identify critical parameters for transmission, achieving significant communication reduction while maintaining competitive performance.", "motivation": "Address the suboptimal communication efficiency in existing PFL methods that sustain substantial communication burdens, which impedes practical deployment, especially for edge intelligence systems with heterogeneous data.", "method": "Proposes FedPURIN framework that strategically identifies critical parameters for transmission through integer programming formulation, integrated into a sparse aggregation scheme.", "result": "Comprehensive evaluations on standard image classification benchmarks under varied non-IID conditions demonstrate competitive performance relative to state-of-the-art methods with quantifiable communication reduction through sparse aggregation.", "conclusion": "FedPURIN establishes a new paradigm for communication-efficient PFL, particularly advantageous for edge intelligence systems operating with heterogeneous data sources."}}
{"id": "2510.16907", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16907", "abs": "https://arxiv.org/abs/2510.16907", "authors": ["Kangrui Wang", "Pingyue Zhang", "Zihan Wang", "Yaning Gao", "Linjie Li", "Qineng Wang", "Hanyang Chen", "Chi Wan", "Yiping Lu", "Zhengyuan Yang", "Lijuan Wang", "Ranjay Krishna", "Jiajun Wu", "Li Fei-Fei", "Yejin Choi", "Manling Li"], "title": "VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents", "comment": "Accepted to NeurIPS 2025", "summary": "A key challenge in training Vision-Language Model (VLM) agents, compared to\nLanguage Model (LLM) agents, lies in the shift from textual states to complex\nvisual observations. This transition introduces partial observability and\ndemands robust world modeling. We ask: Can VLM agents construct internal world\nmodels through explicit visual state reasoning? To address this question, we\narchitecturally enforce and reward the agent's reasoning process via\nreinforcement learning (RL), formulating it as a Partially Observable Markov\nDecision Process (POMDP). We find that decomposing the agent's reasoning into\nState Estimation (\"what is the current state?\") and Transition Modeling (\"what\ncomes next?\") is critical for success, as demonstrated through five reasoning\nstrategies. Our investigation into how agents represent internal beliefs\nreveals that the optimal representation is task-dependent: Natural Language\nexcels at capturing semantic relationships in general tasks, while Structured\nformats are indispensable for precise manipulation and control. Building on\nthese insights, we design a World Modeling Reward that provides dense,\nturn-level supervision for accurate state prediction, and introduce Bi-Level\nGeneral Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.\nThrough this form of visual state reasoning, a 3B-parameter model achieves a\nscore of 0.82 across five diverse agent benchmarks, representing a 3$\\times$\nimprovement over its untrained counterpart (0.21) and outperforming proprietary\nreasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5\n(0.62). All experiments are conducted within our VAGEN framework, a scalable\nsystem for training and analyzing multi-turn VLM agents in diverse visual\nenvironments. Code and data are publicly available at\nhttps://vagen-ai.github.io.", "AI": {"tldr": "VLM agents achieve 3x performance improvement through explicit visual state reasoning using world modeling rewards and bi-level GAE, outperforming proprietary models like GPT-5.", "motivation": "Address the challenge of partial observability in VLM agents when transitioning from textual to visual observations, requiring robust world modeling capabilities.", "method": "Architecturally enforce reasoning via RL formulated as POMDP, decomposing reasoning into State Estimation and Transition Modeling with five strategies, using World Modeling Reward and Bi-Level GAE.", "result": "3B-parameter model achieves 0.82 score across five benchmarks (3x improvement from 0.21 baseline), outperforming GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5 (0.62).", "conclusion": "Optimal belief representation is task-dependent (Natural Language for semantics, Structured formats for precise control), and explicit visual state reasoning enables effective VLM agent training."}}
{"id": "2510.16505", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16505", "abs": "https://arxiv.org/abs/2510.16505", "authors": ["Lukas Selch", "Yufang Hou", "M. Jehanzeb Mirza", "Sivan Doveh", "James Glass", "Rogerio Feris", "Wei Lin"], "title": "PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies", "comment": null, "summary": "Large Multimodal Models (LMMs) are increasingly applied to scientific\nresearch, yet it remains unclear whether they can reliably understand and\nreason over the multimodal complexity of papers. A central challenge lies in\ndetecting and resolving inconsistencies across text, figures, tables, and\nequations, issues that are often subtle, domain-specific, and ultimately\nundermine clarity, reproducibility, and trust. Existing benchmarks overlook\nthis issue, either isolating single modalities or relying on synthetic errors\nthat fail to capture real-world complexity. We introduce PRISMM-Bench\n(Peer-Review-sourced Inconsistency Set for Multimodal Models), the first\nbenchmark grounded in real reviewer-flagged inconsistencies in scientific\npapers. Through a multi-stage pipeline of review mining, LLM-assisted filtering\nand human verification, we curate 262 inconsistencies from 242 papers. Based on\nthis set, we design three tasks, namely inconsistency identification, remedy\nand pair matching, which assess a model's capacity to detect, correct, and\nreason over inconsistencies across different modalities. Furthermore, to\naddress the notorious problem of choice-only shortcuts in multiple-choice\nevaluation, where models exploit answer patterns without truly understanding\nthe question, we further introduce structured JSON-based answer representations\nthat minimize linguistic biases by reducing reliance on superficial stylistic\ncues. We benchmark 21 leading LMMs, including large open-weight models\n(GLM-4.5V 106B, InternVL3 78B) and proprietary models (Gemini 2.5 Pro, GPT-5\nwith high reasoning). Results reveal strikingly low performance (26.1-54.2%),\nunderscoring the challenge of multimodal scientific reasoning and motivating\nprogress towards trustworthy scientific assistants.", "AI": {"tldr": "PRISMM-Bench is the first benchmark using real reviewer-flagged inconsistencies in scientific papers to evaluate multimodal models' ability to detect and resolve inconsistencies across text, figures, tables, and equations.", "motivation": "Current benchmarks overlook real-world multimodal inconsistencies in scientific papers, which undermine clarity, reproducibility, and trust. Existing approaches either isolate single modalities or use synthetic errors that don't capture real complexity.", "method": "Created PRISMM-Bench through multi-stage pipeline: review mining, LLM-assisted filtering, and human verification to curate 262 inconsistencies from 242 papers. Designed three tasks (inconsistency identification, remedy, pair matching) and introduced structured JSON-based answer representations to minimize linguistic biases.", "result": "Benchmarked 21 leading LMMs including large open-weight and proprietary models. Results showed strikingly low performance (26.1-54.2%), highlighting the challenge of multimodal scientific reasoning.", "conclusion": "Current LMMs struggle significantly with detecting and resolving real-world multimodal inconsistencies in scientific papers, motivating the need for progress towards more trustworthy scientific assistants."}}
{"id": "2510.16071", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16071", "abs": "https://arxiv.org/abs/2510.16071", "authors": ["Qinxuan Wang", "Chuang Wang", "Mingyu Zhang", "Jingwei Sun", "Peipei Yang", "Shuo Tang", "Shiming Xiang"], "title": "MNO: Multiscale Neural Operator for Computational Fluid Dynamics with 3D Point Cloud Data", "comment": null, "summary": "Neural operators have emerged as a powerful data-driven paradigm for solving\nPartial Differential Equations (PDEs), offering orders-of-magnitude\nacceleration over traditional solvers. However, existing approaches still\nsuffer from limited accuracy and scalability, particularly on irregular domains\nwhere fluid flows exhibit rich multiscale structures. In this work, we\nintroduce the Multiscale Neural Operator (MNO), a new architecture for\nComputational Fluid Dynamics (CFD) on three-dimensional (3D) unstructured point\nclouds. MNO explicitly decomposes information across three scales: a global\ndimension-shrinkage attention module for long-range dependencies, a local graph\nattention module for neighborhood-level interactions, and a micro point-wise\nattention module for fine-grained details. This design preserves multiscale\ninductive biases while remaining computationally efficient. We evaluate MNO on\nfour diverse benchmarks, covering both steady-state and unsteady flow scenarios\nwith up to 300K points. Across all tasks, MNO consistently outperforms\nstate-of-the-art baselines, reducing prediction errors by 5% to 40% and\ndemonstrating improved robustness in challenging 3D CFD problems. Our results\nhighlight the importance of explicit multiscale design for neural operators and\nestablish MNO as a scalable framework for learning complex fluid dynamics on\nirregular domains.", "AI": {"tldr": "MNO is a multiscale neural operator for 3D CFD on unstructured point clouds that decomposes information across global, local, and micro scales using attention modules, achieving superior accuracy and scalability compared to existing methods.", "motivation": "Existing neural operators for PDEs suffer from limited accuracy and scalability on irregular domains where fluid flows exhibit rich multiscale structures, particularly in 3D unstructured settings.", "method": "MNO uses three-scale decomposition: global dimension-shrinkage attention for long-range dependencies, local graph attention for neighborhood interactions, and micro point-wise attention for fine-grained details, preserving multiscale inductive biases while maintaining computational efficiency.", "result": "MNO outperforms state-of-the-art baselines across four diverse benchmarks with up to 300K points, reducing prediction errors by 5% to 40% and demonstrating improved robustness in challenging 3D CFD problems.", "conclusion": "The explicit multiscale design is crucial for neural operators, and MNO establishes itself as a scalable framework for learning complex fluid dynamics on irregular domains."}}
{"id": "2510.16956", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16956", "abs": "https://arxiv.org/abs/2510.16956", "authors": ["Mark Towers", "Yali Du", "Christopher Freeman", "Timothy J. Norman"], "title": "A Comparative User Evaluation of XRL Explanations using Goal Identification", "comment": "Accepted to ECAI 2025 Workshop on Evaluating Explainable AI and\n  Complex Decision-Making, 8 Pages", "summary": "Debugging is a core application of explainable reinforcement learning (XRL)\nalgorithms; however, limited comparative evaluations have been conducted to\nunderstand their relative performance. We propose a novel evaluation\nmethodology to test whether users can identify an agent's goal from an\nexplanation of its decision-making. Utilising the Atari's Ms. Pacman\nenvironment and four XRL algorithms, we find that only one achieved greater\nthan random accuracy for the tested goals and that users were generally\noverconfident in their selections. Further, we find that users' self-reported\nease of identification and understanding for every explanation did not\ncorrelate with their accuracy.", "AI": {"tldr": "The paper evaluates four explainable RL algorithms for debugging by testing if users can identify an agent's goal from explanations, finding only one algorithm performed better than random chance.", "motivation": "Limited comparative evaluations exist for explainable RL algorithms in debugging applications, despite debugging being a core use case.", "method": "Proposed a novel evaluation methodology using Atari's Ms. Pacman environment and four XRL algorithms to test whether users can identify an agent's goal from decision-making explanations.", "result": "Only one XRL algorithm achieved greater than random accuracy for the tested goals. Users were generally overconfident in their selections, and self-reported ease of identification/understanding did not correlate with accuracy.", "conclusion": "Current XRL algorithms have limited effectiveness for debugging tasks, and user confidence metrics may not reflect actual understanding of the explanations."}}
{"id": "2510.16508", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16508", "abs": "https://arxiv.org/abs/2510.16508", "authors": ["Franko \u0160iki\u0107", "Sven Lon\u010dari\u0107"], "title": "OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks", "comment": null, "summary": "Out-of-stock (OOS) detection is a very important retail verification process\nthat aims to infer the unavailability of products in their designated areas on\nthe shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based\nmethod that advances OOS detection through auxiliary learning. In particular,\nwe extend a well-established YOLOv8 object detection architecture with\nadditional convolutional branches to simultaneously detect OOS, segment\nproducts, and estimate scene depth. While OOS detection and product\nsegmentation branches are trained using ground truth data, the depth estimation\nbranch is trained using pseudo-labeled annotations produced by the\nstate-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore,\nsince the aforementioned pseudo-labeled depth estimates display relative depth,\nwe propose an appropriate depth normalization procedure that stabilizes the\ntraining process. The experimental results show that the proposed method\nsurpassed the performance of the SOTA OOS detection methods by 1.8% of the mean\naverage precision (mAP). In addition, ablation studies confirm the\neffectiveness of auxiliary learning and the proposed depth normalization\nprocedure, with the former increasing mAP by 3.7% and the latter by 4.2%.", "AI": {"tldr": "OOS-DSD is a novel deep learning method that improves out-of-stock detection using auxiliary learning with YOLOv8, adding branches for product segmentation and depth estimation.", "motivation": "Out-of-stock detection is crucial for retail verification to identify product unavailability on shelves, requiring more accurate detection methods.", "method": "Extends YOLOv8 with additional convolutional branches for OOS detection, product segmentation, and depth estimation using pseudo-labeled depth data from Depth Anything V2 with proposed depth normalization.", "result": "Outperformed state-of-the-art OOS detection methods by 1.8% mAP, with auxiliary learning increasing mAP by 3.7% and depth normalization by 4.2%.", "conclusion": "The proposed OOS-DSD method successfully advances OOS detection through auxiliary learning and depth normalization, demonstrating significant performance improvements."}}
{"id": "2510.16074", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16074", "abs": "https://arxiv.org/abs/2510.16074", "authors": ["Jing He", "Hua Jiang", "Cheng Li", "Siqian Xin", "Shuzhen Yang"], "title": "Early-stopping for Transformer model training", "comment": null, "summary": "This work introduces a novel theoretical framework grounded in Random Matrix\nTheory (RMT) for analyzing Transformer training dynamics. We focus on the\nunderlying mechanisms that drive performance improvements and derive principled\nearly-stopping criteria. Empirically, we observe that the spectral density of\nthe shallow self-attention matrix V consistently evolves into a heavy-tailed\ndistribution. Utilizing the PL (Power Law) fit to this matrix as a probe, we\ndemarcate training into three stages: structural exploration, heavy-tailed\nstructure stabilization, and convergence saturation. This staging provides\nguidance for preliminary stopping decisions. Crucially, we propose two\nconsistent and validation-free criteria: a quantitative metric for heavy-tailed\ndynamics and a novel spectral signature indicative of convergence. The strong\nalignment between these criteria highlights the utility of RMT for monitoring\nand diagnosing the progression of Transformer model training.", "AI": {"tldr": "A Random Matrix Theory framework for analyzing Transformer training dynamics, identifying three training stages through spectral density evolution and proposing validation-free early-stopping criteria.", "motivation": "To understand the underlying mechanisms driving Transformer performance improvements and derive principled early-stopping criteria without relying on validation data.", "method": "Using Random Matrix Theory to analyze the spectral density of shallow self-attention matrix V, applying Power Law fit to identify training stages, and proposing quantitative metrics for heavy-tailed dynamics and spectral convergence signatures.", "result": "The spectral density consistently evolves into heavy-tailed distribution, revealing three training stages: structural exploration, heavy-tailed structure stabilization, and convergence saturation. The proposed criteria show strong alignment.", "conclusion": "Random Matrix Theory provides effective tools for monitoring and diagnosing Transformer training progression, enabling validation-free early-stopping decisions based on spectral properties."}}
{"id": "2510.16996", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16996", "abs": "https://arxiv.org/abs/2510.16996", "authors": ["Juncheng Dong", "Yang Yang", "Tao Liu", "Yang Wang", "Feng Qi", "Vahid Tarokh", "Kaushik Rangadurai", "Shuang Yang"], "title": "STARK: Strategic Team of Agents for Refining Kernels", "comment": null, "summary": "The efficiency of GPU kernels is central to the progress of modern AI, yet\noptimizing them remains a difficult and labor-intensive task due to complex\ninteractions between memory hierarchies, thread scheduling, and\nhardware-specific characteristics. While recent advances in large language\nmodels (LLMs) provide new opportunities for automated code generation, existing\napproaches largely treat LLMs as single-shot generators or naive refinement\ntools, limiting their effectiveness in navigating the irregular kernel\noptimization landscape. We introduce an LLM agentic framework for GPU kernel\noptimization that systematically explores the design space through multi-agent\ncollaboration, grounded instruction, dynamic context management, and strategic\nsearch. This framework mimics the workflow of expert engineers, enabling LLMs\nto reason about hardware trade-offs, incorporate profiling feedback, and refine\nkernels iteratively. We evaluate our approach on KernelBench, a benchmark for\nLLM-based kernel optimization, and demonstrate substantial improvements over\nbaseline agents: our system produces correct solutions where baselines often\nfail, and achieves kernels with up to 16x faster runtime performance. These\nresults highlight the potential of agentic LLM frameworks to advance fully\nautomated, scalable GPU kernel optimization.", "AI": {"tldr": "An LLM agentic framework for GPU kernel optimization that uses multi-agent collaboration and systematic design space exploration to achieve up to 16x performance improvements over baseline methods.", "motivation": "GPU kernel optimization is difficult and labor-intensive due to complex hardware interactions, and existing LLM approaches are limited as single-shot generators without effective optimization strategies.", "method": "Multi-agent collaboration framework with grounded instruction, dynamic context management, and strategic search that mimics expert engineer workflows, enabling iterative refinement with hardware trade-off reasoning and profiling feedback.", "result": "Achieved substantial improvements on KernelBench benchmark: produces correct solutions where baselines fail, and achieves kernels with up to 16x faster runtime performance.", "conclusion": "Agentic LLM frameworks have strong potential to advance fully automated, scalable GPU kernel optimization by systematically navigating the complex optimization landscape."}}
{"id": "2510.16514", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16514", "abs": "https://arxiv.org/abs/2510.16514", "authors": ["Duygu Sap", "Martin Lotz", "Connor Mattinson"], "title": "Image Categorization and Search via a GAT Autoencoder and Representative Models", "comment": "10 pages, 22 figures, Under review", "summary": "We propose a method for image categorization and retrieval that leverages\ngraphs and a graph attention network (GAT)-based autoencoder. Our approach is\nrepresentative-centric, that is, we execute the categorization and retrieval\nprocess via the representative models we construct for the images and image\ncategories. We utilize a graph where nodes represent images (or their\nrepresentatives) and edges capture similarity relationships. GAT highlights\nimportant features and relationships between images, enabling the autoencoder\nto construct context-aware latent representations that capture the key features\nof each image relative to its neighbors. We obtain category representatives\nfrom these embeddings and categorize a query image by comparing its\nrepresentative to the category representatives. We then retrieve the most\nsimilar image to the query image within its identified category. We demonstrate\nthe effectiveness of our representative-centric approach through experiments\nwith both the GAT autoencoders and standard feature-based techniques.", "AI": {"tldr": "Proposes a representative-centric image categorization and retrieval method using graph attention network (GAT)-based autoencoders to create context-aware latent representations for images and categories.", "motivation": "To develop an effective image categorization and retrieval approach that leverages representative models and captures important relationships between images through graph structures and attention mechanisms.", "method": "Uses a graph where nodes represent images and edges capture similarity relationships. Applies GAT to highlight important features and relationships, enabling autoencoder to construct context-aware latent representations. Obtains category representatives from embeddings and categorizes query images by comparing their representatives to category representatives.", "result": "Demonstrates effectiveness through experiments comparing GAT autoencoders with standard feature-based techniques.", "conclusion": "The representative-centric approach using GAT-based autoencoders provides an effective method for image categorization and retrieval by leveraging graph structures and attention mechanisms to capture key relationships."}}
{"id": "2510.16075", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16075", "abs": "https://arxiv.org/abs/2510.16075", "authors": ["Sergio Mu\u00f1iz Subi\u00f1as", "Manuel L. Gonz\u00e1lez", "Jorge Ruiz G\u00f3mez", "Alejandro Mata Ali", "Jorge Mart\u00ednez Mart\u00edn", "Miguel Franco Hernando", "\u00c1ngel Miguel Garc\u00eda-Vico"], "title": "Optimization of the quantization of dense neural networks from an exact QUBO formulation", "comment": null, "summary": "This work introduces a post-training quantization (PTQ) method for dense\nneural networks via a novel ADAROUND-based QUBO formulation. Using the\nFrobenius distance between the theoretical output and the dequantized output\n(before the activation function) as the objective, an explicit QUBO whose\nbinary variables represent the rounding choice for each weight and bias is\nobtained. Additionally, by exploiting the structure of the coefficient QUBO\nmatrix, the global problem can be exactly decomposed into $n$ independent\nsubproblems of size $f+1$, which can be efficiently solved using some\nheuristics such as simulated annealing. The approach is evaluated on MNIST,\nFashion-MNIST, EMNIST, and CIFAR-10 across integer precisions from int8 to int1\nand compared with a round-to-nearest traditional quantization methodology.", "AI": {"tldr": "A novel PTQ method using ADAROUND-based QUBO formulation for neural network quantization, with efficient decomposition into independent subproblems solvable via heuristics like simulated annealing.", "motivation": "To develop an efficient post-training quantization method that minimizes accuracy loss while reducing computational complexity through mathematical optimization.", "method": "Formulates quantization as a QUBO problem using Frobenius distance between theoretical and dequantized outputs as objective, then decomposes into independent subproblems of size f+1 that can be solved with heuristics like simulated annealing.", "result": "Evaluated on MNIST, Fashion-MNIST, EMNIST, and CIFAR-10 across int8 to int1 precisions, showing improved performance compared to traditional round-to-nearest quantization.", "conclusion": "The proposed ADAROUND-based QUBO formulation with problem decomposition provides an effective and efficient approach for neural network quantization across various precision levels."}}
{"id": "2510.17052", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17052", "abs": "https://arxiv.org/abs/2510.17052", "authors": ["Hassan Hamad", "Yingru Xu", "Liang Zhao", "Wenbo Yan", "Narendra Gyanchandani"], "title": "ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems", "comment": null, "summary": "Tool-augmented large language models (LLMs) are increasingly employed in\nreal-world applications, but tool usage errors still hinder their reliability.\nWe introduce ToolCritic, a diagnostic framework that evaluates and improves LLM\nbehavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight\ndistinct error types specific to tool-calling (e.g., premature invocation,\nargument misalignment, and misinterpretation of tool outputs) and provides\ntargeted feedback to the main LLM. The main LLM, assumed to have strong\nreasoning, task understanding and orchestration capabilities, then revises its\nresponse based on ToolCritic's feedback. We systematically define these error\ncategories and construct a synthetic dataset to train ToolCritic. Experimental\nresults on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic\nimproves tool-calling accuracy by up to 13% over baselines, including zero-shot\nprompting and self-correction techniques. This represents a promising step\ntoward more robust LLM integration with external tools in real-world dialogue\napplications.", "AI": {"tldr": "ToolCritic is a diagnostic framework that detects and corrects tool-calling errors in LLMs through targeted feedback, improving tool-calling accuracy by up to 13% over baselines.", "motivation": "Tool-augmented LLMs are increasingly used in real-world applications, but tool usage errors hinder their reliability, creating a need for systematic error detection and correction mechanisms.", "method": "ToolCritic detects eight distinct tool-calling error types, provides targeted feedback to the main LLM, which then revises its response. The framework uses a synthetic dataset for training and systematic error category definitions.", "result": "Experimental results on the Schema-Guided Dialogue dataset show ToolCritic improves tool-calling accuracy by up to 13% over baselines including zero-shot prompting and self-correction techniques.", "conclusion": "ToolCritic represents a promising step toward more robust LLM integration with external tools in real-world dialogue applications by systematically addressing tool-calling errors."}}
{"id": "2510.16540", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16540", "abs": "https://arxiv.org/abs/2510.16540", "authors": ["Jihoon Kwon", "Kyle Min", "Jy-yong Sohn"], "title": "Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions", "comment": "Accepted at NeurIPS 2025 (poster). This is the camera-ready version", "summary": "Despite recent advances, vision-language models trained with standard\ncontrastive objectives still struggle with compositional reasoning -- the\nability to understand structured relationships between visual and linguistic\nelements. This shortcoming is largely due to the tendency of the text encoder\nto focus on individual words rather than their relations, a limitation\nreinforced by contrastive training that primarily aligns words with visual\nobjects. In this paper, we introduce REconstruction and Alignment of text\nDescriptions (READ), a fine-tuning method designed to enhance compositional\nreasoning by adding two auxiliary objectives to the contrastive learning: (1) a\ntoken-level reconstruction objective, where a frozen pre-trained decoder\nreconstructs alternative captions based on the embedding of the original\ncaption; and (2) a sentence-level alignment objective, which explicitly aligns\nparaphrased sentences in the embedding space. We show that READ-CLIP, a model\nderived by applying the READ method to the pre-trained CLIP model, achieves the\nstate-of-the-art performance across five major compositional reasoning\nbenchmarks, outperforming the strongest conventional fine-tuning baseline by up\nto 4.1%. Furthermore, applying the READ to existing CLIP variants (including\nNegCLIP and FSC-CLIP) also improves performance on these benchmarks.\nQuantitative and qualitative analyses reveal that our proposed objectives --\nreconstruction and alignment -- offer complementary benefits: the former\nencourages the encoder to capture relationships between words within a caption,\nwhile the latter ensures consistent representations for paraphrases expressed\nwith different wording.", "AI": {"tldr": "READ is a fine-tuning method that enhances compositional reasoning in vision-language models by adding token-level reconstruction and sentence-level alignment objectives to contrastive learning, achieving state-of-the-art performance on compositional reasoning benchmarks.", "motivation": "Standard contrastive training causes text encoders to focus on individual words rather than their relations, limiting compositional reasoning abilities in vision-language models.", "method": "READ adds two auxiliary objectives to contrastive learning: (1) token-level reconstruction using a frozen decoder to reconstruct alternative captions, and (2) sentence-level alignment to explicitly align paraphrased sentences in embedding space.", "result": "READ-CLIP achieves state-of-the-art performance across five major compositional reasoning benchmarks, outperforming the strongest baseline by up to 4.1%. The method also improves existing CLIP variants like NegCLIP and FSC-CLIP.", "conclusion": "The reconstruction and alignment objectives provide complementary benefits - reconstruction captures word relationships within captions, while alignment ensures consistent representations for paraphrases with different wording."}}
{"id": "2510.16076", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16076", "abs": "https://arxiv.org/abs/2510.16076", "authors": ["SeongKu Kang", "Jianxun Lian", "Dongha Lee", "Wonbin Kweon", "Sanghwan Jang", "Jaehyun Lee", "Jindong Wang", "Xing Xie", "Hwanjo Yu"], "title": "BPL: Bias-adaptive Preference Distillation Learning for Recommender System", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "Recommender systems suffer from biases that cause the collected feedback to\nincompletely reveal user preference. While debiasing learning has been\nextensively studied, they mostly focused on the specialized (called\ncounterfactual) test environment simulated by random exposure of items,\nsignificantly degrading accuracy in the typical (called factual) test\nenvironment based on actual user-item interactions. In fact, each test\nenvironment highlights the benefit of a different aspect: the counterfactual\ntest emphasizes user satisfaction in the long-terms, while the factual test\nfocuses on predicting subsequent user behaviors on platforms. Therefore, it is\ndesirable to have a model that performs well on both tests rather than only\none. In this work, we introduce a new learning framework, called Bias-adaptive\nPreference distillation Learning (BPL), to gradually uncover user preferences\nwith dual distillation strategies. These distillation strategies are designed\nto drive high performance in both factual and counterfactual test environments.\nEmploying a specialized form of teacher-student distillation from a biased\nmodel, BPL retains accurate preference knowledge aligned with the collected\nfeedback, leading to high performance in the factual test. Furthermore, through\nself-distillation with reliability filtering, BPL iteratively refines its\nknowledge throughout the training process. This enables the model to produce\nmore accurate predictions across a broader range of user-item combinations,\nthereby improving performance in the counterfactual test. Comprehensive\nexperiments validate the effectiveness of BPL in both factual and\ncounterfactual tests. Our implementation is accessible via:\nhttps://github.com/SeongKu-Kang/BPL.", "AI": {"tldr": "BPL is a new learning framework that uses dual distillation strategies to achieve high performance in both factual and counterfactual test environments for recommender systems, addressing biases in user feedback data.", "motivation": "Recommender systems suffer from biases in collected feedback that incompletely reveal user preferences. Existing debiasing methods focus on counterfactual test environments but degrade accuracy in factual test environments, while both environments are important for different aspects of user satisfaction and behavior prediction.", "method": "BPL uses bias-adaptive preference distillation with dual strategies: teacher-student distillation from a biased model to retain accurate preference knowledge for factual tests, and self-distillation with reliability filtering to iteratively refine knowledge for counterfactual tests.", "result": "Comprehensive experiments validate that BPL achieves high performance in both factual and counterfactual test environments, outperforming specialized approaches that only work well in one environment.", "conclusion": "BPL provides an effective framework for recommender systems to perform well in both factual and counterfactual test scenarios through its dual distillation approach, addressing the limitations of existing debiasing methods."}}
{"id": "2510.17064", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17064", "abs": "https://arxiv.org/abs/2510.17064", "authors": ["Rongbin Li", "Wenbo Chen", "Zhao Li", "Rodrigo Munoz-Castaneda", "Jinbo Li", "Neha S. Maurya", "Arnav Solanki", "Huan He", "Hanwen Xing", "Meaghan Ramlakhan", "Zachary Wise", "Zhuhao Wu", "Hua Xu", "Michael Hawrylycz", "W. Jim Zheng"], "title": "A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation", "comment": "22 pages, 6 figures, 2 tables", "summary": "Single-cell RNA sequencing has transformed our ability to identify diverse\ncell types and their transcriptomic signatures. However, annotating these\nsignatures-especially those involving poorly characterized genes-remains a\nmajor challenge. Traditional methods, such as Gene Set Enrichment Analysis\n(GSEA), depend on well-curated annotations and often perform poorly in these\ncontexts. Large Language Models (LLMs) offer a promising alternative but\nstruggle to represent complex biological knowledge within structured\nontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:\nhttps://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that\nintegrates free-text descriptions with ontology labels to enable more accurate\nand robust gene set annotation. By incorporating retrieval-augmented generation\n(RAG), we developed a robust agentic workflow that refines predictions using\nrelevant PubMed literature, reducing hallucinations and enhancing\ninterpretability. Using this workflow, we achieved correct annotations for 77%\nof mouse gene sets among their top predictions. Applying this approach, we\nannotated 5,322 brain cell clusters from the comprehensive mouse brain cell\natlas generated by the BRAIN Initiative Cell Census Network, enabling novel\ninsights into brain cell function by identifying region-specific gene\nco-expression patterns and inferring functional roles of gene ensembles.\nBRAINCELL-AID also identifies Basal Ganglia-related cell types with\nneurologically meaningful descriptions. Hence, we create a valuable resource to\nsupport community-driven cell type annotation.", "AI": {"tldr": "BRAINCELL-AID is a multi-agent AI system that combines free-text descriptions with ontology labels to improve gene set annotation accuracy, achieving 77% correct annotations for mouse gene sets and successfully annotating 5,322 brain cell clusters from the mouse brain cell atlas.", "motivation": "Traditional gene annotation methods like GSEA rely on well-curated annotations and perform poorly with poorly characterized genes. LLMs struggle to represent complex biological knowledge in structured ontologies, creating a need for better annotation approaches.", "method": "Developed BRAINCELL-AID, a multi-agent AI system that integrates free-text descriptions with ontology labels using retrieval-augmented generation (RAG) to refine predictions with relevant PubMed literature, reducing hallucinations and improving interpretability.", "result": "Achieved correct annotations for 77% of mouse gene sets among top predictions. Successfully annotated 5,322 brain cell clusters from the mouse brain cell atlas, identified region-specific gene co-expression patterns, inferred functional roles of gene ensembles, and identified Basal Ganglia-related cell types with neurologically meaningful descriptions.", "conclusion": "BRAINCELL-AID creates a valuable resource for community-driven cell type annotation, enabling novel insights into brain cell function and providing more accurate and robust gene set annotation compared to traditional methods."}}
{"id": "2510.16541", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16541", "abs": "https://arxiv.org/abs/2510.16541", "authors": ["Binyuan Huang", "Yongdong Luo", "Xianda Guo", "Xiawu Zheng", "Zheng Zhu", "Jiahui Pan", "Chengju Zhou"], "title": "Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition", "comment": null, "summary": "Deep learning-based gait recognition has achieved great success in various\napplications. The key to accurate gait recognition lies in considering the\nunique and diverse behavior patterns in different motion regions, especially\nwhen covariates affect visual appearance. However, existing methods typically\nuse predefined regions for temporal modeling, with fixed or equivalent temporal\nscales assigned to different types of regions, which makes it difficult to\nmodel motion regions that change dynamically over time and adapt to their\nspecific patterns. To tackle this problem, we introduce a Region-aware Dynamic\nAggregation and Excitation framework (GaitRDAE) that automatically searches for\nmotion regions, assigns adaptive temporal scales and applies corresponding\nattention. Specifically, the framework includes two core modules: the\nRegion-aware Dynamic Aggregation (RDA) module, which dynamically searches the\noptimal temporal receptive field for each region, and the Region-aware Dynamic\nExcitation (RDE) module, which emphasizes the learning of motion regions\ncontaining more stable behavior patterns while suppressing attention to static\nregions that are more susceptible to covariates. Experimental results show that\nGaitRDAE achieves state-of-the-art performance on several benchmark datasets.", "AI": {"tldr": "GaitRDAE is a novel gait recognition framework that dynamically adapts temporal scales and attention for different motion regions to handle covariate effects.", "motivation": "Existing gait recognition methods use fixed temporal scales for predefined regions, which fails to model dynamically changing motion regions and adapt to their specific patterns affected by covariates.", "method": "Proposes Region-aware Dynamic Aggregation (RDA) module to dynamically search optimal temporal receptive fields for each region, and Region-aware Dynamic Excitation (RDE) module to emphasize motion regions with stable behavior patterns while suppressing static regions affected by covariates.", "result": "GaitRDAE achieves state-of-the-art performance on several benchmark datasets.", "conclusion": "The proposed dynamic region-aware framework effectively handles covariate effects and improves gait recognition accuracy by adapting to changing motion patterns."}}
{"id": "2510.16077", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16077", "abs": "https://arxiv.org/abs/2510.16077", "authors": ["Naeem Paeedeh", "Mahardhika Pratama", "Weiping Ding", "Jimmy Cao", "Wolfgang Mayer", "Ryszard Kowalczyk"], "title": "Continual Knowledge Consolidation LORA for Domain Incremental Learning", "comment": null, "summary": "Domain Incremental Learning (DIL) is a continual learning sub-branch that\naims to address never-ending arrivals of new domains without catastrophic\nforgetting problems. Despite the advent of parameter-efficient fine-tuning\n(PEFT) approaches, existing works create task-specific LoRAs overlooking shared\nknowledge across tasks. Inaccurate selection of task-specific LORAs during\ninference results in significant drops in accuracy, while existing works rely\non linear or prototype-based classifiers, which have suboptimal generalization\npowers. Our paper proposes continual knowledge consolidation low rank\nadaptation (CONEC-LoRA) addressing the DIL problems. CONEC-LoRA is developed\nfrom consolidations between task-shared LORA to extract common knowledge and\ntask-specific LORA to embrace domain-specific knowledge. Unlike existing\napproaches, CONEC-LoRA integrates the concept of a stochastic classifier whose\nparameters are sampled from a distribution, thus enhancing the likelihood of\ncorrect classifications. Last but not least, an auxiliary network is deployed\nto optimally predict the task-specific LoRAs for inferences and implements the\nconcept of a different-depth network structure in which every layer is\nconnected with a local classifier to take advantage of intermediate\nrepresentations. This module integrates the ball-generator loss and\ntransformation module to address the synthetic sample bias problem. Our\nrigorous experiments demonstrate the advantage of CONEC-LoRA over prior arts in\n4 popular benchmark problems with over 5% margins.", "AI": {"tldr": "CONEC-LoRA is a novel approach for Domain Incremental Learning that combines task-shared and task-specific LoRAs with a stochastic classifier and auxiliary network to prevent catastrophic forgetting while improving generalization.", "motivation": "Existing PEFT approaches create task-specific LoRAs but overlook shared knowledge across tasks, and inaccurate LoRA selection during inference causes significant accuracy drops. Current classifiers have suboptimal generalization.", "method": "Proposes CONEC-LoRA with: 1) Consolidated task-shared and task-specific LoRAs, 2) Stochastic classifier with parameters sampled from distributions, 3) Auxiliary network with different-depth structure and local classifiers, 4) Ball-generator loss and transformation module to address synthetic sample bias.", "result": "CONEC-LoRA outperforms prior methods by over 5% margins across 4 popular benchmark problems in Domain Incremental Learning.", "conclusion": "The proposed CONEC-LoRA effectively addresses DIL challenges by consolidating shared and specific knowledge, using stochastic classification, and leveraging intermediate representations through auxiliary networks, demonstrating significant performance improvements."}}
{"id": "2510.17108", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17108", "abs": "https://arxiv.org/abs/2510.17108", "authors": ["Yoonjin Lee", "Munhee Kim", "Hanbi Choi", "Juhyeon Park", "Seungho Lyoo", "Woojin Park"], "title": "Structured Debate Improves Corporate Credit Reasoning in Financial AI", "comment": "18 pages, 4 figures, 2 algorithms, 2 tables, 4 appendices, will be\n  submitted to AAAI-2026 workshop", "summary": "Despite advances in financial AI, the automation of evidence-based reasoning\nremains unresolved in corporate credit assessment, where qualitative\nnon-financial indicators exert decisive influence on loan repayment outcomes\nyet resist formalization. Existing approaches focus predominantly on numerical\nprediction and provide limited support for the interpretive judgments required\nin professional loan evaluation. This study develops and evaluates two\noperational large language model (LLM)-based systems designed to generate\nstructured reasoning from non-financial evidence. The first is a\nnon-adversarial single-agent system (NAS) that produces bidirectional analysis\nthrough a single-pass reasoning pipeline. The second is a debate-based\nmulti-agent system (KPD-MADS) that operationalizes adversarial verification\nthrough a ten-step structured interaction protocol grounded in Karl Popper's\ncritical dialogue framework. Both systems were applied to three real corporate\ncases and evaluated by experienced credit risk professionals. Compared to\nmanual expert reporting, both systems achieved substantial productivity gains\n(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The\nKPD-MADS demonstrated superior reasoning quality, receiving higher median\nratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.\n3.0), and usability (62.5 vs. 52.5). These findings show that structured\nmulti-agent interaction can enhance reasoning rigor and interpretability in\nfinancial AI, advancing scalable and defensible automation in corporate credit\nassessment.", "AI": {"tldr": "This paper develops two LLM-based systems for corporate credit assessment that generate structured reasoning from non-financial evidence, with a debate-based multi-agent system showing superior reasoning quality over a single-agent approach.", "motivation": "Current financial AI focuses on numerical prediction but lacks support for interpretive judgments in loan evaluation, particularly for qualitative non-financial indicators that significantly influence repayment outcomes.", "method": "Developed two LLM-based systems: a non-adversarial single-agent system (NAS) and a debate-based multi-agent system (KPD-MADS) using Karl Popper's critical dialogue framework with a ten-step structured interaction protocol.", "result": "Both systems achieved substantial productivity gains (NAS: 11.55s, KPD-MADS: 91.97s vs human baseline: 1920s). KPD-MADS demonstrated superior reasoning quality with higher ratings in explanatory adequacy (4.0 vs 3.0), practical applicability (4.0 vs 3.0), and usability (62.5 vs 52.5).", "conclusion": "Structured multi-agent interaction enhances reasoning rigor and interpretability in financial AI, advancing scalable and defensible automation in corporate credit assessment."}}
{"id": "2510.16556", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16556", "abs": "https://arxiv.org/abs/2510.16556", "authors": ["Guangyu Lin", "Li Lin", "Christina P. Walker", "Daniel S. Schiff", "Shu Hu"], "title": "Fit for Purpose? Deepfake Detection in the Real World", "comment": null, "summary": "The rapid proliferation of AI-generated content, driven by advances in\ngenerative adversarial networks, diffusion models, and multimodal large\nlanguage models, has made the creation and dissemination of synthetic media\neffortless, heightening the risks of misinformation, particularly political\ndeepfakes that distort truth and undermine trust in political institutions. In\nturn, governments, research institutions, and industry have strongly promoted\ndeepfake detection initiatives as solutions. Yet, most existing models are\ntrained and validated on synthetic, laboratory-controlled datasets, limiting\ntheir generalizability to the kinds of real-world political deepfakes\ncirculating on social platforms that affect the public. In this work, we\nintroduce the first systematic benchmark based on the Political Deepfakes\nIncident Database, a curated collection of real-world political deepfakes\nshared on social media since 2018. Our study includes a systematic evaluation\nof state-of-the-art deepfake detectors across academia, government, and\nindustry. We find that the detectors from academia and government perform\nrelatively poorly. While paid detection tools achieve relatively higher\nperformance than free-access models, all evaluated detectors struggle to\ngeneralize effectively to authentic political deepfakes, and are vulnerable to\nsimple manipulations, especially in the video domain. Results urge the need for\npolitically contextualized deepfake detection frameworks to better safeguard\nthe public in real-world settings.", "AI": {"tldr": "This paper introduces the first systematic benchmark for political deepfake detection using real-world examples from social media, revealing that current detectors perform poorly on authentic political deepfakes and are vulnerable to simple manipulations.", "motivation": "The rapid growth of AI-generated content, especially political deepfakes, poses serious misinformation risks, but existing detection models are trained on synthetic datasets and lack generalizability to real-world political deepfakes circulating on social platforms.", "method": "Created the first systematic benchmark using the Political Deepfakes Incident Database - a curated collection of real-world political deepfakes from social media since 2018, and conducted comprehensive evaluation of state-of-the-art deepfake detectors from academia, government, and industry.", "result": "Academic and government detectors performed relatively poorly, while paid tools achieved higher performance than free-access models. However, all detectors struggled to generalize to authentic political deepfakes and were vulnerable to simple manipulations, especially in video domain.", "conclusion": "There is an urgent need for politically contextualized deepfake detection frameworks to better protect the public from real-world political deepfake threats, as current detection systems are inadequate for authentic political content."}}
{"id": "2510.16083", "categories": ["cs.LG", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16083", "abs": "https://arxiv.org/abs/2510.16083", "authors": ["Jaehan Kim", "Minkyoo Song", "Minjae Seo", "Youngjin Jin", "Seungwon Shin", "Jinwoo Kim"], "title": "PassREfinder-FL: Privacy-Preserving Credential Stuffing Risk Prediction via Graph-Based Federated Learning for Representing Password Reuse between Websites", "comment": "Accepted by Elsevier Expert Systems with Applications", "summary": "Credential stuffing attacks have caused significant harm to online users who\nfrequently reuse passwords across multiple websites. While prior research has\nattempted to detect users with reused passwords or identify malicious login\nattempts, existing methods often compromise usability by restricting password\ncreation or website access, and their reliance on complex account-sharing\nmechanisms hinders real-world deployment. To address these limitations, we\npropose PassREfinder-FL, a novel framework that predicts credential stuffing\nrisks across websites. We introduce the concept of password reuse relations --\ndefined as the likelihood of users reusing passwords between websites -- and\nrepresent them as edges in a website graph. Using graph neural networks (GNNs),\nwe perform a link prediction task to assess credential reuse risk between\nsites. Our approach scales to a large number of arbitrary websites by\nincorporating public website information and linking newly observed websites as\nnodes in the graph. To preserve user privacy, we extend PassREfinder-FL with a\nfederated learning (FL) approach that eliminates the need to share user\nsensitive information across administrators. Evaluation on a real-world dataset\nof 360 million breached accounts from 22,378 websites shows that\nPassREfinder-FL achieves an F1-score of 0.9153 in the FL setting. We further\nvalidate that our FL-based GNN achieves a 4-11% performance improvement over\nother state-of-the-art GNN models through an ablation study. Finally, we\ndemonstrate that the predicted results can be used to quantify password reuse\nlikelihood as actionable risk scores.", "AI": {"tldr": "PassREfinder-FL is a federated learning framework that predicts credential stuffing risks by modeling password reuse relations as edges in a website graph using GNNs, achieving high accuracy while preserving user privacy.", "motivation": "Address limitations of existing credential stuffing detection methods that compromise usability and rely on complex account-sharing mechanisms, while providing a scalable solution that preserves user privacy.", "method": "Proposes password reuse relations as edges in a website graph and uses graph neural networks (GNNs) for link prediction. Extends with federated learning to eliminate need for sharing user sensitive information across administrators.", "result": "Achieves F1-score of 0.9153 in FL setting on real-world dataset of 360 million breached accounts from 22,378 websites. FL-based GNN shows 4-11% performance improvement over other state-of-the-art GNN models.", "conclusion": "The framework successfully predicts credential stuffing risks across websites, provides actionable risk scores for password reuse likelihood, and maintains user privacy through federated learning approach."}}
{"id": "2510.17145", "categories": ["cs.AI", "68T05, 62H30"], "pdf": "https://arxiv.org/pdf/2510.17145", "abs": "https://arxiv.org/abs/2510.17145", "authors": ["Phi-Hung Hoang", "Nam-Thuan Trinh", "Van-Manh Tran", "Thi-Thu-Hong Phan"], "title": "Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion", "comment": "35 pages, 6 figures and 11 tables", "summary": "Accurate assessment of fish freshness remains a major challenge in the food\nindustry, with direct consequences for product quality, market value, and\nconsumer health. Conventional sensory evaluation is inherently subjective,\ninconsistent, and difficult to standardize across contexts, often limited by\nsubtle, species-dependent spoilage cues. To address these limitations, we\npropose a handcrafted feature-based approach that systematically extracts and\nincrementally fuses complementary descriptors, including color statistics,\nhistograms across multiple color spaces, and texture features such as Local\nBinary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish\neye images. Our method captures global chromatic variations from full images\nand localized degradations from ROI segments, fusing each independently to\nevaluate their effectiveness in assessing freshness. Experiments on the\nFreshness of the Fish Eyes (FFE) dataset demonstrate the approach's\neffectiveness: in a standard train-test setting, a LightGBM classifier achieved\n77.56% accuracy, a 14.35% improvement over the previous deep learning baseline\nof 63.21%. With augmented data, an Artificial Neural Network (ANN) reached\n97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results\ndemonstrate that carefully engineered, handcrafted features, when strategically\nprocessed, yield a robust, interpretable, and reliable solution for automated\nfish freshness assessment, providing valuable insights for practical\napplications in food quality monitoring.", "AI": {"tldr": "A handcrafted feature-based approach using color statistics, histograms, and texture features from fish eye images achieves high accuracy in automated fish freshness assessment, significantly outperforming previous deep learning methods.", "motivation": "Conventional sensory evaluation of fish freshness is subjective, inconsistent, and difficult to standardize, with limitations in detecting subtle, species-dependent spoilage cues.", "method": "Systematically extracts and incrementally fuses complementary descriptors including color statistics, histograms across multiple color spaces, and texture features (LBP, GLCM) from fish eye images, capturing both global chromatic variations and localized degradations.", "result": "LightGBM classifier achieved 77.56% accuracy (14.35% improvement over previous baseline) and ANN with augmented data reached 97.16% accuracy (19.86% improvement over prior best) on the FFE dataset.", "conclusion": "Carefully engineered handcrafted features provide a robust, interpretable, and reliable solution for automated fish freshness assessment, offering practical value for food quality monitoring applications."}}
{"id": "2510.16596", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16596", "abs": "https://arxiv.org/abs/2510.16596", "authors": ["Yiyang Huang", "Liang Shi", "Yitian Zhang", "Yi Xu", "Yun Fu"], "title": "SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense", "comment": null, "summary": "Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.\nHowever, object hallucination, where models produce plausible but inaccurate\nobject descriptions, remains a significant challenge. In contrast to previous\nwork focusing on LLM components, this paper is the first to trace LVLM\nhallucinations to visual encoders and identifies three key issues: statistical\nbias, inherent bias, and vulnerability. To address these challenges, we propose\nSHIELD, a training-free framework that mitigates hallucinations through three\nstrategies: re-weighting visual tokens to reduce statistical bias, introducing\nnoise-derived tokens to counter inherent bias, and applying adversarial attacks\nwith contrastive decoding to address vulnerability. Experiments demonstrate\nthat SHIELD effectively mitigates object hallucinations across diverse\nbenchmarks and LVLM families. Moreover, SHIELD achieves strong performance on\nthe general LVLM benchmark, highlighting its broad applicability. Code will be\nreleased.", "AI": {"tldr": "SHIELD is a training-free framework that mitigates object hallucinations in Large Vision-Language Models by addressing three key issues in visual encoders: statistical bias, inherent bias, and vulnerability.", "motivation": "Object hallucination in LVLMs, where models produce plausible but inaccurate object descriptions, remains a significant challenge. Previous work focused on LLM components, but this paper identifies visual encoders as the primary source of hallucinations.", "method": "SHIELD uses three strategies: re-weighting visual tokens to reduce statistical bias, introducing noise-derived tokens to counter inherent bias, and applying adversarial attacks with contrastive decoding to address vulnerability.", "result": "SHIELD effectively mitigates object hallucinations across diverse benchmarks and LVLM families, and achieves strong performance on general LVLM benchmarks, demonstrating broad applicability.", "conclusion": "The proposed SHIELD framework successfully addresses object hallucinations in LVLMs by targeting visual encoder issues, offering a training-free solution with strong performance across various benchmarks."}}
{"id": "2510.16084", "categories": ["cs.LG", "cond-mat.quant-gas", "math-ph", "math.MP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.16084", "abs": "https://arxiv.org/abs/2510.16084", "authors": ["Karol Sajnok", "Micha\u0142 Matuszewski"], "title": "Near-Equilibrium Propagation training in nonlinear wave systems", "comment": "7 figures", "summary": "Backpropagation learning algorithm, the workhorse of modern artificial\nintelligence, is notoriously difficult to implement in physical neural\nnetworks. Equilibrium Propagation (EP) is an alternative with comparable\nefficiency and strong potential for in-situ training. We extend EP learning to\nboth discrete and continuous complex-valued wave systems. In contrast to\nprevious EP implementations, our scheme is valid in the weakly dissipative\nregime, and readily applicable to a wide range of physical settings, even\nwithout well defined nodes, where trainable inter-node connections can be\nreplaced by trainable local potential. We test the method in driven-dissipative\nexciton-polariton condensates governed by generalized Gross-Pitaevskii\ndynamics. Numerical studies on standard benchmarks, including a simple logical\ntask and handwritten-digit recognition, demonstrate stable convergence,\nestablishing a practical route to in-situ learning in physical systems in which\nsystem control is restricted to local parameters.", "AI": {"tldr": "The paper extends Equilibrium Propagation (EP) learning to complex-valued wave systems, enabling in-situ training of physical neural networks without requiring well-defined nodes or trainable inter-node connections.", "motivation": "Backpropagation is difficult to implement in physical neural networks, and EP offers a comparable alternative for in-situ training that can work with various physical systems.", "method": "Extend EP learning to discrete and continuous complex-valued wave systems, valid in weakly dissipative regime, using trainable local potentials instead of inter-node connections. Tested on driven-dissipative exciton-polariton condensates with Gross-Pitaevskii dynamics.", "result": "Numerical studies on logical tasks and handwritten-digit recognition demonstrate stable convergence, showing the method works effectively for physical system training.", "conclusion": "Establishes a practical route to in-situ learning in physical systems where control is restricted to local parameters, applicable to a wide range of physical settings."}}
{"id": "2510.17146", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.17146", "abs": "https://arxiv.org/abs/2510.17146", "authors": ["Subin Lin", "Chuanbo Hua"], "title": "Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation", "comment": "NeurIPS 2025 Workshop of UrbanAI (Oral)", "summary": "Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a\nsubstantial share of global building energy use, making reliable anomaly\ndetection essential for improving efficiency and reducing emissions. Classical\nrule-based approaches offer explainability but lack adaptability, while deep\nlearning methods provide predictive power at the cost of transparency,\nefficiency, and physical plausibility. Recent attempts to use Large Language\nModels (LLMs) for anomaly detection improve interpretability but largely ignore\nthe physical principles that govern HVAC operations. We present PILLM, a\nPhysics-Informed LLM framework that operates within an evolutionary loop to\nautomatically generate, evaluate, and refine anomaly detection rules. Our\napproach introduces physics-informed reflection and crossover operators that\nembed thermodynamic and control-theoretic constraints, enabling rules that are\nboth adaptive and physically grounded. Experiments on the public Building Fault\nDetection dataset show that PILLM achieves state-of-the-art performance while\nproducing diagnostic rules that are interpretable and actionable, advancing\ntrustworthy and deployable AI for smart building systems.", "AI": {"tldr": "PILLM is a Physics-Informed LLM framework that automatically generates, evaluates, and refines HVAC anomaly detection rules using evolutionary algorithms with physics-informed constraints.", "motivation": "HVAC systems consume significant energy globally, but existing anomaly detection methods lack either adaptability (rule-based) or transparency/physical plausibility (deep learning). LLM approaches ignore physical principles governing HVAC operations.", "method": "Uses evolutionary loop with physics-informed reflection and crossover operators that embed thermodynamic and control-theoretic constraints to generate and refine anomaly detection rules.", "result": "Achieves state-of-the-art performance on the Building Fault Detection dataset while producing interpretable and actionable diagnostic rules.", "conclusion": "Advances trustworthy and deployable AI for smart building systems by combining LLM capabilities with physical principles for HVAC anomaly detection."}}
{"id": "2510.16598", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16598", "abs": "https://arxiv.org/abs/2510.16598", "authors": ["Jiaying Zhu", "Yurui Zhu", "Xin Lu", "Wenrui Yan", "Dong Li", "Kunlin Liu", "Xueyang Fu", "Zheng-Jun Zha"], "title": "VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs", "comment": "22 pages, 8 figures", "summary": "Multimodal Large Language Models (MLLMs) encounter significant computational\nand memory bottlenecks from the massive number of visual tokens generated by\nhigh-resolution images or multi-image inputs. Previous token compression\ntechniques are often constrained by heuristic rules that risk discarding\ncritical information. They may suffer from biases, such as attention sinks,\nthat lead to sharp performance drops under aggressive compression ratios. To\naddress these limitations, we reformulate token compression as a lightweight\nplug-and-play framework that reformulates token compression into an end-to-end\nlearnable decision process. To be specific, we propose VisionSelector, a scorer\nmodule decoupled from the MLLM backbone that incorporates a differentiable\nTop-K mechanism and a curriculum annealing strategy to bridge the\ntraining-inference gap, enabling efficient and adaptive token selection various\narbitrary compression rates. Remarkably lightweight with only 12.85M trainable\nparameters, VisionSelector demonstrates generalization across various\ncompression rates and adaptively identifying critical tokens. This leads to\nsuperior performance across all compression budgets, evidenced by preserving\n100% accuracy on MME with 30% retention budget, outperforming prior methods by\n12.14% at 10% retention budget, and doubling prefill speed. Our code is\navailable at https://github.com/JulietChoo/VisionSelector .", "AI": {"tldr": "VisionSelector is a lightweight plug-and-play framework for compressing visual tokens in Multimodal Large Language Models, using a learnable scorer module with differentiable Top-K mechanism to efficiently select critical tokens while maintaining performance.", "motivation": "MLLMs face computational and memory bottlenecks from massive visual tokens in high-resolution images, and existing token compression methods risk discarding critical information due to heuristic rules and attention biases.", "method": "Proposes VisionSelector - a decoupled scorer module with differentiable Top-K mechanism and curriculum annealing strategy for end-to-end learnable token selection, enabling adaptive compression at various rates with only 12.85M parameters.", "result": "Achieves 100% accuracy on MME with 30% retention budget, outperforms prior methods by 12.14% at 10% retention budget, and doubles prefill speed while maintaining performance across all compression budgets.", "conclusion": "VisionSelector provides an efficient and adaptive token compression solution for MLLMs that generalizes well across compression rates and preserves critical information, significantly reducing computational overhead without performance degradation."}}
{"id": "2510.16086", "categories": ["cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.16086", "abs": "https://arxiv.org/abs/2510.16086", "authors": ["Ziyang Liu", "Pengjunfei Chu", "Shuming Dong", "Chen Zhang", "Mingcheng Li", "Jin Wang"], "title": "FSRF: Factorization-guided Semantic Recovery for Incomplete Multimodal Sentiment Analysis", "comment": "6 pages,3 figures", "summary": "In recent years, Multimodal Sentiment Analysis (MSA) has become a research\nhotspot that aims to utilize multimodal data for human sentiment understanding.\nPrevious MSA studies have mainly focused on performing interaction and fusion\non complete multimodal data, ignoring the problem of missing modalities in\nreal-world applications due to occlusion, personal privacy constraints, and\ndevice malfunctions, resulting in low generalizability.\n  To this end, we propose a Factorization-guided Semantic Recovery Framework\n(FSRF) to mitigate the modality missing problem in the MSA task.\n  Specifically, we propose a de-redundant homo-heterogeneous factorization\nmodule that factorizes modality into modality-homogeneous,\nmodality-heterogeneous, and noisy representations and design elaborate\nconstraint paradigms for representation learning.\n  Furthermore, we design a distribution-aligned self-distillation module that\nfully recovers the missing semantics by utilizing bidirectional knowledge\ntransfer.\n  Comprehensive experiments on two datasets indicate that FSRF has a\nsignificant performance advantage over previous methods with uncertain missing\nmodalities.", "AI": {"tldr": "FSRF is a framework that addresses modality missing in multimodal sentiment analysis through factorization and self-distillation techniques.", "motivation": "Previous MSA methods assume complete multimodal data, but real-world scenarios often have missing modalities due to occlusion, privacy constraints, or device failures, leading to poor generalization.", "method": "Uses de-redundant homo-heterogeneous factorization to separate modality representations into homogeneous, heterogeneous, and noisy components, plus distribution-aligned self-distillation for semantic recovery.", "result": "Comprehensive experiments show FSRF significantly outperforms previous methods when dealing with uncertain missing modalities.", "conclusion": "FSRF effectively mitigates the modality missing problem in MSA through factorization-guided semantic recovery and bidirectional knowledge transfer."}}
{"id": "2510.17149", "categories": ["cs.AI", "I.2.11"], "pdf": "https://arxiv.org/pdf/2510.17149", "abs": "https://arxiv.org/abs/2510.17149", "authors": ["Hongyi Du", "Jiaqi Su", "Jisen Li", "Lijie Ding", "Yingxuan Yang", "Peixuan Han", "Xiangru Tang", "Kunlun Zhu", "Jiaxuan You"], "title": "Which LLM Multi-Agent Protocol to Choose?", "comment": "Under review at ICLR 2026.Code and benchmark artifacts:\n  https://github.com/ulab-uiuc/AgentProtocols", "summary": "As large-scale multi-agent systems evolve, the communication protocol layer\nhas become a critical yet under-evaluated factor shaping performance and\nreliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,\netc.), selection is often intuition-driven and lacks standardized guidance. We\nintroduce ProtocolBench, a benchmark that systematically compares agent\nprotocols along four measurable axes: task success, end-to-end latency, message\nor byte overhead, and robustness under failures. On ProtocolBench, protocol\nchoice significantly influences system behavior. In the Streaming Queue\nscenario, overall completion time varies by up to 36.5% across protocols, and\nmean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,\nresilience also differs consistently across protocols. Beyond evaluation, we\npresent ProtocolRouter, a learnable protocol router that selects per-scenario\n(or per-module) protocols from requirement and runtime signals. ProtocolRouter\nreduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol\nbaseline, and achieves scenario-specific gains such as higher success in GAIA.\nWe also release ProtocolRouterBench to standardize protocol evaluation and\nimprove reliability at scale.", "AI": {"tldr": "ProtocolBench is a benchmark for evaluating multi-agent communication protocols, showing significant performance differences across protocols. ProtocolRouter is a learnable router that dynamically selects optimal protocols per scenario, improving recovery time and success rates.", "motivation": "Current protocol selection in multi-agent systems is intuition-driven without standardized evaluation, leading to suboptimal performance and reliability.", "method": "Developed ProtocolBench benchmark with four evaluation axes, and ProtocolRouter - a learnable router that selects protocols based on requirements and runtime signals.", "result": "Protocol choice causes up to 36.5% completion time variation and 3.48s latency differences. ProtocolRouter reduces recovery time by 18.1% and improves success rates in GAIA scenarios.", "conclusion": "Protocol selection significantly impacts system performance, and dynamic protocol routing via ProtocolRouter can substantially improve reliability and efficiency in multi-agent systems."}}
{"id": "2510.16611", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16611", "abs": "https://arxiv.org/abs/2510.16611", "authors": ["Melika Filvantorkaman", "Maral Filvan Torkaman"], "title": "A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications", "comment": "20 pages, 4 figures", "summary": "Medical imaging plays a vital role in modern diagnostics; however,\ninterpreting high-resolution radiological data remains time-consuming and\nsusceptible to variability among clinicians. Traditional image processing\ntechniques often lack the precision, robustness, and speed required for\nreal-time clinical use. To overcome these limitations, this paper introduces a\ndeep learning framework for real-time medical image analysis designed to\nenhance diagnostic accuracy and computational efficiency across multiple\nimaging modalities, including X-ray, CT, and MRI. The proposed system\nintegrates advanced neural network architectures such as U-Net, EfficientNet,\nand Transformer-based models with real-time optimization strategies including\nmodel pruning, quantization, and GPU acceleration. The framework enables\nflexible deployment on edge devices, local servers, and cloud infrastructures,\nensuring seamless interoperability with clinical systems such as PACS and EHR.\nExperimental evaluations on public benchmark datasets demonstrate\nstate-of-the-art performance, achieving classification accuracies above 92%,\nsegmentation Dice scores exceeding 91%, and inference times below 80\nmilliseconds. Furthermore, visual explanation tools such as Grad-CAM and\nsegmentation overlays enhance transparency and clinical interpretability. These\nresults indicate that the proposed framework can substantially accelerate\ndiagnostic workflows, reduce clinician workload, and support trustworthy AI\nintegration in time-critical healthcare environments.", "AI": {"tldr": "A deep learning framework for real-time medical image analysis that combines U-Net, EfficientNet, and Transformer models with optimization techniques to achieve high accuracy and fast inference times for clinical use.", "motivation": "To address the limitations of traditional image processing in medical diagnostics, including time-consuming interpretation, clinician variability, and lack of precision/robustness for real-time clinical applications.", "method": "Integrates U-Net, EfficientNet, and Transformer-based neural network architectures with real-time optimization strategies (model pruning, quantization, GPU acceleration) for flexible deployment on edge devices, local servers, and cloud infrastructures.", "result": "Achieved state-of-the-art performance with classification accuracies above 92%, segmentation Dice scores exceeding 91%, and inference times below 80 milliseconds on public benchmark datasets.", "conclusion": "The framework can substantially accelerate diagnostic workflows, reduce clinician workload, and support trustworthy AI integration in time-critical healthcare environments through enhanced transparency and clinical interpretability."}}
{"id": "2510.16089", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16089", "abs": "https://arxiv.org/abs/2510.16089", "authors": ["William Hoy", "Nurcin Celik"], "title": "STABLE: Gated Continual Learning for Large Language Models", "comment": null, "summary": "Large language models (LLMs) increasingly require mechanisms for continual\nadaptation without full retraining. However, sequential updates can lead to\ncatastrophic forgetting, where new edits degrade previously acquired knowledge.\nThis work presents STABLE, a gated continual self editing framework that\nconstrains forgetting during sequential updates using parameter efficient fine\ntuning via Low Rank Adaptation (LoRA; see arXiv:2106.09685). Each candidate\nedit is evaluated against a stability budget using one of three metrics: (i)\nExact Match (EM) drop, capturing factual accuracy loss; (ii) bits increase,\nreflecting reduced model confidence; and (iii) KL divergence, quantifying\ndistributional drift between the base and adapted models. If a threshold is\nexceeded, the LoRA update is rescaled through a clipping procedure or rejected.\nExperiments on the Qwen-2.5-7B model show that gating effectively mitigates\nforgetting while preserving adaptability. EM based gating achieved the highest\ncumulative performance in short continual learning sequences. Our results show\nthat different gating strategies can achieve comparable distribution shift\n(measured by KL divergence) while producing different accuracy outcomes,\nhighlighting the importance of gating design in continual adaptation. This\napproach offers a principled method for continual model editing, enabling LLMs\nto integrate new knowledge while maintaining reliability. Code:\nhttps://github.com/Bhoy1/STABLE", "AI": {"tldr": "STABLE is a gated continual self-editing framework that uses LoRA-based parameter efficient fine-tuning to prevent catastrophic forgetting during sequential LLM updates, with three gating metrics (EM drop, bits increase, KL divergence) to evaluate and constrain edits.", "motivation": "LLMs need continual adaptation mechanisms without full retraining, but sequential updates cause catastrophic forgetting where new edits degrade previously acquired knowledge.", "method": "Uses gated continual self-editing with LoRA fine-tuning. Each edit is evaluated against stability budget using three metrics: Exact Match drop, bits increase, or KL divergence. Updates exceeding thresholds are rescaled or rejected.", "result": "Experiments on Qwen-2.5-7B show gating effectively mitigates forgetting while preserving adaptability. EM-based gating achieved highest cumulative performance in short continual learning sequences.", "conclusion": "Different gating strategies achieve comparable distribution shift but different accuracy outcomes, highlighting importance of gating design. Provides principled method for continual model editing to integrate new knowledge while maintaining reliability."}}
{"id": "2510.17172", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17172", "abs": "https://arxiv.org/abs/2510.17172", "authors": ["Shun Huang", "Wenlu Xing", "Shijia Geng", "Hailong Wang", "Guangkun Nie", "Gongzheng Tang", "Chenyang He", "Shenda Hong"], "title": "Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients", "comment": null, "summary": "Malignant ventricular arrhythmias (VT/VF) following acute myocardial\ninfarction (AMI) are a major cause of in-hospital death, yet early\nidentification remains a clinical challenge. While traditional risk scores have\nlimited performance, end-to-end deep learning models often lack the\ninterpretability needed for clinical trust. This study aimed to develop a\nhybrid predictive framework that integrates a large-scale electrocardiogram\n(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to\nimprove both accuracy and interpretability. We analyzed 6,634 ECG recordings\nfrom AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder\nmodel was used to extract 150-dimensional diagnostic probability features ,\nwhich were then refined through feature selection to train the XGBoost\nclassifier. Model performance was evaluated using AUC and F1-score , and the\nSHAP method was used for interpretability. The ECGFounder + XGBoost hybrid\nmodel achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC\n0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that\nmodel-identified key features, such as \"premature ventricular complexes\" (risk\npredictor) and \"normal sinus rhythm\" (protective factor), were highly\nconsistent with clinical knowledge. We conclude that this hybrid framework\nprovides a novel paradigm for VT/VF risk prediction by validating the use of\nfoundation model outputs as effective, automated feature engineering for\nbuilding trustworthy, explainable AI-based clinical decision support systems.", "AI": {"tldr": "Hybrid framework combining ECG foundation model with XGBoost classifier improves VT/VF prediction after heart attack, achieving 0.801 AUC while maintaining interpretability through SHAP analysis.", "motivation": "Malignant ventricular arrhythmias (VT/VF) after acute myocardial infarction are major cause of death, but current risk scores have limited performance and deep learning models lack interpretability needed for clinical trust.", "method": "Used ECGFounder foundation model to extract 150-dimensional diagnostic probability features from 6,634 ECG recordings, then applied feature selection and trained XGBoost classifier. Used SHAP for interpretability.", "result": "Hybrid model achieved AUC of 0.801, outperforming KNN (0.677), RNN (0.676), and 1D-CNN (0.720). SHAP revealed clinically meaningful features like premature ventricular complexes (risk) and normal sinus rhythm (protective).", "conclusion": "Hybrid framework validates foundation model outputs as effective automated feature engineering for building trustworthy, explainable AI-based clinical decision support systems."}}
{"id": "2510.16624", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16624", "abs": "https://arxiv.org/abs/2510.16624", "authors": ["Sebastian Mocanu", "Emil Slusanschi", "Marius Leordeanu"], "title": "Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs", "comment": null, "summary": "This paper presents a vision-only autonomous flight system for small UAVs\noperating in controlled indoor environments. The system combines semantic\nsegmentation with monocular depth estimation to enable obstacle avoidance,\nscene exploration, and autonomous safe landing operations without requiring GPS\nor expensive sensors such as LiDAR. A key innovation is an adaptive scale\nfactor algorithm that converts non-metric monocular depth predictions into\naccurate metric distance measurements by leveraging semantic ground plane\ndetection and camera intrinsic parameters, achieving a mean distance error of\n14.4 cm. The approach uses a knowledge distillation framework where a\ncolor-based Support Vector Machine (SVM) teacher generates training data for a\nlightweight U-Net student network (1.6M parameters) capable of real-time\nsemantic segmentation. For more complex environments, the SVM teacher can be\nreplaced with a state-of-the-art segmentation model. Testing was conducted in a\ncontrolled 5x4 meter laboratory environment with eight cardboard obstacles\nsimulating urban structures. Extensive validation across 30 flight tests in a\nreal-world environment and 100 flight tests in a digital-twin environment\ndemonstrates that the combined segmentation and depth approach increases the\ndistance traveled during surveillance and reduces mission time while\nmaintaining 100% success rates. The system is further optimized through\nend-to-end learning, where a compact student neural network learns complete\nflight policies from demonstration data generated by our best-performing\nmethod, achieving an 87.5% autonomous mission success rate. This work advances\npractical vision-based drone navigation in structured environments,\ndemonstrating solutions for metric depth estimation and computational\nefficiency challenges that enable deployment on resource-constrained platforms.", "AI": {"tldr": "Vision-only autonomous flight system for small UAVs using semantic segmentation and monocular depth estimation for obstacle avoidance and safe landing in GPS-denied indoor environments.", "motivation": "Enable autonomous drone navigation without GPS or expensive sensors like LiDAR, addressing the need for cost-effective vision-based solutions for indoor environments.", "method": "Combines semantic segmentation with monocular depth estimation using adaptive scale factor algorithm for metric distance conversion. Uses knowledge distillation with SVM teacher and lightweight U-Net student network for real-time processing.", "result": "Achieved 14.4 cm mean distance error, 100% success rate in 30 real-world and 100 digital-twin flight tests, with increased surveillance distance and reduced mission time. End-to-end learning achieved 87.5% autonomous mission success rate.", "conclusion": "The system advances practical vision-based drone navigation in structured environments, solving metric depth estimation and computational efficiency challenges for resource-constrained platforms."}}
{"id": "2510.16092", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16092", "abs": "https://arxiv.org/abs/2510.16092", "authors": ["Devvrit Khatri", "Pranamya Kulkarni", "Nilesh Gupta", "Yerram Varun", "Liqian Peng", "Jay Yagnik", "Praneeth Netrapalli", "Cho-Jui Hsieh", "Alec Go", "Inderjit S Dhillon", "Aditya Kusupati", "Prateek Jain"], "title": "Compressing Many-Shots in In-Context Learning", "comment": null, "summary": "Large Language Models (LLMs) have been shown to be able to learn different\ntasks without explicit finetuning when given many input-output examples /\ndemonstrations through In-Context Learning (ICL). Increasing the number of\nexamples, called ``shots'', improves downstream task performance but incurs\nhigher memory and computational costs. In this work, we study an approach to\nimprove the memory and computational efficiency of ICL inference by compressing\nthe many-shot prompts. Given many shots comprising t tokens, our goal is to\ngenerate a m soft-token summary, where m < t. We first show that existing\nprompt compression methods are ineffective for many-shot compression, and\nsimply using fewer shots as a baseline is surprisingly strong. To achieve\neffective compression, we find that: (a) a stronger compressor model with more\ntrainable parameters is necessary, and (b) compressing many-shot\nrepresentations at each transformer layer enables more fine-grained compression\nby providing each layer with its own compressed representation. Based on these\ninsights, we propose MemCom, a layer-wise compression method. We systematically\nevaluate various compressor models and training approaches across different\nmodel sizes (2B and 7B), architectures (Gemma and Mistral), many-shot sequence\nlengths (3k-6k tokens), and compression ratios (3x to 8x). MemCom outperforms\nstrong baselines across all compression ratios on multiple classification tasks\nwith large label sets. Notably, while baseline performance degrades sharply at\nhigher compression ratios, often by over 20-30%, MemCom maintains high accuracy\nwith minimal degradation, typically dropping by less than 10%.", "AI": {"tldr": "MemComp is a layer-wise compression method that improves memory and computational efficiency of In-Context Learning by compressing many-shot prompts into soft-token summaries, outperforming existing methods and maintaining high accuracy even at high compression ratios.", "motivation": "Large Language Models improve performance with more in-context examples but incur higher memory and computational costs. Existing prompt compression methods are ineffective for many-shot compression, and simply using fewer shots is surprisingly strong but limited.", "method": "Proposed MemComp, a layer-wise compression method that uses stronger compressor models with more trainable parameters and compresses many-shot representations at each transformer layer to enable fine-grained compression.", "result": "MemComp outperforms strong baselines across all compression ratios (3x to 8x) on multiple classification tasks with large label sets. While baseline performance degrades sharply (20-30%) at higher compression ratios, MemComp maintains high accuracy with minimal degradation (<10%).", "conclusion": "Layer-wise compression with stronger compressor models is effective for many-shot prompt compression, enabling efficient In-Context Learning inference while maintaining high task performance."}}
{"id": "2510.17173", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17173", "abs": "https://arxiv.org/abs/2510.17173", "authors": ["Melik Ozolcer", "Sang Won Bae"], "title": "Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users", "comment": "Accepted to the NeurIPS 2025 Workshop on Multi-Turn Interactions in\n  Large Language Models", "summary": "We study a web-deployed, tool-augmented LLM health coach with real users. In\na pilot with seven users (280 rated turns), offline policy evaluation (OPE)\nover factorized decision heads (Tool/Style) shows that a uniform heavy-tool\npolicy raises average value on logs but harms specific subgroups, most notably\nlow-health-literacy/high-self-efficacy users. A lightweight simulator with\nhidden archetypes further shows that adding a small early information-gain\nbonus reliably shortens trait identification and improves goal success and\npass@3. Together, these early findings indicate an evaluation-first path to\npersonalization: freeze the generator, learn subgroup-aware decision heads on\ntyped rewards (objective tool outcomes and satisfaction), and always report\nper-archetype metrics to surface subgroup harms that averages obscure.", "AI": {"tldr": "A web-deployed LLM health coach was evaluated with real users, showing that uniform heavy-tool policies can harm specific subgroups like low-health-literacy users. A simulator revealed that adding early information-gain bonuses improves trait identification and goal success.", "motivation": "To understand how tool-augmented LLM health coaches perform with real users and identify potential subgroup harms that average metrics might obscure.", "method": "Used offline policy evaluation (OPE) with factorized decision heads (Tool/Style) on real user data (7 users, 280 rated turns) and a lightweight simulator with hidden archetypes.", "result": "Uniform heavy-tool policies raise average value but harm low-health-literacy/high-self-efficacy users. Adding early information-gain bonuses shortens trait identification and improves goal success and pass@3.", "conclusion": "Proposes an evaluation-first approach to personalization: freeze the generator, learn subgroup-aware decision heads on typed rewards, and always report per-archetype metrics to surface subgroup harms."}}
{"id": "2510.16641", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16641", "abs": "https://arxiv.org/abs/2510.16641", "authors": ["Young-Jun Lee", "Byung-Kwan Lee", "Jianshu Zhang", "Yechan Hwang", "Byungsoo Ko", "Han-Gyu Kim", "Dongyu Yao", "Xuankun Rong", "Eojin Joo", "Seung-Ho Han", "Bowon Ko", "Ho-Jin Choi"], "title": "MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models", "comment": "Project website:\n  https://passing2961.github.io/multiverse-project-page/", "summary": "Vision-and-Language Models (VLMs) have shown impressive capabilities on\nsingle-turn benchmarks, yet real-world applications often demand more intricate\nmulti-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only\npartially capture the breadth and depth of conversational scenarios encountered\nby users. In this work, we introduce MultiVerse, a novel multi-turn\nconversation benchmark featuring 647 dialogues - each averaging four turns -\nderived from a diverse set of 12 popular VLM evaluation benchmarks. With 484\ntasks and 484 interaction goals, MultiVerse covers a wide range of topics, from\nfactual knowledge and perception to advanced reasoning tasks such as\nmathematics and coding. To facilitate robust assessment, we propose a\nchecklist-based evaluation method that leverages GPT-4o as the automated\nevaluator, measuring performance across 37 key aspects, including perceptual\naccuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on\nMultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve\nonly a 50% success rate in complex multi-turn conversations, highlighting the\ndataset's challenging nature. Notably, we find that providing full dialogue\ncontext significantly enhances performance for smaller or weaker models,\nemphasizing the importance of in-context learning. We believe MultiVerse is a\nlandscape of evaluating multi-turn interaction abilities for VLMs.", "AI": {"tldr": "MultiVerse is a challenging multi-turn conversation benchmark with 647 dialogues from 12 VLM evaluation benchmarks, evaluating 18 VLMs across 37 aspects using GPT-4o as automated evaluator.", "motivation": "Real-world VLM applications require complex multi-turn dialogues, but existing datasets only partially capture conversational breadth and depth.", "method": "Created MultiVerse benchmark with 647 dialogues (avg 4 turns each) from 12 VLM benchmarks, using checklist-based evaluation with GPT-4o across 37 aspects like perceptual accuracy and factual correctness.", "result": "Even strongest models (e.g., GPT-4o) achieve only 50% success rate in complex multi-turn conversations. Full dialogue context significantly boosts performance for smaller/weaker models.", "conclusion": "MultiVerse provides comprehensive landscape for evaluating multi-turn interaction abilities, highlighting the challenging nature of complex conversations and importance of in-context learning."}}
{"id": "2510.16097", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.HC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16097", "abs": "https://arxiv.org/abs/2510.16097", "authors": ["Eleni Straitouri", "Stratis Tsirtsis", "Ander Artola Velasco", "Manuel Gomez-Rodriguez"], "title": "Narrowing Action Choices with AI Improves Human Sequential Decisions", "comment": "Accepted at the Human-AI Complementarity for Decision Making Workshop\n  2025 by the NSF AI Institute for Societal Decision Making", "summary": "Recent work has shown that, in classification tasks, it is possible to design\ndecision support systems that do not require human experts to understand when\nto cede agency to a classifier or when to exercise their own agency to achieve\ncomplementarity$\\unicode{x2014}$experts using these systems make more accurate\npredictions than those made by the experts or the classifier alone. The key\nprinciple underpinning these systems reduces to adaptively controlling the\nlevel of human agency, by design. Can we use the same principle to achieve\ncomplementarity in sequential decision making tasks? In this paper, we answer\nthis question affirmatively. We develop a decision support system that uses a\npre-trained AI agent to narrow down the set of actions a human can take to a\nsubset, and then asks the human to take an action from this action set. Along\nthe way, we also introduce a bandit algorithm that leverages the smoothness\nproperties of the action sets provided by our system to efficiently optimize\nthe level of human agency. To evaluate our decision support system, we conduct\na large-scale human subject study ($n = 1{,}600$) where participants play a\nwildfire mitigation game. We find that participants who play the game supported\nby our system outperform those who play on their own by $\\sim$$30$% and the AI\nagent used by our system by $>$$2$%, even though the AI agent largely\noutperforms participants playing without support. We have made available the\ndata gathered in our human subject study as well as an open source\nimplementation of our system at\nhttps://github.com/Networks-Learning/narrowing-action-choices .", "AI": {"tldr": "A decision support system that uses AI to narrow down action choices for humans achieves complementarity in sequential decision making, improving performance by ~30% over humans alone and >2% over the AI agent alone.", "motivation": "To extend the principle of adaptively controlling human agency from classification tasks to sequential decision making tasks, achieving complementarity between humans and AI agents.", "method": "Developed a decision support system that uses a pre-trained AI agent to narrow down the set of actions available to humans, then asks humans to choose from this restricted action set. Used a bandit algorithm that leverages smoothness properties of action sets to optimize human agency level.", "result": "In a large-scale human study (n=1,600) using a wildfire mitigation game, participants using the system outperformed those playing alone by ~30% and the AI agent by >2%, even though the AI agent outperformed unsupported humans.", "conclusion": "The same principle of adaptively controlling human agency can successfully achieve complementarity in sequential decision making tasks, with the proposed system significantly improving human performance beyond both human-only and AI-only approaches."}}
{"id": "2510.17211", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17211", "abs": "https://arxiv.org/abs/2510.17211", "authors": ["Tingsong Xiao", "Yao An Lee", "Zelin Xu", "Yupu Zhang", "Zibo Liu", "Yu Huang", "Jiang Bian", "Serena Jingchuan Guo", "Zhe Jiang"], "title": "Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling", "comment": null, "summary": "Disease progression modeling aims to characterize and predict how a patient's\ndisease complications worsen over time based on longitudinal electronic health\nrecords (EHRs). Accurate modeling of disease progression, such as type 2\ndiabetes, can enhance patient sub-phenotyping and inform effective and timely\ninterventions. However, the problem is challenging due to the need to learn\ncontinuous-time dynamics of progression patterns based on irregular-time event\nsamples and patient heterogeneity (\\eg different progression rates and\npathways). Existing mechanistic and data-driven methods either lack\nadaptability to learn from real-world data or fail to capture complex\ncontinuous-time dynamics on progression trajectories. To address these\nlimitations, we propose Temporally Detailed Hypergraph Neural Ordinary\nDifferential Equation (TD-HNODE), which represents disease progression on\nclinically recognized trajectories as a temporally detailed hypergraph and\nlearns the continuous-time progression dynamics via a neural ODE framework.\nTD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the\ninterdependency of disease complication markers within both intra- and\ninter-progression trajectories. Experiments on two real-world clinical datasets\ndemonstrate that TD-HNODE outperforms multiple baselines in modeling the\nprogression of type 2 diabetes and related cardiovascular diseases.", "AI": {"tldr": "TD-HNODE is a neural ODE framework that models disease progression using temporally detailed hypergraphs to capture continuous-time dynamics from irregular EHR data, outperforming existing methods for type 2 diabetes and cardiovascular disease progression.", "motivation": "To address challenges in disease progression modeling including irregular-time event sampling, patient heterogeneity, and the need to capture complex continuous-time dynamics that existing mechanistic and data-driven methods fail to handle effectively.", "method": "Proposes Temporally Detailed Hypergraph Neural ODE (TD-HNODE) that represents disease progression as a temporally detailed hypergraph and learns continuous-time dynamics via neural ODE framework with learnable TD-Hypergraph Laplacian capturing interdependencies within and between progression trajectories.", "result": "Experiments on two real-world clinical datasets show TD-HNODE outperforms multiple baselines in modeling progression of type 2 diabetes and related cardiovascular diseases.", "conclusion": "TD-HNODE effectively addresses limitations of existing methods by capturing complex continuous-time progression dynamics through temporally detailed hypergraph representation and neural ODE framework."}}
{"id": "2510.16643", "categories": ["cs.CV", "cs.AI", "cs.RO", "I.2.9; I.2.10; H.3.3"], "pdf": "https://arxiv.org/pdf/2510.16643", "abs": "https://arxiv.org/abs/2510.16643", "authors": ["Aaron Ray", "Jacob Arkin", "Harel Biggie", "Chuchu Fan", "Luca Carlone", "Nicholas Roy"], "title": "Structured Interfaces for Automated Reasoning with 3D Scene Graphs", "comment": "25 pages, 3 figures", "summary": "In order to provide a robot with the ability to understand and react to a\nuser's natural language inputs, the natural language must be connected to the\nrobot's underlying representations of the world. Recently, large language\nmodels (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for\ngrounding natural language and representing the world. In this work, we address\nthe challenge of using LLMs with 3DSGs to ground natural language. Existing\nmethods encode the scene graph as serialized text within the LLM's context\nwindow, but this encoding does not scale to large or rich 3DSGs. Instead, we\npropose to use a form of Retrieval Augmented Generation to select a subset of\nthe 3DSG relevant to the task. We encode a 3DSG in a graph database and provide\na query language interface (Cypher) as a tool to the LLM with which it can\nretrieve relevant data for language grounding. We evaluate our approach on\ninstruction following and scene question-answering tasks and compare against\nbaseline context window and code generation methods. Our results show that\nusing Cypher as an interface to 3D scene graphs scales significantly better to\nlarge, rich graphs on both local and cloud-based models. This leads to large\nperformance improvements in grounded language tasks while also substantially\nreducing the token count of the scene graph content. A video supplement is\navailable at https://www.youtube.com/watch?v=zY_YI9giZSA.", "AI": {"tldr": "Using Retrieval Augmented Generation with Cypher query language to efficiently ground natural language in large 3D scene graphs, overcoming scalability limitations of traditional LLM context window methods.", "motivation": "Existing methods encode entire scene graphs as text in LLM context windows, which doesn't scale to large or rich 3D scene graphs, creating a bottleneck for natural language grounding in robotics.", "method": "Proposed using Retrieval Augmented Generation with a graph database encoding 3D scene graphs and providing Cypher query language as a tool for LLMs to retrieve relevant data for language grounding.", "result": "The Cypher interface approach scales significantly better to large, rich graphs on both local and cloud-based models, leading to large performance improvements in grounded language tasks while substantially reducing token count.", "conclusion": "Using Cypher as an interface to 3D scene graphs provides an effective solution for scalable natural language grounding in robotics applications."}}
{"id": "2510.16123", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16123", "abs": "https://arxiv.org/abs/2510.16123", "authors": ["Federico Malato", "Ville Hautam\u00e4ki"], "title": "Zero-shot World Models via Search in Memory", "comment": "10 pages, 8 figures in main text + appendices", "summary": "World Models have vastly permeated the field of Reinforcement Learning. Their\nability to model the transition dynamics of an environment have greatly\nimproved sample efficiency in online RL. Among them, the most notorious example\nis Dreamer, a model that learns to act in a diverse set of image-based\nenvironments. In this paper, we leverage similarity search and stochastic\nrepresentations to approximate a world model without a training procedure. We\nestablish a comparison with PlaNet, a well-established world model of the\nDreamer family. We evaluate the models on the quality of latent reconstruction\nand on the perceived similarity of the reconstructed image, on both next-step\nand long horizon dynamics prediction. The results of our study demonstrate that\na search-based world model is comparable to a training based one in both cases.\nNotably, our model show stronger performance in long-horizon prediction with\nrespect to the baseline on a range of visually different environments.", "AI": {"tldr": "The paper proposes a search-based world model using similarity search and stochastic representations that approximates world models without training, showing comparable performance to trained models like PlaNet/Dreamer.", "motivation": "World models improve RL sample efficiency but require training. The authors aim to create a world model that avoids training procedures while maintaining performance.", "method": "Uses similarity search and stochastic representations to approximate world models without training. Compares with PlaNet (Dreamer family) on latent reconstruction quality and image similarity.", "result": "Search-based model is comparable to training-based models in next-step and long-horizon prediction. Shows stronger performance in long-horizon prediction across visually different environments.", "conclusion": "Training-free world models using similarity search are viable alternatives to traditional trained models, with particular strength in long-term predictions."}}
{"id": "2510.17235", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17235", "abs": "https://arxiv.org/abs/2510.17235", "authors": ["Chong Chen", "Ze Liu", "Lingfeng Bao", "Yanlin Wang", "Ting Chen", "Daoyuan Wu", "Jiachi Chen"], "title": "Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis", "comment": null, "summary": "The cryptocurrency market offers significant investment opportunities but\nfaces challenges including high volatility and fragmented information. Data\nintegration and analysis are essential for informed investment decisions.\nCurrently, investors use three main approaches: (1) Manual analysis across\nvarious sources, which depends heavily on individual experience and is\ntime-consuming and prone to bias; (2) Data aggregation platforms-limited in\nfunctionality and depth of analysis; (3) Large language model agents-based on\nstatic pretrained models, lacking real-time data integration and multi-step\nreasoning capabilities. To address these limitations, we present Coinvisor, a\nreinforcement learning-based chatbot that provides comprehensive analytical\nsupport for cryptocurrency investment through a multi-agent framework.\nCoinvisor integrates diverse analytical capabilities through specialized tools.\nIts key innovation is a reinforcement learning-based tool selection mechanism\nthat enables multi-step planning and flexible integration of diverse data\nsources. This design supports real-time interaction and adaptive analysis of\ndynamic content, delivering accurate and actionable investment insights. We\nevaluated Coinvisor through automated benchmarks on tool calling accuracy and\nuser studies with 20 cryptocurrency investors using our interface. Results show\nthat Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base\nmodel in tool orchestration. User studies show high satisfaction (4.64/5), with\nparticipants preferring Coinvisor to both general LLMs and existing crypto\nplatforms (4.62/5).", "AI": {"tldr": "Coinvisor is a reinforcement learning-based chatbot that provides comprehensive cryptocurrency investment analysis through a multi-agent framework with adaptive tool selection.", "motivation": "Address limitations in current cryptocurrency investment approaches: manual analysis is time-consuming and biased, data platforms lack depth, and LLM agents lack real-time data integration and multi-step reasoning.", "method": "Multi-agent framework with reinforcement learning-based tool selection mechanism that enables multi-step planning and flexible integration of diverse data sources for real-time interaction.", "result": "Improves recall by 40.7% and F1 score by 26.6% over base model in tool orchestration. User studies show high satisfaction (4.64/5) and preference over general LLMs and existing crypto platforms (4.62/5).", "conclusion": "Coinvisor successfully addresses current limitations in cryptocurrency investment analysis by providing accurate, actionable insights through adaptive multi-agent framework with reinforcement learning."}}
{"id": "2510.16660", "categories": ["cs.CV", "cs.LG", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2510.16660", "abs": "https://arxiv.org/abs/2510.16660", "authors": ["Yuntian Wang", "Xilin Yang", "Che-Yung Shen", "Nir Pillar", "Aydogan Ozcan"], "title": "Universal and Transferable Attacks on Pathology Foundation Models", "comment": "38 Pages, 8 Figures", "summary": "We introduce Universal and Transferable Adversarial Perturbations (UTAP) for\npathology foundation models that reveal critical vulnerabilities in their\ncapabilities. Optimized using deep learning, UTAP comprises a fixed and weak\nnoise pattern that, when added to a pathology image, systematically disrupts\nthe feature representation capabilities of multiple pathology foundation\nmodels. Therefore, UTAP induces performance drops in downstream tasks that\nutilize foundation models, including misclassification across a wide range of\nunseen data distributions. In addition to compromising the model performance,\nwe demonstrate two key features of UTAP: (1) universality: its perturbation can\nbe applied across diverse field-of-views independent of the dataset that UTAP\nwas developed on, and (2) transferability: its perturbation can successfully\ndegrade the performance of various external, black-box pathology foundation\nmodels - never seen before. These two features indicate that UTAP is not a\ndedicated attack associated with a specific foundation model or image dataset,\nbut rather constitutes a broad threat to various emerging pathology foundation\nmodels and their applications. We systematically evaluated UTAP across various\nstate-of-the-art pathology foundation models on multiple datasets, causing a\nsignificant drop in their performance with visually imperceptible modifications\nto the input images using a fixed noise pattern. The development of these\npotent attacks establishes a critical, high-standard benchmark for model\nrobustness evaluation, highlighting a need for advancing defense mechanisms and\npotentially providing the necessary assets for adversarial training to ensure\nthe safe and reliable deployment of AI in pathology.", "AI": {"tldr": "UTAP is a universal and transferable adversarial attack method that uses fixed weak noise patterns to systematically disrupt pathology foundation models' feature representations, causing performance drops across various downstream tasks and models.", "motivation": "To reveal critical vulnerabilities in pathology foundation models and establish a benchmark for evaluating model robustness, highlighting the need for better defense mechanisms in AI pathology applications.", "method": "Optimized deep learning approach that generates fixed, weak noise patterns which, when added to pathology images, disrupt feature representations of multiple foundation models.", "result": "UTAP successfully degraded performance of various state-of-the-art pathology foundation models across multiple datasets, causing significant performance drops with visually imperceptible modifications using a fixed noise pattern.", "conclusion": "UTAP constitutes a broad threat to emerging pathology foundation models and their applications, establishing a critical benchmark for robustness evaluation and highlighting the need for advancing defense mechanisms and adversarial training."}}
{"id": "2510.16132", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16132", "abs": "https://arxiv.org/abs/2510.16132", "authors": ["Phalguni Nanda", "Zaiwei Chen"], "title": "A Minimal-Assumption Analysis of Q-Learning with Time-Varying Policies", "comment": "43 pages, 4 figures", "summary": "In this work, we present the first finite-time analysis of the Q-learning\nalgorithm under time-varying learning policies (i.e., on-policy sampling) with\nminimal assumptions -- specifically, assuming only the existence of a policy\nthat induces an irreducible Markov chain over the state space. We establish a\nlast-iterate convergence rate for $\\mathbb{E}[\\|Q_k - Q^*\\|_\\infty^2]$,\nimplying a sample complexity of order $O(1/\\epsilon^2)$ for achieving\n$\\mathbb{E}[\\|Q_k - Q^*\\|_\\infty] \\le \\epsilon$, matching that of off-policy\nQ-learning but with a worse dependence on exploration-related parameters. We\nalso derive an explicit rate for $\\mathbb{E}[\\|Q^{\\pi_k} - Q^*\\|_\\infty^2]$,\nwhere $\\pi_k$ is the learning policy at iteration $k$. These results reveal\nthat on-policy Q-learning exhibits weaker exploration than its off-policy\ncounterpart but enjoys an exploitation advantage, as its policy converges to an\noptimal one rather than remaining fixed. Numerical simulations corroborate our\ntheory.\n  Technically, the combination of time-varying learning policies (which induce\nrapidly time-inhomogeneous Markovian noise) and the minimal assumption on\nexploration presents significant analytical challenges. To address these\nchallenges, we employ a refined approach that leverages the Poisson equation to\ndecompose the Markovian noise corresponding to the lazy transition matrix into\na martingale-difference term and residual terms. To control the residual terms\nunder time inhomogeneity, we perform a sensitivity analysis of the Poisson\nequation solution with respect to both the Q-function estimate and the learning\npolicy. These tools may further facilitate the analysis of general\nreinforcement learning algorithms with rapidly time-varying learning policies\n-- such as single-timescale actor--critic methods and learning-in-games\nalgorithms -- and are of independent interest.", "AI": {"tldr": "First finite-time analysis of on-policy Q-learning with minimal assumptions, showing O(1/\u03b5\u00b2) sample complexity matching off-policy Q-learning but with different exploration-exploitation trade-offs.", "motivation": "To provide theoretical guarantees for on-policy Q-learning under time-varying learning policies with minimal assumptions about exploration, addressing the analytical challenges of rapidly time-inhomogeneous Markovian noise.", "method": "Used refined approach leveraging Poisson equation to decompose Markovian noise into martingale-difference and residual terms, with sensitivity analysis of Poisson equation solution with respect to Q-function estimate and learning policy.", "result": "Established last-iterate convergence rate for Q-learning with time-varying policies, showing O(1/\u03b5\u00b2) sample complexity for \u03b5-optimal Q-function and explicit rate for policy convergence.", "conclusion": "On-policy Q-learning has weaker exploration than off-policy but enjoys exploitation advantage as policy converges to optimal; developed analytical tools applicable to other RL algorithms with time-varying policies."}}
{"id": "2510.17309", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17309", "abs": "https://arxiv.org/abs/2510.17309", "authors": ["Thorsten Fr\u00f6hlich", "Tim Schlippe"], "title": "RubiSCoT: A Framework for AI-Supported Academic Assessment", "comment": null, "summary": "The evaluation of academic theses is a cornerstone of higher education,\nensuring rigor and integrity. Traditional methods, though effective, are\ntime-consuming and subject to evaluator variability. This paper presents\nRubiSCoT, an AI-supported framework designed to enhance thesis evaluation from\nproposal to final submission. Using advanced natural language processing\ntechniques, including large language models, retrieval-augmented generation,\nand structured chain-of-thought prompting, RubiSCoT offers a consistent,\nscalable solution. The framework includes preliminary assessments,\nmultidimensional assessments, content extraction, rubric-based scoring, and\ndetailed reporting. We present the design and implementation of RubiSCoT,\ndiscussing its potential to optimize academic assessment processes through\nconsistent, scalable, and transparent evaluation.", "AI": {"tldr": "RubiSCoT is an AI framework using NLP and LLMs to automate thesis evaluation from proposal to submission, providing consistent and scalable assessment.", "motivation": "Traditional thesis evaluation methods are time-consuming and suffer from evaluator variability, creating a need for more efficient and consistent assessment solutions.", "method": "Uses advanced NLP techniques including large language models, retrieval-augmented generation, and structured chain-of-thought prompting for preliminary assessments, multidimensional assessments, content extraction, rubric-based scoring, and detailed reporting.", "result": "The paper presents the design and implementation of RubiSCoT as a working framework for automated thesis evaluation.", "conclusion": "RubiSCoT has potential to optimize academic assessment processes through consistent, scalable, and transparent evaluation of academic theses."}}
{"id": "2510.16664", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16664", "abs": "https://arxiv.org/abs/2510.16664", "authors": ["Christopher Thirgood", "Oscar Mendez", "Erin Ling", "Jon Storey", "Simon Hadfield"], "title": "HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications", "comment": null, "summary": "Hyperspectral images (HSI) promise to support a range of new applications in\ncomputer vision. Recent research has explored the feasibility of generalizable\nSpectral Reconstruction (SR), the problem of recovering a HSI from a natural\nthree-channel color image in unseen scenarios.\n  However, previous Multi-Scale Attention (MSA) works have only demonstrated\nsufficient generalizable results for very sparse spectra, while modern HSI\nsensors contain hundreds of channels.\n  This paper introduces a novel approach to spectral reconstruction via our\nHYbrid knowledge Distillation and spectral Reconstruction Architecture (HYDRA).\n  Using a Teacher model that encapsulates latent hyperspectral image data and a\nStudent model that learns mappings from natural images to the Teacher's encoded\ndomain, alongside a novel training method, we achieve high-quality spectral\nreconstruction.\n  This addresses key limitations of prior SR models, providing SOTA performance\nacross all metrics, including an 18\\% boost in accuracy, and faster inference\ntimes than current SOTA models at various channel depths.", "AI": {"tldr": "HYDRA introduces a hybrid knowledge distillation approach for spectral reconstruction, achieving SOTA performance with 18% accuracy improvement and faster inference than current models.", "motivation": "Previous multi-scale attention methods only work well for sparse spectra, while modern hyperspectral sensors have hundreds of channels, creating a need for more effective generalizable spectral reconstruction.", "method": "Uses a Teacher model to encapsulate latent hyperspectral data and a Student model that learns mappings from natural images to the Teacher's encoded domain, combined with a novel training method.", "result": "Achieves high-quality spectral reconstruction with 18% boost in accuracy across all metrics and faster inference times than current SOTA models at various channel depths.", "conclusion": "HYDRA successfully addresses key limitations of prior spectral reconstruction models, providing superior performance for reconstructing hyperspectral images from natural color images."}}
{"id": "2510.16138", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16138", "abs": "https://arxiv.org/abs/2510.16138", "authors": ["Dung V. Nguyen", "Anh T. Nguyen", "Minh H. Nguyen", "Luc Q. Nguyen", "Shiqi Jiang", "Ethan Fetaya", "Linh Duy Tran", "Gal Chechik", "Tan M. Nguyen"], "title": "Expert Merging in Sparse Mixture of Experts with Nash Bargaining", "comment": "10 pages in the main text. Under Review", "summary": "Existing expert merging strategies for Sparse Mixture of Experts (SMoE)\ntypically rely on input-dependent or input-independent averaging of expert\nparameters, but often lack a principled weighting mechanism. In this work, we\nreinterpret expert merging through the lens of game theory, revealing\ncooperative and competitive dynamics among experts. Based on this perspective,\nwe introduce Nash Merging of Experts (NAMEx), a novel framework that\nincorporates Nash Bargaining into the merging process, enabling more balanced\nand efficient collaboration among experts. Additionally, we incorporate complex\nmomentum into NAMEx to accelerate expert propagation with theoretical\nguarantees for convergence. Extensive experiments across language modelling,\ntext classification, image classification, and zero-shot robustness under data\ncorruption show that NAMEx consistently outperforms competing methods while\nintegrating seamlessly with popular MoE architectures. Finally, we demonstrate\nNAMEx's scalability by applying it to large-scale systems, including\nQwen1.5-MoE (14B) and DeepSeek-MoE (16B), where it proves effective in both\nzero-shot and fine-tuning settings.", "AI": {"tldr": "NAMEx is a novel expert merging framework that uses Nash Bargaining from game theory to enable balanced collaboration among experts in Sparse Mixture of Experts models, outperforming existing methods across multiple tasks.", "motivation": "Existing expert merging strategies for SMoE lack principled weighting mechanisms and don't properly account for cooperative and competitive dynamics among experts.", "method": "NAMEx incorporates Nash Bargaining into the merging process and uses complex momentum to accelerate expert propagation with theoretical convergence guarantees.", "result": "NAMEx consistently outperforms competing methods across language modeling, text classification, image classification, and zero-shot robustness tasks, and scales effectively to large models like Qwen1.5-MoE (14B) and DeepSeek-MoE (16B).", "conclusion": "The game-theoretic approach of NAMEx provides a principled framework for expert merging that enables more balanced and efficient collaboration, demonstrating effectiveness in both zero-shot and fine-tuning settings."}}
{"id": "2510.17382", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17382", "abs": "https://arxiv.org/abs/2510.17382", "authors": ["Rishabh Jain", "Keisuke Okumura", "Michael Amir", "Amanda Prorok"], "title": "Graph Attention-Guided Search for Dense Multi-Agent Pathfinding", "comment": null, "summary": "Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)\nproblems in real-time remains challenging even for state-of-the-art planners.\nTo this end, we develop a hybrid framework that integrates a learned heuristic\nderived from MAGAT, a neural MAPF policy with a graph attention scheme, into a\nleading search-based algorithm, LaCAM. While prior work has explored\nlearning-guided search in MAPF, such methods have historically underperformed.\nIn contrast, our approach, termed LaGAT, outperforms both purely search-based\nand purely learning-based methods in dense scenarios. This is achieved through\nan enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of\ninterest, and a deadlock detection scheme to account for imperfect neural\nguidance. Our results demonstrate that, when carefully designed, hybrid search\noffers a powerful solution for tightly coupled, challenging multi-agent\ncoordination problems.", "AI": {"tldr": "LaGAT: A hybrid framework combining learned neural heuristics from MAGAT with search-based LaCAM algorithm for dense multi-agent pathfinding, outperforming both pure search and pure learning methods.", "motivation": "Real-time dense MAPF problems remain challenging for state-of-the-art planners, with prior learning-guided search methods historically underperforming.", "method": "Integrates learned heuristic from enhanced MAGAT neural policy into LaCAM search algorithm, using pre-train-then-fine-tune strategy and deadlock detection for imperfect neural guidance.", "result": "Outperforms both purely search-based and purely learning-based methods in dense scenarios.", "conclusion": "Hybrid search offers powerful solution for challenging multi-agent coordination problems when carefully designed."}}
{"id": "2510.16688", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16688", "abs": "https://arxiv.org/abs/2510.16688", "authors": ["Yejie Guo", "Yunzhong Hou", "Wufei Ma", "Meng Tang", "Ming-Hsuan Yang"], "title": "Pursuing Minimal Sufficiency in Spatial Reasoning", "comment": null, "summary": "Spatial reasoning, the ability to ground language in 3D understanding,\nremains a persistent challenge for Vision-Language Models (VLMs). We identify\ntwo fundamental bottlenecks: inadequate 3D understanding capabilities stemming\nfrom 2D-centric pre-training, and reasoning failures induced by redundant 3D\ninformation. To address these, we first construct a Minimal Sufficient Set\n(MSS) of information before answering a given question: a compact selection of\n3D perception results from \\textit{expert models}. We introduce MSSR (Minimal\nSufficient Spatial Reasoner), a dual-agent framework that implements this\nprinciple. A Perception Agent programmatically queries 3D scenes using a\nversatile perception toolbox to extract sufficient information, including a\nnovel SOG (Situated Orientation Grounding) module that robustly extracts\nlanguage-grounded directions. A Reasoning Agent then iteratively refines this\ninformation to pursue minimality, pruning redundant details and requesting\nmissing ones in a closed loop until the MSS is curated. Extensive experiments\ndemonstrate that our method, by explicitly pursuing both sufficiency and\nminimality, significantly improves accuracy and achieves state-of-the-art\nperformance across two challenging benchmarks. Furthermore, our framework\nproduces interpretable reasoning paths, offering a promising source of\nhigh-quality training data for future models. Source code is available at\nhttps://github.com/gyj155/mssr.", "AI": {"tldr": "MSSR is a dual-agent framework that improves spatial reasoning in VLMs by first extracting sufficient 3D information from expert models, then iteratively refining it to minimal essential data, achieving state-of-the-art performance.", "motivation": "Current VLMs struggle with spatial reasoning due to inadequate 3D understanding from 2D-centric pre-training and reasoning failures caused by redundant 3D information.", "method": "Dual-agent framework: Perception Agent queries 3D scenes using expert models and SOG module for direction grounding; Reasoning Agent iteratively refines information to achieve minimal sufficient set through pruning and supplementation.", "result": "Significantly improves accuracy and achieves state-of-the-art performance across two challenging benchmarks, while producing interpretable reasoning paths.", "conclusion": "Explicitly pursuing both sufficiency and minimality in 3D information processing effectively addresses spatial reasoning challenges in VLMs and provides high-quality training data for future models."}}
{"id": "2510.16157", "categories": ["cs.LG", "cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16157", "abs": "https://arxiv.org/abs/2510.16157", "authors": ["Xuchen Gong", "Tian Li"], "title": "Zeroth-Order Sharpness-Aware Learning with Exponential Tilting", "comment": null, "summary": "Classic zeroth-order optimization approaches typically optimize for a\nsmoothed version of the original function, i.e., the expected objective under\nrandomly perturbed model parameters. This can be interpreted as encouraging the\nloss values in the perturbation set to be small on average. Popular\nsharpness-aware minimization (SAM) objectives, however, typically focus on the\nlargest loss within the neighborhood to arrive at flat minima more effectively.\nIn this work, we connect zeroth-order optimization (and its corresponding\nobjectives) with SAM approaches explicitly, through an exponential tilting\nobjective that provides a smooth transition between the average- and the\nmax-loss formulations. We explore new zeroth-order algorithms to solve a soft\nSAM objective parameterized by a tilting parameter $t$. We provide precise\ncharacterizations of the sharpness notions of the tilted SAM framework.\nPractically, our approach can be used as a gradient-free and memory-efficient\nalternative to SAM variants, and it achieves better generalization compared to\nvanilla zeroth-order baselines on a wide range of downstream tasks, including\nclassification, multiple choice QA, and language generation.", "AI": {"tldr": "This paper connects zeroth-order optimization with sharpness-aware minimization (SAM) through an exponential tilting objective that bridges average-loss and max-loss formulations, enabling gradient-free flat minima optimization.", "motivation": "To bridge the gap between classic zeroth-order optimization (which optimizes smoothed functions) and SAM approaches (which focus on worst-case losses), providing a unified framework that offers gradient-free alternatives to SAM with better generalization.", "method": "Proposes an exponential tilting objective that smoothly transitions between average-loss (zeroth-order) and max-loss (SAM) formulations. Develops new zeroth-order algorithms to solve this soft SAM objective parameterized by a tilting parameter, providing precise characterizations of the sharpness notions.", "result": "The approach serves as a gradient-free and memory-efficient alternative to SAM variants, achieving better generalization compared to vanilla zeroth-order baselines across classification, multiple choice QA, and language generation tasks.", "conclusion": "The exponential tilting framework successfully connects zeroth-order optimization with SAM, offering practical gradient-free alternatives that improve generalization performance while maintaining computational efficiency."}}
{"id": "2510.17418", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2510.17418", "abs": "https://arxiv.org/abs/2510.17418", "authors": ["Mustafa F. Abdelwahed", "Alice Toniolo", "Joan Espasa", "Ian P. Gent"], "title": "Diverse Planning with Simulators via Linear Temporal Logic", "comment": null, "summary": "Autonomous agents rely on automated planning algorithms to achieve their\nobjectives. Simulation-based planning offers a significant advantage over\ndeclarative models in modelling complex environments. However, relying solely\non a planner that produces a single plan may not be practical, as the generated\nplans may not always satisfy the agent's preferences. To address this\nlimitation, we introduce $\\texttt{FBI}_\\texttt{LTL}$, a diverse planner\nexplicitly designed for simulation-based planning problems.\n$\\texttt{FBI}_\\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define\nsemantic diversity criteria, enabling agents to specify what constitutes\nmeaningfully different plans. By integrating these LTL-based diversity models\ndirectly into the search process, $\\texttt{FBI}_\\texttt{LTL}$ ensures the\ngeneration of semantically diverse plans, addressing a critical limitation of\nexisting diverse planning approaches that may produce syntactically different\nbut semantically identical solutions. Extensive evaluations on various\nbenchmarks consistently demonstrate that $\\texttt{FBI}_\\texttt{LTL}$ generates\nmore diverse plans compared to a baseline approach. This work establishes the\nfeasibility of semantically-guided diverse planning in simulation-based\nenvironments, paving the way for innovative approaches in realistic,\nnon-symbolic domains where traditional model-based approaches fail.", "AI": {"tldr": "FBI_LTL is a diverse planner for simulation-based planning that uses LTL to define semantic diversity criteria, generating meaningfully different plans rather than just syntactically different ones.", "motivation": "Traditional planners produce single plans that may not satisfy agent preferences, and existing diverse planning approaches often generate syntactically different but semantically identical solutions.", "method": "Uses Linear Temporal Logic (LTL) to define semantic diversity criteria and integrates these LTL-based diversity models directly into the search process.", "result": "Extensive evaluations show FBI_LTL generates more diverse plans compared to baseline approaches across various benchmarks.", "conclusion": "Establishes feasibility of semantically-guided diverse planning in simulation-based environments, enabling innovative approaches in realistic, non-symbolic domains where traditional model-based approaches fail."}}
{"id": "2510.16702", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16702", "abs": "https://arxiv.org/abs/2510.16702", "authors": ["Huy Minh Nhat Nguyen", "Triet Hoang Minh Dao", "Chau Vinh Hoang Truong", "Cuong Tuan Nguyen"], "title": "SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation", "comment": "2025 IEEE Conference on Computational Intelligence in Bioinformatics\n  and Computational Biology (CIBCB)", "summary": "Optical Coherence Tomography (OCT) is a widely used non-invasive imaging\ntechnique that provides detailed three-dimensional views of the retina, which\nare essential for the early and accurate diagnosis of ocular diseases.\nConsequently, OCT image analysis and processing have emerged as key research\nareas in biomedical imaging. However, acquiring paired datasets of clean and\nreal-world noisy OCT images for supervised denoising models remains a\nformidable challenge due to intrinsic speckle noise and practical constraints\nin clinical imaging environments. To address these issues, we propose SDPA++: A\nGeneral Framework for Self-Supervised Denoising with Patch Aggregation. Our\nnovel approach leverages only noisy OCT images by first generating\npseudo-ground-truth images through self-fusion and self-supervised denoising.\nThese refined images then serve as targets to train an ensemble of denoising\nmodels using a patch-based strategy that effectively enhances image clarity.\nPerformance improvements are validated via metrics such as Contrast-to-Noise\nRatio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge\nPreservation (EP) on the real-world dataset from the IEEE SPS Video and Image\nProcessing Cup. Notably, the VIP Cup dataset contains only real-world noisy OCT\nimages without clean references, highlighting our method's potential for\nimproving image quality and diagnostic outcomes in clinical practice.", "AI": {"tldr": "SDPA++ is a self-supervised denoising framework for OCT images that uses only noisy images to generate pseudo-ground-truth through self-fusion and trains ensemble denoising models without requiring clean reference images.", "motivation": "Acquiring paired datasets of clean and noisy OCT images for supervised denoising is challenging due to intrinsic speckle noise and clinical constraints, creating a need for self-supervised approaches.", "method": "Leverages only noisy OCT images to generate pseudo-ground-truth through self-fusion and self-supervised denoising, then trains an ensemble of denoising models using a patch-based aggregation strategy.", "result": "Validated on real-world VIP Cup dataset showing improvements in Contrast-to-Noise Ratio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge Preservation (EP) metrics.", "conclusion": "The method demonstrates potential for improving OCT image quality and diagnostic outcomes in clinical practice without requiring clean reference images."}}
{"id": "2510.16161", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16161", "abs": "https://arxiv.org/abs/2510.16161", "authors": ["Ankitkumar Joshi", "Milos Hauskrecht"], "title": "Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction", "comment": null, "summary": "Modeling irregularly sampled multivariate time series is a persistent\nchallenge in domains like healthcare and sensor networks. While recent works\nhave explored a variety of complex learning architectures to solve the\nprediction problems for irregularly sampled time series, it remains unclear\nwhat are the true benefits of some of these architectures, and whether clever\nmodifications of simpler and more efficient RNN-based algorithms are still\ncompetitive, i.e. they are on par with or even superior to these methods. In\nthis work, we propose and study GRUwE: Gated Recurrent Unit with Exponential\nbasis functions, that builds upon RNN-based architectures for observations made\nat irregular times. GRUwE supports both regression-based and event-based\npredictions in continuous time. GRUwE works by maintaining a Markov state\nrepresentation of the time series that updates with the arrival of irregular\nobservations. The Markov state update relies on two reset mechanisms: (i)\nobservation-triggered reset, and (ii) time-triggered reset of the GRU state\nusing learnable exponential decays, to support the predictions in continuous\ntime. Our empirical evaluations across several real-world benchmarks on\nnext-observation and next-event prediction tasks demonstrate that GRUwE can\nindeed achieve competitive to superior performance compared to the recent\nstate-of-the-art (SOTA) methods. Thanks to its simplicity, GRUwE offers\ncompelling advantages: it is easy to implement, requires minimal\nhyper-parameter tuning efforts, and significantly reduces the computational\noverhead in the online deployment.", "AI": {"tldr": "GRUwE is a simple yet effective RNN-based method for irregularly sampled multivariate time series that achieves competitive performance with state-of-the-art methods while being computationally efficient and easy to implement.", "motivation": "To determine if simpler RNN-based architectures can compete with complex learning methods for irregular time series prediction, and to provide an efficient solution for domains like healthcare and sensor networks.", "method": "GRUwE extends GRU with exponential basis functions, maintaining a Markov state that updates via two reset mechanisms: observation-triggered and time-triggered resets using learnable exponential decays for continuous-time predictions.", "result": "GRUwE achieves competitive to superior performance compared to state-of-the-art methods on real-world benchmarks for next-observation and next-event prediction tasks.", "conclusion": "Simple RNN-based approaches like GRUwE remain highly competitive for irregular time series modeling, offering significant advantages in implementation simplicity, reduced hyperparameter tuning, and computational efficiency."}}
{"id": "2510.17450", "categories": ["cs.AI", "H.4.2; I.2.3; I.2.6; I.2.8; I.2.9; J.7"], "pdf": "https://arxiv.org/pdf/2510.17450", "abs": "https://arxiv.org/abs/2510.17450", "authors": ["Johan Schubert", "Farzad Kamrani", "Tove Gustavi"], "title": "Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions", "comment": "Presented at the 6th International Workshop on Active Inference,\n  15-17 October 2025, Montreal, Canada", "summary": "We develop an active inference route-planning method for the autonomous\ncontrol of intelligent agents. The aim is to reconnoiter a geographical area to\nmaintain a common operational picture. To achieve this, we construct an\nevidence map that reflects our current understanding of the situation,\nincorporating both positive and \"negative\" sensor observations of possible\ntarget objects collected over time, and diffusing the evidence across the map\nas time progresses. The generative model of active inference uses\nDempster-Shafer theory and a Gaussian sensor model, which provides input to the\nagent. The generative process employs a Bayesian approach to update a posterior\nprobability distribution. We calculate the variational free energy for all\npositions within the area by assessing the divergence between a pignistic\nprobability distribution of the evidence map and a posterior probability\ndistribution of a target object based on the observations, including the level\nof surprise associated with receiving new observations. Using the free energy,\nwe direct the agents' movements in a simulation by taking an incremental step\ntoward a position that minimizes the free energy. This approach addresses the\nchallenge of exploration and exploitation, allowing agents to balance searching\nextensive areas of the geographical map while tracking identified target\nobjects.", "AI": {"tldr": "Active inference route-planning method for autonomous agents that balances exploration and exploitation using evidence maps, Dempster-Shafer theory, and variational free energy minimization.", "motivation": "To develop autonomous agents capable of maintaining a common operational picture by reconnoitering geographical areas, addressing the challenge of balancing exploration (searching new areas) and exploitation (tracking identified targets).", "method": "Constructs evidence maps incorporating positive and negative sensor observations over time, uses Dempster-Shafer theory with Gaussian sensor model for generative model, Bayesian approach for posterior probability updates, and calculates variational free energy to guide agent movements.", "result": "The method successfully directs agent movements by taking incremental steps toward positions that minimize free energy, enabling effective area reconnaissance while tracking targets.", "conclusion": "The active inference approach provides an effective framework for autonomous route planning that balances exploration and exploitation in geographical reconnaissance tasks."}}
{"id": "2510.16704", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16704", "abs": "https://arxiv.org/abs/2510.16704", "authors": ["Tianxin Wei", "Yifan Chen", "Xinrui He", "Wenxuan Bao", "Jingrui He"], "title": "Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization", "comment": "Accepted by KDD 2025", "summary": "Distribution shifts between training and testing samples frequently occur in\npractice and impede model generalization performance. This crucial challenge\nthereby motivates studies on domain generalization (DG), which aim to predict\nthe label on unseen target domain data by solely using data from source\ndomains. It is intuitive to conceive the class-separated representations\nlearned in contrastive learning (CL) are able to improve DG, while the reality\nis quite the opposite: users observe directly applying CL deteriorates the\nperformance. We analyze the phenomenon with the insights from CL theory and\ndiscover lack of intra-class connectivity in the DG setting causes the\ndeficiency. We thus propose a new paradigm, domain-connecting contrastive\nlearning (DCCL), to enhance the conceptual connectivity across domains and\nobtain generalizable representations for DG. On the data side, more aggressive\ndata augmentation and cross-domain positive samples are introduced to improve\nintra-class connectivity. On the model side, to better embed the unseen test\ndomains, we propose model anchoring to exploit the intra-class connectivity in\npre-trained representations and complement the anchoring with generative\ntransformation loss. Extensive experiments on five standard DG benchmarks are\nperformed. The results verify that DCCL outperforms state-of-the-art baselines\neven without domain supervision. The detailed model implementation and the code\nare provided through https://github.com/weitianxin/DCCL", "AI": {"tldr": "The paper proposes Domain-Connecting Contrastive Learning (DCCL) to address domain generalization challenges by improving intra-class connectivity across domains through enhanced data augmentation, cross-domain positive samples, and model anchoring techniques.", "motivation": "Distribution shifts between training and testing samples hinder model generalization. While contrastive learning should theoretically help domain generalization by learning class-separated representations, direct application actually deteriorates performance due to lack of intra-class connectivity in the DG setting.", "method": "DCCL introduces: 1) More aggressive data augmentation and cross-domain positive samples to improve intra-class connectivity; 2) Model anchoring to exploit intra-class connectivity in pre-trained representations; 3) Generative transformation loss to complement the anchoring.", "result": "Extensive experiments on five standard DG benchmarks show that DCCL outperforms state-of-the-art baselines even without domain supervision.", "conclusion": "DCCL successfully addresses the domain generalization challenge by enhancing intra-class connectivity across domains, providing a more effective approach than direct contrastive learning application."}}
{"id": "2510.16165", "categories": ["cs.LG", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.16165", "abs": "https://arxiv.org/abs/2510.16165", "authors": ["Charles Rhys Campbell", "Aldo H. Romero", "Kamal Choudhary"], "title": "AtomBench: A Benchmark for Generative Atomic Structure Models using GPT, Diffusion, and Flow Architectures", "comment": null, "summary": "Generative models have become significant assets in the exploration and\nidentification of new materials, enabling the rapid proposal of candidate\ncrystal structures that satisfy target properties. Despite the increasing\nadoption of diverse architectures, a rigorous comparative evaluation of their\nperformance on materials datasets is lacking. In this work, we present a\nsystematic benchmark of three representative generative models- AtomGPT (a\ntransformer-based model), Crystal Diffusion Variational Autoencoder (CDVAE),\nand FlowMM (a Riemannian flow matching model). These models were trained to\nreconstruct crystal structures from subsets of two publicly available\nsuperconductivity datasets- JARVIS Supercon 3D and DS A/B from the Alexandria\ndatabase. Performance was assessed using the Kullback-Leibler (KL) divergence\nbetween predicted and reference distributions of lattice parameters, as well as\nthe mean absolute error (MAE) of individual lattice constants. For the computed\nKLD and MAE scores, CDVAE performs most favorably, followed by AtomGPT, and\nthen FlowMM. All benchmarking code and model configurations will be made\npublicly available at https://github.com/atomgptlab/atombench_inverse.", "AI": {"tldr": "Systematic benchmark of three generative models (AtomGPT, CDVAE, FlowMM) for crystal structure generation using superconductivity datasets, with CDVAE performing best.", "motivation": "Lack of rigorous comparative evaluation of diverse generative model architectures for materials discovery, despite their increasing adoption.", "method": "Trained three models (transformer-based AtomGPT, CDVAE, and FlowMM) on superconductivity datasets and evaluated using KL divergence and MAE metrics for lattice parameters.", "result": "CDVAE performed most favorably, followed by AtomGPT, then FlowMM based on KLD and MAE scores for lattice parameter distributions.", "conclusion": "CDVAE shows superior performance in crystal structure generation, and all benchmarking code will be publicly available for reproducibility."}}
{"id": "2510.17463", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17463", "abs": "https://arxiv.org/abs/2510.17463", "authors": ["Cor Steging", "Tadeusz Zbiegie\u0144"], "title": "Label Indeterminacy in AI & Law", "comment": "This manuscript has been accepted for presentation as a short paper\n  at the 38th International Conference on Legal Knowledge and Information\n  Systems (JURIX) in Turin, December 9 to 11 of 2025", "summary": "Machine learning is increasingly used in the legal domain, where it typically\noperates retrospectively by treating past case outcomes as ground truth.\nHowever, legal outcomes are often shaped by human interventions that are not\ncaptured in most machine learning approaches. A final decision may result from\na settlement, an appeal, or other procedural actions. This creates label\nindeterminacy: the outcome could have been different if the intervention had or\nhad not taken place. We argue that legal machine learning applications need to\naccount for label indeterminacy. Methods exist that can impute these\nindeterminate labels, but they are all grounded in unverifiable assumptions. In\nthe context of classifying cases from the European Court of Human Rights, we\nshow that the way that labels are constructed during training can significantly\naffect model behaviour. We therefore position label indeterminacy as a relevant\nconcern in AI & Law and demonstrate how it can shape model behaviour.", "AI": {"tldr": "Legal ML models face label indeterminacy because court outcomes are shaped by procedural interventions like settlements and appeals, making past cases unreliable as ground truth. This affects model behavior significantly.", "motivation": "To address the problem that machine learning in law treats past case outcomes as definitive ground truth, ignoring that legal outcomes are often shaped by human interventions like settlements, appeals, and procedural actions that create label indeterminacy.", "method": "Analyze case classification from the European Court of Human Rights to demonstrate how different label construction approaches during training affect model behavior, using methods that impute indeterminate labels while acknowledging their reliance on unverifiable assumptions.", "result": "The study shows that the way labels are constructed during training significantly affects model behavior in legal machine learning applications, demonstrating the practical impact of label indeterminacy.", "conclusion": "Label indeterminacy is a critical concern in AI & Law that shapes model behavior, and legal machine learning applications must account for this inherent uncertainty in legal outcomes rather than treating past cases as definitive ground truth."}}
{"id": "2510.16709", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16709", "abs": "https://arxiv.org/abs/2510.16709", "authors": ["Liu Haojie", "Gao Suixiang"], "title": "HumanCM: One Step Human Motion Prediction", "comment": "6 pages, 2 figures, 2 tables", "summary": "We present HumanCM, a one-step human motion prediction framework built upon\nconsistency models. Instead of relying on multi-step denoising as in\ndiffusion-based methods, HumanCM performs efficient single-step generation by\nlearning a self-consistent mapping between noisy and clean motion states. The\nframework adopts a Transformer-based spatiotemporal architecture with temporal\nembeddings to model long-range dependencies and preserve motion coherence.\nExperiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves\ncomparable or superior accuracy to state-of-the-art diffusion models while\nreducing inference steps by up to two orders of magnitude.", "AI": {"tldr": "HumanCM is a one-step human motion prediction framework using consistency models that achieves comparable accuracy to diffusion models with significantly fewer inference steps.", "motivation": "To develop an efficient human motion prediction method that avoids the computational overhead of multi-step denoising in diffusion models while maintaining high accuracy.", "method": "Uses consistency models to learn self-consistent mapping between noisy and clean motion states, employing Transformer-based spatiotemporal architecture with temporal embeddings for long-range dependencies and motion coherence.", "result": "Achieves comparable or superior accuracy to state-of-the-art diffusion models on Human3.6M and HumanEva-I datasets while reducing inference steps by up to two orders of magnitude.", "conclusion": "HumanCM provides an efficient alternative to diffusion models for human motion prediction, offering significant speed improvements without sacrificing accuracy."}}
{"id": "2510.16167", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16167", "abs": "https://arxiv.org/abs/2510.16167", "authors": ["Archie Chaudhury"], "title": "Alignment is Localized: A Causal Probe into Preference Layers", "comment": null, "summary": "Reinforcement Learning frameworks, particularly those utilizing human\nannotations, have become an increasingly popular method for preference\nfine-tuning, where the outputs of a language model are tuned to match a certain\nset of behavioral policies or guidelines. Reinforcement Learning through Human\nFeedback (RLHF) is perhaps the most popular implementation of such a framework,\nparticularly for aligning LMs toward safety and human intent. However, the\ninternal workings of how such alignment is achieved remain largely opaque. In\nthis work, we systematically analyze preference optimization for language model\nalignment by applying layer-wide causal patching between a base model and its\ntuned counterpart across human preference pairs. We implement our methodology\non \\textit{Llama-3.2-1B}, and find that alignment is spatially localized:\nmid-layer activations encode a distinct subspace that causally determines\nreward-consistent behavior, while early and late layers remain largely\nunaffected. Utilizing LASSO regression, we also find that only a small number\nof layers possess non-zero coefficients linking activation distances to reward\ngains. Overall, we show that, at least for some language models, alignment from\nhuman-based, preferential tuning is a directional, low rank process, rather\nthan diffuse and parameteric.", "AI": {"tldr": "This paper analyzes how preference optimization aligns language models through causal patching, finding alignment is localized in mid-layer activations rather than being diffuse across all parameters.", "motivation": "To understand the opaque internal workings of how reinforcement learning with human feedback (RLHF) achieves language model alignment, as current methods remain largely unexplained.", "method": "Systematic analysis using layer-wide causal patching between base and tuned models across human preference pairs, applied to Llama-3.2-1B, combined with LASSO regression to identify key layers.", "result": "Alignment is spatially localized: mid-layer activations encode a distinct subspace that causally determines reward-consistent behavior, while early and late layers remain largely unaffected. Only a small number of layers have non-zero coefficients linking activation distances to reward gains.", "conclusion": "Alignment from human-based preferential tuning is a directional, low rank process rather than diffuse and parametric, at least for some language models."}}
{"id": "2510.17590", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.CY", "cs.LG", "I.2.7; H.3.3; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.17590", "abs": "https://arxiv.org/abs/2510.17590", "authors": ["Mir Nafis Sharear Shopnil", "Sharad Duwal", "Abhishek Tyagi", "Adiba Mahbub Proma"], "title": "MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning", "comment": "16 pages, 3 tables, 1 figure", "summary": "Misinformation spreads across web platforms through billions of daily\nmultimodal posts that combine text and images, overwhelming manual\nfact-checking capacity. Supervised detection models require domain-specific\ntraining data and fail to generalize across diverse manipulation tactics. We\npresent MIRAGE, an inference-time, model-pluggable agentic framework that\ndecomposes multimodal verification into four sequential modules: visual\nveracity assessment detects AI-generated images, cross-modal consistency\nanalysis identifies out-of-context repurposing, retrieval-augmented factual\nchecking grounds claims in web evidence through iterative question generation,\nand a calibrated judgment module integrates all signals. MIRAGE orchestrates\nvision-language model reasoning with targeted web retrieval, outputs structured\nand citation-linked rationales. On MMFakeBench validation set (1,000 samples),\nMIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming\nthe strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65\npoints while maintaining 34.3% false positive rate versus 97.3% for a\njudge-only baseline. Test set results (5,000 samples) confirm generalization\nwith 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification\ncontributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97\npoints. Our results demonstrate that decomposed agentic reasoning with web\nretrieval can match supervised detector performance without domain-specific\ntraining, enabling misinformation detection across modalities where labeled\ndata remains scarce.", "AI": {"tldr": "MIRAGE is an agentic framework that decomposes multimodal misinformation detection into four modules: visual veracity assessment, cross-modal consistency analysis, retrieval-augmented factual checking, and calibrated judgment, achieving strong performance without domain-specific training.", "motivation": "Misinformation spreads through billions of multimodal posts daily, overwhelming manual fact-checking capacity. Supervised detection models require domain-specific training data and fail to generalize across diverse manipulation tactics.", "method": "MIRAGE decomposes multimodal verification into four sequential modules: visual veracity assessment for AI-generated images, cross-modal consistency analysis for out-of-context repurposing, retrieval-augmented factual checking with iterative question generation, and a calibrated judgment module that integrates all signals.", "result": "On MMFakeBench validation set (1,000 samples), MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming the strongest zero-shot baseline by 7.65 F1 points. Test set results (5,000 samples) confirm generalization with 81.44% F1 and 75.08% accuracy.", "conclusion": "Decomposed agentic reasoning with web retrieval can match supervised detector performance without domain-specific training, enabling misinformation detection across modalities where labeled data remains scarce."}}
{"id": "2510.16714", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16714", "abs": "https://arxiv.org/abs/2510.16714", "authors": ["Xiongkun Linghu", "Jiangyong Huang", "Ziyu Zhu", "Baoxiong Jia", "Siyuan Huang"], "title": "Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes", "comment": "Project page: https://scenecot.github.io/", "summary": "Existing research on 3D Large Language Models (LLMs) still struggles to\nachieve grounded question-answering, primarily due to the under-exploration of\nthe mech- anism of human-like scene-object grounded reasoning. This paper\nbridges the gap by presenting a novel framework. We first introduce a grounded\nChain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a\ncomplex reasoning task into simpler and manageable problems, and building\ncorresponding visual clues based on multimodal expert modules. To enable such a\nmethod, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning\ndataset, consisting of 185K high-quality instances. Extensive experiments\nacross various complex 3D scene reasoning benchmarks demonstrate that our new\nframework achieves strong performance with high grounding-QA coherence. To the\nbest of our knowledge, this is the first successful application of CoT\nreasoning to 3D scene understanding, enabling step-by-step human-like reasoning\nand showing potential for extension to broader 3D scene understanding\nscenarios.", "AI": {"tldr": "This paper introduces SCENECOT, a novel framework for grounded Chain-of-Thought reasoning in 3D scenes, along with SCENECOT-185K dataset, achieving strong performance in complex 3D scene reasoning with high grounding-QA coherence.", "motivation": "Existing 3D LLMs struggle with grounded question-answering due to under-exploration of human-like scene-object grounded reasoning mechanisms.", "method": "Proposes SCENECOT framework that decouples complex reasoning into simpler problems using multimodal expert modules, and creates SCENECOT-185K dataset with 185K high-quality grounded CoT reasoning instances.", "result": "Extensive experiments show strong performance across various complex 3D scene reasoning benchmarks with high grounding-QA coherence.", "conclusion": "This is the first successful application of CoT reasoning to 3D scene understanding, enabling human-like step-by-step reasoning with potential for broader 3D scene understanding applications."}}
{"id": "2510.16171", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16171", "abs": "https://arxiv.org/abs/2510.16171", "authors": ["Longwei Wang", "Ifrat Ikhtear Uddin", "KC Santosh", "Chaowei Zhang", "Xiao Qin", "Yang Zhou"], "title": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "comment": "Accepted for the proceedings of 39th Conference on Neural Information\n  Processing Systems (NeurIPS 2025)", "summary": "Adversarial examples reveal critical vulnerabilities in deep neural networks\nby exploiting their sensitivity to imperceptible input perturbations. While\nadversarial training remains the predominant defense strategy, it often incurs\nsignificant computational cost and may compromise clean-data accuracy. In this\nwork, we investigate an architectural approach to adversarial robustness by\nembedding group-equivariant convolutions-specifically, rotation- and\nscale-equivariant layers-into standard convolutional neural networks (CNNs).\nThese layers encode symmetry priors that align model behavior with structured\ntransformations in the input space, promoting smoother decision boundaries and\ngreater resilience to adversarial attacks. We propose and evaluate two\nsymmetry-aware architectures: a parallel design that processes standard and\nequivariant features independently before fusion, and a cascaded design that\napplies equivariant operations sequentially. Theoretically, we demonstrate that\nsuch models reduce hypothesis space complexity, regularize gradients, and yield\ntighter certified robustness bounds under the CLEVER (Cross Lipschitz Extreme\nValue for nEtwork Robustness) framework. Empirically, our models consistently\nimprove adversarial robustness and generalization across CIFAR-10, CIFAR-100,\nand CIFAR-10C under both FGSM and PGD attacks, without requiring adversarial\ntraining. These findings underscore the potential of symmetry-enforcing\narchitectures as efficient and principled alternatives to data\naugmentation-based defenses.", "AI": {"tldr": "This paper proposes using group-equivariant convolutions (rotation- and scale-equivariant layers) in CNNs to improve adversarial robustness without adversarial training, achieving better resilience to attacks while maintaining clean-data accuracy.", "motivation": "Adversarial training is computationally expensive and can reduce clean-data accuracy. The authors aim to develop architectural solutions that provide inherent robustness through symmetry priors rather than data augmentation.", "method": "Two symmetry-aware architectures: parallel design (processing standard and equivariant features independently then fusing) and cascaded design (applying equivariant operations sequentially). Uses group-equivariant convolutions to encode rotation and scale symmetries.", "result": "Models consistently improve adversarial robustness and generalization across CIFAR-10, CIFAR-100, and CIFAR-10C datasets under FGSM and PGD attacks, without requiring adversarial training. Theoretically shows reduced hypothesis space complexity and tighter certified robustness bounds.", "conclusion": "Symmetry-enforcing architectures offer efficient and principled alternatives to data augmentation-based defenses, demonstrating the potential of architectural approaches for adversarial robustness."}}
{"id": "2510.17598", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17598", "abs": "https://arxiv.org/abs/2510.17598", "authors": ["Amir Jalilifard", "Anderson de Rezende Rocha", "Marcos Medeiros Raimundo"], "title": "Reasoning Distillation and Structural Alignment for Improved Code Generation", "comment": null, "summary": "Effective code generation with language models hinges on two critical\nfactors: accurately understanding the intent of the prompt and generating code\nthat applies algorithmic reasoning to produce correct solutions capable of\npassing diverse test cases while adhering to the syntax of the target\nprogramming language. Unlike other language tasks, code generation requires\nmore than accurate token prediction; it demands comprehension of solution-level\nand structural relationships rather than merely generating the most likely\ntokens. very large language model (VLLM) are capable of generating detailed\nsteps toward the correct solution of complex tasks where reasoning is crucial\nin solving the problem. Such reasoning capabilities may be absent in smaller\nlanguage models. Therefore, in this work, we distill the reasoning capabilities\nof a VLLM into a smaller, more efficient model that is faster and cheaper to\ndeploy. Our approach trains the model to emulate the reasoning and\nproblem-solving abilities of the VLLM by learning to identify correct solution\npathways and establishing a structural correspondence between problem\ndefinitions and potential solutions through a novel method of structure-aware\nloss optimization. This enables the model to transcend token-level generation\nand to deeply grasp the overarching structure of solutions for given problems.\nExperimental results show that our fine-tuned model, developed through a cheap\nand simple to implement process, significantly outperforms our baseline model\nin terms of pass@1, average data flow, and average syntax match metrics across\nthe MBPP, MBPP Plus, and HumanEval benchmarks.", "AI": {"tldr": "This paper proposes a method to distill reasoning capabilities from very large language models (VLLMs) into smaller, more efficient models for code generation, enabling better understanding of solution structure and algorithmic reasoning.", "motivation": "Smaller language models lack the reasoning capabilities of VLLMs for complex code generation tasks, which require understanding solution-level relationships rather than just token prediction.", "method": "Distills VLLM reasoning into smaller models through structure-aware loss optimization, training the model to emulate VLLM's reasoning by identifying correct solution pathways and establishing structural correspondence between problems and solutions.", "result": "The fine-tuned model significantly outperforms baseline in pass@1, average data flow, and average syntax match metrics across MBPP, MBPP Plus, and HumanEval benchmarks.", "conclusion": "A cheap and simple distillation process can effectively transfer reasoning capabilities from VLLMs to smaller models, enabling efficient deployment while maintaining strong code generation performance."}}
{"id": "2510.16729", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16729", "abs": "https://arxiv.org/abs/2510.16729", "authors": ["Jianbiao Mei", "Yu Yang", "Xuemeng Yang", "Licheng Wen", "Jiajun Lv", "Botian Shi", "Yong Liu"], "title": "Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models", "comment": null, "summary": "End-to-end autonomous driving systems increasingly rely on vision-centric\nworld models to understand and predict their environment. However, a common\nineffectiveness in these models is the full reconstruction of future scenes,\nwhich expends significant capacity on redundantly modeling static backgrounds.\nTo address this, we propose IR-WM, an Implicit Residual World Model that\nfocuses on modeling the current state and evolution of the world. IR-WM first\nestablishes a robust bird's-eye-view representation of the current state from\nthe visual observation. It then leverages the BEV features from the previous\ntimestep as a strong temporal prior and predicts only the \"residual\", i.e., the\nchanges conditioned on the ego-vehicle's actions and scene context. To\nalleviate error accumulation over time, we further apply an alignment module to\ncalibrate semantic and dynamic misalignments. Moreover, we investigate\ndifferent forecasting-planning coupling schemes and demonstrate that the\nimplicit future state generated by world models substantially improves planning\naccuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D\noccupancy forecasting and trajectory planning.", "AI": {"tldr": "IR-WM is an Implicit Residual World Model that focuses on modeling world state changes rather than full scene reconstruction, using BEV representations and residual prediction to improve autonomous driving performance.", "motivation": "Current vision-centric world models in autonomous driving inefficiently reconstruct entire future scenes, including static backgrounds, wasting computational capacity on redundant modeling.", "method": "Uses BEV representation of current state, leverages previous timestep BEV features as temporal prior, predicts only residual changes conditioned on ego-vehicle actions and scene context, and applies alignment module to correct semantic/dynamic misalignments.", "result": "Achieves top performance on nuScenes benchmark in both 4D occupancy forecasting and trajectory planning, with implicit future state generation substantially improving planning accuracy.", "conclusion": "The residual modeling approach focusing on state changes rather than full reconstruction is more effective for autonomous driving world models, with different forecasting-planning coupling schemes demonstrating improved performance."}}
{"id": "2510.16175", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16175", "abs": "https://arxiv.org/abs/2510.16175", "authors": ["Pablo Samuel Castro"], "title": "The Formalism-Implementation Gap in Reinforcement Learning Research", "comment": null, "summary": "The last decade has seen an upswing in interest and adoption of reinforcement\nlearning (RL) techniques, in large part due to its demonstrated capabilities at\nperforming certain tasks at \"super-human levels\". This has incentivized the\ncommunity to prioritize research that demonstrates RL agent performance, often\nat the expense of research aimed at understanding their learning dynamics.\nPerformance-focused research runs the risk of overfitting on academic\nbenchmarks -- thereby rendering them less useful -- which can make it difficult\nto transfer proposed techniques to novel problems. Further, it implicitly\ndiminishes work that does not push the performance-frontier, but aims at\nimproving our understanding of these techniques. This paper argues two points:\n(i) RL research should stop focusing solely on demonstrating agent\ncapabilities, and focus more on advancing the science and understanding of\nreinforcement learning; and (ii) we need to be more precise on how our\nbenchmarks map to the underlying mathematical formalisms. We use the popular\nArcade Learning Environment (ALE; Bellemare et al., 2013) as an example of a\nbenchmark that, despite being increasingly considered \"saturated\", can be\neffectively used for developing this understanding, and facilitating the\ndeployment of RL techniques in impactful real-world problems.", "AI": {"tldr": "RL research should shift from performance-focused demonstrations to understanding learning dynamics and improving benchmark precision to better transfer techniques to real-world problems.", "motivation": "Current RL research prioritizes performance metrics over understanding learning dynamics, risking overfitting on benchmarks and hindering transfer to novel problems.", "method": "Using the Arcade Learning Environment (ALE) as a case study to demonstrate how benchmarks can be effectively used for developing understanding rather than just performance measurement.", "result": "The paper argues that ALE, despite being considered \"saturated\", remains valuable for understanding RL techniques and facilitating real-world deployment.", "conclusion": "RL research needs to focus more on scientific understanding and precise benchmark formalisms rather than solely on performance demonstrations to advance the field effectively."}}
{"id": "2510.17614", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17614", "abs": "https://arxiv.org/abs/2510.17614", "authors": ["Praphul Singh", "Corey Barrett", "Sumana Srivasta", "Irfan Bulu", "Sri Gadde", "Krishnaram Kenthapadi"], "title": "OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration", "comment": null, "summary": "Clinicians need ranking systems that work in real time and still justify\ntheir choices. Motivated by the need for a low-latency, decoder-based reranker,\nwe present OG-Rank, a single-decoder approach that pairs a pooled first-token\nscoring signal with an uncertainty-gated explanation step. The model scores all\ncandidates in one pass and generates a brief, structured rationale only when\nthe list is genuinely ambiguous, keeping latency predictable. Trained with a\ncurriculum that concentrates effort on hard cases, OG-Rank delivers strong\neffectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,\nnDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,\nnDCG@20~0.699 at a 45\\% gate rate), while compact backbones show similar gains\nunder the same policy. Encoder baselines trail in both effectiveness and\nflexibility. The result is a practical recipe: rank fast by default and explain\nwhen it helps, a pattern that applies broadly to decision tasks where selective\ngeneration buys accuracy at acceptable cost. The single-policy design\nsimplifies deployment and budget planning, and the curriculum principle (spend\nmore on the hard cases, less on the easy ones) readily transfers beyond\nclinical order selection.", "AI": {"tldr": "OG-Rank is a low-latency decoder-based reranker that scores candidates in one pass and generates explanations only when needed, achieving strong performance on clinical order selection tasks with predictable latency.", "motivation": "Clinicians need real-time ranking systems that can justify their choices, requiring low-latency solutions that provide explanations when necessary.", "method": "Single-decoder approach with pooled first-token scoring and uncertainty-gated explanation step. Uses curriculum training focused on hard cases, scores all candidates in one pass.", "result": "Strong effectiveness on encounter-scoped order selection (Recall@1~0.45, nDCG@20~0.625 on fast path; improves to Recall@1~0.56, nDCG@20~0.699 at 45% gate rate). Outperforms encoder baselines in effectiveness and flexibility.", "conclusion": "Practical recipe: rank fast by default and explain when it helps. Single-policy design simplifies deployment, and curriculum principle transfers beyond clinical order selection."}}
{"id": "2510.16730", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16730", "abs": "https://arxiv.org/abs/2510.16730", "authors": ["Tianyang Dou", "Ming Li", "Jiangying Qin", "Xuan Liao", "Jiageng Zhong", "Armin Gruen", "Mengyi Deng"], "title": "UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid", "comment": null, "summary": "Coral reefs are vital yet fragile ecosystems that require accurate\nlarge-scale mapping for effective conservation. Although global products such\nas the Allen Coral Atlas provide unprecedented coverage of global coral reef\ndistri-bution, their predictions are frequently limited in spatial precision\nand semantic consistency, especially in regions requiring fine-grained boundary\ndelineation. To address these challenges, we propose UKANFormer, a novel\nse-mantic segmentation model designed to achieve high-precision mapping under\nnoisy supervision derived from Allen Coral Atlas. Building upon the UKAN\narchitecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans)\nblock in the decoder, enabling the extraction of both global semantic\nstructures and local boundary details. In experiments, UKANFormer achieved a\ncoral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming\nconventional baselines under the same noisy labels setting. Remarkably, the\nmodel produces predictions that are visually and structurally more accurate\nthan the noisy labels used for training. These results challenge the notion\nthat data quality directly limits model performance, showing that architectural\ndesign can mitigate label noise and sup-port scalable mapping under imperfect\nsupervision. UKANFormer provides a foundation for ecological monitoring where\nreliable labels are scarce.", "AI": {"tldr": "UKANFormer is a semantic segmentation model that achieves high-precision coral reef mapping using noisy supervision from Allen Coral Atlas, outperforming conventional methods and producing more accurate predictions than the training labels themselves.", "motivation": "Global coral reef mapping products like Allen Coral Atlas have limited spatial precision and semantic consistency, especially for fine-grained boundary delineation, which hinders effective conservation efforts.", "method": "UKANFormer builds on UKAN architecture with a Global-Local Transformer (GL-Trans) block in the decoder to extract both global semantic structures and local boundary details, enabling high-precision mapping under noisy supervision.", "result": "Achieved coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming conventional baselines under the same noisy labels setting. The model produces predictions that are visually and structurally more accurate than the noisy training labels.", "conclusion": "Architectural design can mitigate label noise and support scalable mapping under imperfect supervision, challenging the notion that data quality directly limits model performance. UKANFormer provides a foundation for ecological monitoring where reliable labels are scarce."}}
{"id": "2510.16185", "categories": ["cs.LG", "cs.AI", "cs.FL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16185", "abs": "https://arxiv.org/abs/2510.16185", "authors": ["Daniel Donnelly", "Angelo Ferrando", "Francesco Belardinelli"], "title": "Expressive Reward Synthesis with the Runtime Monitoring Language", "comment": null, "summary": "A key challenge in reinforcement learning (RL) is reward (mis)specification,\nwhereby imprecisely defined reward functions can result in unintended, possibly\nharmful, behaviours. Indeed, reward functions in RL are typically treated as\nblack-box mappings from state-action pairs to scalar values. While effective in\nmany settings, this approach provides no information about why rewards are\ngiven, which can hinder learning and interpretability. Reward Machines address\nthis issue by representing reward functions as finite state automata, enabling\nthe specification of structured, non-Markovian reward functions. However, their\nexpressivity is typically bounded by regular languages, leaving them unable to\ncapture more complex behaviours such as counting or parametrised conditions. In\nthis work, we build on the Runtime Monitoring Language (RML) to develop a novel\nclass of language-based Reward Machines. By leveraging the built-in memory of\nRML, our approach can specify reward functions for non-regular, non-Markovian\ntasks. We demonstrate the expressiveness of our approach through experiments,\nhighlighting additional advantages in flexible event-handling and task\nspecification over existing Reward Machine-based methods.", "AI": {"tldr": "The paper introduces language-based Reward Machines using Runtime Monitoring Language (RML) to overcome limitations of traditional Reward Machines in capturing non-regular, non-Markovian tasks.", "motivation": "Traditional RL reward functions are black-box mappings that lack interpretability and cannot capture complex behaviors like counting or parameterized conditions. Reward Machines help but are limited to regular languages.", "method": "Developed a novel class of language-based Reward Machines by building on Runtime Monitoring Language (RML), leveraging RML's built-in memory to specify reward functions for non-regular, non-Markovian tasks.", "result": "The approach demonstrates enhanced expressiveness through experiments, showing advantages in flexible event-handling and task specification over existing Reward Machine methods.", "conclusion": "Language-based Reward Machines using RML provide a more expressive framework for specifying complex reward functions in reinforcement learning, addressing limitations of traditional approaches."}}
{"id": "2510.17638", "categories": ["cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17638", "abs": "https://arxiv.org/abs/2510.17638", "authors": ["Qingchuan Yang", "Simon Mahns", "Sida Li", "Anri Gu", "Jibang Wu", "Haifeng Xu"], "title": "LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena", "comment": "https://www.prophetarena.co/", "summary": "Forecasting is not only a fundamental intellectual pursuit but also is of\nsignificant importance to societal systems such as finance and economics. With\nthe rapid advances of large language models (LLMs) trained on Internet-scale\ndata, it raises the promise of employing LLMs to forecast real-world future\nevents, an emerging paradigm we call \"LLM-as-a-Prophet\". This paper\nsystematically investigates such predictive intelligence of LLMs. To this end,\nwe build Prophet Arena, a general evaluation benchmark that continuously\ncollects live forecasting tasks and decomposes each task into distinct pipeline\nstages, in order to support our controlled and large-scale experimentation. Our\ncomprehensive evaluation reveals that many LLMs already exhibit impressive\nforecasting capabilities, reflected in, e.g., their small calibration errors,\nconsistent prediction confidence and promising market returns. However, we also\nuncover key bottlenecks towards achieving superior predictive intelligence via\nLLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of\ndata sources and slower information aggregation compared to markets when\nresolution nears.", "AI": {"tldr": "This paper systematically evaluates LLMs' forecasting capabilities on real-world events, finding they show promising potential but face key bottlenecks in event recall, data understanding, and information aggregation speed.", "motivation": "To investigate whether large language models (LLMs) can effectively forecast real-world future events, given their training on Internet-scale data and potential applications in finance and economics.", "method": "Built Prophet Arena, a general evaluation benchmark that continuously collects live forecasting tasks and decomposes them into distinct pipeline stages for controlled, large-scale experimentation.", "result": "LLMs exhibit impressive forecasting capabilities with small calibration errors, consistent prediction confidence, and promising market returns, but struggle with inaccurate event recalls, misunderstanding data sources, and slower information aggregation compared to markets.", "conclusion": "While LLMs show promise as forecasting tools (LLM-as-a-Prophet), key bottlenecks need addressing for achieving superior predictive intelligence, particularly in event recall accuracy, data source comprehension, and information aggregation speed."}}
{"id": "2510.16732", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16732", "abs": "https://arxiv.org/abs/2510.16732", "authors": ["Xinqing Li", "Xin He", "Le Zhang", "Yun Liu"], "title": "A Comprehensive Survey on World Models for Embodied AI", "comment": "https://github.com/Li-Zn-H/AwesomeWorldModels", "summary": "Embodied AI requires agents that perceive, act, and anticipate how actions\nreshape future world states. World models serve as internal simulators that\ncapture environment dynamics, enabling forward and counterfactual rollouts to\nsupport perception, prediction, and decision making. This survey presents a\nunified framework for world models in embodied AI. Specifically, we formalize\nthe problem setting and learning objectives, and propose a three-axis taxonomy\nencompassing: (1) Functionality, Decision-Coupled vs. General-Purpose; (2)\nTemporal Modeling, Sequential Simulation and Inference vs. Global Difference\nPrediction; (3) Spatial Representation, Global Latent Vector, Token Feature\nSequence, Spatial Latent Grid, and Decomposed Rendering Representation. We\nsystematize data resources and metrics across robotics, autonomous driving, and\ngeneral video settings, covering pixel prediction quality, state-level\nunderstanding, and task performance. Furthermore, we offer a quantitative\ncomparison of state-of-the-art models and distill key open challenges,\nincluding the scarcity of unified datasets and the need for evaluation metrics\nthat assess physical consistency over pixel fidelity, the trade-off between\nmodel performance and the computational efficiency required for real-time\ncontrol, and the core modeling difficulty of achieving long-horizon temporal\nconsistency while mitigating error accumulation. Finally, we maintain a curated\nbibliography at https://github.com/Li-Zn-H/AwesomeWorldModels.", "AI": {"tldr": "This survey presents a unified framework for world models in embodied AI, proposing a three-axis taxonomy covering functionality, temporal modeling, and spatial representation, while systematizing data resources, metrics, and current challenges.", "motivation": "Embodied AI requires agents that perceive, act, and anticipate how actions reshape future world states, with world models serving as internal simulators that capture environment dynamics to support perception, prediction, and decision making.", "method": "The authors formalize the problem setting and learning objectives, and propose a three-axis taxonomy: (1) Functionality (Decision-Coupled vs. General-Purpose), (2) Temporal Modeling (Sequential Simulation vs. Global Difference Prediction), (3) Spatial Representation (Global Latent Vector, Token Feature Sequence, Spatial Latent Grid, Decomposed Rendering Representation).", "result": "The survey systematizes data resources and metrics across robotics, autonomous driving, and general video settings, covering pixel prediction quality, state-level understanding, and task performance, and provides quantitative comparison of state-of-the-art models.", "conclusion": "Key open challenges include scarcity of unified datasets, need for evaluation metrics that assess physical consistency over pixel fidelity, trade-off between model performance and computational efficiency for real-time control, and difficulty of achieving long-horizon temporal consistency while mitigating error accumulation."}}
{"id": "2510.16188", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16188", "abs": "https://arxiv.org/abs/2510.16188", "authors": ["Fateme Golivand Darvishvand", "Hikaru Shindo", "Sahil Sidheekh", "Kristian Kersting", "Sriraam Natarajan"], "title": "Human-Allied Relational Reinforcement Learning", "comment": "Proceedings of the Twelfth Annual Conference on Advances in Cognitive\n  Systems, ACS-2025 (143-159)", "summary": "Reinforcement learning (RL) has experienced a second wind in the past decade.\nWhile incredibly successful in images and videos, these systems still operate\nwithin the realm of propositional tasks ignoring the inherent structure that\nexists in the problem. Consequently, relational extensions (RRL) have been\ndeveloped for such structured problems that allow for effective generalization\nto arbitrary number of objects. However, they inherently make strong\nassumptions about the problem structure. We introduce a novel framework that\ncombines RRL with object-centric representation to handle both structured and\nunstructured data. We enhance learning by allowing the system to actively query\nthe human expert for guidance by explicitly modeling the uncertainty over the\npolicy. Our empirical evaluation demonstrates the effectiveness and efficiency\nof our proposed approach.", "AI": {"tldr": "A novel framework combining relational reinforcement learning with object-centric representations and human guidance through uncertainty modeling.", "motivation": "Traditional RL systems ignore inherent problem structure, while relational RL makes strong assumptions about structure. Need a framework that handles both structured and unstructured data effectively.", "method": "Combines relational RL with object-centric representations and allows active querying of human experts by explicitly modeling policy uncertainty.", "result": "Empirical evaluation shows the approach is effective and efficient.", "conclusion": "The proposed framework successfully handles both structured and unstructured data while incorporating human guidance through uncertainty modeling."}}
{"id": "2510.17697", "categories": ["cs.AI", "cs.LG", "cs.MA", "I.2.11; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.17697", "abs": "https://arxiv.org/abs/2510.17697", "authors": ["Anjie Liu", "Jianhong Wang", "Samuel Kaski", "Jun Wang", "Mengyue Yang"], "title": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "comment": "Accepted to NeurIPS 2025", "summary": "Steering cooperative multi-agent reinforcement learning (MARL) towards\ndesired outcomes is challenging, particularly when the global guidance from a\nhuman on the whole multi-agent system is impractical in a large-scale MARL. On\nthe other hand, designing mechanisms to coordinate agents most relies on\nempirical studies, lacking a easy-to-use research tool. In this work, we employ\nmulti-agent influence diagrams (MAIDs) as a graphical framework to address the\nabove issues. First, we introduce interaction paradigms that leverage MAIDs to\nanalyze and visualize existing approaches in MARL. Then, we design a new\ninteraction paradigm based on MAIDs, referred to as targeted intervention that\nis applied to only a single targeted agent, so the problem of global guidance\ncan be mitigated. In our implementation, we introduce a causal inference\ntechnique-referred to as Pre-Strategy Intervention (PSI)-to realize the\ntargeted intervention paradigm. Since MAIDs can be regarded as a special class\nof causal diagrams, a composite desired outcome that integrates the primary\ntask goal and an additional desired outcome can be achieved by maximizing the\ncorresponding causal effect through the PSI. Moreover, the bundled relevance\ngraph analysis of MAIDs provides a tool to identify whether an MARL learning\nparadigm is workable under the design of an interaction paradigm. In\nexperiments, we demonstrate the effectiveness of our proposed targeted\nintervention, and verify the result of relevance graph analysis.", "AI": {"tldr": "This paper proposes using multi-agent influence diagrams (MAIDs) to steer cooperative multi-agent reinforcement learning, introducing targeted intervention through Pre-Strategy Intervention (PSI) to achieve desired outcomes with minimal agent involvement.", "motivation": "Steering cooperative MARL towards desired outcomes is challenging with global human guidance, and existing coordination mechanisms lack easy-to-use research tools.", "method": "Uses MAIDs as graphical framework, introduces targeted intervention paradigm applied to single agents via Pre-Strategy Intervention (PSI) causal inference technique, and employs relevance graph analysis.", "result": "Demonstrated effectiveness of targeted intervention and verified relevance graph analysis results in experiments.", "conclusion": "MAIDs provide an effective framework for analyzing and designing MARL interaction paradigms, with targeted intervention mitigating global guidance problems and achieving composite desired outcomes."}}
{"id": "2510.16751", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16751", "abs": "https://arxiv.org/abs/2510.16751", "authors": ["Erik Riise", "Mehmet Onurcan Kaya", "Dim P. Papadopoulos"], "title": "Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling", "comment": null, "summary": "While inference-time scaling through search has revolutionized Large Language\nModels, translating these gains to image generation has proven difficult.\nRecent attempts to apply search strategies to continuous diffusion models show\nlimited benefits, with simple random sampling often performing best. We\ndemonstrate that the discrete, sequential nature of visual autoregressive\nmodels enables effective search for image generation. We show that beam search\nsubstantially improves text-to-image generation, enabling a 2B parameter\nautoregressive model to outperform a 12B parameter diffusion model across\nbenchmarks. Systematic ablations show that this advantage comes from the\ndiscrete token space, which allows early pruning and computational reuse, and\nour verifier analysis highlights trade-offs between speed and reasoning\ncapability. These findings suggest that model architecture, not just scale, is\ncritical for inference-time optimization in visual generation.", "AI": {"tldr": "Beam search significantly improves text-to-image generation in autoregressive models, enabling a 2B parameter model to outperform a 12B parameter diffusion model, highlighting the importance of discrete token spaces for effective inference-time optimization.", "motivation": "While search strategies have greatly improved LLMs, similar gains haven't translated well to image generation, with diffusion models showing limited benefits from search techniques.", "method": "Applied beam search to discrete, sequential visual autoregressive models, leveraging the discrete token space for early pruning and computational reuse.", "result": "Beam search substantially improved text-to-image generation, with a 2B parameter autoregressive model outperforming a 12B parameter diffusion model across benchmarks.", "conclusion": "Model architecture (discrete token space) is critical for inference-time optimization in visual generation, not just scale, with trade-offs between speed and reasoning capability."}}
{"id": "2510.16208", "categories": ["cs.LG", "cs.SY", "eess.SY", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16208", "abs": "https://arxiv.org/abs/2510.16208", "authors": ["Sunmook Choi", "Yahya Sattar", "Yassir Jedra", "Maryam Fazel", "Sarah Dean"], "title": "Explore-then-Commit for Nonstationary Linear Bandits with Latent Dynamics", "comment": null, "summary": "We study a nonstationary bandit problem where rewards depend on both actions\nand latent states, the latter governed by unknown linear dynamics. Crucially,\nthe state dynamics also depend on the actions, resulting in tension between\nshort-term and long-term rewards. We propose an explore-then-commit algorithm\nfor a finite horizon $T$. During the exploration phase, random Rademacher\nactions enable estimation of the Markov parameters of the linear dynamics,\nwhich characterize the action-reward relationship. In the commit phase, the\nalgorithm uses the estimated parameters to design an optimized action sequence\nfor long-term reward. Our proposed algorithm achieves\n$\\tilde{\\mathcal{O}}(T^{2/3})$ regret. Our analysis handles two key challenges:\nlearning from temporally correlated rewards, and designing action sequences\nwith optimal long-term reward. We address the first challenge by providing\nnear-optimal sample complexity and error bounds for system identification using\nbilinear rewards. We address the second challenge by proving an equivalence\nwith indefinite quadratic optimization over a hypercube, a known NP-hard\nproblem. We provide a sub-optimality guarantee for this problem, enabling our\nregret upper bound. Lastly, we propose a semidefinite relaxation with\nGoemans-Williamson rounding as a practical approach.", "AI": {"tldr": "The paper studies nonstationary bandits with action-dependent linear state dynamics, proposing an explore-then-commit algorithm that achieves \u00d5(T^{2/3}) regret by learning system parameters and optimizing long-term rewards.", "motivation": "There is a need to handle bandit problems where rewards depend on both actions and latent states with unknown linear dynamics, creating tension between short-term and long-term rewards due to action-dependent state transitions.", "method": "An explore-then-commit algorithm with random Rademacher actions for exploration to estimate Markov parameters, followed by optimized action sequence design using estimated parameters for long-term reward maximization.", "result": "The proposed algorithm achieves \u00d5(T^{2/3}) regret, with analysis addressing challenges of learning from correlated rewards and designing optimal action sequences through system identification and indefinite quadratic optimization.", "conclusion": "The paper successfully addresses nonstationary bandits with linear dynamics, providing theoretical guarantees and practical approaches for balancing exploration and long-term optimization in action-dependent state systems."}}
{"id": "2510.17705", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17705", "abs": "https://arxiv.org/abs/2510.17705", "authors": ["Dayan Pan", "Zhaoyang Fu", "Jingyuan Wang", "Xiao Han", "Yue Zhu", "Xiangyu Zhao"], "title": "Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models", "comment": "Accepted by CIKM' 25", "summary": "Large Language Models (LLMs) possess remarkable generalization capabilities\nbut struggle with multi-task adaptation, particularly in balancing knowledge\nretention with task-specific specialization. Conventional fine-tuning methods\nsuffer from catastrophic forgetting and substantial resource consumption, while\nexisting parameter-efficient methods perform suboptimally in complex multi-task\nscenarios. To address this, we propose Contextual Attention Modulation (CAM), a\nnovel mechanism that dynamically modulates the representations of\nself-attention modules in LLMs. CAM enhances task-specific features while\npreserving general knowledge, thereby facilitating more effective and efficient\nadaptation. For effective multi-task adaptation, CAM is integrated into our\nHybrid Contextual Attention Modulation (HyCAM) framework, which combines a\nshared, full-parameter CAM module with multiple specialized, lightweight CAM\nmodules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.\nExtensive experiments on heterogeneous tasks, including question answering,\ncode generation, and logical reasoning, demonstrate that our approach\nsignificantly outperforms existing approaches, achieving an average performance\nimprovement of 3.65%. The implemented code and data are available to ease\nreproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.", "AI": {"tldr": "Proposes Contextual Attention Modulation (CAM) and Hybrid CAM (HyCAM) framework for efficient multi-task adaptation in LLMs, addressing catastrophic forgetting and resource issues while improving performance by 3.65% on average.", "motivation": "LLMs struggle with multi-task adaptation, facing catastrophic forgetting and high resource consumption in conventional fine-tuning, while existing parameter-efficient methods underperform in complex multi-task scenarios.", "method": "Uses Contextual Attention Modulation (CAM) to dynamically modulate self-attention representations, and HyCAM framework combining shared full-parameter CAM with specialized lightweight CAM modules using dynamic routing for adaptive knowledge fusion.", "result": "Significantly outperforms existing approaches on heterogeneous tasks (question answering, code generation, logical reasoning) with 3.65% average performance improvement.", "conclusion": "CAM and HyCAM effectively balance knowledge retention with task-specific specialization, enabling more efficient and effective multi-task adaptation in LLMs."}}
{"id": "2510.16752", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16752", "abs": "https://arxiv.org/abs/2510.16752", "authors": ["Ivan Molodetskikh", "Kirill Malyshev", "Mark Mirgaleev", "Nikita Zagainov", "Evgeney Bogatyrev", "Dmitriy Vatolin"], "title": "Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution", "comment": null, "summary": "Generative image super-resolution (SR) is rapidly advancing in visual quality\nand detail restoration. As the capacity of SR models expands, however, so does\ntheir tendency to produce artifacts: incorrect, visually disturbing details\nthat reduce perceived quality. Crucially, their perceptual impact varies: some\nartifacts are barely noticeable while others strongly degrade the image. We\nargue that artifacts should be characterized by their prominence to human\nobservers rather than treated as uniform binary defects. Motivated by this, we\npresent a novel dataset of 1302 artifact examples from 11 contemporary image-SR\nmethods, where each artifact is paired with a crowdsourced prominence score.\nBuilding on this dataset, we train a lightweight regressor that produces\nspatial prominence heatmaps and outperforms existing methods at detecting\nprominent artifacts. We release the dataset and code to facilitate\nprominence-aware evaluation and mitigation of SR artifacts.", "AI": {"tldr": "The paper introduces a dataset of SR artifacts with human-rated prominence scores and trains a model to detect prominent artifacts, moving beyond binary artifact classification.", "motivation": "Current SR models produce artifacts with varying perceptual impact, but existing methods treat all artifacts as equally important. The authors argue artifacts should be characterized by their prominence to human observers.", "method": "Created a dataset of 1302 artifact examples from 11 SR methods with crowdsourced prominence scores, then trained a lightweight regressor to produce spatial prominence heatmaps.", "result": "The trained regressor outperforms existing methods at detecting prominent artifacts and produces spatial prominence heatmaps.", "conclusion": "The work enables prominence-aware evaluation and mitigation of SR artifacts, with the dataset and code released to facilitate further research."}}
{"id": "2510.16211", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16211", "abs": "https://arxiv.org/abs/2510.16211", "authors": ["Henrique Pickler", "Jorge K. S. Kamassury", "Danilo Silva"], "title": "Benchmarking noisy label detection methods", "comment": null, "summary": "Label noise is a common problem in real-world datasets, affecting both model\ntraining and validation. Clean data are essential for achieving strong\nperformance and ensuring reliable evaluation. While various techniques have\nbeen proposed to detect noisy labels, there is no clear consensus on optimal\napproaches. We perform a comprehensive benchmark of detection methods by\ndecomposing them into three fundamental components: label agreement function,\naggregation method, and information gathering approach (in-sample vs\nout-of-sample). This decomposition can be applied to many existing detection\nmethods, and enables systematic comparison across diverse approaches. To fairly\ncompare methods, we propose a unified benchmark task, detecting a fraction of\ntraining samples equal to the dataset's noise rate. We also introduce a novel\nmetric: the false negative rate at this fixed operating point. Our evaluation\nspans vision and tabular datasets under both synthetic and real-world noise\nconditions. We identify that in-sample information gathering using average\nprobability aggregation combined with the logit margin as the label agreement\nfunction achieves the best results across most scenarios. Our findings provide\npractical guidance for designing new detection methods and selecting techniques\nfor specific applications.", "AI": {"tldr": "A comprehensive benchmark of label noise detection methods decomposed into three components: label agreement function, aggregation method, and information gathering approach, with evaluation across vision and tabular datasets under synthetic and real-world noise conditions.", "motivation": "Label noise is a common problem in real-world datasets affecting model training and validation, but there's no clear consensus on optimal detection approaches despite various proposed techniques.", "method": "Decompose detection methods into three fundamental components (label agreement function, aggregation method, information gathering approach), propose unified benchmark task detecting training samples equal to dataset's noise rate, and introduce novel metric of false negative rate at fixed operating point.", "result": "In-sample information gathering using average probability aggregation combined with logit margin as label agreement function achieves best results across most scenarios in vision and tabular datasets under both synthetic and real-world noise conditions.", "conclusion": "The findings provide practical guidance for designing new detection methods and selecting techniques for specific applications, with the proposed decomposition enabling systematic comparison across diverse approaches."}}
{"id": "2510.17771", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17771", "abs": "https://arxiv.org/abs/2510.17771", "authors": ["Zhining Liu", "Ziyi Chen", "Hui Liu", "Chen Luo", "Xianfeng Tang", "Suhang Wang", "Joy Zeng", "Zhenwei Dai", "Zhan Shi", "Tianxin Wei", "Benoit Dumoulin", "Hanghang Tong"], "title": "Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs", "comment": "21 pages, 10 figures, 6 tables", "summary": "Vision-Language Models (VLMs) achieve strong results on multimodal tasks such\nas visual question answering, yet they can still fail even when the correct\nvisual evidence is present. In this work, we systematically investigate whether\nthese failures arise from not perceiving the evidence or from not leveraging it\neffectively. By examining layer-wise attention dynamics, we find that shallow\nlayers focus primarily on text, while deeper layers sparsely but reliably\nattend to localized evidence regions. Surprisingly, VLMs often perceive the\nvisual evidence when outputting incorrect answers, a phenomenon we term\n``seeing but not believing'' that widely exists in major VLM families. Building\non this, we introduce an inference-time intervention that highlights deep-layer\nevidence regions through selective attention-based masking. It requires no\ntraining and consistently improves accuracy across multiple families, including\nLLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable\nevidence internally but under-utilize it, making such signals explicit can\nbridge the gap between perception and reasoning, advancing the diagnostic\nunderstanding and reliability of VLMs.", "AI": {"tldr": "VLMs often perceive visual evidence but fail to use it effectively, leading to incorrect answers. An attention-based intervention improves accuracy without training.", "motivation": "To understand why VLMs fail on multimodal tasks despite having correct visual evidence, and determine if failures are due to perception issues or reasoning limitations.", "method": "Analyzed layer-wise attention dynamics, discovered shallow layers focus on text while deeper layers attend to visual evidence. Introduced inference-time intervention using selective attention-based masking on deep-layer evidence regions.", "result": "Found widespread 'seeing but not believing' phenomenon where VLMs perceive evidence but output wrong answers. Intervention consistently improved accuracy across LLaVA, Qwen, Gemma, and InternVL without training.", "conclusion": "VLMs encode reliable visual evidence internally but under-utilize it. Making these signals explicit can bridge perception-reasoning gap and improve VLM reliability."}}
{"id": "2510.16765", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16765", "abs": "https://arxiv.org/abs/2510.16765", "authors": ["Shengyu Zhu", "Fan", "Fuxuan Zhang"], "title": "WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement", "comment": "Chinese Conference on Pattern Recognition and Computer Vision (PRCV),\n  Oral", "summary": "Image restoration is a fundamental and challenging task in computer vision,\nwhere CNN-based frameworks demonstrate significant computational efficiency.\nHowever, previous CNN-based methods often face challenges in adequately\nrestoring fine texture details, which are limited by the small receptive field\nof CNN structures and the lack of channel feature modeling. In this paper, we\npropose WaMaIR, which is a novel framework with a large receptive field for\nimage perception and improves the reconstruction of texture details in restored\nimages. Specifically, we introduce the Global Multiscale Wavelet Transform\nConvolutions (GMWTConvs) for expandding the receptive field to extract image\nfeatures, preserving and enriching texture features in model inputs. Meanwhile,\nwe propose the Mamba-Based Channel-Aware Module (MCAM), explicitly designed to\ncapture long-range dependencies within feature channels, which enhancing the\nmodel sensitivity to color, edges, and texture information. Additionally, we\npropose Multiscale Texture Enhancement Loss (MTELoss) for image restoration to\nguide the model in preserving detailed texture structures effectively.\nExtensive experiments confirm that WaMaIR outperforms state-of-the-art methods,\nachieving better image restoration and efficient computational performance of\nthe model.", "AI": {"tldr": "WaMaIR is a CNN-based image restoration framework that uses wavelet transforms to expand receptive fields and a Mamba-based module for channel-aware feature modeling, achieving superior texture detail restoration with computational efficiency.", "motivation": "Previous CNN-based image restoration methods struggle with restoring fine texture details due to limited receptive fields and lack of channel feature modeling, leading to suboptimal texture reconstruction.", "method": "Proposes three key components: Global Multiscale Wavelet Transform Convolutions (GMWTConvs) to expand receptive fields and preserve texture features; Mamba-Based Channel-Aware Module (MCAM) to capture long-range dependencies and enhance sensitivity to color, edges, and textures; and Multiscale Texture Enhancement Loss (MTELoss) to guide texture preservation.", "result": "Extensive experiments show WaMaIR outperforms state-of-the-art methods in image restoration quality while maintaining efficient computational performance.", "conclusion": "WaMaIR effectively addresses the limitations of previous CNN-based approaches by combining large receptive fields through wavelet transforms with channel-aware modeling, achieving superior texture detail restoration in image restoration tasks."}}
{"id": "2510.16233", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16233", "abs": "https://arxiv.org/abs/2510.16233", "authors": ["Patricia West", "Michelle WL Wan", "Alexander Hepburn", "Edwin Simpson", "Raul Santos-Rodriguez", "Jeffrey N Clark"], "title": "Machine Learning for Climate Policy: Understanding Policy Progression in the European Green Deal", "comment": null, "summary": "Climate change demands effective legislative action to mitigate its impacts.\nThis study explores the application of machine learning (ML) to understand the\nprogression of climate policy from announcement to adoption, focusing on\npolicies within the European Green Deal. We present a dataset of 165 policies,\nincorporating text and metadata. We aim to predict a policy's progression\nstatus, and compare text representation methods, including TF-IDF, BERT, and\nClimateBERT. Metadata features are included to evaluate the impact on\npredictive performance. On text features alone, ClimateBERT outperforms other\napproaches (RMSE = 0.17, R^2 = 0.29), while BERT achieves superior performance\nwith the addition of metadata features (RMSE = 0.16, R^2 = 0.38). Using methods\nfrom explainable AI highlights the influence of factors such as policy wording\nand metadata including political party and country representation. These\nfindings underscore the potential of ML tools in supporting climate policy\nanalysis and decision-making.", "AI": {"tldr": "This study uses machine learning to predict climate policy progression in the European Green Deal, finding that ClimateBERT performs best with text features alone, while BERT with metadata achieves superior overall performance.", "motivation": "Climate change requires effective legislative action, and understanding how policies progress from announcement to adoption can support better climate policy analysis and decision-making.", "method": "Analyzed 165 policies using text and metadata features, compared text representation methods (TF-IDF, BERT, ClimateBERT), and used explainable AI techniques to identify influential factors.", "result": "ClimateBERT achieved best performance on text features alone (RMSE=0.17, R\u00b2=0.29), while BERT with metadata features performed best overall (RMSE=0.16, R\u00b2=0.38). Key factors included policy wording, political party, and country representation.", "conclusion": "Machine learning tools show significant potential for supporting climate policy analysis by predicting policy progression and identifying influential factors through explainable AI methods."}}
{"id": "2510.16772", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16772", "abs": "https://arxiv.org/abs/2510.16772", "authors": ["Thuy Phuong Vu", "Dinh-Cuong Hoang", "Minhhuy Le", "Phan Xuan Tan"], "title": "Region in Context: Text-condition Image editing with Human-like semantic reasoning", "comment": null, "summary": "Recent research has made significant progress in localizing and editing image\nregions based on text. However, most approaches treat these regions in\nisolation, relying solely on local cues without accounting for how each part\ncontributes to the overall visual and semantic composition. This often results\nin inconsistent edits, unnatural transitions, or loss of coherence across the\nimage. In this work, we propose Region in Context, a novel framework for\ntext-conditioned image editing that performs multilevel semantic alignment\nbetween vision and language, inspired by the human ability to reason about\nedits in relation to the whole scene. Our method encourages each region to\nunderstand its role within the global image context, enabling precise and\nharmonized changes. At its core, the framework introduces a dual-level guidance\nmechanism: regions are represented with full-image context and aligned with\ndetailed region-level descriptions, while the entire image is simultaneously\nmatched to a comprehensive scene-level description generated by a large\nvision-language model. These descriptions serve as explicit verbal references\nof the intended content, guiding both local modifications and global structure.\nExperiments show that it produces more coherent and instruction-aligned\nresults. Code is available at:\nhttps://github.com/thuyvuphuong/Region-in-Context.git", "AI": {"tldr": "Region in Context is a novel framework for text-conditioned image editing that performs multilevel semantic alignment between vision and language, enabling precise and harmonized changes by understanding regions within global image context.", "motivation": "Most existing approaches treat image regions in isolation, relying solely on local cues without accounting for how each part contributes to the overall visual and semantic composition, resulting in inconsistent edits, unnatural transitions, or loss of coherence.", "method": "The framework introduces a dual-level guidance mechanism: regions are represented with full-image context and aligned with detailed region-level descriptions, while the entire image is simultaneously matched to a comprehensive scene-level description generated by a large vision-language model.", "result": "Experiments show that the method produces more coherent and instruction-aligned results compared to existing approaches.", "conclusion": "The proposed Region in Context framework enables precise and harmonized image editing by performing multilevel semantic alignment between vision and language, with regions understanding their role within the global image context."}}
{"id": "2510.16250", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16250", "abs": "https://arxiv.org/abs/2510.16250", "authors": ["Danil Akhtiamov", "Reza Ghane", "Babak Hassibi"], "title": "One-Bit Quantization for Random Features Models", "comment": null, "summary": "Recent advances in neural networks have led to significant computational and\nmemory demands, spurring interest in one-bit weight compression to enable\nefficient inference on resource-constrained devices. However, the theoretical\nunderpinnings of such compression remain poorly understood. We address this gap\nby analyzing one-bit quantization in the Random Features model, a simplified\nframework that corresponds to neural networks with random representations. We\nprove that, asymptotically, quantizing weights of all layers except the last\nincurs no loss in generalization error, compared to the full precision random\nfeatures model. Our findings offer theoretical insights into neural network\ncompression. We also demonstrate empirically that one-bit quantization leads to\nsignificant inference speed ups for the Random Features models even on a laptop\nGPU, confirming the practical benefits of our work. Additionally, we provide an\nasymptotically precise characterization of the generalization error for Random\nFeatures with an arbitrary number of layers. To the best of our knowledge, our\nanalysis yields more general results than all previous works in the related\nliterature.", "AI": {"tldr": "Theoretical analysis shows one-bit weight quantization in neural networks (using Random Features model) incurs no asymptotic loss in generalization error compared to full precision models, while providing significant inference speedups.", "motivation": "Address the theoretical gap in understanding one-bit weight compression for neural networks, as computational and memory demands increase for efficient inference on resource-constrained devices.", "method": "Analyze one-bit quantization in the Random Features model (neural networks with random representations), proving asymptotic results about generalization error and providing empirical validation.", "result": "Proved that quantizing all layers except the last incurs no asymptotic loss in generalization error. Demonstrated significant inference speedups on laptop GPU. Provided asymptotically precise characterization of generalization error for arbitrary number of layers.", "conclusion": "One-bit quantization is theoretically sound for neural network compression, offering no loss in generalization performance while enabling practical inference speed improvements, with more general results than previous literature."}}
{"id": "2510.16776", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16776", "abs": "https://arxiv.org/abs/2510.16776", "authors": ["Mingzheng Zhang", "Jinfeng Gao", "Dan Xu", "Jiangrui Yu", "Yuhan Qiao", "Lan Chen", "Jin Tang", "Xiao Wang"], "title": "EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation", "comment": null, "summary": "X-ray image-based medical report generation (MRG) is a pivotal area in\nartificial intelligence that can significantly reduce diagnostic burdens for\nclinicians and patient wait times. Existing MRG models predominantly rely on\nLarge Language Models (LLMs) to improve report generation, with limited\nexploration of pre-trained vision foundation models or advanced fine-tuning\ntechniques. Mainstream frameworks either avoid fine-tuning or utilize\nsimplistic methods like LoRA, often neglecting the potential of enhancing\ncross-attention mechanisms. Additionally, while Transformer-based models\ndominate vision-language tasks, non-Transformer architectures, such as the\nMamba network, remain underexplored for medical report generation, presenting a\npromising avenue for future research. In this paper, we propose EMRRG, a novel\nX-ray report generation framework that fine-tunes pre-trained Mamba networks\nusing parameter-efficient methods. Specifically, X-ray images are divided into\npatches, tokenized, and processed by an SSM-based vision backbone for feature\nextraction, with Partial LoRA yielding optimal performance. An LLM with a\nhybrid decoder generates the medical report, enabling end-to-end training and\nachieving strong results on benchmark datasets. Extensive experiments on three\nwidely used benchmark datasets fully validated the effectiveness of our\nproposed strategies for the X-ray MRG. The source code of this paper will be\nreleased on https://github.com/Event-AHU/Medical_Image_Analysis.", "AI": {"tldr": "EMRRG is a novel X-ray medical report generation framework that fine-tunes pre-trained Mamba networks using parameter-efficient methods, achieving strong performance on benchmark datasets.", "motivation": "Existing MRG models rely heavily on LLMs with limited exploration of pre-trained vision foundation models or advanced fine-tuning techniques, and non-Transformer architectures like Mamba networks remain underexplored for medical report generation.", "method": "X-ray images are divided into patches, tokenized, and processed by an SSM-based vision backbone for feature extraction using Partial LoRA. An LLM with hybrid decoder generates medical reports through end-to-end training.", "result": "Extensive experiments on three benchmark datasets fully validated the effectiveness of the proposed strategies for X-ray MRG.", "conclusion": "The EMRRG framework demonstrates that fine-tuning pre-trained Mamba networks with parameter-efficient methods can achieve strong performance in medical report generation, providing a promising alternative to Transformer-based approaches."}}
{"id": "2510.16252", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16252", "abs": "https://arxiv.org/abs/2510.16252", "authors": ["Yuxuan Lu", "Jing Huang", "Hui Liu", "Jiri Gesi", "Yan Han", "Shihan Fu", "Tianqi Zheng", "Dakuo Wang"], "title": "WEBSERV: A Browser-Server Environment for Efficient Training of Reinforcement Learning-based Web Agents at Scale", "comment": null, "summary": "Training and evaluation of Reinforcement Learning (RL) web agents have gained\nincreasing attention, yet a scalable and efficient environment that couples\nrealistic and robust browser-side interaction with controllable server-side\nstate at scale is still missing. Existing environments tend to have one or more\nof the following issues: they overwhelm policy models with excessive and noisy\ncontext; they perform actions non-deterministically without waiting for the UI\nor network to stabilize; or they cannot scale isolated client-server containers\neffectively for parallel RL rollouts. We propose WEBSERV, an environment that\nincludes 1) a compact, site-agnostic browser environment that balances context\nand action complexity, and 2) a scalable RL environment via efficient launching\nand resetting web-servers to enable scalable RL training and evaluation. We\nevaluate WEBSERV on the shopping CMS and Gitlab tasks in WebArena, achieving\nstate-of-the-art single-prompt success rates while cutting launch latency by\n~5x and storage need by ~240x, with a comparable memory footprint, enabling\n200+ concurrent containers on a single host.", "AI": {"tldr": "WEBSERV is a scalable web environment for RL agents that combines compact browser interaction with efficient server management, achieving state-of-the-art performance while significantly reducing latency and storage requirements.", "motivation": "Existing RL web environments have issues with excessive context noise, non-deterministic actions, and poor scalability for parallel training, creating a need for a more efficient and scalable solution.", "method": "WEBSERV includes 1) a compact, site-agnostic browser environment that balances context and action complexity, and 2) scalable RL environment with efficient web-server launching and resetting for parallel training.", "result": "Achieved state-of-the-art single-prompt success rates on WebArena tasks while cutting launch latency by ~5x, storage need by ~240x, and enabling 200+ concurrent containers on a single host with comparable memory footprint.", "conclusion": "WEBSERV provides an effective solution for scalable RL web agent training by addressing key limitations of existing environments through its compact browser interface and efficient server management system."}}
{"id": "2510.16777", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16777", "abs": "https://arxiv.org/abs/2510.16777", "authors": ["Junbo Li", "Weimin Yuan", "Yinuo Wang", "Yue Zeng", "Shihao Shu", "Cai Meng", "Xiangzhi Bai"], "title": "GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation", "comment": null, "summary": "Accurate 6D pose estimation of 3D objects is a fundamental task in computer\nvision, and current research typically predicts the 6D pose by establishing\ncorrespondences between 2D image features and 3D model features. However, these\nmethods often face difficulties with textureless objects and varying\nillumination conditions. To overcome these limitations, we propose GS2POSE, a\nnovel approach for 6D object pose estimation. GS2POSE formulates a pose\nregression algorithm inspired by the principles of Bundle Adjustment (BA). By\nleveraging Lie algebra, we extend the capabilities of 3DGS to develop a\npose-differentiable rendering pipeline, which iteratively optimizes the pose by\ncomparing the input image to the rendered image. Additionally, GS2POSE updates\ncolor parameters within the 3DGS model, enhancing its adaptability to changes\nin illumination. Compared to previous models, GS2POSE demonstrates accuracy\nimprovements of 1.4\\%, 2.8\\% and 2.5\\% on the T-LESS, LineMod-Occlusion and\nLineMod datasets, respectively.", "AI": {"tldr": "GS2POSE is a novel 6D object pose estimation method that uses Bundle Adjustment principles and 3D Gaussian Splatting to create a pose-differentiable rendering pipeline, achieving improved accuracy on textureless objects under varying illumination.", "motivation": "Current 6D pose estimation methods struggle with textureless objects and varying illumination conditions, as they rely on correspondences between 2D image features and 3D model features.", "method": "GS2POSE formulates pose regression using Bundle Adjustment principles, leverages Lie algebra to extend 3DGS capabilities for pose-differentiable rendering, and iteratively optimizes pose by comparing input and rendered images while updating color parameters for illumination adaptation.", "result": "GS2POSE achieves accuracy improvements of 1.4%, 2.8% and 2.5% on T-LESS, LineMod-Occlusion and LineMod datasets respectively compared to previous models.", "conclusion": "The proposed GS2POSE method effectively addresses challenges with textureless objects and varying illumination in 6D pose estimation through its pose-differentiable rendering pipeline and illumination-adaptive color parameter updates."}}
{"id": "2510.16253", "categories": ["cs.LG", "cs.AI", "q-bio.BM", "q-bio.QM", "stat.ML", "I.2.1; J.3"], "pdf": "https://arxiv.org/pdf/2510.16253", "abs": "https://arxiv.org/abs/2510.16253", "authors": ["Arielle Sanford", "Shuo Sun", "Christian B. Mendl"], "title": "Protein Folding with Neural Ordinary Differential Equations", "comment": null, "summary": "Recent advances in protein structure prediction, such as AlphaFold, have\ndemonstrated the power of deep neural architectures like the Evoformer for\ncapturing complex spatial and evolutionary constraints on protein conformation.\nHowever, the depth of the Evoformer, comprising 48 stacked blocks, introduces\nhigh computational costs and rigid layerwise discretization. Inspired by Neural\nOrdinary Differential Equations (Neural ODEs), we propose a continuous-depth\nformulation of the Evoformer, replacing its 48 discrete blocks with a Neural\nODE parameterization that preserves its core attention-based operations. This\ncontinuous-time Evoformer achieves constant memory cost (in depth) via the\nadjoint method, while allowing a principled trade-off between runtime and\naccuracy through adaptive ODE solvers. Benchmarking on protein structure\nprediction tasks, we find that the Neural ODE-based Evoformer produces\nstructurally plausible predictions and reliably captures certain secondary\nstructure elements, such as alpha-helices, though it does not fully replicate\nthe accuracy of the original architecture. However, our model achieves this\nperformance using dramatically fewer resources, just 17.5 hours of training on\na single GPU, highlighting the promise of continuous-depth models as a\nlightweight and interpretable alternative for biomolecular modeling. This work\nopens new directions for efficient and adaptive protein structure prediction\nframeworks.", "AI": {"tldr": "The paper proposes a continuous-depth Evoformer using Neural ODEs to replace the 48 discrete blocks of AlphaFold's Evoformer, achieving constant memory cost and resource efficiency while maintaining structural prediction capabilities.", "motivation": "To address the high computational costs and rigid layerwise discretization of deep neural architectures like AlphaFold's Evoformer (48 blocks), while preserving complex spatial and evolutionary constraints on protein conformation.", "method": "Replace the 48 discrete Evoformer blocks with a Neural ODE parameterization that maintains attention-based operations, using the adjoint method for constant memory cost and adaptive ODE solvers for runtime-accuracy trade-offs.", "result": "The Neural ODE-based Evoformer produces structurally plausible predictions and captures secondary structure elements like alpha-helices, though with slightly reduced accuracy compared to the original architecture. It achieves this with dramatically fewer resources (17.5 hours on single GPU).", "conclusion": "Continuous-depth models offer a promising lightweight and interpretable alternative for biomolecular modeling, opening new directions for efficient and adaptive protein structure prediction frameworks."}}
{"id": "2510.16781", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16781", "abs": "https://arxiv.org/abs/2510.16781", "authors": ["Shihao Ji", "Zihui Song"], "title": "Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features", "comment": null, "summary": "The remarkable zero-shot reasoning capabilities of large-scale Visual\nLanguage Models (VLMs) on static images have yet to be fully translated to the\nvideo domain. Conventional video understanding models often rely on extensive,\ntask-specific training on annotated datasets, a process that is both costly and\nlimited in scalability. This paper introduces a novel, training-free framework\nfor video understanding that circumvents end-to-end training by synergistically\ncombining the rich semantic priors of pre-trained VLMs with classic machine\nlearning algorithms for pattern discovery. Our core idea is to reframe video\nunderstanding as a self-supervised spatio-temporal clustering problem within a\nhigh-dimensional semantic feature space. The proposed pipeline first transforms\na video stream into a semantic feature trajectory using the frozen visual\nencoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal\nSegmentation (KTS), a robust machine learning technique, to partition the\ncontinuous feature stream into discrete, semantically coherent event segments.\nThese segments are then subjected to unsupervised density-based clustering to\nidentify recurring macroscopic scenes and themes throughout the video. By\nselecting representative keyframes from each discovered cluster and leveraging\nthe VLM's generative capabilities for textual description, our framework\nautomatically produces a structured, multi-modal summary of the video content.\nThis approach provides an effective, interpretable, and model-agnostic pathway\nfor zero-shot, automated structural analysis of video content.", "AI": {"tldr": "A training-free framework for video understanding that combines pre-trained VLMs with machine learning algorithms to perform spatio-temporal clustering and generate structured video summaries without task-specific training.", "motivation": "Current video understanding models require extensive annotated datasets and task-specific training, which is costly and lacks scalability. The goal is to leverage zero-shot reasoning capabilities of VLMs for video understanding without end-to-end training.", "method": "Transform video into semantic feature trajectories using frozen VLM encoders, apply Kernel Temporal Segmentation (KTS) to partition videos into event segments, use unsupervised density-based clustering to identify recurring scenes, and generate summaries using VLM's generative capabilities.", "result": "The framework successfully performs automated structural analysis of video content in a zero-shot manner, producing interpretable multi-modal summaries without requiring training on video datasets.", "conclusion": "This approach provides an effective, interpretable, and model-agnostic pathway for zero-shot video understanding by synergistically combining pre-trained VLMs with classic machine learning algorithms for pattern discovery."}}
{"id": "2510.16289", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16289", "abs": "https://arxiv.org/abs/2510.16289", "authors": ["Yoonho Lee", "Junseok Lee", "Sangwoo Seo", "Sungwon Kim", "Yeongmin Kim", "Chanyoung Park"], "title": "Disentangling Hyperedges through the Lens of Category Theory", "comment": "Accepted to NeurIPS 2025", "summary": "Despite the promising results of disentangled representation learning in\ndiscovering latent patterns in graph-structured data, few studies have explored\ndisentanglement for hypergraph-structured data. Integrating hyperedge\ndisentanglement into hypergraph neural networks enables models to leverage\nhidden hyperedge semantics, such as unannotated relations between nodes, that\nare associated with labels. This paper presents an analysis of hyperedge\ndisentanglement from a category-theoretical perspective and proposes a novel\ncriterion for disentanglement derived from the naturality condition. Our\nproof-of-concept model experimentally showed the potential of the proposed\ncriterion by successfully capturing functional relations of genes (nodes) in\ngenetic pathways (hyperedges).", "AI": {"tldr": "This paper proposes a novel criterion for hyperedge disentanglement in hypergraph neural networks using category theory, and demonstrates its effectiveness in capturing gene functional relations in genetic pathways.", "motivation": "Few studies have explored disentangled representation learning for hypergraph-structured data, despite its potential to reveal hidden hyperedge semantics and unannotated node relations that are associated with labels.", "method": "The paper analyzes hyperedge disentanglement from a category-theoretical perspective and proposes a novel disentanglement criterion derived from the naturality condition, implementing a proof-of-concept model.", "result": "The experimental results showed that the proposed criterion successfully captured functional relations of genes (nodes) in genetic pathways (hyperedges), demonstrating the potential of the approach.", "conclusion": "The category-theoretical approach to hyperedge disentanglement provides an effective framework for discovering latent patterns in hypergraph-structured data, particularly for capturing meaningful semantic relations in complex systems like genetic pathways."}}
{"id": "2510.16785", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16785", "abs": "https://arxiv.org/abs/2510.16785", "authors": ["Jiazhen Liu", "Long Chen"], "title": "Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs", "comment": null, "summary": "Integrating diverse visual capabilities into a unified model is a significant\ntrend in Multimodal Large Language Models (MLLMs). Among these, the inclusion\nof segmentation poses a distinct set of challenges. To equip MLLMs with\npixel-level segmentation abilities, prevailing methods require finetuning the\nmodel to produce specific outputs compatible with a mask decoder. This process\ntypically alters the model's output space and compromises its intrinsic\ngeneralization, which undermines the goal of building a unified model. We\nintroduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel\nplug-and-play solution. LENS attaches a lightweight, trainable head to a\ncompletely frozen MLLM. By refining the spatial cues embedded in attention\nmaps, LENS extracts keypoints and describes them into point-wise features\ndirectly compatible with the mask decoder. Extensive experiments validate our\napproach: LENS achieves segmentation performance competitive with or superior\nto that of retraining-based methods. Crucially, it does so while fully\npreserving the MLLM's generalization capabilities, which are significantly\ndegraded by finetuning approaches. As such, the attachable design of LENS\nestablishes an efficient and powerful paradigm for extending MLLMs, paving the\nway for truly multi-talented, unified models.", "AI": {"tldr": "LENS is a plug-and-play method that enables MLLMs to perform pixel-level segmentation without finetuning, preserving the model's generalization by using attention maps to extract keypoints compatible with mask decoders.", "motivation": "Current methods for adding segmentation to MLLMs require finetuning, which alters the model's output space and compromises its intrinsic generalization, undermining the goal of unified multimodal models.", "method": "Attaches a lightweight trainable head to a frozen MLLM, refines spatial cues from attention maps to extract keypoints, and generates point-wise features directly compatible with mask decoders.", "result": "Achieves segmentation performance competitive with or superior to retraining-based methods while fully preserving the MLLM's generalization capabilities that are degraded by finetuning approaches.", "conclusion": "LENS establishes an efficient paradigm for extending MLLMs without compromising their core capabilities, paving the way for truly multi-talented unified models."}}
{"id": "2510.16292", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16292", "abs": "https://arxiv.org/abs/2510.16292", "authors": ["Yutong Wang", "Haiyu Wang", "Sai Qian Zhang"], "title": "QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models", "comment": "Accepted as Spotlight paper by NeurIPS 2025", "summary": "Vision-Language Models (VLMs) are integral to tasks such as image captioning\nand visual question answering, but their high computational cost, driven by\nlarge memory footprints and processing time, limits their scalability and\nreal-time applicability. In this work, we propose leveraging Singular-Value\nDecomposition (SVD) over the joint query (Q), key (K), and value (V) weight\nmatrices to reduce KV cache size and computational overhead. We in addition\nintroduce an efficient rank allocation strategy that dynamically adjusts the\nSVD rank based on its impact on VLM accuracy, achieving a significant reduction\nin both memory usage and computational cost. Finally, we extend this approach\nby applying quantization to both VLM weights and activations, resulting in a\nhighly efficient VLM. Our method outperforms previous approaches that rely\nsolely on quantization or SVD by achieving more than $10\\%$ accuracy\nimprovement while consuming less hardware cost, making it better for real-time\ndeployment on resource-constrained devices. We open source our code at\n\\href{https://github.com/SAI-Lab-NYU/QSVD}{\\texttt{https://github.com/SAI-Lab-NYU/QSVD}}.", "AI": {"tldr": "Proposes QSVD method combining SVD compression and quantization to reduce Vision-Language Models' computational cost while maintaining accuracy.", "motivation": "VLMs have high computational costs that limit scalability and real-time deployment on resource-constrained devices.", "method": "Uses SVD on QKV weight matrices to reduce KV cache size, introduces dynamic rank allocation strategy, and applies quantization to weights and activations.", "result": "Achieves >10% accuracy improvement over quantization-only or SVD-only approaches while consuming less hardware cost.", "conclusion": "QSVD enables efficient VLM deployment on resource-constrained devices, outperforming previous methods in accuracy and efficiency."}}
{"id": "2510.16790", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16790", "abs": "https://arxiv.org/abs/2510.16790", "authors": ["Sara Hatami Rostami", "Behrooz Nasihatkon"], "title": "Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry", "comment": "7 pages, 3 figures", "summary": "This paper presents a fully unsupervised approach for binary road\nsegmentation (road vs. non-road), eliminating the reliance on costly manually\nlabeled datasets. The method leverages scene geometry and temporal cues to\ndistinguish road from non-road regions. Weak labels are first generated from\ngeometric priors, marking pixels above the horizon as non-road and a predefined\nquadrilateral in front of the vehicle as road. In a refinement stage, temporal\nconsistency is enforced by tracking local feature points across frames and\npenalizing inconsistent label assignments using mutual information\nmaximization. This enhances both precision and temporal stability. On the\nCityscapes dataset, the model achieves an Intersection-over-Union (IoU) of\n0.82, demonstrating high accuracy with a simple design. These findings\ndemonstrate the potential of combining geometric constraints and temporal\nconsistency for scalable unsupervised road segmentation in autonomous driving.", "AI": {"tldr": "Unsupervised binary road segmentation using geometric priors and temporal consistency, achieving 0.82 IoU on Cityscapes without manual labels.", "motivation": "Eliminate reliance on costly manually labeled datasets for road segmentation in autonomous driving by developing a fully unsupervised approach.", "method": "Use geometric priors to generate weak labels (pixels above horizon as non-road, quadrilateral in front as road), then refine with temporal consistency through feature tracking and mutual information maximization.", "result": "Achieves 0.82 Intersection-over-Union (IoU) on Cityscapes dataset, demonstrating high accuracy with simple design.", "conclusion": "Combining geometric constraints and temporal consistency enables scalable unsupervised road segmentation for autonomous driving applications."}}
{"id": "2510.16306", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16306", "abs": "https://arxiv.org/abs/2510.16306", "authors": ["Xin Wang", "Yu Wang", "Yunchao Liu", "Jens Meiler", "Tyler Derr"], "title": "Scaffold-Aware Generative Augmentation and Reranking for Enhanced Virtual Screening", "comment": null, "summary": "Ligand-based virtual screening (VS) is an essential step in drug discovery\nthat evaluates large chemical libraries to identify compounds that potentially\nbind to a therapeutic target. However, VS faces three major challenges: class\nimbalance due to the low active rate, structural imbalance among active\nmolecules where certain scaffolds dominate, and the need to identify\nstructurally diverse active compounds for novel drug development. We introduce\nScaffAug, a scaffold-aware VS framework that addresses these challenges through\nthree modules. The augmentation module first generates synthetic data\nconditioned on scaffolds of actual hits using generative AI, specifically a\ngraph diffusion model. This helps mitigate the class imbalance and furthermore\nthe structural imbalance, due to our proposed scaffold-aware sampling\nalgorithm, designed to produce more samples for active molecules with\nunderrepresented scaffolds. A model-agnostic self-training module is then used\nto safely integrate the generated synthetic data from our augmentation module\nwith the original labeled data. Lastly, we introduce a reranking module that\nimproves VS by enhancing scaffold diversity in the top recommended set of\nmolecules, while still maintaining and even enhancing the overall general\nperformance of identifying novel, active compounds. We conduct comprehensive\ncomputational experiments across five target classes, comparing ScaffAug\nagainst existing baseline methods by reporting the performance of multiple\nevaluation metrics and performing ablation studies on ScaffAug. Overall, this\nwork introduces novel perspectives on effectively enhancing VS by leveraging\ngenerative augmentations, reranking, and general scaffold-awareness.", "AI": {"tldr": "ScaffAug is a scaffold-aware virtual screening framework that addresses class imbalance, structural imbalance, and diversity needs through generative AI augmentation, self-training, and reranking modules.", "motivation": "Virtual screening faces three major challenges: class imbalance (low active rate), structural imbalance (certain scaffolds dominate), and the need to identify structurally diverse active compounds for novel drug development.", "method": "Three-module framework: 1) Augmentation module using graph diffusion model to generate synthetic data conditioned on scaffolds; 2) Model-agnostic self-training to integrate synthetic and original data; 3) Reranking module to enhance scaffold diversity in top recommendations.", "result": "Comprehensive computational experiments across five target classes showed ScaffAug outperforms baseline methods in multiple evaluation metrics while maintaining/enhancing performance in identifying novel active compounds.", "conclusion": "ScaffAug provides novel perspectives on enhancing virtual screening through generative augmentations, reranking, and scaffold-awareness to address fundamental challenges in drug discovery."}}
{"id": "2510.16791", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16791", "abs": "https://arxiv.org/abs/2510.16791", "authors": ["Chengxuan Zhu", "Shuchen Weng", "Jiacong Fang", "Peixuan Zhang", "Si Li", "Chao Xu", "Boxin Shi"], "title": "Personalized Image Filter: Mastering Your Photographic Style", "comment": null, "summary": "Photographic style, as a composition of certain photographic concepts, is the\ncharm behind renowned photographers. But learning and transferring photographic\nstyle need a profound understanding of how the photo is edited from the unknown\noriginal appearance. Previous works either fail to learn meaningful\nphotographic concepts from reference images, or cannot preserve the content of\nthe content image. To tackle these issues, we proposed a Personalized Image\nFilter (PIF). Based on a pretrained text-to-image diffusion model, the\ngenerative prior enables PIF to learn the average appearance of photographic\nconcepts, as well as how to adjust them according to text prompts. PIF then\nlearns the photographic style of reference images with the textual inversion\ntechnique, by optimizing the prompts for the photographic concepts. PIF shows\noutstanding performance in extracting and transferring various kinds of\nphotographic style. Project page: https://pif.pages.dev/", "AI": {"tldr": "PIF (Personalized Image Filter) is a novel method that uses a pretrained text-to-image diffusion model and textual inversion to learn and transfer photographic styles from reference images while preserving content.", "motivation": "Previous methods either fail to learn meaningful photographic concepts from reference images or cannot preserve the content of the original image, limiting effective photographic style transfer.", "method": "Based on a pretrained text-to-image diffusion model, PIF uses textual inversion technique to optimize prompts for photographic concepts, learning both the average appearance of concepts and how to adjust them according to text prompts.", "result": "PIF demonstrates outstanding performance in extracting and transferring various kinds of photographic style while maintaining content preservation.", "conclusion": "The proposed PIF method effectively addresses the limitations of previous approaches by successfully learning photographic concepts and transferring styles while preserving image content."}}
{"id": "2510.16311", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16311", "abs": "https://arxiv.org/abs/2510.16311", "authors": ["Daohan Su", "Yang Zhang", "Xunkai Li", "Rong-Hua Li", "Guoren Wang"], "title": "Toward General Digraph Contrastive Learning: A Dual Spatial Perspective", "comment": null, "summary": "Graph Contrastive Learning (GCL) has emerged as a powerful tool for\nextracting consistent representations from graphs, independent of labeled\ninformation. However, existing methods predominantly focus on undirected\ngraphs, disregarding the pivotal directional information that is fundamental\nand indispensable in real-world networks (e.g., social networks and\nrecommendations).In this paper, we introduce S2-DiGCL, a novel framework that\nemphasizes spatial insights from complex and real domain perspectives for\ndirected graph (digraph) contrastive learning. From the complex-domain\nperspective, S2-DiGCL introduces personalized perturbations into the magnetic\nLaplacian to adaptively modulate edge phases and directional semantics. From\nthe real-domain perspective, it employs a path-based subgraph augmentation\nstrategy to capture fine-grained local asymmetries and topological\ndependencies. By jointly leveraging these two complementary spatial views,\nS2-DiGCL constructs high-quality positive and negative samples, leading to more\ngeneral and robust digraph contrastive learning. Extensive experiments on 7\nreal-world digraph datasets demonstrate the superiority of our approach,\nachieving SOTA performance with 4.41% improvement in node classification and\n4.34% in link prediction under both supervised and unsupervised settings.", "AI": {"tldr": "S2-DiGCL is a novel graph contrastive learning framework for directed graphs that combines complex-domain magnetic Laplacian perturbations and real-domain path-based subgraph augmentation to capture directional information and spatial asymmetries.", "motivation": "Existing graph contrastive learning methods mainly focus on undirected graphs and ignore directional information, which is crucial in real-world networks like social networks and recommendation systems.", "method": "Uses personalized perturbations in magnetic Laplacian to modulate edge phases and directional semantics from complex-domain perspective, and employs path-based subgraph augmentation to capture local asymmetries and topological dependencies from real-domain perspective.", "result": "Achieves state-of-the-art performance with 4.41% improvement in node classification and 4.34% in link prediction across 7 real-world digraph datasets under both supervised and unsupervised settings.", "conclusion": "S2-DiGCL effectively captures directional information through complementary spatial views, leading to more general and robust directed graph contrastive learning."}}
{"id": "2510.16800", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.16800", "abs": "https://arxiv.org/abs/2510.16800", "authors": ["Zhenpeng Zhang", "Yi Wang", "Shanglei Chai", "Yingying Liu", "Zekai Xie", "Wenhao Huang", "Pengyu Li", "Zipei Luo", "Dajiang Lu", "Yibin Tian"], "title": "An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting", "comment": null, "summary": "Lychee is a high-value subtropical fruit. The adoption of vision-based\nharvesting robots can significantly improve productivity while reduce reliance\non labor. High-quality data are essential for developing such harvesting\nrobots. However, there are currently no consistently and comprehensively\nannotated open-source lychee datasets featuring fruits in natural growing\nenvironments. To address this, we constructed a dataset to facilitate lychee\ndetection and maturity classification. Color (RGB) images were acquired under\ndiverse weather conditions, and at different times of the day, across multiple\nlychee varieties, such as Nuomici, Feizixiao, Heiye, and Huaizhi. The dataset\nencompasses three different ripeness stages and contains 11,414 images,\nconsisting of 878 raw RGB images, 8,780 augmented RGB images, and 1,756 depth\nimages. The images are annotated with 9,658 pairs of lables for lychee\ndetection and maturity classification. To improve annotation consistency, three\nindividuals independently labeled the data, and their results were then\naggregated and verified by a fourth reviewer. Detailed statistical analyses\nwere done to examine the dataset. Finally, we performed experiments using three\nrepresentative deep learning models to evaluate the dataset. It is publicly\navailable for academic", "AI": {"tldr": "Created a comprehensive lychee dataset with 11,414 images (RGB and depth) for fruit detection and maturity classification, featuring multiple varieties and ripeness stages, with consistent annotations validated by multiple reviewers.", "motivation": "There are no consistently annotated open-source lychee datasets for developing vision-based harvesting robots, which could improve productivity and reduce labor dependency.", "method": "Collected color (RGB) images under diverse conditions across multiple lychee varieties, used data augmentation, depth imaging, and implemented a multi-reviewer annotation process with statistical analysis and evaluation using three deep learning models.", "result": "Produced a dataset with 11,414 images (878 raw RGB, 8,780 augmented RGB, 1,756 depth) annotated with 9,658 label pairs for detection and maturity classification across three ripeness stages.", "conclusion": "The dataset is publicly available for academic use and addresses the gap in annotated lychee datasets for developing harvesting robots."}}
{"id": "2510.16322", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16322", "abs": "https://arxiv.org/abs/2510.16322", "authors": ["Mo Zhou", "Haoyang Ma", "Rong Ge"], "title": "Memorizing Long-tail Data Can Help Generalization Through Composition", "comment": "30 pages", "summary": "Deep learning has led researchers to rethink the relationship between\nmemorization and generalization. In many settings, memorization does not hurt\ngeneralization due to implicit regularization and may help by memorizing\nlong-tailed examples. In this paper, we consider the synergy between\nmemorization and simple composition -- the ability to make correct prediction\non a combination of long-tailed features. Theoretically, we show that for a\nlinear setting, memorization together with composition can help the model make\ncorrect predictions on rare test examples that require a combination of\nlong-tailed features, even if such combinations were never observed in the\ntraining data. Experiments on neural network architecture on simple data show\nthat the theoretical insight extends beyond the linear setting, and we further\nobserve that the composition capability of the model depends on its\narchitecture.", "AI": {"tldr": "Memorization combined with composition helps models predict rare test examples with unseen combinations of long-tailed features, even in linear settings.", "motivation": "To explore the synergy between memorization and composition in deep learning, particularly how memorizing long-tailed examples can aid generalization through composition of features.", "method": "Theoretical analysis in a linear setting and experiments with neural network architectures on simple data to validate the insights.", "result": "Memorization with composition enables correct predictions on rare test examples with unseen combinations of long-tailed features; composition capability varies with model architecture.", "conclusion": "Memorization and composition synergistically enhance generalization, allowing models to handle rare feature combinations not seen during training, with architecture influencing composition effectiveness."}}
{"id": "2510.16822", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16822", "abs": "https://arxiv.org/abs/2510.16822", "authors": ["Yahia Battach", "Abdulwahab Felemban", "Faizan Farooq Khan", "Yousef A. Radwan", "Xiang Li", "Fabio Marchese", "Sara Beery", "Burton H. Jones", "Francesca Benzoni", "Mohamed Elhoseiny"], "title": "ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification", "comment": null, "summary": "Coral reefs are rapidly declining due to anthropogenic pressures such as\nclimate change, underscoring the urgent need for scalable, automated\nmonitoring. We introduce ReefNet, a large public coral reef image dataset with\npoint-label annotations mapped to the World Register of Marine Species (WoRMS).\nReefNet aggregates imagery from 76 curated CoralNet sources and an additional\nsite from Al Wajh in the Red Sea, totaling approximately 925000 genus-level\nhard coral annotations with expert-verified labels. Unlike prior datasets,\nwhich are often limited by size, geography, or coarse labels and are not\nML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global\nscale to WoRMS. We propose two evaluation settings: (i) a within-source\nbenchmark that partitions each source's images for localized evaluation, and\n(ii) a cross-source benchmark that withholds entire sources to test domain\ngeneralization. We analyze both supervised and zero-shot classification\nperformance on ReefNet and find that while supervised within-source performance\nis promising, supervised performance drops sharply across domains, and\nperformance is low across the board for zero-shot models, especially for rare\nand visually similar genera. This provides a challenging benchmark intended to\ncatalyze advances in domain generalization and fine-grained coral\nclassification. We will release our dataset, benchmarking code, and pretrained\nmodels to advance robust, domain-adaptive, global coral reef monitoring and\nconservation.", "AI": {"tldr": "ReefNet is a large public coral reef image dataset with fine-grained genus-level annotations mapped to WoRMS, providing challenging benchmarks for domain generalization and fine-grained coral classification.", "motivation": "Coral reefs are rapidly declining due to climate change, creating urgent need for scalable automated monitoring. Existing datasets are limited by size, geography, coarse labels, and lack ML-readiness.", "method": "Aggregated imagery from 76 curated CoralNet sources and Al Wajh site in Red Sea, totaling ~925K genus-level hard coral annotations with expert-verified labels mapped to WoRMS. Proposed two evaluation settings: within-source and cross-source benchmarks.", "result": "Supervised within-source performance is promising but drops sharply across domains. Zero-shot models perform poorly across the board, especially for rare and visually similar genera.", "conclusion": "ReefNet provides a challenging benchmark to catalyze advances in domain generalization and fine-grained coral classification, supporting robust global coral reef monitoring and conservation."}}
{"id": "2510.16350", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16350", "abs": "https://arxiv.org/abs/2510.16350", "authors": ["Shule Hao", "Junpeng Bao", "Wenli Li"], "title": "MGTS-Net: Exploring Graph-Enhanced Multimodal Fusion for Augmented Time Series Forecasting", "comment": null, "summary": "Recent research in time series forecasting has explored integrating\nmultimodal features into models to improve accuracy. However, the accuracy of\nsuch methods is constrained by three key challenges: inadequate extraction of\nfine-grained temporal patterns, suboptimal integration of multimodal\ninformation, and limited adaptability to dynamic multi-scale features. To\naddress these problems, we propose MGTS-Net, a Multimodal Graph-enhanced\nNetwork for Time Series forecasting. The model consists of three core\ncomponents: (1) a Multimodal Feature Extraction layer (MFE), which optimizes\nfeature encoders according to the characteristics of temporal, visual, and\ntextual modalities to extract temporal features of fine-grained patterns; (2) a\nMultimodal Feature Fusion layer (MFF), which constructs a heterogeneous graph\nto model intra-modal temporal dependencies and cross-modal alignment\nrelationships and dynamically aggregates multimodal knowledge; (3) a\nMulti-Scale Prediction layer (MSP), which adapts to multi-scale features by\ndynamically weighting and fusing the outputs of short-term, medium-term, and\nlong-term predictors. Extensive experiments demonstrate that MGTS-Net exhibits\nexcellent performance with light weight and high efficiency. Compared with\nother state-of-the-art baseline models, our method achieves superior\nperformance, validating the superiority of the proposed methodology.", "AI": {"tldr": "MGTS-Net is a multimodal graph-enhanced network for time series forecasting that addresses challenges in fine-grained temporal pattern extraction, multimodal integration, and multi-scale feature adaptation through three core components.", "motivation": "Current multimodal time series forecasting methods face limitations in extracting fine-grained temporal patterns, optimally integrating multimodal information, and adapting to dynamic multi-scale features.", "method": "Three core components: (1) Multimodal Feature Extraction layer with optimized encoders for temporal, visual, and textual modalities; (2) Multimodal Feature Fusion layer using heterogeneous graphs to model intra-modal dependencies and cross-modal alignments; (3) Multi-Scale Prediction layer with dynamic weighting of short-term, medium-term, and long-term predictors.", "result": "Extensive experiments show MGTS-Net achieves excellent performance with lightweight and high efficiency, outperforming state-of-the-art baseline models.", "conclusion": "The proposed MGTS-Net methodology demonstrates superiority in multimodal time series forecasting through its effective feature extraction, fusion, and multi-scale prediction capabilities."}}
{"id": "2510.16832", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16832", "abs": "https://arxiv.org/abs/2510.16832", "authors": ["Abdur Rahman", "Mohammad Marufuzzaman", "Jason Street", "Haifeng Wang", "Veera G. Gude", "Randy Buchanan"], "title": "Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction", "comment": null, "summary": "Accurate and quick prediction of wood chip moisture content is critical for\noptimizing biofuel production and ensuring energy efficiency. The current\nwidely used direct method (oven drying) is limited by its longer processing\ntime and sample destructiveness. On the other hand, existing indirect methods,\nincluding near-infrared spectroscopy-based, electrical capacitance-based, and\nimage-based approaches, are quick but not accurate when wood chips come from\nvarious sources. Variability in the source material can alter data\ndistributions, undermining the performance of data-driven models. Therefore,\nthere is a need for a robust approach that effectively mitigates the impact of\nsource variability. Previous studies show that manually extracted texture\nfeatures have the potential to predict wood chip moisture class. Building on\nthis, in this study, we conduct a comprehensive analysis of five distinct\ntexture feature types extracted from wood chip images to predict moisture\ncontent. Our findings reveal that a combined feature set incorporating all five\ntexture features achieves an accuracy of 95% and consistently outperforms\nindividual texture features in predicting moisture content. To ensure robust\nmoisture prediction, we propose a domain adaptation method named AdaptMoist\nthat utilizes the texture features to transfer knowledge from one source of\nwood chip data to another, addressing variability across different domains. We\nalso proposed a criterion for model saving based on adjusted mutual\ninformation. The AdaptMoist method improves prediction accuracy across domains\nby 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted\nmodels. These results highlight the effectiveness of AdaptMoist as a robust\nsolution for wood chip moisture content estimation across domains, making it a\npotential solution for wood chip-reliant industries.", "AI": {"tldr": "This paper proposes AdaptMoist, a domain adaptation method using texture features from wood chip images to predict moisture content across different wood sources, achieving 80% accuracy compared to 57% for non-adapted models.", "motivation": "Current moisture prediction methods for wood chips are either slow/destructive (oven drying) or inaccurate across varied sources (indirect methods). Source variability undermines data-driven models, requiring robust approaches that handle domain shifts.", "method": "Comprehensive analysis of five texture feature types from wood chip images, combined into feature sets. Proposed AdaptMoist domain adaptation method transfers knowledge between wood chip sources using texture features, with model saving based on adjusted mutual information.", "result": "Combined texture features achieved 95% accuracy for moisture prediction. AdaptMoist improved cross-domain prediction accuracy by 23% (from 57% to 80% average accuracy), demonstrating effectiveness across different wood chip domains.", "conclusion": "AdaptMoist provides a robust solution for wood chip moisture content estimation across varying sources, making it suitable for wood chip-reliant industries by effectively addressing domain variability through texture-based domain adaptation."}}
{"id": "2510.16356", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16356", "abs": "https://arxiv.org/abs/2510.16356", "authors": ["Fuqun Han", "Stanley Osher", "Wuchen Li"], "title": "Sparse Transformer Architectures via Regularized Wasserstein Proximal Operator with $L_1$ Prior", "comment": null, "summary": "In this work, we propose a sparse transformer architecture that incorporates\nprior information about the underlying data distribution directly into the\ntransformer structure of the neural network. The design of the model is\nmotivated by a special optimal transport problem, namely the regularized\nWasserstein proximal operator, which admits a closed-form solution and turns\nout to be a special representation of transformer architectures. Compared with\nclassical flow-based models, the proposed approach improves the convexity\nproperties of the optimization problem and promotes sparsity in the generated\nsamples. Through both theoretical analysis and numerical experiments, including\napplications in generative modeling and Bayesian inverse problems, we\ndemonstrate that the sparse transformer achieves higher accuracy and faster\nconvergence to the target distribution than classical neural ODE-based methods.", "AI": {"tldr": "A sparse transformer architecture that incorporates prior data distribution information via optimal transport theory, improving convexity and sparsity compared to classical flow-based models.", "motivation": "To incorporate prior information about data distribution directly into transformer architecture and improve upon classical flow-based models by enhancing convexity properties and promoting sparsity.", "method": "Proposes a sparse transformer architecture motivated by regularized Wasserstein proximal operator from optimal transport theory, which has closed-form solution and represents transformer architectures.", "result": "Achieves higher accuracy and faster convergence to target distribution than classical neural ODE-based methods in generative modeling and Bayesian inverse problems.", "conclusion": "The sparse transformer architecture, grounded in optimal transport theory, provides improved performance over traditional methods while promoting sparsity in generated samples."}}
{"id": "2510.16833", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2510.16833", "abs": "https://arxiv.org/abs/2510.16833", "authors": ["Xiangyu Mu", "Dongliang Zhou", "Jie Hou", "Haijun Zhang", "Weili Guan"], "title": "From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display", "comment": null, "summary": "Mannequin-based clothing displays offer a cost-effective alternative to\nreal-model showcases for online fashion presentation, but lack realism and\nexpressive detail. To overcome this limitation, we introduce a new task called\nmannequin-to-human (M2H) video generation, which aims to synthesize\nidentity-controllable, photorealistic human videos from footage of mannequins.\nWe propose M2HVideo, a pose-aware and identity-preserving video generation\nframework that addresses two key challenges: the misalignment between head and\nbody motion, and identity drift caused by temporal modeling. In particular,\nM2HVideo incorporates a dynamic pose-aware head encoder that fuses facial\nsemantics with body pose to produce consistent identity embeddings across\nframes. To address the loss of fine facial details due to latent space\ncompression, we introduce a mirror loss applied in pixel space through a\ndenoising diffusion implicit model (DDIM)-based one-step denoising.\nAdditionally, we design a distribution-aware adapter that aligns statistical\ndistributions of identity and clothing features to enhance temporal coherence.\nExtensive experiments on the UBC fashion dataset, our self-constructed ASOS\ndataset, and the newly collected MannequinVideos dataset captured on-site\ndemonstrate that M2HVideo achieves superior performance in terms of clothing\nconsistency, identity preservation, and video fidelity in comparison to\nstate-of-the-art methods.", "AI": {"tldr": "M2HVideo framework generates photorealistic human videos from mannequin footage by addressing head-body misalignment and identity drift through pose-aware head encoding, mirror loss, and distribution-aware feature alignment.", "motivation": "Mannequin-based clothing displays are cost-effective but lack realism and expressive detail compared to real-model showcases in online fashion presentation.", "method": "Proposes M2HVideo with dynamic pose-aware head encoder, mirror loss in pixel space using DDIM-based denoising, and distribution-aware adapter for feature alignment to enhance temporal coherence.", "result": "Extensive experiments on UBC fashion, ASOS, and MannequinVideos datasets show superior performance in clothing consistency, identity preservation, and video fidelity compared to state-of-the-art methods.", "conclusion": "M2HVideo effectively addresses key challenges in mannequin-to-human video generation, achieving realistic and identity-preserving results for online fashion applications."}}
{"id": "2510.16411", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16411", "abs": "https://arxiv.org/abs/2510.16411", "authors": ["Minh-Khoi Nguyen-Nhat", "Rachel S. Y. Teo", "Laziz Abdullaev", "Maurice Mok", "Viet-Hoang Tran", "Tan Minh Nguyen"], "title": "Modeling Expert Interactions in Sparse Mixture of Experts via Graph Structures", "comment": null, "summary": "Sparse Mixture of Experts (SMoE) has emerged as a promising solution to\nachieving unparalleled scalability in deep learning by decoupling model\nparameter count from computational cost. By activating only a small subset of\nparameters per sample, SMoE enables significant growth in model capacity while\nmaintaining efficiency. However, SMoE struggles to adapt to distributional\nshifts, leading to reduced robustness under data contamination. In this work,\nwe introduce SymphonySMoE, a novel family of SMoE that introduces a social\ngraph to model interactions among experts. This graph-based structure enhances\nthe token routing process, addressing the robustness challenges that are\ninherent in conventional SMoE designs. SymphonySMoE is lightweight, modular,\nand integrates seamlessly with existing SMoE-based models such as the XMoE and\nthe Generalist Language Model. We provide both theoretical analysis and\nempirical evidence demonstrating SymphonySMoE's advantages over baseline SMoE.\nExtensive experiments on language modeling and visual instruction tuning\nvalidate our method's effectiveness. We further highlight the scalability of\nSymphonySMoE to models with 4.2 and 7.4 billion parameters, showcasing its\napplicability in fine-tuning tasks for large-scale systems.", "AI": {"tldr": "SymphonySMoE introduces a social graph structure to enhance Sparse Mixture of Experts (SMoE) models, addressing robustness issues under distribution shifts while maintaining efficiency and scalability.", "motivation": "SMoE enables model scalability by activating only a subset of parameters per sample, but struggles with distributional shifts and reduced robustness under data contamination. The paper aims to solve these robustness challenges in conventional SMoE designs.", "method": "Proposes SymphonySMoE, a novel SMoE family that introduces a social graph to model interactions among experts, enhancing the token routing process. The approach is lightweight, modular, and integrates with existing SMoE-based models like XMoE and Generalist Language Model.", "result": "Extensive experiments on language modeling and visual instruction tuning validate the method's effectiveness. SymphonySMoE scales to models with 4.2 and 7.4 billion parameters and shows advantages over baseline SMoE in both theoretical analysis and empirical evidence.", "conclusion": "SymphonySMoE successfully addresses robustness challenges in SMoE while maintaining scalability and efficiency, making it applicable for fine-tuning tasks in large-scale systems."}}
{"id": "2510.16837", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16837", "abs": "https://arxiv.org/abs/2510.16837", "authors": ["Haofan Ren", "Qingsong Yan", "Ming Lu", "Rongfeng Lu", "Zunjie Zhu"], "title": "2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting", "comment": null, "summary": "Recent advancements in 3D Gaussian Splatting (3DGS) have greatly influenced\nneural fields, as it enables high-fidelity rendering with impressive visual\nquality. However, 3DGS has difficulty accurately representing surfaces. In\ncontrast, 2DGS transforms the 3D volume into a collection of 2D planar Gaussian\ndisks. Despite advancements in geometric fidelity, rendering quality remains\ncompromised, highlighting the challenge of achieving both high-quality\nrendering and precise geometric structures. This indicates that optimizing both\ngeometric and rendering quality in a single training stage is currently\nunfeasible. To overcome this limitation, we present 2DGS-R, a new method that\nuses a hierarchical training approach to improve rendering quality while\nmaintaining geometric accuracy. 2DGS-R first trains the original 2D Gaussians\nwith the normal consistency regularization. Then 2DGS-R selects the 2D\nGaussians with inadequate rendering quality and applies a novel in-place\ncloning operation to enhance the 2D Gaussians. Finally, we fine-tune the 2DGS-R\nmodel with opacity frozen. Experimental results show that compared to the\noriginal 2DGS, our method requires only 1\\% more storage and minimal additional\ntraining time. Despite this negligible overhead, it achieves high-quality\nrendering results while preserving fine geometric structures. These findings\nindicate that our approach effectively balances efficiency with performance,\nleading to improvements in both visual fidelity and geometric reconstruction\naccuracy.", "AI": {"tldr": "2DGS-R is a hierarchical training method that improves rendering quality while maintaining geometric accuracy in 2D Gaussian Splatting, achieving high-quality results with only 1% more storage and minimal training time.", "motivation": "3DGS has difficulty representing surfaces accurately, while 2DGS compromises rendering quality despite better geometric fidelity. The challenge is achieving both high-quality rendering and precise geometric structures simultaneously.", "method": "Uses hierarchical training: first trains 2D Gaussians with normal consistency regularization, then selects poorly rendered Gaussians for in-place cloning operation, and finally fine-tunes with opacity frozen.", "result": "Achieves high-quality rendering results while preserving fine geometric structures with only 1% more storage and minimal additional training time compared to original 2DGS.", "conclusion": "The approach effectively balances efficiency with performance, leading to improvements in both visual fidelity and geometric reconstruction accuracy."}}
{"id": "2510.16440", "categories": ["cs.LG", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.16440", "abs": "https://arxiv.org/abs/2510.16440", "authors": ["Dimitris Stefanopoulos", "Andreas Voskou"], "title": "Colliding with Adversaries at ECML-PKDD 2025 Adversarial Attack Competition 1st Prize Solution", "comment": null, "summary": "This report presents the winning solution for Task 1 of Colliding with\nAdversaries: A Challenge on Robust Learning in High Energy Physics Discovery at\nECML-PKDD 2025. The task required designing an adversarial attack against a\nprovided classification model that maximizes misclassification while minimizing\nperturbations. Our approach employs a multi-round gradient-based strategy that\nleverages the differentiable structure of the model, augmented with random\ninitialization and sample-mixing techniques to enhance effectiveness. The\nresulting attack achieved the best results in perturbation size and fooling\nsuccess rate, securing first place in the competition.", "AI": {"tldr": "Winning solution for adversarial attack competition using multi-round gradient-based strategy with random initialization and sample-mixing techniques.", "motivation": "To design an effective adversarial attack that maximizes misclassification while minimizing perturbations for a high energy physics classification challenge.", "method": "Multi-round gradient-based strategy leveraging the model's differentiable structure, augmented with random initialization and sample-mixing techniques.", "result": "Achieved best results in perturbation size and fooling success rate, securing first place in the competition.", "conclusion": "The proposed gradient-based attack strategy with enhancements proved highly effective for adversarial attacks in high energy physics classification tasks."}}
{"id": "2510.16854", "categories": ["cs.CV", "cs.AI", "68T07", "I.2.10; I.5.4; I.4.6"], "pdf": "https://arxiv.org/pdf/2510.16854", "abs": "https://arxiv.org/abs/2510.16854", "authors": ["Akhila Kambhatla", "Taminul Islam", "Khaled R Ahmed"], "title": "ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification", "comment": "9 pages with 4 figures and 5 tables. This is a preprint submitted to\n  arXiv", "summary": "The escalating threat of weapon-related violence necessitates automated\ndetection systems capable of pixel-level precision for accurate threat\nassessment in real-time security applications. Traditional weapon detection\napproaches rely on object detection frameworks that provide only coarse\nbounding box localizations, lacking the fine-grained segmentation required for\ncomprehensive threat analysis. Furthermore, existing semantic segmentation\nmodels either sacrifice accuracy for computational efficiency or require\nexcessive computational resources incompatible with edge deployment scenarios.\nThis paper presents ArmFormer, a lightweight transformer-based semantic\nsegmentation framework that strategically integrates Convolutional Block\nAttention Module (CBAM) with MixVisionTransformer architecture to achieve\nsuperior accuracy while maintaining computational efficiency suitable for\nresource-constrained edge devices. Our approach combines CBAM-enhanced encoder\nbackbone with attention-integrated hamburger decoder to enable multi-class\nweapon segmentation across five categories: handgun, rifle, knife, revolver,\nand human. Comprehensive experiments demonstrate that ArmFormer achieves\nstate-of-the-art performance with 80.64% mIoU and 89.13% mFscore while\nmaintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M\nparameters, ArmFormer outperforms heavyweight models requiring up to 48x more\ncomputation, establishing it as the optimal solution for deployment on portable\nsecurity cameras, surveillance drones, and embedded AI accelerators in\ndistributed security infrastructure.", "AI": {"tldr": "ArmFormer is a lightweight transformer-based semantic segmentation framework that integrates CBAM with MixVisionTransformer to achieve high-accuracy weapon detection with real-time performance suitable for edge devices.", "motivation": "Traditional weapon detection methods provide only bounding boxes, lacking fine-grained segmentation needed for threat analysis. Existing segmentation models either sacrifice accuracy for efficiency or require excessive computational resources incompatible with edge deployment.", "method": "Strategic integration of Convolutional Block Attention Module (CBAM) with MixVisionTransformer architecture, combining CBAM-enhanced encoder backbone with attention-integrated hamburger decoder for multi-class weapon segmentation across five categories.", "result": "Achieves state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M parameters, outperforms heavyweight models requiring up to 48x more computation.", "conclusion": "ArmFormer establishes itself as the optimal solution for deployment on portable security cameras, surveillance drones, and embedded AI accelerators in distributed security infrastructure."}}
{"id": "2510.16443", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16443", "abs": "https://arxiv.org/abs/2510.16443", "authors": ["Dimitris Stefanopoulos", "Andreas Voskou"], "title": "Colliding with Adversaries at ECML-PKDD 2025 Model Robustness Competition 1st Prize Solution", "comment": null, "summary": "This report presents the winning solution for Task 2 of Colliding with\nAdversaries: A Challenge on Robust Learning in High Energy Physics Discovery at\nECML-PKDD 2025. The goal of the challenge was to design and train a robust\nANN-based model capable of achieving high accuracy in a binary classification\ntask on both clean and adversarial data generated with the Random Distribution\nShuffle Attack (RDSA). Our solution consists of two components: a data\ngeneration phase and a robust model training phase. In the first phase, we\nproduced 15 million artificial training samples using a custom methodology\nderived from Random Distribution Shuffle Attack (RDSA). In the second phase, we\nintroduced a robust architecture comprising (i)a Feature Embedding Block with\nshared weights among features of the same type and (ii)a Dense Fusion Tail\nresponsible for the final prediction. Training this architecture on our\nadversarial dataset achieved a mixed accuracy score of 80\\%, exceeding the\nsecond-place solution by two percentage points.", "AI": {"tldr": "Winning solution for Task 2 of ECML-PKDD 2025 challenge that achieved 80% mixed accuracy on clean and adversarial data using a two-phase approach: custom RDSA-based data generation and a robust neural network architecture.", "motivation": "To design a robust ANN-based model that maintains high accuracy on both clean and adversarial data in high energy physics discovery, specifically addressing the Random Distribution Shuffle Attack (RDSA).", "method": "Two-phase approach: 1) Generated 15 million artificial training samples using custom RDSA methodology, 2) Developed robust architecture with Feature Embedding Block (shared weights for same-type features) and Dense Fusion Tail for final prediction.", "result": "Achieved 80% mixed accuracy score on both clean and adversarial data, outperforming the second-place solution by 2 percentage points.", "conclusion": "The proposed two-phase approach combining custom adversarial data generation and specialized neural architecture successfully created a robust model that maintains high performance under adversarial attacks in high energy physics applications."}}
{"id": "2510.16863", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16863", "abs": "https://arxiv.org/abs/2510.16863", "authors": ["Shujian Gao", "Yuan Wang", "Zekuan Yu"], "title": "BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation", "comment": "14 pages, 5 figures", "summary": "Semi-supervised medical image segmentation (SSMIS) seeks to match fully\nsupervised performance while sharply reducing annotation cost. Mainstream SSMIS\nmethods rely on \\emph{label-space consistency}, yet they overlook the equally\ncritical \\emph{representation-space alignment}. Without harmonizing latent\nfeatures, models struggle to learn representations that are both discriminative\nand spatially coherent. To this end, we introduce \\textbf{Bilateral Alignment\nin Representation and Label spaces (BARL)}, a unified framework that couples\ntwo collaborative branches and enforces alignment in both spaces. For\nlabel-space alignment, inspired by co-training and multi-scale decoding, we\ndevise \\textbf{Dual-Path Regularization (DPR)} and \\textbf{Progressively\nCognitive Bias Correction (PCBC)} to impose fine-grained cross-branch\nconsistency while mitigating error accumulation from coarse to fine scales. For\nrepresentation-space alignment, we conduct region-level and lesion-instance\nmatching between branches, explicitly capturing the fragmented, complex\npathological patterns common in medical imagery. Extensive experiments on four\npublic benchmarks and a proprietary CBCT dataset demonstrate that BARL\nconsistently surpasses state-of-the-art SSMIS methods. Ablative studies further\nvalidate the contribution of each component. Code will be released soon.", "AI": {"tldr": "BARL introduces a unified semi-supervised medical image segmentation framework that enforces alignment in both representation and label spaces through collaborative branches, achieving state-of-the-art performance while reducing annotation costs.", "motivation": "Current semi-supervised medical image segmentation methods focus only on label-space consistency while overlooking representation-space alignment, leading to models that struggle to learn discriminative and spatially coherent representations.", "method": "BARL uses two collaborative branches with Dual-Path Regularization (DPR) and Progressively Cognitive Bias Correction (PCBC) for label-space alignment, plus region-level and lesion-instance matching for representation-space alignment.", "result": "Extensive experiments on four public benchmarks and a proprietary CBCT dataset show BARL consistently surpasses state-of-the-art SSMIS methods.", "conclusion": "The proposed bilateral alignment framework effectively addresses the limitations of existing methods by harmonizing both representation and label spaces, with ablative studies confirming the contribution of each component."}}
{"id": "2510.16448", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16448", "abs": "https://arxiv.org/abs/2510.16448", "authors": ["Yongxiang Hua", "Haoyu Cao", "Zhou Tao", "Bocheng Li", "Zihao Wu", "Chaohu Liu", "Linli Xu"], "title": "Input Domain Aware MoE: Decoupling Routing Decisions from Task Optimization in Mixture of Experts", "comment": "ACM MM25", "summary": "Sparse Mixture of Experts (sMoE) has become a pivotal approach for scaling\nlarge vision-language models, offering substantial capacity while maintaining\ncomputational efficiency through dynamic, sparse activation of experts.\nHowever, existing routing mechanisms, typically based on similarity scoring,\nstruggle to effectively capture the underlying input structure. This limitation\nleads to a trade-off between expert specialization and balanced computation,\nhindering both scalability and performance. We propose Input Domain Aware MoE,\na novel routing framework that leverages a probabilistic mixture model to\nbetter partition the input space. By modeling routing probabilities as a\nmixture of distributions, our method enables experts to develop clear\nspecialization boundaries while achieving balanced utilization. Unlike\nconventional approaches, our routing mechanism is trained independently of\ntask-specific objectives, allowing for stable optimization and decisive expert\nassignments. Empirical results on vision-language tasks demonstrate that our\nmethod consistently outperforms existing sMoE approaches, achieving higher task\nperformance and improved expert utilization balance.", "AI": {"tldr": "Input Domain Aware MoE improves sparse Mixture of Experts routing by using a probabilistic mixture model to better partition input space, enabling clearer expert specialization and balanced utilization without task-specific training.", "motivation": "Existing routing mechanisms in sparse Mixture of Experts struggle to capture input structure, creating a trade-off between expert specialization and balanced computation that limits scalability and performance.", "method": "Proposes a novel routing framework using probabilistic mixture model to partition input space, modeling routing probabilities as mixture distributions, with independent training from task objectives for stable optimization.", "result": "Empirical results on vision-language tasks show consistent outperformance over existing sMoE approaches, achieving higher task performance and improved expert utilization balance.", "conclusion": "The Input Domain Aware MoE framework effectively addresses routing limitations in sparse Mixture of Experts, enabling better expert specialization and computational balance while improving overall performance."}}
{"id": "2510.16865", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16865", "abs": "https://arxiv.org/abs/2510.16865", "authors": ["Yuyang Yu", "Zhengwei Chen", "Xuemiao Xu", "Lei Zhang", "Haoxin Yang", "Yongwei Nie", "Shengfeng He"], "title": "Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection", "comment": null, "summary": "3D anomaly detection in point-cloud data is critical for industrial quality\ncontrol, aiming to identify structural defects with high reliability. However,\ncurrent memory bank-based methods often suffer from inconsistent feature\ntransformations and limited discriminative capacity, particularly in capturing\nlocal geometric details and achieving rotation invariance. These limitations\nbecome more pronounced when registration fails, leading to unreliable detection\nresults. We argue that point-cloud registration plays an essential role not\nonly in aligning geometric structures but also in guiding feature extraction\ntoward rotation-invariant and locally discriminative representations. To this\nend, we propose a registration-induced, rotation-invariant feature extraction\nframework that integrates the objectives of point-cloud registration and\nmemory-based anomaly detection. Our key insight is that both tasks rely on\nmodeling local geometric structures and leveraging feature similarity across\nsamples. By embedding feature extraction into the registration learning\nprocess, our framework jointly optimizes alignment and representation learning.\nThis integration enables the network to acquire features that are both robust\nto rotations and highly effective for anomaly detection. Extensive experiments\non the Anomaly-ShapeNet and Real3D-AD datasets demonstrate that our method\nconsistently outperforms existing approaches in effectiveness and\ngeneralizability.", "AI": {"tldr": "A registration-induced rotation-invariant feature extraction framework for 3D anomaly detection that jointly optimizes point-cloud registration and memory-based anomaly detection to overcome limitations of current methods.", "motivation": "Current memory bank-based methods suffer from inconsistent feature transformations and limited discriminative capacity, especially in capturing local geometric details and achieving rotation invariance, which becomes problematic when registration fails.", "method": "Proposes a framework that integrates point-cloud registration and memory-based anomaly detection by embedding feature extraction into the registration learning process, enabling joint optimization of alignment and representation learning.", "result": "Extensive experiments on Anomaly-ShapeNet and Real3D-AD datasets show the method consistently outperforms existing approaches in effectiveness and generalizability.", "conclusion": "The integration of registration and feature extraction enables acquisition of rotation-invariant features that are highly effective for anomaly detection, demonstrating superior performance over current methods."}}
{"id": "2510.16462", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16462", "abs": "https://arxiv.org/abs/2510.16462", "authors": ["Emmanuelle Claeys", "Elena Kerjean", "Jean-Michel Loubes"], "title": "Buzz, Choose, Forget: A Meta-Bandit Framework for Bee-Like Decision Making", "comment": null, "summary": "We introduce a sequential reinforcement learning framework for imitation\nlearning designed to model heterogeneous cognitive strategies in pollinators.\nFocusing on honeybees, our approach leverages trajectory similarity to capture\nand forecast behavior across individuals that rely on distinct strategies: some\nexploiting numerical cues, others drawing on memory, or being influenced by\nenvironmental factors such as weather. Through empirical evaluation, we show\nthat state-of-the-art imitation learning methods often fail in this setting:\nwhen expert policies shift across memory windows or deviate from optimality,\nthese models overlook both fast and slow learning behaviors and cannot\nfaithfully reproduce key decision patterns. Moreover, they offer limited\ninterpretability, hindering biological insight. Our contribution addresses\nthese challenges by (i) introducing a model that minimizes predictive loss\nwhile identifying the effective memory horizon most consistent with behavioral\ndata, and (ii) ensuring full interpretability to enable biologists to analyze\nunderlying decision-making strategies and finally (iii) providing a\nmathematical framework linking bee policy search with bandit formulations under\nvarying exploration-exploitation dynamics, and releasing a novel dataset of 80\ntracked bees observed under diverse weather conditions. This benchmark\nfacilitates research on pollinator cognition and supports ecological governance\nby improving simulations of insect behavior in agroecosystems. Our findings\nshed new light on the learning strategies and memory interplay shaping\npollinator decision-making.", "AI": {"tldr": "A sequential reinforcement learning framework for imitation learning that models heterogeneous cognitive strategies in pollinators, particularly honeybees, addressing limitations of existing methods in capturing diverse learning behaviors and providing interpretability.", "motivation": "To overcome the limitations of state-of-the-art imitation learning methods that fail when expert policies shift across memory windows or deviate from optimality, and to provide interpretable models for biological insight into pollinator decision-making.", "method": "Introduces a model that minimizes predictive loss while identifying effective memory horizons, ensures full interpretability, provides a mathematical framework linking bee policy search with bandit formulations under varying exploration-exploitation dynamics, and uses a novel dataset of 80 tracked bees under diverse weather conditions.", "result": "The framework successfully captures and forecasts behavior across individuals using distinct cognitive strategies (numerical cues, memory, environmental factors), overcoming limitations of existing methods that overlook fast and slow learning behaviors and cannot reproduce key decision patterns.", "conclusion": "The findings shed new light on learning strategies and memory interplay shaping pollinator decision-making, supporting ecological governance by improving simulations of insect behavior in agroecosystems and facilitating research on pollinator cognition."}}
{"id": "2510.16870", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16870", "abs": "https://arxiv.org/abs/2510.16870", "authors": ["Yudan Ren", "Xinlong Wang", "Kexin Wang", "Tian Xia", "Zihan Ma", "Zhaowei Li", "Xiangrong Bi", "Xiao Li", "Xiaowei He"], "title": "Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding", "comment": "14 pages, 7 figures", "summary": "While brain-inspired artificial intelligence(AI) has demonstrated promising\nresults, current understanding of the parallels between artificial neural\nnetworks (ANNs) and human brain processing remains limited: (1) unimodal ANN\nstudies fail to capture the brain's inherent multimodal processing\ncapabilities, and (2) multimodal ANN research primarily focuses on high-level\nmodel outputs, neglecting the crucial role of individual neurons. To address\nthese limitations, we propose a novel neuron-level analysis framework that\ninvestigates the multimodal information processing mechanisms in\nvision-language models (VLMs) through the lens of human brain activity. Our\napproach uniquely combines fine-grained artificial neuron (AN) analysis with\nfMRI-based voxel encoding to examine two architecturally distinct VLMs: CLIP\nand METER. Our analysis reveals four key findings: (1) ANs successfully predict\nbiological neurons (BNs) activities across multiple functional networks\n(including language, vision, attention, and default mode), demonstrating shared\nrepresentational mechanisms; (2) Both ANs and BNs demonstrate functional\nredundancy through overlapping neural representations, mirroring the brain's\nfault-tolerant and collaborative information processing mechanisms; (3) ANs\nexhibit polarity patterns that parallel the BNs, with oppositely activated BNs\nshowing mirrored activation trends across VLM layers, reflecting the complexity\nand bidirectional nature of neural information processing; (4) The\narchitectures of CLIP and METER drive distinct BNs: CLIP's independent branches\nshow modality-specific specialization, whereas METER's cross-modal design\nyields unified cross-modal activation, highlighting the architecture's\ninfluence on ANN brain-like properties. These results provide compelling\nevidence for brain-like hierarchical processing in VLMs at the neuronal level.", "AI": {"tldr": "A neuron-level analysis framework that compares vision-language models (CLIP and METER) with human brain activity using fMRI-based voxel encoding, revealing shared representational mechanisms and brain-like hierarchical processing in artificial neural networks.", "motivation": "Current ANN studies have limitations: unimodal approaches don't capture the brain's multimodal processing, and multimodal research focuses on high-level outputs while neglecting individual neurons' crucial role.", "method": "Proposed a novel neuron-level analysis framework combining fine-grained artificial neuron analysis with fMRI-based voxel encoding to examine two architecturally distinct VLMs (CLIP and METER).", "result": "Four key findings: (1) ANs predict BN activities across multiple functional networks; (2) Both show functional redundancy; (3) ANs exhibit polarity patterns paralleling BNs; (4) Different architectures drive distinct BN patterns - CLIP shows modality-specific specialization while METER yields unified cross-modal activation.", "conclusion": "The results provide compelling evidence for brain-like hierarchical processing in VLMs at the neuronal level, demonstrating shared representational mechanisms between artificial and biological neural networks."}}
{"id": "2510.16474", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16474", "abs": "https://arxiv.org/abs/2510.16474", "authors": ["Farwa Abbas", "Hussain Ahmad", "Claudia Szabo"], "title": "SCALAR: Self-Calibrating Adaptive Latent Attention Representation Learning", "comment": null, "summary": "High-dimensional, heterogeneous data with complex feature interactions pose\nsignificant challenges for traditional predictive modeling approaches. While\nProjection to Latent Structures (PLS) remains a popular technique, it struggles\nto model complex non-linear relationships, especially in multivariate systems\nwith high-dimensional correlation structures. This challenge is further\ncompounded by simultaneous interactions across multiple scales, where local\nprocessing fails to capture crossgroup dependencies. Additionally, static\nfeature weighting limits adaptability to contextual variations, as it ignores\nsample-specific relevance. To address these limitations, we propose a novel\nmethod that enhances predictive performance through novel architectural\ninnovations. Our architecture introduces an adaptive kernel-based attention\nmechanism that processes distinct feature groups separately before integration,\nenabling capture of local patterns while preserving global relationships.\nExperimental results show substantial improvements in performance metrics,\ncompared to the state-of-the-art methods across diverse datasets.", "AI": {"tldr": "A novel adaptive kernel-based attention method that processes feature groups separately before integration, improving predictive performance for high-dimensional heterogeneous data with complex non-linear relationships.", "motivation": "Traditional PLS methods struggle with complex non-linear relationships in high-dimensional correlated data, fail to capture cross-group dependencies, and use static feature weighting that lacks adaptability to contextual variations.", "method": "Proposes an adaptive kernel-based attention mechanism that processes distinct feature groups separately before integration, enabling capture of both local patterns and global relationships.", "result": "Experimental results show substantial improvements in performance metrics compared to state-of-the-art methods across diverse datasets.", "conclusion": "The proposed method effectively addresses limitations of traditional PLS by capturing complex non-linear relationships and cross-group dependencies through adaptive feature processing."}}
{"id": "2510.16887", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16887", "abs": "https://arxiv.org/abs/2510.16887", "authors": ["Nusrat Munia", "Abdullah Imran"], "title": "Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis", "comment": "EMBC 2025", "summary": "Generative models, especially Diffusion Models, have demonstrated remarkable\ncapability in generating high-quality synthetic data, including medical images.\nHowever, traditional class-conditioned generative models often struggle to\ngenerate images that accurately represent specific medical categories, limiting\ntheir usefulness for applications such as skin cancer diagnosis. To address\nthis problem, we propose a classification-induced diffusion model, namely,\nClass-N-Diff, to simultaneously generate and classify dermoscopic images. Our\nClass-N-Diff model integrates a classifier within a diffusion model to guide\nimage generation based on its class conditions. Thus, the model has better\ncontrol over class-conditioned image synthesis, resulting in more realistic and\ndiverse images. Additionally, the classifier demonstrates improved performance,\nhighlighting its effectiveness for downstream diagnostic tasks. This unique\nintegration in our Class-N-Diff makes it a robust tool for enhancing the\nquality and utility of diffusion model-based synthetic dermoscopic image\ngeneration. Our code is available at https://github.com/Munia03/Class-N-Diff.", "AI": {"tldr": "Class-N-Diff is a classification-induced diffusion model that integrates a classifier within a diffusion model to simultaneously generate and classify dermoscopic images, improving both image quality and classification performance for medical applications.", "motivation": "Traditional class-conditioned generative models struggle to generate accurate medical images for specific categories like skin cancer, limiting their usefulness for diagnostic applications.", "method": "Integrates a classifier within a diffusion model to guide image generation based on class conditions, enabling better control over class-conditioned image synthesis.", "result": "Generates more realistic and diverse dermoscopic images while the classifier shows improved performance for downstream diagnostic tasks.", "conclusion": "Class-N-Diff is a robust tool that enhances the quality and utility of diffusion model-based synthetic dermoscopic image generation through unique integration of classification and generation."}}
{"id": "2510.16511", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16511", "abs": "https://arxiv.org/abs/2510.16511", "authors": ["Dongchan Cho", "Jiho Han", "Keumyeong Kang", "Minsang Kim", "Honggyu Ryu", "Namsoon Jung"], "title": "Structured Temporal Causality for Interpretable Multivariate Time Series Anomaly Detection", "comment": "Accepted by NeurIPS 2025", "summary": "Real-world multivariate time series anomalies are rare and often unlabeled.\nAdditionally, prevailing methods rely on increasingly complex architectures\ntuned to benchmarks, detecting only fragments of anomalous segments and\noverstating performance. In this paper, we introduce OracleAD, a simple and\ninterpretable unsupervised framework for multivariate time series anomaly\ndetection. OracleAD encodes each variable's past sequence into a single causal\nembedding to jointly predict the present time point and reconstruct the input\nwindow, effectively modeling temporal dynamics. These embeddings then undergo a\nself-attention mechanism to project them into a shared latent space and capture\nspatial relationships. These relationships are not static, since they are\nmodeled by a property that emerges from each variable's temporal dynamics. The\nprojected embeddings are aligned to a Stable Latent Structure (SLS)\nrepresenting normal-state relationships. Anomalies are identified using a dual\nscoring mechanism based on prediction error and deviation from the SLS,\nenabling fine-grained anomaly diagnosis at each time point and across\nindividual variables. Since any noticeable SLS deviation originates from\nembeddings that violate the learned temporal causality of normal data, OracleAD\ndirectly pinpoints the root-cause variables at the embedding level. OracleAD\nachieves state-of-the-art results across multiple real-world datasets and\nevaluation protocols, while remaining interpretable through SLS.", "AI": {"tldr": "OracleAD is a simple unsupervised framework for multivariate time series anomaly detection that uses causal embeddings and a Stable Latent Structure to identify anomalies while providing interpretable root-cause analysis.", "motivation": "Real-world multivariate time series anomalies are rare, unlabeled, and current methods detect only fragments of anomalies while overstating performance with complex architectures.", "method": "Encodes each variable's past sequence into causal embeddings for joint prediction and reconstruction, uses self-attention to capture spatial relationships in a shared latent space, and aligns embeddings to a Stable Latent Structure (SLS) representing normal-state relationships.", "result": "Achieves state-of-the-art results across multiple real-world datasets and evaluation protocols while maintaining interpretability.", "conclusion": "OracleAD provides an effective and interpretable approach for multivariate time series anomaly detection that directly pinpoints root-cause variables through temporal causality violations."}}
{"id": "2510.16888", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16888", "abs": "https://arxiv.org/abs/2510.16888", "authors": ["Zongjian Li", "Zheyuan Liu", "Qihui Zhang", "Bin Lin", "Shenghai Yuan", "Zhiyuan Yan", "Yang Ye", "Wangbo Yu", "Yuwei Niu", "Li Yuan"], "title": "Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback", "comment": null, "summary": "Instruction-based image editing has achieved remarkable progress; however,\nmodels solely trained via supervised fine-tuning often overfit to annotated\npatterns, hindering their ability to explore and generalize beyond training\ndistributions. To this end, we introduce Edit-R1, a novel post-training\nframework for instruction-based image editing based on policy optimization.\nSpecifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a\nlikelihood-free policy optimization method consistent with the flow matching\nforward process, thereby enabling the use of higher-order samplers and more\nefficient training. Another key challenge here is the absence of a universal\nreward model, resulting from the diverse nature of editing instructions and\ntasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM)\nas a unified, training-free reward model, leveraging its output logits to\nprovide fine-grained feedback. Furthermore, we carefully design a low-variance\ngroup filtering mechanism to reduce MLLM scoring noise and stabilize\noptimization. UniWorld-V2, trained with this framework, achieves\n\\textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks,\nscoring 4.49 and 7.83, respectively. Crucially, our framework is\nmodel-agnostic, delivering substantial performance gains when applied to\ndiverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its\nwide applicability. Code and models are publicly available at\nhttps://github.com/PKU-YuanGroup/UniWorld-V2.", "AI": {"tldr": "Edit-R1 is a policy optimization framework that uses Diffusion Negative-aware Finetuning and MLLM-based rewards to improve instruction-based image editing models' generalization beyond training data.", "motivation": "Models trained via supervised fine-tuning overfit to annotated patterns and struggle to generalize beyond training distributions, limiting their practical effectiveness.", "method": "Uses Diffusion Negative-aware Finetuning (DiffusionNFT) for policy optimization and employs MLLM as a unified reward model with low-variance group filtering to reduce scoring noise.", "result": "UniWorld-V2 achieves state-of-the-art results on ImgEdit (4.49) and GEdit-Bench (7.83), and the framework shows substantial performance gains when applied to diverse base models.", "conclusion": "Edit-R1 is a model-agnostic framework that effectively addresses overfitting in instruction-based image editing and demonstrates wide applicability across different base models."}}
{"id": "2510.16513", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16513", "abs": "https://arxiv.org/abs/2510.16513", "authors": ["Dhruv Gupta", "Aditya Nagarsekar", "Vraj Shah", "Sujith Thomas"], "title": "eDCF: Estimating Intrinsic Dimension using Local Connectivity", "comment": "58 pages (35 (main) + 23 (appendix)), 54 figures (27 (main) + 27\n  (appendix))", "summary": "Modern datasets often contain high-dimensional features exhibiting complex\ndependencies. To effectively analyze such data, dimensionality reduction\nmethods rely on estimating the dataset's intrinsic dimension (id) as a measure\nof its underlying complexity. However, estimating id is challenging due to its\ndependence on scale: at very fine scales, noise inflates id estimates, while at\ncoarser scales, estimates stabilize to lower, scale-invariant values. This\npaper introduces a novel, scalable, and parallelizable method called eDCF,\nwhich is based on Connectivity Factor (CF), a local connectivity-based metric,\nto robustly estimate intrinsic dimension across varying scales. Our method\nconsistently matches leading estimators, achieving comparable values of mean\nabsolute error (MAE) on synthetic benchmarks with noisy samples. Moreover, our\napproach also attains higher exact intrinsic dimension match rates, reaching up\nto 25.0% compared to 16.7% for MLE and 12.5% for TWO-NN, particularly excelling\nunder medium to high noise levels and large datasets. Further, we showcase our\nmethod's ability to accurately detect fractal geometries in decision\nboundaries, confirming its utility for analyzing realistic, structured data.", "AI": {"tldr": "eDCF is a novel scalable method for robust intrinsic dimension estimation that outperforms existing approaches, especially under noise and large datasets, and can detect fractal geometries.", "motivation": "Modern high-dimensional datasets have complex dependencies, making intrinsic dimension estimation challenging due to scale dependency issues where noise inflates estimates at fine scales.", "method": "The paper introduces eDCF, a scalable and parallelizable method based on Connectivity Factor (CF) - a local connectivity-based metric that estimates intrinsic dimension across varying scales.", "result": "eDCF matches leading estimators with comparable MAE on synthetic benchmarks, achieves higher exact intrinsic dimension match rates (25.0% vs 16.7% for MLE and 12.5% for TWO-NN), and excels under medium to high noise levels and large datasets.", "conclusion": "The method effectively estimates intrinsic dimension across scales and can accurately detect fractal geometries in decision boundaries, demonstrating utility for analyzing realistic structured data."}}
{"id": "2510.16891", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16891", "abs": "https://arxiv.org/abs/2510.16891", "authors": ["Ramon Dalmau", "Gabriel Jarry", "Philippe Very"], "title": "Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data", "comment": null, "summary": "Aviation's non-CO2 effects, particularly contrails, are a significant\ncontributor to its climate impact. Persistent contrails can evolve into\ncirrus-like clouds that trap outgoing infrared radiation, with radiative\nforcing potentially comparable to or exceeding that of aviation's CO2\nemissions. While physical models simulate contrail formation, evolution and\ndissipation, validating and calibrating these models requires linking observed\ncontrails to the flights that generated them, a process known as\ncontrail-to-flight attribution. Satellite-based attribution is challenging due\nto limited spatial and temporal resolution, as contrails often drift and deform\nbefore detection. In this paper, we evaluate an alternative approach using\nground-based cameras, which capture contrails shortly after formation at high\nspatial and temporal resolution, when they remain thin, linear, and visually\ndistinct. Leveraging the ground visible camera contrail sequences (GVCCS)\ndataset, we introduce a modular framework for attributing contrails observed\nusing ground-based cameras to theoretical contrails derived from aircraft\nsurveillance and meteorological data. The framework accommodates multiple\ngeometric representations and distance metrics, incorporates temporal\nsmoothing, and enables flexible probability-based assignment strategies. This\nwork establishes a strong baseline and provides a modular framework for future\nresearch in linking contrails to their source flight.", "AI": {"tldr": "A modular framework for attributing contrails observed by ground-based cameras to source flights using aircraft surveillance and meteorological data, addressing challenges in contrail-to-flight attribution.", "motivation": "Aviation's non-CO2 effects from contrails are a major climate impact, potentially exceeding CO2 emissions. Current satellite-based attribution is limited due to contrail drifting and deformation, requiring better methods to validate physical models.", "method": "Uses ground-based cameras that capture contrails shortly after formation when they're thin and linear. Introduces a modular framework with geometric representations, distance metrics, temporal smoothing, and probability-based assignment strategies.", "result": "Developed a framework that can link observed contrails to source flights using the GVCCS dataset, establishing a strong baseline for contrail-to-flight attribution research.", "conclusion": "This work provides an effective alternative to satellite-based attribution and enables future research in connecting contrails to their generating flights for better climate impact assessment."}}
{"id": "2510.16530", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16530", "abs": "https://arxiv.org/abs/2510.16530", "authors": ["Ashutosh Srivastava", "Lokesh Nagalapatti", "Gautam Jajoo", "Aniket Vashishtha", "Parameswari Krishnamurthy", "Amit Sharma"], "title": "Realizing LLMs' Causal Potential Requires Science-Grounded, Novel Benchmarks", "comment": null, "summary": "Recent claims of strong performance by Large Language Models (LLMs) on causal\ndiscovery are undermined by a key flaw: many evaluations rely on benchmarks\nlikely included in pretraining corpora. Thus, apparent success suggests that\nLLM-only methods, which ignore observational data, outperform classical\nstatistical approaches. We challenge this narrative by asking: Do LLMs truly\nreason about causal structure, and how can we measure it without memorization\nconcerns? Can they be trusted for real-world scientific discovery? We argue\nthat realizing LLMs' potential for causal analysis requires two shifts: (P.1)\ndeveloping robust evaluation protocols based on recent scientific studies to\nguard against dataset leakage, and (P.2) designing hybrid methods that combine\nLLM-derived knowledge with data-driven statistics. To address P.1, we encourage\nevaluating discovery methods on novel, real-world scientific studies. We\noutline a practical recipe for extracting causal graphs from recent\npublications released after an LLM's training cutoff, ensuring relevance and\npreventing memorization while capturing both established and novel relations.\nCompared to benchmarks like BNLearn, where LLMs achieve near-perfect accuracy,\nthey perform far worse on our curated graphs, underscoring the need for\nstatistical grounding. Supporting P.2, we show that using LLM predictions as\npriors for the classical PC algorithm significantly improves accuracy over both\nLLM-only and purely statistical methods. We call on the community to adopt\nscience-grounded, leakage-resistant benchmarks and invest in hybrid causal\ndiscovery methods suited to real-world inquiry.", "AI": {"tldr": "LLMs' apparent strong performance on causal discovery is flawed due to benchmark memorization. The paper proposes science-grounded evaluation protocols and hybrid methods combining LLM knowledge with statistical approaches.", "motivation": "To challenge the narrative that LLM-only methods outperform classical statistical approaches for causal discovery, and to address concerns about dataset leakage and memorization in current evaluations.", "method": "Proposes two shifts: (1) developing robust evaluation protocols using recent scientific studies to prevent memorization, and (2) designing hybrid methods that combine LLM-derived knowledge with data-driven statistics. Specifically uses LLM predictions as priors for the classical PC algorithm.", "result": "LLMs perform far worse on curated graphs from recent publications compared to benchmarks like BNLearn where they achieve near-perfect accuracy. Using LLM predictions as priors for PC algorithm significantly improves accuracy over both LLM-only and purely statistical methods.", "conclusion": "The community should adopt science-grounded, leakage-resistant benchmarks and invest in hybrid causal discovery methods that combine LLM knowledge with statistical approaches for real-world scientific inquiry."}}
{"id": "2510.16913", "categories": ["cs.CV", "68T07, 68U10, 68U35", "I.2.10; I.4.8; I.4.9"], "pdf": "https://arxiv.org/pdf/2510.16913", "abs": "https://arxiv.org/abs/2510.16913", "authors": ["Akhila Kambhatla", "Ahmed R Khaled"], "title": "Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation", "comment": "9 Images with 1 figure and 3 Tables. This is a preprint submitted to\n  arXiv", "summary": "Thermal weapon segmentation is crucial for surveillance and security\napplications, enabling robust detection under lowlight and visually obscured\nconditions where RGB-based systems fail. While convolutional neural networks\n(CNNs) dominate thermal segmentation literature, their ability to capture\nlong-range dependencies and fine structural details is limited. Vision\nTransformers (ViTs), with their global context modeling capabilities, have\nachieved state-of-the-art results in RGB segmentation tasks, yet their\npotential in thermal weapon segmentation remains underexplored. This work\nadapts and evaluates four transformer-based architectures SegFormer,\nDeepLabV3\\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a\ncustom thermal dataset comprising 9,711 images collected from real world\nsurveillance videos and automatically annotated using SAM2. We employ standard\naugmentation strategies within the MMSegmentation framework to ensure robust\nmodel training and fair architectural comparison. Experimental results\ndemonstrate significant improvements in segmentation performance: SegFormer-b5\nachieves the highest mIoU (94.15\\%) and Pixel Accuracy (97.04\\%), while\nSegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive\nmIoU (90.84\\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and\n92.24\\% mIoU, and DeepLabV3\\+ R101-D8 reaches 92.76\\% mIoU at 29.86 FPS. The\ntransformer architectures demonstrate robust generalization capabilities for\nweapon detection in low-light and occluded thermal environments, with flexible\naccuracy-speed trade-offs suitable for diverse real-time security applications.", "AI": {"tldr": "This paper evaluates transformer-based architectures for thermal weapon segmentation, showing significant improvements over traditional CNNs with SegFormer-b5 achieving the best accuracy (94.15% mIoU) and SegFormer-b0 providing the fastest inference (98.32 FPS).", "motivation": "Thermal weapon segmentation is crucial for surveillance in low-light/obscured conditions where RGB systems fail. While CNNs dominate thermal segmentation, they struggle with long-range dependencies and fine details. Vision Transformers have shown success in RGB tasks but remain underexplored for thermal weapon segmentation.", "method": "Adapted and evaluated four transformer-based architectures (SegFormer, DeepLabV3+, SegNeXt, Swin Transformer) on a custom thermal dataset of 9,711 images from real surveillance videos, using SAM2 for automatic annotation. Employed standard augmentation strategies within MMSegmentation framework for robust training and fair comparison.", "result": "Significant performance improvements: SegFormer-b5 achieved highest mIoU (94.15%) and Pixel Accuracy (97.04%); SegFormer-b0 provided fastest inference (98.32 FPS) with competitive mIoU (90.84%); SegNeXt-mscans offered balanced performance (85.12 FPS, 92.24% mIoU); DeepLabV3+ R101-D8 reached 92.76% mIoU at 29.86 FPS.", "conclusion": "Transformer architectures demonstrate robust generalization for weapon detection in low-light and occluded thermal environments, offering flexible accuracy-speed trade-offs suitable for diverse real-time security applications."}}
{"id": "2510.16547", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16547", "abs": "https://arxiv.org/abs/2510.16547", "authors": ["Alif Elham Khan", "Mohammad Junayed Hasan", "Humayra Anjum", "Nabeel Mohammed", "Sifat Momen"], "title": "Predicting life satisfaction using machine learning and explainable AI", "comment": null, "summary": "Life satisfaction is a crucial facet of human well-being. Hence, research on\nlife satisfaction is incumbent for understanding how individuals experience\ntheir lives and influencing interventions targeted at enhancing mental health\nand well-being. Life satisfaction has traditionally been measured using analog,\ncomplicated, and frequently error-prone methods. These methods raise questions\nconcerning validation and propagation. However, this study demonstrates the\npotential for machine learning algorithms to predict life satisfaction with a\nhigh accuracy of 93.80% and a 73.00% macro F1-score. The dataset comes from a\ngovernment survey of 19000 people aged 16-64 years in Denmark. Using feature\nlearning techniques, 27 significant questions for assessing contentment were\nextracted, making the study highly reproducible, simple, and easily\ninterpretable. Furthermore, clinical and biomedical large language models\n(LLMs) were explored for predicting life satisfaction by converting tabular\ndata into natural language sentences through mapping and adding meaningful\ncounterparts, achieving an accuracy of 93.74% and macro F1-score of 73.21%. It\nwas found that life satisfaction prediction is more closely related to the\nbiomedical domain than the clinical domain. Ablation studies were also\nconducted to understand the impact of data resampling and feature selection\ntechniques on model performance. Moreover, the correlation between primary\ndeterminants with different age brackets was analyzed, and it was found that\nhealth condition is the most important determinant across all ages. This study\ndemonstrates how machine learning, large language models and XAI can jointly\ncontribute to building trust and understanding in using AI to investigate human\nbehavior, with significant ramifications for academics and professionals\nworking to quantify and comprehend subjective well-being.", "AI": {"tldr": "Machine learning and LLMs can predict life satisfaction with high accuracy (93.80% and 93.74%) using Danish survey data, identifying health as the key determinant across all ages.", "motivation": "Traditional life satisfaction measurement methods are analog, complicated, and error-prone, raising validation concerns. This study explores ML and LLMs for more reliable prediction.", "method": "Used Danish government survey data (19,000 people), feature learning to extract 27 key questions, converted tabular data to natural language for LLMs, and conducted ablation studies on data resampling and feature selection.", "result": "Achieved 93.80% accuracy with ML and 93.74% with LLMs, with health condition identified as the most important determinant across all age groups. Biomedical domain LLMs performed better than clinical ones.", "conclusion": "ML, LLMs, and XAI can jointly build trust in using AI to investigate human behavior, with significant implications for understanding subjective well-being."}}
{"id": "2510.16926", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16926", "abs": "https://arxiv.org/abs/2510.16926", "authors": ["Chenxu Li", "Zhicai Wang", "Yuan Sheng", "Xingyu Zhu", "Yanbin Hao", "Xiang Wang"], "title": "Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input", "comment": "23 pages,19 figures", "summary": "Multimodal Large Language Models (MLLMs) increasingly support dynamic image\nresolutions. However, current evaluation paradigms primarily assess semantic\nperformance, overlooking the critical question of resolution robustness -\nwhether performance remains stable across varying input resolutions. To address\nthis gap, we introduce \\textbf{Res-Bench}, a comprehensive benchmark comprising\n14,400 samples across 12 resolution levels and six core capability dimensions.\nWe designed a novel evaluation framework that goes beyond traditional accuracy\nmetrics to capture performance stability. This framework introduces multiple\nrobustness metrics: Spearman's correlation for assessing resolution-performance\ntrends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring\nperformance volatility. Using these metrics, we conducted a large-scale\nevaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and\ntask-centric robustness examination, (2) investigation of preprocessing\nstrategies including padding and super-resolution, and (3) exploration of\nfine-tuning for stability enhancement.", "AI": {"tldr": "Res-Bench is a benchmark for evaluating resolution robustness in Multimodal Large Language Models (MLLMs), introducing new metrics to assess performance stability across different input resolutions.", "motivation": "Current MLLM evaluations focus on semantic performance but overlook resolution robustness - whether performance remains stable across varying input resolutions, creating a critical gap in understanding model reliability.", "method": "Created Res-Bench with 14,400 samples across 12 resolution levels and 6 capability dimensions. Introduced novel robustness metrics: Spearman's correlation for resolution-performance trends, and Absolute/Relative Continuous Error (ACE/RCE) for performance volatility. Evaluated leading MLLMs with model/task-centric analysis, preprocessing strategies (padding, super-resolution), and fine-tuning for stability.", "result": "Conducted large-scale evaluation of leading MLLMs using the new benchmark and metrics framework to systematically assess resolution robustness.", "conclusion": "The study addresses the critical gap in MLLM evaluation by providing comprehensive tools and methodologies to assess resolution robustness, enabling better understanding of model stability across varying input conditions."}}
{"id": "2510.16548", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16548", "abs": "https://arxiv.org/abs/2510.16548", "authors": ["Zitao Fang", "Chenxuan Li", "Hongting Zhou", "Shuyang Yu", "Guodong Du", "Ashwaq Qasem", "Yang Lu", "Jing Li", "Junsong Zhang", "Sim Kuan Goh"], "title": "NeurIPT: Foundation Model for Neural Interfaces", "comment": "Accepted by The Thirty-Ninth Annual Conference on Neural Information\n  Processing Systems (NeurIPS 2025). Project Page:\n  https://ZzzitaoFang.github.io/projects/NeurIPT/", "summary": "Electroencephalography (EEG) has wide-ranging applications, from clinical\ndiagnosis to brain-computer interfaces (BCIs). With the increasing volume and\nvariety of EEG data, there has been growing interest in establishing foundation\nmodels (FMs) to scale up and generalize neural decoding. Despite showing early\npotential, applying FMs to EEG remains challenging due to substantial\ninter-subject, inter-task, and inter-condition variability, as well as diverse\nelectrode configurations across recording setups. To tackle these open\nchallenges, we propose NeurIPT, a foundation model developed for diverse\nEEG-based Neural Interfaces with a Pre-trained Transformer by capturing both\nhomogeneous and heterogeneous spatio-temporal characteristics inherent in EEG\nsignals. Temporally, we introduce Amplitude-Aware Masked Pretraining (AAMP),\nmasking based on signal amplitude rather than random intervals, to learn robust\nrepresentations across varying signal intensities beyond local interpolation.\nMoreover, this temporal representation is enhanced by a Progressive\nMixture-of-Experts (PMoE) architecture, where specialized expert subnetworks\nare progressively introduced at deeper layers, adapting effectively to the\ndiverse temporal characteristics of EEG signals. Spatially, NeurIPT leverages\nthe 3D physical coordinates of electrodes, enabling effective transfer of\nembedding across varying EEG settings, and develops Intra-Inter Lobe Pooling\n(IILP) during fine-tuning to efficiently exploit regional brain features.\nEmpirical evaluations across eight downstream BCI datasets, via fine-tuning,\ndemonstrated NeurIPT consistently achieved state-of-the-art performance,\nhighlighting its broad applicability and robust generalization. Our work pushes\nforward the state of FMs in EEG and offers insights into scalable and\ngeneralizable neural information processing systems.", "AI": {"tldr": "NeurIPT is a foundation model for EEG-based neural interfaces that addresses variability challenges through amplitude-aware masking, progressive MoE architecture, and spatial electrode coordinate integration, achieving SOTA performance across multiple BCI datasets.", "motivation": "EEG applications face challenges from inter-subject, inter-task, and inter-condition variability, plus diverse electrode configurations. Current foundation models struggle with these EEG-specific challenges.", "method": "Proposes NeurIPT with: 1) Amplitude-Aware Masked Pretraining (AAMP) for temporal robustness, 2) Progressive Mixture-of-Experts (PMoE) for diverse temporal characteristics, 3) 3D electrode coordinate embeddings for spatial transfer, and 4) Intra-Inter Lobe Pooling (IILP) for regional brain feature exploitation.", "result": "Achieved state-of-the-art performance across eight downstream BCI datasets through fine-tuning, demonstrating broad applicability and robust generalization.", "conclusion": "NeurIPT advances foundation models for EEG by providing scalable and generalizable neural information processing systems that effectively handle EEG's inherent variability challenges."}}
{"id": "2510.16973", "categories": ["cs.CV", "cs.AI", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2510.16973", "abs": "https://arxiv.org/abs/2510.16973", "authors": ["Praveenbalaji Rajendran", "Mojtaba Safari", "Wenfeng He", "Mingzhe Hu", "Shansong Wang", "Jun Zhou", "Xiaofeng Yang"], "title": "Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis", "comment": null, "summary": "Recent advancements in artificial intelligence (AI), particularly foundation\nmodels (FMs), have revolutionized medical image analysis, demonstrating strong\nzero- and few-shot performance across diverse medical imaging tasks, from\nsegmentation to report generation. Unlike traditional task-specific AI models,\nFMs leverage large corpora of labeled and unlabeled multimodal datasets to\nlearn generalized representations that can be adapted to various downstream\nclinical applications with minimal fine-tuning. However, despite the rapid\nproliferation of FM research in medical imaging, the field remains fragmented,\nlacking a unified synthesis that systematically maps the evolution of\narchitectures, training paradigms, and clinical applications across modalities.\nTo address this gap, this review article provides a comprehensive and\nstructured analysis of FMs in medical image analysis. We systematically\ncategorize studies into vision-only and vision-language FMs based on their\narchitectural foundations, training strategies, and downstream clinical tasks.\nAdditionally, a quantitative meta-analysis of the studies was conducted to\ncharacterize temporal trends in dataset utilization and application domains. We\nalso critically discuss persistent challenges, including domain adaptation,\nefficient fine-tuning, computational constraints, and interpretability along\nwith emerging solutions such as federated learning, knowledge distillation, and\nadvanced prompting. Finally, we identify key future research directions aimed\nat enhancing the robustness, explainability, and clinical integration of FMs,\nthereby accelerating their translation into real-world medical practice.", "AI": {"tldr": "This review paper provides a comprehensive analysis of foundation models (FMs) in medical image analysis, systematically categorizing studies, analyzing trends, and discussing challenges and future directions for clinical translation.", "motivation": "Despite rapid proliferation of FM research in medical imaging, the field remains fragmented without unified synthesis of architectural evolution, training paradigms, and clinical applications across modalities.", "method": "Systematic categorization of studies into vision-only and vision-language FMs based on architectural foundations, training strategies, and downstream clinical tasks, with quantitative meta-analysis of temporal trends in dataset utilization and application domains.", "result": "The review maps the evolution of FMs in medical imaging, characterizes trends in dataset usage and applications, and identifies persistent challenges including domain adaptation, efficient fine-tuning, computational constraints, and interpretability.", "conclusion": "Key future research directions focus on enhancing robustness, explainability, and clinical integration of FMs to accelerate their translation into real-world medical practice, with emerging solutions like federated learning, knowledge distillation, and advanced prompting."}}
{"id": "2510.16552", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16552", "abs": "https://arxiv.org/abs/2510.16552", "authors": ["Ang Li", "Yifei Wang", "Zhihang Yuan", "Stefanie Jegelka", "Yisen Wang"], "title": "LANPO: Bootstrapping Language and Numerical Feedback for Reinforcement Learning in LLMs", "comment": null, "summary": "Reinforcement learning in large language models (LLMs) often relies on scalar\nrewards, a practice that discards valuable textual rationale buried in the\nrollouts, forcing the model to explore \\textit{de novo} with each attempt and\nhindering sample efficiency. While LLMs can uniquely learn from language\nfeedback provided in-context, naively integrating on-line experiences into RL\ntraining presents a paradox: feedback from the same problem risks information\nleakage and memorization, while feedback from different problems often leads to\nbehavior collapse due to irrelevant context. To resolve this tension, we\npropose \\textbf{Language-And-Numerical Policy Optimization (LANPO)}, a\nframework that cleanly separates the roles of feedback: language guides\nexploration, while numerical rewards drive optimization. LANPO builds a dynamic\nexperience pool from past trials and introduces two principles to ensure\nfeedback is effective: \\emph{Reward-Agnostic Reflection} for safe intra-sample\nself-correction and \\emph{Relevant Abstraction} to distill generalizable\nlessons from inter-sample experiences. Across mathematical reasoning\nbenchmarks, LANPO enables 7B and 14B models to significantly outperform strong\nbaselines trained with GRPO in test accuracy. Our work provides a robust method\nfor integrating historical experiences into the LLM RL loop, creating more\neffective and data-efficient learning agents.", "AI": {"tldr": "LANPO is a reinforcement learning framework that separates language feedback for exploration from numerical rewards for optimization, improving sample efficiency in LLMs by leveraging historical experiences without causing behavior collapse.", "motivation": "Traditional RL in LLMs discards valuable textual rationale from rollouts and faces a paradox: same-problem feedback risks memorization while different-problem feedback causes behavior collapse due to irrelevant context.", "method": "LANPO builds a dynamic experience pool with two principles: Reward-Agnostic Reflection for safe intra-sample self-correction and Relevant Abstraction to distill generalizable lessons from inter-sample experiences.", "result": "Across mathematical reasoning benchmarks, LANPO enables 7B and 14B models to significantly outperform strong baselines trained with GRPO in test accuracy.", "conclusion": "LANPO provides a robust method for integrating historical experiences into the LLM RL loop, creating more effective and data-efficient learning agents."}}
{"id": "2510.16983", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16983", "abs": "https://arxiv.org/abs/2510.16983", "authors": ["Yuanzhi Zhu", "Eleftherios Tsonis", "Lucas Degeorge", "Vicky Kalogeiton"], "title": "One-step Diffusion Models with Bregman Density Ratio Matching", "comment": "work in progress", "summary": "Diffusion and flow models achieve high generative quality but remain\ncomputationally expensive due to slow multi-step sampling. Distillation methods\naccelerate them by training fast student generators, yet most existing\nobjectives lack a unified theoretical foundation. In this work, we propose\nDi-Bregman, a compact framework that formulates diffusion distillation as\nBregman divergence-based density-ratio matching. This convex-analytic view\nconnects several existing objectives through a common lens. Experiments on\nCIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves\nimproved one-step FID over reverse-KL distillation and maintains high visual\nfidelity compared to the teacher model. Our results highlight Bregman\ndensity-ratio matching as a practical and theoretically-grounded route toward\nefficient one-step diffusion generation.", "AI": {"tldr": "Di-Bregman is a unified framework for diffusion distillation that uses Bregman divergence-based density-ratio matching to accelerate multi-step diffusion models into efficient one-step generators.", "motivation": "Diffusion models achieve high quality but are computationally expensive due to slow multi-step sampling. Existing distillation methods lack a unified theoretical foundation.", "method": "Proposes Di-Bregman framework that formulates diffusion distillation as Bregman divergence-based density-ratio matching, providing a convex-analytic view that connects existing objectives.", "result": "Achieves improved one-step FID over reverse-KL distillation on CIFAR-10 and text-to-image generation, while maintaining high visual fidelity compared to teacher models.", "conclusion": "Bregman density-ratio matching provides a practical and theoretically-grounded approach for efficient one-step diffusion generation."}}
{"id": "2510.16588", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16588", "abs": "https://arxiv.org/abs/2510.16588", "authors": ["Jiaxi Zhuang", "Yu Zhang", "Aimin Zhou", "Ying Qian"], "title": "Copy-Augmented Representation for Structure Invariant Template-Free Retrosynthesis", "comment": null, "summary": "Retrosynthesis prediction is fundamental to drug discovery and chemical\nsynthesis, requiring the identification of reactants that can produce a target\nmolecule. Current template-free methods struggle to capture the structural\ninvariance inherent in chemical reactions, where substantial molecular\nscaffolds remain unchanged, leading to unnecessarily large search spaces and\nreduced prediction accuracy. We introduce C-SMILES, a novel molecular\nrepresentation that decomposes traditional SMILES into element-token pairs with\nfive special tokens, effectively minimizing editing distance between reactants\nand products. Building upon this representation, we incorporate a\ncopy-augmented mechanism that dynamically determines whether to generate new\ntokens or preserve unchanged molecular fragments from the product. Our approach\nintegrates SMILES alignment guidance to enhance attention consistency with\nground-truth atom mappings, enabling more chemically coherent predictions.\nComprehensive evaluation on USPTO-50K and large-scale USPTO-FULL datasets\ndemonstrates significant improvements: 67.2% top-1 accuracy on USPTO-50K and\n50.8% on USPTO-FULL, with 99.9% validity in generated molecules. This work\nestablishes a new paradigm for structure-aware molecular generation with direct\napplications in computational drug discovery.", "AI": {"tldr": "C-SMILES introduces a novel molecular representation that decomposes SMILES into element-token pairs with special tokens to minimize editing distance between reactants and products, combined with copy-augmented generation and SMILES alignment guidance for improved retrosynthesis prediction.", "motivation": "Current template-free retrosynthesis methods struggle to capture structural invariance in chemical reactions, where substantial molecular scaffolds remain unchanged, leading to large search spaces and reduced prediction accuracy.", "method": "Proposes C-SMILES representation with element-token pairs and five special tokens, incorporates copy-augmented mechanism to preserve unchanged fragments, and uses SMILES alignment guidance to enhance attention consistency with ground-truth atom mappings.", "result": "Achieves 67.2% top-1 accuracy on USPTO-50K and 50.8% on USPTO-FULL datasets, with 99.9% validity in generated molecules.", "conclusion": "Establishes a new paradigm for structure-aware molecular generation with direct applications in computational drug discovery."}}
{"id": "2510.16988", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16988", "abs": "https://arxiv.org/abs/2510.16988", "authors": ["Junhao Zhao", "Zishuai Liu", "Ruili Fang", "Jin Lu", "Linghan Zhang", "Fei Dou"], "title": "CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams", "comment": null, "summary": "The recognition of Activities of Daily Living (ADLs) from event-triggered\nambient sensors is an essential task in Ambient Assisted Living, yet existing\nmethods remain constrained by representation-level limitations. Sequence-based\napproaches preserve temporal order of sensor activations but are sensitive to\nnoise and lack spatial awareness, while image-based approaches capture global\npatterns and implicit spatial correlations but compress fine-grained temporal\ndynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)\nfail to enforce alignment between sequence- and image-based representation\nviews, underutilizing their complementary strengths. We propose Contrastive\nAlignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an\nend-to-end framework that jointly optimizes representation learning via\nSequence-Image Contrastive Alignment (SICA) and classification via\ncross-entropy, ensuring both cross-representation alignment and task-specific\ndiscriminability. CARE integrates (i) time-aware, noise-resilient sequence\nencoding with (ii) spatially-informed and frequency-sensitive image\nrepresentations, and employs (iii) a joint contrastive-classification objective\nfor end-to-end learning of aligned and discriminative embeddings. Evaluated on\nthree CASAS datasets, CARE achieves state-of-the-art performance (89.8% on\nMilan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to\nsensor malfunctions and layout variability, highlighting its potential for\nreliable ADL recognition in smart homes.", "AI": {"tldr": "CARE is a framework for ADL recognition that aligns sequence- and image-based sensor representations using contrastive learning to overcome limitations of existing methods.", "motivation": "Existing ADL recognition methods have limitations: sequence-based approaches are noise-sensitive and lack spatial awareness, while image-based approaches lose temporal dynamics and distort layouts. Naive fusion fails to properly align these complementary representations.", "method": "Proposes CARE framework with Sequence-Image Contrastive Alignment (SICA) that jointly optimizes representation learning via contrastive alignment and classification via cross-entropy. Integrates time-aware sequence encoding, spatially-informed image representations, and a joint contrastive-classification objective.", "result": "Achieves state-of-the-art performance on three CASAS datasets: 89.8% on Milan, 88.9% on Cairo, and 73.3% on Kyoto7. Demonstrates robustness to sensor malfunctions and layout variability.", "conclusion": "CARE enables reliable ADL recognition in smart homes by effectively aligning complementary sequence and image representations through contrastive learning, outperforming existing methods and showing robustness to real-world challenges."}}
{"id": "2510.16590", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2510.16590", "abs": "https://arxiv.org/abs/2510.16590", "authors": ["Alan Kai Hassen", "Andrius Bernatavicius", "Antonius P. A. Janssen", "Mike Preuss", "Gerard J. P. van Westen", "Djork-Arn\u00e9 Clevert"], "title": "Atom-anchored LLMs speak Chemistry: A Retrosynthesis Demonstration", "comment": "Alan Kai Hassen and Andrius Bernatavicius contributed equally to this\n  work", "summary": "Applications of machine learning in chemistry are often limited by the\nscarcity and expense of labeled data, restricting traditional supervised\nmethods. In this work, we introduce a framework for molecular reasoning using\ngeneral-purpose Large Language Models (LLMs) that operates without requiring\nlabeled training data. Our method anchors chain-of-thought reasoning to the\nmolecular structure by using unique atomic identifiers. First, the LLM performs\na one-shot task to identify relevant fragments and their associated chemical\nlabels or transformation classes. In an optional second step, this\nposition-aware information is used in a few-shot task with provided class\nexamples to predict the chemical transformation. We apply our framework to\nsingle-step retrosynthesis, a task where LLMs have previously underperformed.\nAcross academic benchmarks and expert-validated drug discovery molecules, our\nwork enables LLMs to achieve high success rates in identifying chemically\nplausible reaction sites ($\\geq90\\%$), named reaction classes ($\\geq40\\%$), and\nfinal reactants ($\\geq74\\%$). Beyond solving complex chemical tasks, our work\nalso provides a method to generate theoretically grounded synthetic datasets by\nmapping chemical knowledge onto the molecular structure and thereby addressing\ndata scarcity.", "AI": {"tldr": "A framework for molecular reasoning using LLMs without labeled data, using atomic identifiers for chain-of-thought reasoning and achieving high success rates in retrosynthesis tasks.", "motivation": "Overcoming data scarcity and expense in chemistry machine learning applications by enabling LLMs to perform molecular reasoning without requiring labeled training data.", "method": "Anchors chain-of-thought reasoning to molecular structure using unique atomic identifiers, with one-shot task for fragment identification and optional few-shot task for chemical transformation prediction.", "result": "Achieved high success rates in retrosynthesis: \u226590% for plausible reaction sites, \u226540% for named reaction classes, and \u226574% for final reactants across academic benchmarks and drug discovery molecules.", "conclusion": "The framework enables LLMs to solve complex chemical tasks without labeled data and provides a method to generate synthetic datasets by mapping chemical knowledge onto molecular structure."}}
{"id": "2510.16989", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16989", "abs": "https://arxiv.org/abs/2510.16989", "authors": ["Luca Zanella", "Massimiliano Mancini", "Yiming Wang", "Alessio Tonioni", "Elisa Ricci"], "title": "Training-free Online Video Step Grounding", "comment": "NeurIPS 2025. Project website at https://lucazanella.github.io/baglm/", "summary": "Given a task and a set of steps composing it, Video Step Grounding (VSG) aims\nto detect which steps are performed in a video. Standard approaches for this\ntask require a labeled training set (e.g., with step-level annotations or\nnarrations), which may be costly to collect. Moreover, they process the full\nvideo offline, limiting their applications for scenarios requiring online\ndecisions. Thus, in this work, we explore how to perform VSG online and without\ntraining. We achieve this by exploiting the zero-shot capabilities of recent\nLarge Multimodal Models (LMMs). In particular, we use LMMs to predict the step\nassociated with a restricted set of frames, without access to the whole video.\nWe show that this online strategy without task-specific tuning outperforms\noffline and training-based models. Motivated by this finding, we develop\nBayesian Grounding with Large Multimodal Models (BaGLM), further injecting\nknowledge of past frames into the LMM-based predictions. BaGLM exploits\nBayesian filtering principles, modeling step transitions via (i) a dependency\nmatrix extracted through large language models and (ii) an estimation of step\nprogress. Experiments on three datasets show superior performance of BaGLM over\nstate-of-the-art training-based offline methods.", "AI": {"tldr": "This paper proposes BaGLM, a method for Video Step Grounding (VSG) that performs online step detection without training by leveraging Large Multimodal Models and Bayesian filtering principles.", "motivation": "Standard VSG approaches require labeled training data and process full videos offline, which is costly and limits online applications. The authors aim to perform VSG online without training.", "method": "Uses LMMs to predict steps from limited frames, then develops BaGLM which incorporates Bayesian filtering with step transition knowledge from LLMs and step progress estimation.", "result": "The online strategy without task-specific tuning outperforms offline training-based models. BaGLM shows superior performance over state-of-the-art training-based offline methods on three datasets.", "conclusion": "BaGLM successfully enables online VSG without training requirements, demonstrating that LMMs combined with Bayesian filtering can achieve state-of-the-art performance in video step grounding."}}
{"id": "2510.16591", "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16591", "abs": "https://arxiv.org/abs/2510.16591", "authors": ["Cassidy Ashworth", "Pietro Li\u00f2", "Francesco Caso"], "title": "Symmetry and Generalisation in Neural Approximations of Renormalisation Transformations", "comment": null, "summary": "Deep learning models have proven enormously successful at using multiple\nlayers of representation to learn relevant features of structured data.\nEncoding physical symmetries into these models can improve performance on\ndifficult tasks, and recent work has motivated the principle of parameter\nsymmetry breaking and restoration as a unifying mechanism underlying their\nhierarchical learning dynamics. We evaluate the role of parameter symmetry and\nnetwork expressivity in the generalisation behaviour of neural networks when\nlearning a real-space renormalisation group (RG) transformation, using the\ncentral limit theorem (CLT) as a test case map. We consider simple multilayer\nperceptrons (MLPs) and graph neural networks (GNNs), and vary weight symmetries\nand activation functions across architectures. Our results reveal a competition\nbetween symmetry constraints and expressivity, with overly complex or\noverconstrained models generalising poorly. We analytically demonstrate this\npoor generalisation behaviour for certain constrained MLP architectures by\nrecasting the CLT as a cumulant recursion relation and making use of an\nestablished framework to propagate cumulants through MLPs. We also empirically\nvalidate an extension of this framework from MLPs to GNNs, elucidating the\ninternal information processing performed by these more complex models. These\nfindings offer new insight into the learning dynamics of symmetric networks and\ntheir limitations in modelling structured physical transformations.", "AI": {"tldr": "The paper investigates how parameter symmetry and network expressivity affect neural network generalization when learning renormalization group transformations, revealing a trade-off between symmetry constraints and model complexity.", "motivation": "To understand how encoding physical symmetries into deep learning models affects their hierarchical learning dynamics and generalization behavior, particularly for modeling structured physical transformations like renormalization group maps.", "method": "Used multilayer perceptrons (MLPs) and graph neural networks (GNNs) with varied weight symmetries and activation functions to learn real-space renormalization group transformations. Analyzed the central limit theorem as a test case and developed analytical frameworks to propagate cumulants through networks.", "result": "Found a competition between symmetry constraints and expressivity, where overly complex or overconstrained models generalize poorly. Demonstrated poor generalization analytically for constrained MLPs and empirically validated extension to GNNs.", "conclusion": "The findings provide new insights into symmetric network learning dynamics and their limitations in modeling structured physical transformations, highlighting the delicate balance needed between symmetry preservation and model expressivity."}}
{"id": "2510.17007", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17007", "abs": "https://arxiv.org/abs/2510.17007", "authors": ["Ignacio M. De la Jara", "Cristian Rodriguez-Opazo", "Edison Marrese-Taylor", "Felipe Bravo-Marquez"], "title": "An empirical study of the effect of video encoders on Temporal Video Grounding", "comment": null, "summary": "Temporal video grounding is a fundamental task in computer vision, aiming to\nlocalize a natural language query in a long, untrimmed video. It has a key role\nin the scientific community, in part due to the large amount of video generated\nevery day. Although we find extensive work in this task, we note that research\nremains focused on a small selection of video representations, which may lead\nto architectural overfitting in the long run. To address this issue, we propose\nan empirical study to investigate the impact of different video features on a\nclassical architecture. We extract features for three well-known benchmarks,\nCharades-STA, ActivityNet-Captions and YouCookII, using video encoders based on\nCNNs, temporal reasoning and transformers. Our results show significant\ndifferences in the performance of our model by simply changing the video\nencoder, while also revealing clear patterns and errors derived from the use of\ncertain features, ultimately indicating potential feature complementarity.", "AI": {"tldr": "An empirical study investigating how different video feature encoders (CNN, temporal reasoning, transformers) affect temporal video grounding performance across three benchmarks, revealing significant performance variations and potential feature complementarity.", "motivation": "Current research in temporal video grounding focuses on a limited set of video representations, which may lead to architectural overfitting. The study aims to address this by systematically evaluating different video feature encoders.", "method": "Extracted features from three benchmarks (Charades-STA, ActivityNet-Captions, YouCookII) using various video encoders based on CNNs, temporal reasoning, and transformers, then evaluated their impact on a classical grounding architecture.", "result": "Significant performance differences were observed by simply changing the video encoder, with clear patterns and errors emerging from specific feature types, indicating potential complementarity between different feature approaches.", "conclusion": "The choice of video encoder significantly impacts temporal video grounding performance, and different feature types may be complementary, suggesting opportunities for improved architectures through feature combination."}}
{"id": "2510.16607", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16607", "abs": "https://arxiv.org/abs/2510.16607", "authors": ["Tianwei Wang", "Xinhui Ma", "Wei Pang"], "title": "Asymptotically Stable Quaternion-valued Hopfield-structured Neural Network with Periodic Projection-based Supervised Learning Rules", "comment": null, "summary": "Motivated by the geometric advantages of quaternions in representing\nrotations and postures, we propose a quaternion-valued supervised learning\nHopfield-structured neural network (QSHNN) with a fully connected structure\ninspired by the classic Hopfield neural network (HNN). Starting from a\ncontinuous-time dynamical model of HNNs, we extend the formulation to the\nquaternionic domain and establish the existence and uniqueness of fixed points\nwith asymptotic stability. For the learning rules, we introduce a periodic\nprojection strategy that modifies standard gradient descent by periodically\nprojecting each 4*4 block of the weight matrix onto the closest quaternionic\nstructure in the least-squares sense. This approach preserves both convergence\nand quaternionic consistency throughout training. Benefiting from this rigorous\nmathematical foundation, the experimental model implementation achieves high\naccuracy, fast convergence, and strong reliability across randomly generated\ntarget sets. Moreover, the evolution trajectories of the QSHNN exhibit\nwell-bounded curvature, i.e., sufficient smoothness, which is crucial for\napplications such as control systems or path planning modules in robotic arms,\nwhere joint postures are parameterized by quaternion neurons. Beyond these\napplication scenarios, the proposed model offers a practical implementation\nframework and a general mathematical methodology for designing neural networks\nunder hypercomplex or non-commutative algebraic structures.", "AI": {"tldr": "A quaternion-valued supervised learning Hopfield neural network (QSHNN) is proposed, leveraging quaternions' geometric advantages for rotation representation. It features a periodic projection strategy for weight updates and demonstrates high accuracy, fast convergence, and smooth trajectories suitable for robotic applications.", "motivation": "Motivated by the geometric advantages of quaternions in representing rotations and postures, particularly for applications like robotic arm control and path planning where joint postures are parameterized by quaternion neurons.", "method": "Extends continuous-time Hopfield neural networks to quaternionic domain, establishes existence/uniqueness of fixed points with asymptotic stability, and introduces periodic projection strategy for weight updates that preserves quaternionic structure while maintaining convergence.", "result": "Experimental implementation achieves high accuracy, fast convergence, and strong reliability across randomly generated target sets. Evolution trajectories exhibit well-bounded curvature and sufficient smoothness.", "conclusion": "The model provides both a practical implementation framework and general mathematical methodology for designing neural networks under hypercomplex or non-commutative algebraic structures, with particular relevance to robotic control systems."}}
{"id": "2510.17014", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17014", "abs": "https://arxiv.org/abs/2510.17014", "authors": ["Ani Vanyan", "Alvard Barseghyan", "Hakob Tamazyan", "Tigran Galstyan", "Vahan Huroyan", "Naira Hovakimyan", "Hrant Khachatrian"], "title": "Do Satellite Tasks Need Special Pretraining?", "comment": null, "summary": "Foundation models have advanced machine learning across various modalities,\nincluding images. Recently multiple teams trained foundation models specialized\nfor remote sensing applications. This line of research is motivated by the\ndistinct characteristics of remote sensing imagery, specific applications and\ntypes of robustness useful for satellite image analysis. In this work we\nsystematically challenge the idea that specific foundation models are more\nuseful than general-purpose vision foundation models, at least in the small\nscale. First, we design a simple benchmark that measures generalization of\nremote sensing models towards images with lower resolution for two downstream\ntasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID,\nan ImageNet-scale satellite imagery dataset, with several modifications\nspecific to remote sensing. We show that none of those pretrained models bring\nconsistent improvements upon general-purpose baselines at the ViT-B scale.", "AI": {"tldr": "The paper challenges the idea that specialized foundation models for remote sensing are more useful than general-purpose vision foundation models, showing no consistent improvements at ViT-B scale.", "motivation": "To systematically test whether specialized remote sensing foundation models provide better performance than general-purpose vision foundation models for satellite image analysis tasks.", "method": "Designed a benchmark to measure generalization to lower resolution images, trained iBOT (self-supervised vision encoder) on MillionAID dataset with remote sensing-specific modifications, and compared against general-purpose baselines.", "result": "None of the pretrained remote sensing models showed consistent improvements over general-purpose baselines at the ViT-B scale.", "conclusion": "Specialized foundation models for remote sensing do not necessarily outperform general-purpose vision foundation models, at least at smaller scales."}}
{"id": "2510.16609", "categories": ["cs.LG", "cs.AI", "cs.CC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.16609", "abs": "https://arxiv.org/abs/2510.16609", "authors": ["Avrim Blum", "Daniel Hsu", "Cyrus Rashtchian", "Donya Saless"], "title": "Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods", "comment": null, "summary": "Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool\nuse, critically depends on an interplay between a model's parametric knowledge\nand externally retrieved information. However, the theoretical underpinnings of\nthis relationship remain poorly understood. Specifically, it is not clear how\nmuch pre-training knowledge is required to answer queries with a small number\nof augmentation steps, which is a desirable property in practice. To address\nthis question, we formulate multi-step reasoning as an $s$-$t$ connectivity\nproblem on a knowledge graph. We represent a model's pre-training parametric\nknowledge as a partial, potentially noisy subgraph. We view augmentation as\nquerying an oracle for true edges that augment the model's knowledge. Then, we\ncharacterize the necessary and sufficient number of augmentation steps for the\nmodel to generate an accurate answer given partial prior knowledge. One key\nresult shows a phase transition: if the prior knowledge graph over $n$ vertices\nis disconnected into small components, then finding a path via augmentation is\ninefficient and requires $\\Omega(\\sqrt{n})$ queries. On the other hand, once\nthe density of correct knowledge surpasses a threshold, forming a giant\ncomponent, we can find paths with an expected constant number of queries.", "AI": {"tldr": "This paper analyzes the theoretical relationship between a model's parametric knowledge and external augmentation in multi-step reasoning tasks, showing a phase transition in efficiency based on the density of prior knowledge.", "motivation": "To understand the theoretical foundations of how much pre-training knowledge is needed for effective test-time augmentation (like RAG or tool use) in multi-step reasoning tasks.", "method": "Formulates multi-step reasoning as an s-t connectivity problem on a knowledge graph, representing pre-training knowledge as a partial noisy subgraph and augmentation as querying an oracle for true edges.", "result": "Shows a phase transition: when prior knowledge is disconnected into small components, augmentation requires \u03a9(\u221an) queries, but once density surpasses a threshold forming a giant component, paths can be found with constant expected queries.", "conclusion": "The efficiency of test-time augmentation depends critically on the density and connectivity of the model's prior knowledge, with a clear phase transition determining whether augmentation is efficient or requires many queries."}}
{"id": "2510.17023", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.17023", "abs": "https://arxiv.org/abs/2510.17023", "authors": ["Shraman Pramanick", "Effrosyni Mavroudi", "Yale Song", "Rama Chellappa", "Lorenzo Torresani", "Triantafyllos Afouras"], "title": "Enrich and Detect: Video Temporal Grounding with Multimodal LLMs", "comment": "ICCV 2025 (Highlights)", "summary": "We introduce ED-VTG, a method for fine-grained video temporal grounding\nutilizing multi-modal large language models. Our approach harnesses the\ncapabilities of multimodal LLMs to jointly process text and video, in order to\neffectively localize natural language queries in videos through a two-stage\nprocess. Rather than being directly grounded, language queries are initially\ntransformed into enriched sentences that incorporate missing details and cues\nto aid in grounding. In the second stage, these enriched queries are grounded,\nusing a lightweight decoder, which specializes at predicting accurate\nboundaries conditioned on contextualized representations of the enriched\nqueries. To mitigate noise and reduce the impact of hallucinations, our model\nis trained with a multiple-instance-learning objective that dynamically selects\nthe optimal version of the query for each training sample. We demonstrate\nstate-of-the-art results across various benchmarks in temporal video grounding\nand paragraph grounding settings. Experiments reveal that our method\nsignificantly outperforms all previously proposed LLM-based temporal grounding\napproaches and is either superior or comparable to specialized models, while\nmaintaining a clear advantage against them in zero-shot evaluation scenarios.", "AI": {"tldr": "ED-VTG is a two-stage method for video temporal grounding that uses multimodal LLMs to enrich natural language queries before grounding them with a lightweight decoder, achieving state-of-the-art performance.", "motivation": "To improve fine-grained video temporal grounding by leveraging multimodal LLMs' capabilities to process text and video jointly, addressing the challenge of accurately localizing natural language queries in videos.", "method": "Two-stage approach: 1) Transform language queries into enriched sentences with missing details and cues, 2) Ground enriched queries using lightweight decoder with multiple-instance-learning objective to mitigate noise and hallucinations.", "result": "State-of-the-art results across various benchmarks in temporal video grounding and paragraph grounding settings, significantly outperforming previous LLM-based approaches and comparable to specialized models.", "conclusion": "ED-VTG demonstrates superior performance in temporal video grounding, particularly excelling in zero-shot evaluation scenarios while maintaining advantages over specialized models."}}
{"id": "2510.16629", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16629", "abs": "https://arxiv.org/abs/2510.16629", "authors": ["Jiatong Yu", "Yinghui He", "Anirudh Goyal", "Sanjeev Arora"], "title": "On the Impossibility of Retrain Equivalence in Machine Unlearning", "comment": "Code available at\n  https://princeton-pli.github.io/impossibility-unlearning/", "summary": "Machine unlearning seeks to selectively remove the \"influence\" of specific\ntraining data on a model's outputs. The ideal goal is Retrain\nEquivalence--behavior identical to a model trained from scratch on only the\nretained data. This goal was formulated for models trained on i.i.d. data\nbatches, but modern pipelines often involve multi-stage training, with each\nstage having a distinct data distribution and objective. Examples include LLM\nfine-tuning for alignment, reasoning ability, etc. Our study shows via theory\nand experiments that this shift to multi-stage training introduces a\nfundamental barrier for machine unlearning. The theory indicates that the\noutcome of local unlearning--methods that only use gradients computed on the\nforget set--is path-dependent. That is, a model's behavior during unlearning is\ninfluenced by the order of its training stages during learning, making it\nimpossible for path-oblivious algorithms to universally achieve Retrain\nEquivalence. We empirically demonstrate the same phenomenon in LLM\npost-training across Llama and Qwen models (1B to 14B) with gradient ascent,\nNPO, and SimNPO local unlearning algorithms. Models fine-tuned via different\norderings of identical training stages diverge in behavior during unlearning,\nwith the degradation in GSM8K accuracy after unlearning varying by over 20%\nacross paths. We also observe that some learning paths consistently produce\nmodels that unlearn slowly. During unlearning, whether the probability mass\ngets squeezed into paraphrasing or alternative concepts is also path-dependent.\nThese results consistently show that Retrain Equivalence is an ill-posed target\nfor local unlearning algorithms, so long as the target models are trained in\nstages. In situations where access to models' training histories is hard, the\ncurrent work calls for rethinking the definition and desiderata of machine\nunlearning.", "AI": {"tldr": "Machine unlearning faces fundamental barriers in multi-stage training pipelines, as local unlearning methods become path-dependent and cannot universally achieve Retrain Equivalence due to training stage order effects.", "motivation": "Modern ML pipelines often involve multi-stage training with distinct data distributions and objectives (e.g., LLM fine-tuning for alignment, reasoning), but current unlearning theory was formulated for i.i.d. data batches, creating a gap between theory and practice.", "method": "Theoretical analysis and empirical experiments on LLM post-training across Llama and Qwen models (1B to 14B) using gradient ascent, NPO, and SimNPO local unlearning algorithms, testing different orderings of identical training stages.", "result": "Models fine-tuned via different stage orderings diverge in behavior during unlearning, with GSM8K accuracy degradation varying by over 20% across paths. Some learning paths consistently produce models that unlearn slowly, and probability mass distribution during unlearning is path-dependent.", "conclusion": "Retrain Equivalence is an ill-posed target for local unlearning algorithms when models are trained in stages, calling for rethinking machine unlearning definitions and desiderata when training history access is limited."}}
{"id": "2510.17034", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17034", "abs": "https://arxiv.org/abs/2510.17034", "authors": ["Yutong Zhong"], "title": "Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding", "comment": null, "summary": "Multimodal 3D grounding has garnered considerable interest in Vision-Language\nModels (VLMs) \\cite{yin2025spatial} for advancing spatial reasoning in complex\nenvironments. However, these models suffer from a severe \"2D semantic bias\"\nthat arises from over-reliance on 2D image features for coarse localization,\nlargely disregarding 3D geometric inputs and resulting in suboptimal fusion\nperformance. In this paper, we propose a novel training framework called\nWhat-Where Representation Re-Forming (W2R2) to tackle this issue via\ndisentangled representation learning and targeted shortcut suppression. Our\napproach fundamentally reshapes the model's internal space by designating 2D\nfeatures as semantic beacons for \"What\" identification and 3D features as\nspatial anchors for \"Where\" localization, enabling precise 3D grounding without\nmodifying inference architecture. Key components include a dual-objective loss\nfunction with an Alignment Loss that supervises fused predictions using adapted\ncross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes\noverly effective 2D-dominant pseudo-outputs via a margin-based mechanism.\nExperiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of\nW2R2, with significant gains in localization accuracy and robustness,\nparticularly in cluttered outdoor scenes.", "AI": {"tldr": "W2R2 is a training framework that addresses 2D semantic bias in multimodal 3D grounding by disentangling 2D semantic and 3D spatial representations, improving localization accuracy without changing inference architecture.", "motivation": "Current multimodal 3D grounding models suffer from \"2D semantic bias\" - over-reliance on 2D image features that disregards 3D geometric inputs, leading to suboptimal fusion performance.", "method": "Proposes What-Where Representation Re-Forming (W2R2) using disentangled representation learning: 2D features as \"What\" semantic beacons and 3D features as \"Where\" spatial anchors. Uses dual-objective loss with Alignment Loss for multimodal synergy and Pseudo-Label Loss to suppress 2D-dominant shortcuts.", "result": "Experiments on ScanRefer and ScanQA show significant gains in localization accuracy and robustness, particularly in cluttered outdoor scenes.", "conclusion": "W2R2 effectively addresses 2D semantic bias through representation disentanglement and targeted shortcut suppression, enabling precise 3D grounding without architectural modifications."}}
{"id": "2510.16656", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.16656", "abs": "https://arxiv.org/abs/2510.16656", "authors": ["Noah El Rimawi-Fine", "Adam Stecklov", "Lucas Nelson", "Mathieu Blanchette", "Alexander Tong", "Stephen Y. Zhang", "Lazar Atanackovic"], "title": "Simulation-free Structure Learning for Stochastic Dynamics", "comment": null, "summary": "Modeling dynamical systems and unraveling their underlying causal\nrelationships is central to many domains in the natural sciences. Various\nphysical systems, such as those arising in cell biology, are inherently\nhigh-dimensional and stochastic in nature, and admit only partial, noisy state\nmeasurements. This poses a significant challenge for addressing the problems of\nmodeling the underlying dynamics and inferring the network structure of these\nsystems. Existing methods are typically tailored either for structure learning\nor modeling dynamics at the population level, but are limited in their ability\nto address both problems together. In this work, we address both problems\nsimultaneously: we present StructureFlow, a novel and principled\nsimulation-free approach for jointly learning the structure and stochastic\npopulation dynamics of physical systems. We showcase the utility of\nStructureFlow for the tasks of structure learning from interventions and\ndynamical (trajectory) inference of conditional population dynamics. We\nempirically evaluate our approach on high-dimensional synthetic systems, a set\nof biologically plausible simulated systems, and an experimental single-cell\ndataset. We show that StructureFlow can learn the structure of underlying\nsystems while simultaneously modeling their conditional population dynamics --\na key step toward the mechanistic understanding of systems behavior.", "AI": {"tldr": "StructureFlow is a simulation-free method that jointly learns network structure and stochastic population dynamics of high-dimensional physical systems from partial, noisy measurements.", "motivation": "Many physical systems like those in cell biology are high-dimensional, stochastic, and only partially observable, making it challenging to model dynamics and infer causal structure simultaneously. Existing methods address either structure learning or population dynamics separately.", "method": "StructureFlow is a principled simulation-free approach that jointly learns system structure and stochastic population dynamics. It handles structure learning from interventions and dynamical inference of conditional population dynamics.", "result": "The method was evaluated on high-dimensional synthetic systems, biologically plausible simulations, and experimental single-cell data. It successfully learned underlying system structures while modeling conditional population dynamics.", "conclusion": "StructureFlow enables simultaneous learning of system structure and population dynamics, representing a key step toward mechanistic understanding of complex system behavior."}}
{"id": "2510.17035", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17035", "abs": "https://arxiv.org/abs/2510.17035", "authors": ["Syed Konain Abbas", "Sandip Purnapatra", "M. G. Sarwar Murshed", "Conor Miller-Lynch", "Lambert Igene", "Soumyabrata Dey", "Stephanie Schuckers", "Faraz Hussain"], "title": "Conditional Synthetic Live and Spoof Fingerprint Generation", "comment": null, "summary": "Large fingerprint datasets, while important for training and evaluation, are\ntime-consuming and expensive to collect and require strict privacy measures.\nResearchers are exploring the use of synthetic fingerprint data to address\nthese issues. This paper presents a novel approach for generating synthetic\nfingerprint images (both spoof and live), addressing concerns related to\nprivacy, cost, and accessibility in biometric data collection. Our approach\nutilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce\nhigh-resolution synthetic live fingerprints, conditioned on specific finger\nidentities (thumb through little finger). Additionally, we employ CycleGANs to\ntranslate these into realistic spoof fingerprints, simulating a variety of\npresentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof\nfingerprints are crucial for developing robust spoof detection systems. Through\nthese generative models, we created two synthetic datasets (DB2 and DB3), each\ncontaining 1,500 fingerprint images of all ten fingers with multiple\nimpressions per finger, and including corresponding spoofs in eight material\ntypes. The results indicate robust performance: our StyleGAN3 model achieves a\nFr\\'echet Inception Distance (FID) as low as 5, and the generated fingerprints\nachieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The\nStyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess\nfingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably,\nmatching experiments confirm strong privacy preservation, with no significant\nevidence of identity leakage, confirming the strong privacy-preserving\nproperties of our synthetic datasets.", "AI": {"tldr": "This paper presents a novel approach for generating synthetic fingerprint images using conditional StyleGAN2-ADA and StyleGAN3 architectures to create high-resolution live fingerprints, and CycleGANs to translate them into realistic spoof fingerprints for spoof detection systems.", "motivation": "Large fingerprint datasets are time-consuming, expensive to collect, and require strict privacy measures. Synthetic fingerprint data can address privacy, cost, and accessibility issues in biometric data collection.", "method": "Uses conditional StyleGAN2-ADA and StyleGAN3 to generate high-resolution synthetic live fingerprints conditioned on finger identities, and CycleGANs to translate them into realistic spoof fingerprints simulating various presentation attack materials.", "result": "Created two synthetic datasets (DB2 and DB3) with 1,500 fingerprint images each. StyleGAN3 achieved FID as low as 5, with True Accept Rate of 99.47% at 0.01% False Accept Rate. StyleGAN2-ADA achieved 98.67% TAR at same FAR. No significant identity leakage detected.", "conclusion": "The approach successfully generates high-quality synthetic fingerprints that preserve privacy while maintaining strong biometric performance, making them suitable for developing robust spoof detection systems."}}
{"id": "2510.16674", "categories": ["cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2510.16674", "abs": "https://arxiv.org/abs/2510.16674", "authors": ["Azam Shirali", "Giri Narasimhan"], "title": "Evaluating protein binding interfaces with PUMBA", "comment": null, "summary": "Protein-protein docking tools help in studying interactions between proteins,\nand are essential for drug, vaccine, and therapeutic development. However, the\naccuracy of a docking tool depends on a robust scoring function that can\nreliably differentiate between native and non-native complexes. PIsToN is a\nstate-of-the-art deep learning-based scoring function that uses Vision\nTransformers in its architecture. Recently, the Mamba architecture has\ndemonstrated exceptional performance in both natural language processing and\ncomputer vision, often outperforming Transformer-based models in their domains.\nIn this study, we introduce PUMBA (Protein-protein interface evaluation with\nVision Mamba), which improves PIsToN by replacing its Vision Transformer\nbackbone with Vision Mamba. This change allows us to leverage Mamba's efficient\nlong-range sequence modeling for sequences of image patches. As a result, the\nmodel's ability to capture both global and local patterns in protein-protein\ninterface features is significantly improved. Evaluation on several\nwidely-used, large-scale public datasets demonstrates that PUMBA consistently\noutperforms its original Transformer-based predecessor, PIsToN.", "AI": {"tldr": "PUMBA improves protein-protein docking by replacing Vision Transformers with Vision Mamba architecture, achieving better performance than PIsToN.", "motivation": "To enhance protein-protein docking accuracy by leveraging Mamba's superior long-range sequence modeling capabilities over Transformers.", "method": "Replaced Vision Transformer backbone in PIsToN with Vision Mamba architecture to better capture global and local patterns in protein-protein interface features.", "result": "PUMBA consistently outperforms PIsToN across multiple large-scale public datasets.", "conclusion": "Vision Mamba architecture provides significant improvements for protein-protein interface evaluation compared to Transformer-based approaches."}}
{"id": "2510.17039", "categories": ["cs.CV", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2510.17039", "abs": "https://arxiv.org/abs/2510.17039", "authors": ["Mohammad R. Salmanpour", "Sonya Falahati", "Amir Hossein Pouria", "Amin Mousavi", "Somayeh Sadat Mehrnia", "Morteza Alizadeh", "Arman Gorji", "Zeinab Farsangi", "Alireza Safarian", "Mehdi Maghsudi", "Carlos Uribe", "Arman Rahmim", "Ren Yuan"], "title": "Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework", "comment": "13 pages, 2 figures, and 2 tables", "summary": "Lung cancer remains the leading cause of cancer mortality, with CT imaging\ncentral to screening, prognosis, and treatment. Manual segmentation is variable\nand time-intensive, while deep learning (DL) offers automation but faces\nbarriers to clinical adoption. Guided by the Knowledge-to-Action framework,\nthis study develops a clinician-in-the-loop DL pipeline to enhance\nreproducibility, prognostic accuracy, and clinical trust. Multi-center CT data\nfrom 999 patients across 12 public datasets were analyzed using five DL models\n(3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against\nexpert contours on whole and click-point cropped images. Segmentation\nreproducibility was assessed using 497 PySERA-extracted radiomic features via\nSpearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic\nmodeling compared supervised (SL) and semi-supervised learning (SSL) across 38\ndimensionality reduction strategies and 24 classifiers. Six physicians\nqualitatively evaluated masks across seven domains, including clinical\nmeaningfulness, boundary quality, prognostic value, trust, and workflow\nintegration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71),\nradiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive\naccuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed\nSL across models. Radiologists favored VNet for peritumoral representation and\nsmoother boundaries, preferring AI-generated initial masks for refinement\nrather than replacement. These results demonstrate that integrating VNet with\nSSL yields accurate, reproducible, and clinically trusted CT-based lung cancer\nprognosis, highlighting a feasible path toward physician-centered AI\ntranslation.", "AI": {"tldr": "A clinician-in-the-loop DL pipeline using VNet with semi-supervised learning achieves accurate, reproducible, and clinically trusted CT-based lung cancer segmentation and prognosis.", "motivation": "Manual lung cancer segmentation is variable and time-intensive, while existing deep learning approaches face barriers to clinical adoption. The study aims to enhance reproducibility, prognostic accuracy, and clinical trust through a clinician-in-the-loop approach.", "method": "Used multi-center CT data from 999 patients across 12 datasets with five DL models (3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D). Assessed segmentation reproducibility using 497 radiomic features and compared supervised vs semi-supervised learning across 38 dimensionality reduction strategies and 24 classifiers. Six physicians qualitatively evaluated masks across seven clinical domains.", "result": "VNet achieved best performance (Dice=0.83, IoU=0.71), radiomic stability (mean correlation=0.76, ICC=0.65), and predictive accuracy under SSL (accuracy=0.88, F1=0.83). SSL consistently outperformed SL. Radiologists preferred VNet for peritumoral representation and AI-generated masks for refinement rather than replacement.", "conclusion": "Integrating VNet with SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer prognosis, providing a feasible path toward physician-centered AI translation in clinical practice."}}
{"id": "2510.16676", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16676", "abs": "https://arxiv.org/abs/2510.16676", "authors": ["Anindya Sarkar", "Binglin Ji", "Yevgeniy Vorobeychik"], "title": "Active Target Discovery under Uninformative Prior: The Power of Permanent and Transient Memory", "comment": "32 pages, 20 figures, Accepted to NeurIPS 2025", "summary": "In many scientific and engineering fields, where acquiring high-quality data\nis expensive--such as medical imaging, environmental monitoring, and remote\nsensing--strategic sampling of unobserved regions based on prior observations\nis crucial for maximizing discovery rates within a constrained budget. The rise\nof powerful generative models, such as diffusion models, has enabled active\ntarget discovery in partially observable environments by leveraging learned\npriors--probabilistic representations that capture underlying structure from\ndata. With guidance from sequentially gathered task-specific observations,\nthese models can progressively refine exploration and efficiently direct\nqueries toward promising regions. However, in domains where learning a strong\nprior is infeasible due to extremely limited data or high sampling cost (such\nas rare species discovery, diagnostics for emerging diseases, etc.), these\nmethods struggle to generalize. To overcome this limitation, we propose a novel\napproach that enables effective active target discovery even in settings with\nuninformative priors, ensuring robust exploration and adaptability in complex\nreal-world scenarios. Our framework is theoretically principled and draws\ninspiration from neuroscience to guide its design. Unlike black-box policies,\nour approach is inherently interpretable, providing clear insights into\ndecision-making. Furthermore, it guarantees a strong, monotonic improvement in\nprior estimates with each new observation, leading to increasingly accurate\nsampling and reinforcing both reliability and adaptability in dynamic settings.\nThrough comprehensive experiments and ablation studies across various domains,\nincluding species distribution modeling and remote sensing, we demonstrate that\nour method substantially outperforms baseline approaches.", "AI": {"tldr": "A novel framework for active target discovery that works effectively even with uninformative priors, ensuring robust exploration and adaptability in data-scarce domains.", "motivation": "Existing methods relying on strong generative priors struggle in domains with extremely limited data or high sampling costs (e.g., rare species discovery, emerging disease diagnostics), necessitating approaches that work with uninformative priors.", "method": "A theoretically principled framework inspired by neuroscience, providing interpretable decision-making with guaranteed monotonic improvement in prior estimates with each new observation.", "result": "Substantially outperforms baseline approaches across various domains including species distribution modeling and remote sensing, as demonstrated through comprehensive experiments and ablation studies.", "conclusion": "The proposed method enables effective active target discovery in settings with uninformative priors, offering robust exploration, interpretability, and reliable performance in complex real-world scenarios."}}
{"id": "2510.16677", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16677", "abs": "https://arxiv.org/abs/2510.16677", "authors": ["Ran Tong", "Jiaqi Liu", "Su Liu", "Xin Hu", "Lanruo Wang"], "title": "Renaissance of RNNs in Streaming Clinical Time Series: Compact Recurrence Remains Competitive with Transformers", "comment": null, "summary": "We present a compact, strictly causal benchmark for streaming clinical time\nseries on the MIT--BIH Arrhythmia Database using per-second heart rate. Two\ntasks are studied under record-level, non-overlapping splits: near-term\ntachycardia risk (next ten seconds) and one-step heart rate forecasting. We\ncompare a GRU-D (RNN) and a Transformer under matched training budgets against\nstrong non-learned baselines. Evaluation is calibration-aware for\nclassification and proper for forecasting, with temperature scaling and grouped\nbootstrap confidence intervals. On MIT-BIH, GRU-D slightly surpasses the\nTransformer for tachycardia risk, while the Transformer clearly lowers\nforecasting error relative to GRU-D and persistence. Our results show that, in\nlongitudinal monitoring, model choice is task-dependent: compact RNNs remain\ncompetitive for short-horizon risk scoring, whereas compact Transformers\ndeliver clearer gains for point forecasting.", "AI": {"tldr": "A compact, strictly causal benchmark for streaming clinical time series on MIT-BIH Arrhythmia Database comparing GRU-D and Transformer models for tachycardia risk prediction and heart rate forecasting.", "motivation": "To establish a rigorous benchmark for streaming clinical time series analysis and compare the performance of RNNs vs Transformers in longitudinal monitoring tasks.", "method": "Used per-second heart rate data from MIT-BIH Arrhythmia Database with record-level, non-overlapping splits. Compared GRU-D (RNN) and Transformer models against non-learned baselines for two tasks: near-term tachycardia risk prediction (next 10 seconds) and one-step heart rate forecasting.", "result": "On MIT-BIH, GRU-D slightly outperformed Transformer for tachycardia risk prediction, while Transformer clearly reduced forecasting error compared to both GRU-D and persistence baseline.", "conclusion": "Model choice in longitudinal monitoring is task-dependent: compact RNNs remain competitive for short-horizon risk scoring, while compact Transformers provide clearer advantages for point forecasting tasks."}}
{"id": "2510.17045", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17045", "abs": "https://arxiv.org/abs/2510.17045", "authors": ["Deepak Sridhar", "Kartikeya Bhardwaj", "Jeya Pradha Jeyaraj", "Nuno Vasconcelos", "Ankita Nayak", "Harris Teague"], "title": "Video Reasoning without Training", "comment": null, "summary": "Video reasoning using Large Multimodal Models (LMMs) relies on costly\nreinforcement learning (RL) and verbose chain-of-thought, resulting in\nsubstantial computational overhead during both training and inference.\nMoreover, the mechanisms that control the thinking process in these reasoning\nmodels are very limited. In this paper, using entropy of the model's output as\na signal, we discover that the high-quality models go through a series of\nmicro-explorations and micro-exploitations which keep the reasoning process\ngrounded (i.e., avoid excessive randomness while the model is exploring or\nthinking through an answer). We further observe that once this \"thinking\"\nprocess is over, more accurate models demonstrate a better convergence by\nreducing the entropy significantly via a final exploitation phase (i.e., a more\ncertain convergence towards a solution trajectory). We then use these novel,\ntheoretically-grounded insights to tune the model's behavior directly at\ninference, without using any RL or supervised fine-tuning. Specifically, during\ninference, our proposed approach called V-Reason (Video-Reason) adapts the\nvalue cache of the LMM via a few optimization steps on a small, trainable\ncontroller using an entropy-based objective, i.e., no supervision from any\ndataset or RL is necessary. This tuning improves the model's micro-exploration\nand exploitation behavior during inference. Our experiments show that our\nproposed method achieves significant improvements over the base\ninstruction-tuned models across several video reasoning datasets, narrowing the\ngap with RL-trained models to within 0.6% average accuracy without any\ntraining, while offering massive efficiency benefits: output tokens are reduced\nby 58.6% compared to the RL model.", "AI": {"tldr": "V-Reason improves video reasoning in Large Multimodal Models by optimizing entropy during inference, reducing computational costs and output tokens without requiring reinforcement learning or fine-tuning.", "motivation": "Current video reasoning methods rely on expensive reinforcement learning and verbose chain-of-thought processes, creating substantial computational overhead and limited control over the thinking process.", "method": "Uses entropy of model outputs to guide micro-exploration and exploitation phases, then adapts the model's value cache during inference using a small trainable controller with entropy-based optimization.", "result": "Achieves significant improvements over base models, narrowing gap with RL-trained models to within 0.6% average accuracy while reducing output tokens by 58.6% compared to RL models.", "conclusion": "V-Reason provides an efficient, training-free approach to enhance video reasoning by optimizing entropy dynamics during inference, offering substantial computational benefits while maintaining competitive performance."}}
{"id": "2510.16687", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16687", "abs": "https://arxiv.org/abs/2510.16687", "authors": ["Shurong Lin", "Eric D. Kolaczyk", "Adam Smith", "Elliot Paquette"], "title": "High-Dimensional Privacy-Utility Dynamics of Noisy Stochastic Gradient Descent on Least Squares", "comment": null, "summary": "The interplay between optimization and privacy has become a central theme in\nprivacy-preserving machine learning. Noisy stochastic gradient descent (SGD)\nhas emerged as a cornerstone algorithm, particularly in large-scale settings.\nThese variants of gradient methods inject carefully calibrated noise into each\nupdate to achieve differential privacy, the gold standard notion of rigorous\nprivacy guarantees. Prior work primarily provides various bounds on statistical\nrisk and privacy loss for noisy SGD, yet the \\textit{exact} behavior of the\nprocess remains unclear, particularly in high-dimensional settings. This work\nleverages a diffusion approach to analyze noisy SGD precisely, providing a\ncontinuous-time perspective that captures both statistical risk evolution and\nprivacy loss dynamics in high dimensions. Moreover, we study a variant of noisy\nSGD that does not require explicit knowledge of gradient sensitivity, unlike\nexisting work that assumes or enforces sensitivity through gradient clipping.\nSpecifically, we focus on the least squares problem with $\\ell_2$\nregularization.", "AI": {"tldr": "This paper provides a diffusion-based analysis of noisy SGD for privacy-preserving machine learning, offering exact characterization of statistical risk and privacy loss in high dimensions, including a variant that doesn't require gradient sensitivity knowledge.", "motivation": "Prior work on noisy SGD for differential privacy provides bounds but lacks exact characterization of the algorithm's behavior, especially in high-dimensional settings. The interplay between optimization and privacy needs more precise analysis.", "method": "Uses a diffusion approach to analyze noisy SGD in continuous time, focusing on least squares with \u21132 regularization. Studies a variant that doesn't require explicit gradient sensitivity knowledge, unlike existing methods that rely on gradient clipping.", "result": "Provides exact characterization of both statistical risk evolution and privacy loss dynamics in high dimensions through the diffusion framework. The analysis captures the precise behavior of noisy SGD processes.", "conclusion": "The diffusion approach offers a powerful continuous-time perspective for precisely analyzing noisy SGD, enabling better understanding of privacy-optimization trade-offs in high-dimensional settings without requiring gradient sensitivity assumptions."}}
{"id": "2510.17051", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17051", "abs": "https://arxiv.org/abs/2510.17051", "authors": ["Masoud Khairi Atani", "Alon Harell", "Hyomin Choi", "Runyu Yang", "Fabien Racape", "Ivan V. Bajic"], "title": "How Universal Are SAM2 Features?", "comment": "This work has been accepted for publication in IEEE Picture Coding\n  Symposium (PCS) 2025", "summary": "The trade-off between general-purpose foundation vision models and their\nspecialized counterparts is critical for efficient feature coding design and is\nnot yet fully understood. We investigate this trade-off by comparing the\nfeature versatility of the general-purpose Hiera encoder against the\nsegmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight,\ntrainable neck to probe the adaptability of their frozen features, we quantify\nthe information-theoretic cost of specialization. Our results reveal that while\nSAM2's specialization is highly effective for spatially-related tasks like\ndepth estimation, it comes at a cost. The specialized SAM2 encoder\nunderperforms its generalist predecessor, Hiera, on conceptually distant tasks\nsuch as pose estimation and image captioning, demonstrating a measurable loss\nof broader semantic information. A novel cross-neck analysis on SAM2 reveals\nthat each level of adaptation creates a further representational bottleneck.\nOur analysis illuminates these trade-offs in feature universality, providing a\nquantitative foundation for designing efficient feature coding and adaptation\nstrategies for diverse downstream applications.", "AI": {"tldr": "This paper investigates the trade-off between general-purpose foundation vision models (Hiera) and specialized models (SAM2), revealing that specialization for spatial tasks comes at the cost of broader semantic capabilities.", "motivation": "To understand the trade-off between general-purpose foundation vision models and specialized counterparts for efficient feature coding design, as this relationship is not yet fully understood.", "method": "Compare feature versatility of Hiera encoder against SAM2 using a lightweight trainable neck to probe adaptability of frozen features, and quantify information-theoretic cost of specialization through cross-neck analysis.", "result": "SAM2's specialization is highly effective for spatially-related tasks like depth estimation but underperforms Hiera on conceptually distant tasks such as pose estimation and image captioning, showing measurable loss of broader semantic information. Each level of adaptation in SAM2 creates further representational bottlenecks.", "conclusion": "Specialization for spatial tasks comes at the cost of broader semantic capabilities, providing quantitative foundation for designing efficient feature coding and adaptation strategies for diverse applications."}}
{"id": "2510.16694", "categories": ["cs.LG", "cs.CR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.16694", "abs": "https://arxiv.org/abs/2510.16694", "authors": ["Anthony DiMaggio", "Raghav Sharma", "Gururaj Saileshwar"], "title": "CLIP: Client-Side Invariant Pruning for Mitigating Stragglers in Secure Federated Learning", "comment": null, "summary": "Secure federated learning (FL) preserves data privacy during distributed\nmodel training. However, deploying such frameworks across heterogeneous devices\nresults in performance bottlenecks, due to straggler clients with limited\ncomputational or network capabilities, slowing training for all participating\nclients. This paper introduces the first straggler mitigation technique for\nsecure aggregation with deep neural networks. We propose CLIP, a client-side\ninvariant neuron pruning technique coupled with network-aware pruning, that\naddresses compute and network bottlenecks due to stragglers during training\nwith minimal accuracy loss. Our technique accelerates secure FL training by 13%\nto 34% across multiple datasets (CIFAR10, Shakespeare, FEMNIST) with an\naccuracy impact of between 1.3% improvement to 2.6% reduction.", "AI": {"tldr": "CLIP introduces client-side invariant neuron pruning with network-aware pruning to mitigate straggler bottlenecks in secure federated learning, accelerating training by 13-34% with minimal accuracy impact.", "motivation": "Secure federated learning preserves data privacy but suffers from performance bottlenecks due to straggler clients with limited computational or network capabilities, which slow down training for all participants.", "method": "Proposes CLIP - a client-side invariant neuron pruning technique coupled with network-aware pruning to address compute and network bottlenecks during secure aggregation with deep neural networks.", "result": "Accelerates secure FL training by 13% to 34% across multiple datasets (CIFAR10, Shakespeare, FEMNIST) with accuracy impact ranging from 1.3% improvement to 2.6% reduction.", "conclusion": "CLIP effectively mitigates straggler bottlenecks in secure federated learning while maintaining model accuracy, making secure FL more practical for deployment across heterogeneous devices."}}
{"id": "2510.17068", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17068", "abs": "https://arxiv.org/abs/2510.17068", "authors": ["Zhe Luo", "Wenjing Jia", "Stuart Perry"], "title": "ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding", "comment": null, "summary": "Three-dimensional (3D) point clouds are becoming increasingly vital in\napplications such as autonomous driving, augmented reality, and immersive\ncommunication, demanding real-time processing and low latency. However, their\nlarge data volumes and bandwidth constraints hinder the deployment of\nhigh-quality services in resource-limited environments. Progres- sive coding,\nwhich allows for decoding at varying levels of detail, provides an alternative\nby allowing initial partial decoding with subsequent refinement. Although\nrecent learning-based point cloud geometry coding methods have achieved notable\nsuccess, their fixed latent representation does not support progressive\ndecoding. To bridge this gap, we propose ProDAT, a novel density-aware\ntail-drop mechanism for progressive point cloud coding. By leveraging density\ninformation as a guidance signal, latent features and coordinates are decoded\nadaptively based on their significance, therefore achieving progressive\ndecoding at multiple bitrates using one single model. Experimental results on\nbenchmark datasets show that the proposed ProDAT not only enables progressive\ncoding but also achieves superior coding efficiency compared to\nstate-of-the-art learning-based coding techniques, with over 28.6% BD-rate\nimprovement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet", "AI": {"tldr": "ProDAT enables progressive point cloud coding using density-aware tail-drop mechanism, achieving superior compression efficiency with single-model multi-bitrate support.", "motivation": "3D point clouds require real-time processing but face bandwidth constraints; existing learning-based methods lack progressive decoding capability.", "method": "Proposed ProDAT with density-aware tail-drop mechanism that adaptively decodes latent features and coordinates based on significance using density guidance.", "result": "Achieved over 28.6% BD-rate improvement for PSNR-D2 on SemanticKITTI and over 18.15% on ShapeNet compared to state-of-the-art methods.", "conclusion": "ProDAT successfully bridges the gap for progressive point cloud coding while maintaining superior compression performance with single-model efficiency."}}
{"id": "2510.16695", "categories": ["cs.LG", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.16695", "abs": "https://arxiv.org/abs/2510.16695", "authors": ["Iman Deznabi", "Peeyush Kumar", "Madalina Fiterau"], "title": "Resolution-Aware Retrieval Augmented Zero-Shot Forecasting", "comment": null, "summary": "Zero-shot forecasting aims to predict outcomes for previously unseen\nconditions without direct historical data, posing a significant challenge for\ntraditional forecasting methods. We introduce a Resolution-Aware\nRetrieval-Augmented Forecasting model that enhances predictive accuracy by\nleveraging spatial correlations and temporal frequency characteristics. By\ndecomposing signals into different frequency components, our model employs\nresolution-aware retrieval, where lower-frequency components rely on broader\nspatial context, while higher-frequency components focus on local influences.\nThis allows the model to dynamically retrieve relevant data and adapt to new\nlocations with minimal historical context.\n  Applied to microclimate forecasting, our model significantly outperforms\ntraditional forecasting methods, numerical weather prediction models, and\nmodern foundation time series models, achieving 71% lower MSE than HRRR and 34%\nlower MSE than Chronos on the ERA5 dataset.\n  Our results highlight the effectiveness of retrieval-augmented and\nresolution-aware strategies, offering a scalable and data-efficient solution\nfor zero-shot forecasting in microclimate modeling and beyond.", "AI": {"tldr": "A Resolution-Aware Retrieval-Augmented Forecasting model for zero-shot forecasting that leverages spatial correlations and temporal frequency characteristics to predict outcomes for unseen conditions without direct historical data.", "motivation": "Zero-shot forecasting poses significant challenges for traditional methods when predicting outcomes for previously unseen conditions without direct historical data.", "method": "Decomposes signals into different frequency components and employs resolution-aware retrieval - lower-frequency components use broader spatial context while higher-frequency components focus on local influences, allowing dynamic retrieval of relevant data.", "result": "Significantly outperforms traditional forecasting methods, numerical weather prediction models, and modern foundation time series models, achieving 71% lower MSE than HRRR and 34% lower MSE than Chronos on the ERA5 dataset for microclimate forecasting.", "conclusion": "The retrieval-augmented and resolution-aware strategies offer a scalable and data-efficient solution for zero-shot forecasting in microclimate modeling and beyond."}}
{"id": "2510.17078", "categories": ["cs.CV", "I.2.10; I.4.8"], "pdf": "https://arxiv.org/pdf/2510.17078", "abs": "https://arxiv.org/abs/2510.17078", "authors": ["Jad Berjawi", "Yoann Dupas", "Christophe C'erin"], "title": "Towards a Generalizable Fusion Architecture for Multimodal Object Detection", "comment": "8 pages, 8 figures, accepted at ICCV 2025 MIRA Workshop", "summary": "Multimodal object detection improves robustness in chal- lenging conditions\nby leveraging complementary cues from multiple sensor modalities. We introduce\nFiltered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing\narchitecture designed to enhance the fusion of RGB and infrared (IR) inputs.\nFMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress\nredun- dant spectral features with a cross-attention-based fusion module (MCAF)\nto improve intermodal feature sharing. Unlike approaches tailored to specific\ndatasets, FMCAF aims for generalizability, improving performance across\ndifferent multimodal challenges without requiring dataset- specific tuning. On\nLLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection),\nFMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50\non VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a\nflexible foundation for robust multimodal fusion in future detection pipelines.", "AI": {"tldr": "FMCAF is a preprocessing architecture that enhances RGB and infrared fusion using frequency-domain filtering and cross-attention, achieving improved performance on multimodal object detection without dataset-specific tuning.", "motivation": "To improve multimodal object detection robustness by leveraging complementary cues from RGB and infrared sensors, addressing the need for generalizable fusion methods that work across different challenging conditions.", "method": "Combines frequency-domain filtering (Freq-Filter) to suppress redundant spectral features with cross-attention-based fusion module (MCAF) to improve intermodal feature sharing.", "result": "Outperforms traditional concatenation fusion, achieving +13.9% mAP@50 on VEDAI and +1.1% on LLVIP datasets.", "conclusion": "FMCAF shows potential as a flexible foundation for robust multimodal fusion in future detection pipelines, demonstrating generalizability across different multimodal challenges."}}
{"id": "2510.16703", "categories": ["cs.LG", "cs.AI", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.16703", "abs": "https://arxiv.org/abs/2510.16703", "authors": ["Yizuo Chen", "Adnan Darwiche"], "title": "On the Granularity of Causal Effect Identifiability", "comment": null, "summary": "The classical notion of causal effect identifiability is defined in terms of\ntreatment and outcome variables. In this note, we consider the identifiability\nof state-based causal effects: how an intervention on a particular state of\ntreatment variables affects a particular state of outcome variables. We\ndemonstrate that state-based causal effects may be identifiable even when\nvariable-based causal effects may not. Moreover, we show that this separation\noccurs only when additional knowledge -- such as context-specific\nindependencies and conditional functional dependencies -- is available. We\nfurther examine knowledge that constrains the states of variables, and show\nthat such knowledge does not improve identifiability on its own but can improve\nboth variable-based and state-based identifiability when combined with other\nknowledge such as context-specific independencies. Our findings highlight\nsituations where causal effects of interest may be estimable from observational\ndata and this identifiability may be missed by existing variable-based\nframeworks.", "AI": {"tldr": "State-based causal effects (interventions on specific states of treatment variables affecting specific states of outcome variables) can be identifiable even when variable-based causal effects are not, particularly when additional knowledge like context-specific independencies is available.", "motivation": "To extend causal effect identifiability beyond traditional variable-based frameworks by considering state-based interventions, which may be estimable from observational data even when conventional methods fail.", "method": "Theoretical analysis of state-based causal effect identifiability, examining how additional knowledge (context-specific independencies, conditional functional dependencies, and state constraints) affects identifiability compared to variable-based approaches.", "result": "State-based causal effects can be identifiable when variable-based effects are not, but this separation only occurs with additional knowledge. State constraints alone don't improve identifiability but can enhance both variable-based and state-based identifiability when combined with other knowledge.", "conclusion": "State-based causal analysis can reveal estimable causal effects that existing variable-based frameworks might miss, highlighting the importance of incorporating additional domain knowledge for more refined causal inference."}}
{"id": "2510.17095", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17095", "abs": "https://arxiv.org/abs/2510.17095", "authors": ["Ruitong Gan", "Junran Peng", "Yang Liu", "Chuanchen Luo", "Qing Li", "Zhaoxiang Zhang"], "title": "GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation", "comment": null, "summary": "Planes are fundamental primitives of 3D sences, especially in man-made\nenvironments such as indoor spaces and urban streets. Representing these planes\nin a structured and parameterized format facilitates scene editing and physical\nsimulations in downstream applications. Recently, Gaussian Splatting (GS) has\ndemonstrated remarkable effectiveness in the Novel View Synthesis task, with\nextensions showing great potential in accurate surface reconstruction. However,\neven state-of-the-art GS representations often struggle to reconstruct planar\nregions with sufficient smoothness and precision. To address this issue, we\npropose GSPlane, which recovers accurate geometry and produces clean and\nwell-structured mesh connectivity for plane regions in the reconstructed scene.\nBy leveraging off-the-shelf segmentation and normal prediction models, GSPlane\nextracts robust planar priors to establish structured representations for\nplanar Gaussian coordinates, which help guide the training process by enforcing\ngeometric consistency. To further enhance training robustness, a Dynamic\nGaussian Re-classifier is introduced to adaptively reclassify planar Gaussians\nwith persistently high gradients as non-planar, ensuring more reliable\noptimization. Furthermore, we utilize the optimized planar priors to refine the\nmesh layouts, significantly improving topological structure while reducing the\nnumber of vertices and faces. We also explore applications of the structured\nplanar representation, which enable decoupling and flexible manipulation of\nobjects on supportive planes. Extensive experiments demonstrate that, with no\nsacrifice in rendering quality, the introduction of planar priors significantly\nimproves the geometric accuracy of the extracted meshes across various\nbaselines.", "AI": {"tldr": "GSPlane improves 3D scene reconstruction by incorporating planar priors into Gaussian Splatting, enabling more accurate geometry, cleaner meshes, and structured representations for planar regions.", "motivation": "Existing Gaussian Splatting representations struggle to reconstruct planar regions with sufficient smoothness and precision, limiting their effectiveness for scene editing and physical simulations.", "method": "Leverages segmentation and normal prediction models to extract planar priors, establishes structured representations for planar Gaussians, introduces Dynamic Gaussian Re-classifier for robust optimization, and refines mesh layouts using optimized planar priors.", "result": "Significantly improves geometric accuracy of extracted meshes across various baselines without sacrificing rendering quality, produces clean mesh connectivity with reduced vertices and faces, and enables object decoupling and manipulation on supportive planes.", "conclusion": "GSPlane successfully addresses planar reconstruction challenges in Gaussian Splatting by incorporating structured planar priors, leading to improved geometric accuracy and enabling practical applications in scene editing and manipulation."}}
{"id": "2510.16719", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.16719", "abs": "https://arxiv.org/abs/2510.16719", "authors": ["Zak Ressler", "Marcus Grijalva", "Angelica Marie Ignacio", "Melanie Torres", "Abelardo Cuadra Rojas", "Rohollah Moghadam", "Mohammad Rasoul narimani"], "title": "LSTM-Based Forecasting and Analysis of EV Charging Demand in a Dense Urban Campus", "comment": null, "summary": "This paper presents a framework for processing EV charging load data in order\nto forecast future load predictions using a Recurrent Neural Network,\nspecifically an LSTM. The framework processes a large set of raw data from\nmultiple locations and transforms it with normalization and feature extraction\nto train the LSTM. The pre-processing stage corrects for missing or incomplete\nvalues by interpolating and normalizing the measurements. This information is\nthen fed into a Long Short-Term Memory Model designed to capture the short-term\nfluctuations while also interpreting the long-term trends in the charging data.\nExperimental results demonstrate the model's ability to accurately predict\ncharging demand across multiple time scales (daily, weekly, and monthly),\nproviding valuable insights for infrastructure planning, energy management, and\ngrid integration of EV charging facilities. The system's modular design allows\nfor adaptation to different charging locations with varying usage patterns,\nmaking it applicable across diverse deployment scenarios.", "AI": {"tldr": "A framework using LSTM neural networks to forecast EV charging load across multiple time scales through data preprocessing and feature extraction.", "motivation": "To enable accurate forecasting of EV charging demand for infrastructure planning, energy management, and grid integration of charging facilities.", "method": "Processes raw EV charging data with normalization and feature extraction, then trains a Long Short-Term Memory (LSTM) model to capture both short-term fluctuations and long-term trends.", "result": "The model accurately predicts charging demand across daily, weekly, and monthly time scales, with modular design allowing adaptation to different locations and usage patterns.", "conclusion": "The LSTM-based framework provides valuable forecasting capabilities for EV charging infrastructure planning and can be applied across diverse deployment scenarios."}}
{"id": "2510.17105", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17105", "abs": "https://arxiv.org/abs/2510.17105", "authors": ["Xiaogang Xu", "Jian Wang", "Yunfan Lu", "Ruihang Chu", "Ruixing Wang", "Jiafei Wu", "Bei Yu", "Liang Lin"], "title": "Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement", "comment": null, "summary": "Diffusion-based methods, leveraging pre-trained large models like Stable\nDiffusion via ControlNet, have achieved remarkable performance in several\nlow-level vision tasks. However, Pre-Trained Diffusion-Based (PTDB) methods\noften sacrifice content fidelity to attain higher perceptual realism. This\nissue is exacerbated in low-light scenarios, where severely degraded\ninformation caused by the darkness limits effective control. We identify two\nprimary causes of fidelity loss: the absence of suitable conditional latent\nmodeling and the lack of bidirectional interaction between the conditional\nlatent and noisy latent in the diffusion process. To address this, we propose a\nnovel optimization strategy for conditioning in pre-trained diffusion models,\nenhancing fidelity while preserving realism and aesthetics. Our method\nintroduces a mechanism to recover spatial details lost during VAE encoding,\ni.e., a latent refinement pipeline incorporating generative priors.\nAdditionally, the refined latent condition interacts dynamically with the noisy\nlatent, leading to improved restoration performance. Our approach is\nplug-and-play, seamlessly integrating into existing diffusion networks to\nprovide more effective control. Extensive experiments demonstrate significant\nfidelity improvements in PTDB methods.", "AI": {"tldr": "Proposes a novel optimization strategy for pre-trained diffusion models to enhance fidelity in low-level vision tasks, addressing content fidelity loss in low-light scenarios through latent refinement and bidirectional interaction.", "motivation": "Pre-trained diffusion-based methods sacrifice content fidelity for perceptual realism, especially in low-light scenarios where degraded information limits effective control. Two main causes identified: absence of suitable conditional latent modeling and lack of bidirectional interaction between conditional and noisy latents.", "method": "Introduces a latent refinement pipeline to recover spatial details lost during VAE encoding, incorporating generative priors. Enables dynamic bidirectional interaction between refined latent condition and noisy latent during diffusion process. Plug-and-play approach that integrates into existing diffusion networks.", "result": "Extensive experiments demonstrate significant fidelity improvements in pre-trained diffusion-based methods while preserving realism and aesthetics.", "conclusion": "The proposed optimization strategy effectively enhances fidelity in diffusion-based low-level vision tasks, providing more effective control through improved latent conditioning and interaction mechanisms."}}
{"id": "2510.16743", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16743", "abs": "https://arxiv.org/abs/2510.16743", "authors": ["Viktoria Schram", "Markus Hiller", "Daniel Beck", "Trevor Cohn"], "title": "Zero-Shot Performance Prediction for Probabilistic Scaling Laws", "comment": "Accepted to NeurIPS 2025", "summary": "The prediction of learning curves for Natural Language Processing (NLP)\nmodels enables informed decision-making to meet specific performance\nobjectives, while reducing computational overhead and lowering the costs\nassociated with dataset acquisition and curation. In this work, we formulate\nthe prediction task as a multitask learning problem, where each task's data is\nmodelled as being organized within a two-layer hierarchy. To model the shared\ninformation and dependencies across tasks and hierarchical levels, we employ\nlatent variable multi-output Gaussian Processes, enabling to account for task\ncorrelations and supporting zero-shot prediction of learning curves (LCs). We\ndemonstrate that this approach facilitates the development of probabilistic\nscaling laws at lower costs. Applying an active learning strategy, LCs can be\nqueried to reduce predictive uncertainty and provide predictions close to\nground truth scaling laws. We validate our framework on three small-scale NLP\ndatasets with up to $30$ LCs. These are obtained from nanoGPT models, from\nbilingual translation using mBART and Transformer models, and from multilingual\ntranslation using M2M100 models of varying sizes.", "AI": {"tldr": "This paper proposes a multitask learning approach using latent variable multi-output Gaussian Processes to predict learning curves for NLP models, enabling probabilistic scaling laws and reducing computational costs.", "motivation": "To enable informed decision-making for NLP model development by predicting learning curves, reducing computational overhead and dataset acquisition costs.", "method": "Formulates learning curve prediction as a multitask learning problem with two-layer hierarchical data organization, using latent variable multi-output Gaussian Processes to model task correlations and support zero-shot prediction.", "result": "The approach facilitates development of probabilistic scaling laws at lower costs, and with active learning, provides predictions close to ground truth scaling laws. Validated on three small-scale NLP datasets with up to 30 learning curves.", "conclusion": "The proposed framework successfully predicts learning curves for various NLP models, supporting efficient model development and resource allocation through probabilistic scaling laws."}}
{"id": "2510.17114", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17114", "abs": "https://arxiv.org/abs/2510.17114", "authors": ["Hodaka Kawachi", "Tomoya Nakamura", "Hiroaki Santo", "SaiKiran Kumar Tedla", "Trevor Dalton Canham", "Yasushi Yagi", "Michael S. Brown"], "title": "Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras", "comment": null, "summary": "This paper introduces a method for using LED-based environmental lighting to\nproduce visually imperceptible watermarks for consumer cameras. Our approach\noptimizes an LED light source's spectral profile to be minimally visible to the\nhuman eye while remaining highly detectable by typical consumer cameras. The\nmethod jointly considers the human visual system's sensitivity to visible\nspectra, modern consumer camera sensors' spectral sensitivity, and narrowband\nLEDs' ability to generate broadband spectra perceived as \"white light\"\n(specifically, D65 illumination). To ensure imperceptibility, we employ\nspectral modulation rather than intensity modulation. Unlike conventional\nvisible light communication, our approach enables watermark extraction at\nstandard low frame rates (30-60 fps). While the information transfer rate is\nmodest-embedding 128 bits within a 10-second video clip-this capacity is\nsufficient for essential metadata supporting privacy protection and content\nverification.", "AI": {"tldr": "A method for creating imperceptible watermarks using LED lighting that is invisible to humans but detectable by cameras, enabling privacy protection and content verification.", "motivation": "To develop a watermarking system that protects privacy and verifies content without being noticeable to human observers, leveraging the differences between human vision and camera sensors.", "method": "Optimizes LED spectral profiles to be minimally visible to humans but highly detectable by cameras, using spectral modulation instead of intensity modulation, and works at standard frame rates (30-60 fps).", "result": "Achieves embedding of 128 bits within a 10-second video clip, sufficient for essential metadata while maintaining visual imperceptibility to human viewers.", "conclusion": "The proposed LED-based watermarking system successfully creates imperceptible watermarks that can support privacy protection and content verification applications."}}
{"id": "2510.16747", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16747", "abs": "https://arxiv.org/abs/2510.16747", "authors": ["Danish Nazir", "Gowtham Sai Inti", "Timo Bartels", "Jan Piewek", "Thorsten Bagdonat", "Tim Fingscheidt"], "title": "An Efficient Semantic Segmentation Decoder for In-Car or Distributed Applications", "comment": null, "summary": "Modern automotive systems leverage deep neural networks (DNNs) for semantic\nsegmentation and operate in two key application areas: (1) In-car, where the\nDNN solely operates in the vehicle without strict constraints on the data rate.\n(2) Distributed, where one DNN part operates in the vehicle and the other part\ntypically on a large-scale cloud platform with a particular constraint on\ntransmission bitrate efficiency. Typically, both applications share an image\nand source encoder, while each uses distinct (joint) source and task decoders.\nPrior work utilized convolutional neural networks for joint source and task\ndecoding but did not investigate transformer-based alternatives such as\nSegDeformer, which offer superior performance at the cost of higher\ncomputational complexity. In this work, we propose joint feature and task\ndecoding for SegDeformer, thereby enabling lower computational complexity in\nboth in-car and distributed applications, despite SegDeformer's computational\ndemands. This improves scalability in the cloud while reducing in-car\ncomputational complexity. For the in-car application, we increased the frames\nper second (fps) by up to a factor of $11.7$ ($1.4$ fps to $16.5$ fps) on\nCityscapes and by up to a factor of $3.5$ ($43.3$ fps to $154.3$ fps) on\nADE20K, while being on-par w.r.t.\\ the mean intersection over union (mIoU) of\nthe transformer-based baseline that doesn't compress by a source codec. For the\ndistributed application, we achieve state-of-the-art (SOTA) over a wide range\nof bitrates on the mIoU metric, while using only $0.14$\\% ($0.04$\\%) of cloud\nDNN parameters used in previous SOTA, reported on ADE20K (Cityscapes).", "AI": {"tldr": "Proposes joint feature and task decoding for SegDeformer transformer models in automotive systems, enabling lower computational complexity for both in-car and distributed applications while maintaining performance.", "motivation": "Modern automotive systems use DNNs for semantic segmentation in two scenarios: in-car (no data rate constraints) and distributed (bitrate-constrained cloud processing). Prior work used CNNs but didn't explore transformer alternatives like SegDeformer, which offer better performance but higher complexity.", "method": "Developed joint feature and task decoding for SegDeformer transformer models, allowing computational complexity reduction in both in-car and distributed automotive applications despite SegDeformer's high computational demands.", "result": "For in-car: Increased fps by up to 11.7x (1.4 to 16.5 fps) on Cityscapes and 3.5x (43.3 to 154.3 fps) on ADE20K while maintaining similar mIoU. For distributed: Achieved SOTA mIoU across bitrates using only 0.14% (ADE20K) and 0.04% (Cityscapes) of cloud DNN parameters compared to previous SOTA.", "conclusion": "The proposed joint decoding approach enables efficient use of transformer-based models in automotive systems, significantly improving computational efficiency for both in-car and distributed applications while maintaining or exceeding performance metrics."}}
{"id": "2510.17131", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17131", "abs": "https://arxiv.org/abs/2510.17131", "authors": ["Xin Gao", "Jiyao Liu", "Guanghao Li", "Yueming Lyu", "Jianxiong Gao", "Weichen Yu", "Ningsheng Xu", "Liang Wang", "Caifeng Shan", "Ziwei Liu", "Chenyang Si"], "title": "GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection", "comment": "28 pages, 16 figures, conference", "summary": "Recent advancements have explored text-to-image diffusion models for\nsynthesizing out-of-distribution (OOD) samples, substantially enhancing the\nperformance of OOD detection. However, existing approaches typically rely on\nperturbing text-conditioned embeddings, resulting in semantic instability and\ninsufficient shift diversity, which limit generalization to realistic OOD. To\naddress these challenges, we propose GOOD, a novel and flexible framework that\ndirectly guides diffusion sampling trajectories towards OOD regions using\noff-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level\nguidance: (1) Image-level guidance based on the gradient of log partition to\nreduce input likelihood, drives samples toward low-density regions in pixel\nspace. (2) Feature-level guidance, derived from k-NN distance in the\nclassifier's latent space, promotes sampling in feature-sparse regions. Hence,\nthis dual-guidance design enables more controllable and diverse OOD sample\ngeneration. Additionally, we introduce a unified OOD score that adaptively\ncombines image and feature discrepancies, enhancing detection robustness. We\nperform thorough quantitative and qualitative analyses to evaluate the\neffectiveness of GOOD, demonstrating that training with samples generated by\nGOOD can notably enhance OOD detection performance.", "AI": {"tldr": "GOOD is a novel framework that uses dual-level guidance (image-level and feature-level) with diffusion models to generate diverse out-of-distribution samples, improving OOD detection performance.", "motivation": "Existing text-to-image diffusion approaches for OOD sample generation suffer from semantic instability and insufficient shift diversity due to text-embedding perturbations, limiting generalization to realistic OOD scenarios.", "method": "GOOD guides diffusion sampling trajectories using ID classifiers with dual-level guidance: (1) image-level guidance reduces input likelihood via gradient of log partition, and (2) feature-level guidance uses k-NN distance in classifier's latent space to sample feature-sparse regions.", "result": "GOOD enables more controllable and diverse OOD sample generation, and training with GOOD-generated samples notably enhances OOD detection performance.", "conclusion": "The proposed GOOD framework with dual-level guidance and unified OOD score effectively addresses limitations of existing methods, demonstrating significant improvements in OOD detection through more diverse and realistic sample generation."}}
{"id": "2510.16757", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16757", "abs": "https://arxiv.org/abs/2510.16757", "authors": ["Young In Kim", "Andrea Agiollo", "Rajiv Khanna"], "title": "SAMOSA: Sharpness Aware Minimization for Open Set Active learning", "comment": null, "summary": "Modern machine learning solutions require extensive data collection where\nlabeling remains costly. To reduce this burden, open set active learning\napproaches aim to select informative samples from a large pool of unlabeled\ndata that includes irrelevant or unknown classes. In this context, we propose\nSharpness Aware Minimization for Open Set Active Learning (SAMOSA) as an\neffective querying algorithm. Building on theoretical findings concerning the\nimpact of data typicality on the generalization properties of traditional\nstochastic gradient descent (SGD) and sharpness-aware minimization (SAM),\nSAMOSA actively queries samples based on their typicality. SAMOSA effectively\nidentifies atypical samples that belong to regions of the embedding manifold\nclose to the model decision boundaries. Therefore, SAMOSA prioritizes the\nsamples that are (i) highly informative for the targeted classes, and (ii)\nuseful for distinguishing between targeted and unwanted classes. Extensive\nexperiments show that SAMOSA achieves up to 3% accuracy improvement over the\nstate of the art across several datasets, while not introducing computational\noverhead. The source code of our experiments is available at:\nhttps://anonymous.4open.science/r/samosa-DAF4", "AI": {"tldr": "SAMOSA is a new open set active learning method that uses sharpness-aware minimization to select informative samples from unlabeled data containing irrelevant classes, achieving up to 3% accuracy improvement over state-of-the-art methods.", "motivation": "To reduce the high cost of data labeling in machine learning by developing an active learning approach that can effectively select informative samples from unlabeled data pools that include irrelevant or unknown classes.", "method": "SAMOSA uses sharpness-aware minimization and theoretical findings about data typicality to actively query samples based on their typicality, identifying atypical samples near model decision boundaries that are both informative for target classes and useful for distinguishing between target and unwanted classes.", "result": "Extensive experiments show SAMOSA achieves up to 3% accuracy improvement over state-of-the-art methods across several datasets, without introducing computational overhead.", "conclusion": "SAMOSA provides an effective open set active learning approach that significantly improves performance while maintaining computational efficiency, addressing the challenge of costly data labeling in machine learning."}}
{"id": "2510.17137", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17137", "abs": "https://arxiv.org/abs/2510.17137", "authors": ["WenBo Xu", "Liu Liu", "Li Zhang", "Ran Zhang", "Hao Wu", "Dan Guo", "Meng Wang"], "title": "KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation", "comment": null, "summary": "Articulated objects, such as laptops and drawers, exhibit significant\nchallenges for 3D reconstruction and pose estimation due to their multi-part\ngeometries and variable joint configurations, which introduce structural\ndiversity across different states. To address these challenges, we propose\nKineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object\nShape Reconstruction and Generation, a unified framework for reconstructing\ndiverse articulated instances and pose estimation from single view input.\nSpecifically, we first encode complete geometry (SDFs), joint angles, and part\nsegmentation into a structured latent space via a novel Kinematic-Aware VAE\n(KA-VAE). In addition, we employ two conditional diffusion models: one for\nregressing global pose (SE(3)) and joint parameters, and another for generating\nthe kinematic-aware latent code from partial observations. Finally, we produce\nan iterative optimization module that bidirectionally refines reconstruction\naccuracy and kinematic parameters via Chamfer-distance minimization while\npreserving articulation constraints. Experimental results on synthetic,\nsemi-synthetic, and real-world datasets demonstrate the effectiveness of our\napproach in accurately reconstructing articulated objects and estimating their\nkinematic properties.", "AI": {"tldr": "KineDiff3D is a unified framework for reconstructing articulated objects and estimating pose from single-view input using kinematic-aware diffusion models.", "motivation": "Articulated objects like laptops and drawers pose challenges for 3D reconstruction due to their multi-part geometries and variable joint configurations, requiring methods that handle structural diversity across different states.", "method": "The approach uses a Kinematic-Aware VAE to encode geometry, joint angles, and part segmentation into structured latent space, then employs two conditional diffusion models for pose/joint regression and kinematic-aware latent generation, with iterative optimization for refinement.", "result": "Experimental results on synthetic, semi-synthetic, and real-world datasets demonstrate accurate reconstruction of articulated objects and estimation of kinematic properties.", "conclusion": "KineDiff3D effectively addresses the challenges of articulated object reconstruction and pose estimation through its kinematic-aware diffusion framework."}}
{"id": "2510.16774", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16774", "abs": "https://arxiv.org/abs/2510.16774", "authors": ["Yuguang Yue", "Irakli Salia", "Samuel Hunt", "Christopher Green", "Wenzhe Shi", "Jonathan J Hunt"], "title": "Learning to play: A Multimodal Agent for 3D Game-Play", "comment": "International Conference on Computer Vision Workshop on Multi-Modal\n  Reasoning for Agentic Intelligence", "summary": "We argue that 3-D first-person video games are a challenging environment for\nreal-time multi-modal reasoning. We first describe our dataset of human\ngame-play, collected across a large variety of 3-D first-person games, which is\nboth substantially larger and more diverse compared to prior publicly disclosed\ndatasets, and contains text instructions. We demonstrate that we can learn an\ninverse dynamics model from this dataset, which allows us to impute actions on\na much larger dataset of publicly available videos of human game play that lack\nrecorded actions. We then train a text-conditioned agent for game playing using\nbehavior cloning, with a custom architecture capable of realtime inference on a\nconsumer GPU. We show the resulting model is capable of playing a variety of\n3-D games and responding to text input. Finally, we outline some of the\nremaining challenges such as long-horizon tasks and quantitative evaluation\nacross a large set of games.", "AI": {"tldr": "A system for real-time multi-modal reasoning in 3D first-person games using a large dataset of human gameplay, inverse dynamics modeling for action imputation, and text-conditioned agents trained via behavior cloning.", "motivation": "3D first-person video games present a challenging environment for real-time multi-modal reasoning, requiring systems that can process visual input and respond to text instructions while playing games.", "method": "Collected a large dataset of human gameplay across various 3D first-person games, learned an inverse dynamics model to impute actions on public videos, trained text-conditioned agents using behavior cloning with custom architecture for real-time inference.", "result": "The resulting model can play various 3D games and respond to text input in real-time on consumer GPUs, demonstrating capability in multi-modal reasoning for gaming environments.", "conclusion": "The approach shows promise for game-playing agents with text interaction, though challenges remain in handling long-horizon tasks and quantitative evaluation across diverse games."}}
{"id": "2510.17157", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17157", "abs": "https://arxiv.org/abs/2510.17157", "authors": ["Yinghui Wang", "Xinyu Zhang", "Peng Du"], "title": "GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image", "comment": null, "summary": "Generating editable, parametric CAD models from a single image holds great\npotential to lower the barriers of industrial concept design. However, current\nmulti-modal large language models (MLLMs) still struggle with accurately\ninferring 3D geometry from 2D images due to limited spatial reasoning\ncapabilities. We address this limitation by introducing GACO-CAD, a novel\ntwo-stage post-training framework. It is designed to achieve a joint objective:\nsimultaneously improving the geometric accuracy of the generated CAD models and\nencouraging the use of more concise modeling procedures. First, during\nsupervised fine-tuning, we leverage depth and surface normal maps as dense\ngeometric priors, combining them with the RGB image to form a multi-channel\ninput. In the context of single-view reconstruction, these priors provide\ncomplementary spatial cues that help the MLLM more reliably recover 3D geometry\nfrom 2D observations. Second, during reinforcement learning, we introduce a\ngroup length reward that, while preserving high geometric fidelity, promotes\nthe generation of more compact and less redundant parametric modeling\nsequences. A simple dynamic weighting strategy is adopted to stabilize\ntraining. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD\nachieves state-of-the-art performance under the same MLLM backbone,\nconsistently outperforming existing methods in terms of code validity,\ngeometric accuracy, and modeling conciseness.", "AI": {"tldr": "GACO-CAD is a two-stage post-training framework that improves geometric accuracy and modeling conciseness in generating editable CAD models from single images using MLLMs.", "motivation": "Current MLLMs struggle with accurately inferring 3D geometry from 2D images due to limited spatial reasoning capabilities, which limits their effectiveness in industrial concept design.", "method": "Two-stage framework: 1) Supervised fine-tuning using depth and surface normal maps as geometric priors with multi-channel input, 2) Reinforcement learning with group length reward to promote compact parametric modeling sequences and dynamic weighting for training stability.", "result": "Achieves state-of-the-art performance on DeepCAD and Fusion360 datasets, outperforming existing methods in code validity, geometric accuracy, and modeling conciseness under the same MLLM backbone.", "conclusion": "GACO-CAD effectively addresses the spatial reasoning limitations of MLLMs for CAD generation by combining geometric priors with reinforcement learning for more accurate and concise modeling procedures."}}
{"id": "2510.16780", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16780", "abs": "https://arxiv.org/abs/2510.16780", "authors": ["Chang Wu", "Zhiyuan Liu", "Wen Shu", "Liang Wang", "Yanchen Luo", "Wenqiang Lei", "Yatao Bian", "Junfeng Fang", "Xiang Wang"], "title": "3D-GSRD: 3D Molecular Graph Auto-Encoder with Selective Re-mask Decoding", "comment": null, "summary": "Masked graph modeling (MGM) is a promising approach for molecular\nrepresentation learning (MRL).However, extending the success of re-mask\ndecoding from 2D to 3D MGM is non-trivial, primarily due to two conflicting\nchallenges: avoiding 2D structure leakage to the decoder, while still providing\nsufficient 2D context for reconstructing re-masked atoms.To address these\nchallenges, we propose 3D-GSRD: a 3D Molecular Graph Auto-Encoder with\nSelective Re-mask Decoding. The core innovation of 3D-GSRD lies in its\nSelective Re-mask Decoding(SRD), which re-masks only 3D-relevant information\nfrom encoder representations while preserving the 2D graph structures.This SRD\nis synergistically integrated with a 3D Relational-Transformer(3D-ReTrans)\nencoder alongside a structure-independent decoder. We analyze that SRD,\ncombined with the structure-independent decoder, enhances the encoder's role in\nMRL. Extensive experiments show that 3D-GSRD achieves strong downstream\nperformance, setting a new state-of-the-art on 7 out of 8 targets in the widely\nused MD17 molecular property prediction benchmark. The code is released at\nhttps://github.com/WuChang0124/3D-GSRD.", "AI": {"tldr": "3D-GSRD is a novel 3D molecular graph auto-encoder with selective re-mask decoding that addresses challenges in extending masked graph modeling from 2D to 3D molecular representation learning.", "motivation": "Extending the success of re-mask decoding from 2D to 3D masked graph modeling is challenging due to conflicting requirements: avoiding 2D structure leakage to the decoder while providing sufficient 2D context for reconstructing re-masked atoms.", "method": "Proposes 3D-GSRD with Selective Re-mask Decoding (SRD) that re-masks only 3D-relevant information while preserving 2D graph structures, combined with a 3D Relational-Transformer encoder and structure-independent decoder.", "result": "Achieves state-of-the-art performance on 7 out of 8 targets in the widely used MD17 molecular property prediction benchmark.", "conclusion": "The selective re-mask decoding approach effectively enhances the encoder's role in molecular representation learning and demonstrates strong downstream performance in molecular property prediction."}}
{"id": "2510.17169", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17169", "abs": "https://arxiv.org/abs/2510.17169", "authors": ["Roland Croft", "Brian Du", "Darcy Joseph", "Sharath Kumar"], "title": "Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition", "comment": "Accepted for publication in DICTA 2025", "summary": "Face Recognition (FR) models have been shown to be vulnerable to adversarial\nexamples that subtly alter benign facial images, exposing blind spots in these\nsystems, as well as protecting user privacy. End-to-end FR systems first obtain\npreprocessed faces from diverse facial imagery prior to computing the\nsimilarity of the deep feature embeddings. Whilst face preprocessing is a\ncritical component of FR systems, and hence adversarial attacks against them,\nwe observe that this preprocessing is often overlooked in blackbox settings.\nOur study seeks to investigate the transferability of several out-of-the-box\nstate-of-the-art adversarial attacks against FR when applied against different\npreprocessing techniques used in a blackbox setting. We observe that the choice\nof face detection model can degrade the attack success rate by up to 78%,\nwhereas choice of interpolation method during downsampling has relatively\nminimal impacts. Furthermore, we find that the requirement for facial\npreprocessing even degrades attack strength in a whitebox setting, due to the\nunintended interaction of produced noise vectors against face detection models.\nBased on these findings, we propose a preprocessing-invariant method using\ninput transformations that improves the transferability of the studied attacks\nby up to 27%. Our findings highlight the importance of preprocessing in FR\nsystems, and the need for its consideration towards improving the adversarial\ngeneralisation of facial adversarial examples.", "AI": {"tldr": "Face recognition systems are vulnerable to adversarial attacks, but face preprocessing techniques significantly impact attack success rates. Different preprocessing methods can reduce attack effectiveness by up to 78%, and a new preprocessing-invariant method improves transferability by 27%.", "motivation": "To investigate how face preprocessing techniques in FR systems affect the transferability of adversarial attacks in blackbox settings, as preprocessing is often overlooked but critical for attack effectiveness.", "method": "Studied transferability of state-of-the-art adversarial attacks against different preprocessing techniques, analyzed impact of face detection models and interpolation methods, and proposed a preprocessing-invariant method using input transformations.", "result": "Face detection model choice degrades attack success rate by up to 78%, while interpolation methods have minimal impact. Preprocessing degrades attack strength even in whitebox settings. The proposed preprocessing-invariant method improves transferability by up to 27%.", "conclusion": "Face preprocessing is crucial in FR systems and significantly impacts adversarial attack effectiveness. Considering preprocessing is essential for improving adversarial generalization of facial adversarial examples."}}
{"id": "2510.16805", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16805", "abs": "https://arxiv.org/abs/2510.16805", "authors": ["Mariam Rakka", "Marios Fournarakis", "Olga Krestinskaya", "Jinane Bazzi", "Khaled N. Salama", "Fadi Kurdahi", "Ahmed M. Eltawil", "Mohammed E. Fouda"], "title": "Mixed-Precision Quantization for Language Models: Techniques and Prospects", "comment": "46 pages, 6 figures, 5 tables", "summary": "The rapid scaling of language models (LMs) has resulted in unprecedented\ncomputational, memory, and energy requirements, making their training and\ndeployment increasingly unsustainable. Quantization has emerged as an essential\ncompression technique to reduce model size, alleviate memory bottlenecks, and\naccelerate inference. However, while uniform low-bit quantization (e.g., INT8,\nINT4) provides significant efficiency gains, it can degrade accuracy in\nsensitive components of transformer-based LMs. Mixed-precision quantization\noffers a promising alternative by selectively allocating precision across\nlayers or within tensors to balance efficiency and accuracy. This survey\nprovides a comprehensive overview of Mixed-Precision quantization frameworks\nfor LMs (MXPLMs). We first review quantization fundamentals, including uniform\nand non-uniform quantizers, quantization granularity, and methods widely used\nin post-training quantization. We then categorize and compare recent MXPLM\nframeworks according to their bit allocation strategies and precision\nconfigurations across weights, activations, and key-value caches. A comparative\nanalysis highlights differences in perplexity, zero-shot task performance, and\ndeployment trade-offs. Furthermore, we contrast MXPLMs with earlier\nmixed-precision quantization methods for deep neural networks, identifying\nstrategies that transfer and those that face challenges in the LM setting.\nFinally, we summarize open issues and future directions, including\nhardware-aware design, activation quantization, and scalable optimization\nmethods for billion-parameter models. By consolidating recent advances, this\nwork serves as a reference for understanding the current landscape and research\nprospects of mixed-precision quantization for large-scale language models.", "AI": {"tldr": "This survey provides a comprehensive overview of Mixed-Precision Quantization frameworks for Large Language Models (MXPLMs), covering quantization fundamentals, bit allocation strategies, performance comparisons, and future research directions.", "motivation": "The rapid scaling of language models has led to unsustainable computational, memory, and energy requirements, making quantization essential for reducing model size, alleviating memory bottlenecks, and accelerating inference while maintaining accuracy.", "method": "The survey categorizes and compares MXPLM frameworks based on bit allocation strategies and precision configurations across weights, activations, and key-value caches. It reviews quantization fundamentals including uniform/non-uniform quantizers, granularity, and post-training quantization methods.", "result": "Comparative analysis reveals differences in perplexity, zero-shot task performance, and deployment trade-offs. The survey contrasts MXPLMs with earlier mixed-precision methods for deep neural networks, identifying transferable strategies and LM-specific challenges.", "conclusion": "Mixed-precision quantization offers a promising approach to balance efficiency and accuracy in large language models. Future directions include hardware-aware design, activation quantization, and scalable optimization methods for billion-parameter models."}}
{"id": "2510.17171", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17171", "abs": "https://arxiv.org/abs/2510.17171", "authors": ["Feihong Yan", "Peiru Wang", "Yao Zhu", "Kaiyu Pang", "Qingyan Wei", "Huiqi Li", "Linfeng Zhang"], "title": "Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling", "comment": "12 pages, 6 figures", "summary": "Masked Autoregressive (MAR) models promise better efficiency in visual\ngeneration than autoregressive (AR) models for the ability of parallel\ngeneration, yet their acceleration potential remains constrained by the\nmodeling complexity of spatially correlated visual tokens in a single step. To\naddress this limitation, we introduce Generation then Reconstruction (GtR), a\ntraining-free hierarchical sampling strategy that decomposes generation into\ntwo stages: structure generation establishing global semantic scaffolding,\nfollowed by detail reconstruction efficiently completing remaining tokens.\nAssuming that it is more difficult to create an image from scratch than to\ncomplement images based on a basic image framework, GtR is designed to achieve\nacceleration by computing the reconstruction stage quickly while maintaining\nthe generation quality by computing the generation stage slowly. Moreover,\nobserving that tokens on the details of an image often carry more semantic\ninformation than tokens in the salient regions, we further propose\nFrequency-Weighted Token Selection (FTS) to offer more computation budget to\ntokens on image details, which are localized based on the energy of high\nfrequency information. Extensive experiments on ImageNet class-conditional and\ntext-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining\ncomparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1),\nsubstantially outperforming existing acceleration methods across various model\nscales and generation tasks. Our codes will be released in\nhttps://github.com/feihongyan1/GtR.", "AI": {"tldr": "GtR is a training-free hierarchical sampling strategy that accelerates masked autoregressive models by decomposing generation into structure generation and detail reconstruction stages, achieving 3.72x speedup while maintaining quality.", "motivation": "Masked autoregressive models have efficiency limitations due to the complexity of modeling spatially correlated visual tokens in parallel generation.", "method": "Two-stage approach: structure generation for global semantic scaffolding followed by detail reconstruction for completing remaining tokens, plus frequency-weighted token selection to allocate more computation to detail tokens.", "result": "Achieved 3.72x speedup on MAR-H while maintaining comparable quality (FID: 1.59, IS: 304.4 vs original 1.59, 299.1), outperforming existing acceleration methods across various model scales and tasks.", "conclusion": "GtR effectively accelerates masked autoregressive models through hierarchical sampling and intelligent token selection, demonstrating significant speed improvements without quality degradation."}}
{"id": "2510.16806", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16806", "abs": "https://arxiv.org/abs/2510.16806", "authors": ["Weilin Wan", "Weizhong Zhang", "Cheng Jin"], "title": "Computational Budget Should Be Considered in Data Selection", "comment": null, "summary": "Data selection improves computational efficiency by choosing informative\nsubsets of training samples. However, existing methods ignore the compute\nbudget, treating data selection and importance evaluation independently of\ncompute budget constraints. Yet empirical studies show no algorithm can\nconsistently outperform others (or even random selection) across varying\nbudgets. We therefore argue that compute budget must be integral to\ndata-selection strategies, since different budgets impose distinct requirements\non data quantity, quality, and distribution for effective training. To this\nend, we propose a novel Computational budget-Aware Data Selection (CADS) method\nand naturally formulate it into a bilevel optimization framework, where the\ninner loop trains the model within the constraints of the computational budget\non some selected subset of training data, while the outer loop optimizes data\nselection based on model evaluation. Our technical contributions lie in\naddressing two main challenges in solving this bilevel optimization problem:\nthe expensive Hessian matrix estimation for outer-loop gradients and the\ncomputational burden of achieving inner-loop optimality during iterations. To\nsolve the first issue, we propose a probabilistic reparameterization strategy\nand compute the gradient using a Hessian-free policy gradient estimator. To\naddress the second challenge, we transform the inner optimization problem into\na penalty term in the outer objective, further discovering that we only need to\nestimate the minimum of a one-dimensional loss to calculate the gradient,\nsignificantly improving efficiency. Extensive experiments show that our method\nachieves performance gains of up to 14.42% over baselines in vision and\nlanguage benchmarks.", "AI": {"tldr": "Proposes CADS, a computational budget-aware data selection method that formulates data selection as a bilevel optimization problem, addressing challenges in gradient estimation and computational efficiency.", "motivation": "Existing data selection methods ignore compute budget constraints, but empirical studies show no algorithm consistently outperforms others across varying budgets. Compute budget must be integral to data selection strategies as different budgets impose distinct requirements on data quantity, quality, and distribution.", "method": "Formulates data selection as bilevel optimization: inner loop trains model within computational budget constraints on selected data subset, outer loop optimizes data selection based on model evaluation. Uses probabilistic reparameterization with Hessian-free policy gradient estimator for outer-loop gradients, and transforms inner optimization into penalty term requiring only one-dimensional loss estimation.", "result": "Extensive experiments show performance gains up to 14.42% over baselines in vision and language benchmarks.", "conclusion": "Compute budget must be integral to data selection strategies, and the proposed CADS method effectively addresses this by formulating the problem as bilevel optimization with efficient solutions to computational challenges."}}
{"id": "2510.17179", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17179", "abs": "https://arxiv.org/abs/2510.17179", "authors": ["Yingzi Han", "Jiakai He", "Chuanlong Xie", "Jianping Li"], "title": "Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring", "comment": null, "summary": "Automated plankton recognition models face significant challenges during\nreal-world deployment due to distribution shifts (Out-of-Distribution, OoD)\nbetween training and test data. This stems from plankton's complex\nmorphologies, vast species diversity, and the continuous discovery of novel\nspecies, which leads to unpredictable errors during inference. Despite rapid\nadvancements in OoD detection methods in recent years, the field of plankton\nrecognition still lacks a systematic integration of the latest computer vision\ndevelopments and a unified benchmark for large-scale evaluation. To address\nthis, this paper meticulously designed a series of OoD benchmarks simulating\nvarious distribution shift scenarios based on the DYB-PlanktonNet dataset\n\\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection\nmethods. Extensive experimental results demonstrate that the ViM\n\\cite{wang2022vim} method significantly outperforms other approaches in our\nconstructed benchmarks, particularly excelling in Far-OoD scenarios with\nsubstantial improvements in key metrics. This comprehensive evaluation not only\nprovides a reliable reference for algorithm selection in automated plankton\nrecognition but also lays a solid foundation for future research in plankton\nOoD detection. To our knowledge, this study marks the first large-scale,\nsystematic evaluation and analysis of Out-of-Distribution data detection\nmethods in plankton recognition. Code is available at\nhttps://github.com/BlackJack0083/PlanktonOoD.", "AI": {"tldr": "This paper presents the first large-scale systematic evaluation of Out-of-Distribution (OoD) detection methods for plankton recognition, identifying ViM as the top-performing approach.", "motivation": "Plankton recognition models face challenges from distribution shifts due to complex morphologies, species diversity, and novel species discovery, leading to unpredictable errors during deployment. The field lacks systematic integration of latest computer vision developments and unified benchmarks.", "method": "Created OoD benchmarks simulating various distribution shift scenarios using DYB-PlanktonNet dataset, and systematically evaluated twenty-two OoD detection methods.", "result": "ViM method significantly outperformed other approaches, particularly excelling in Far-OoD scenarios with substantial improvements in key metrics.", "conclusion": "The study provides a reliable reference for algorithm selection in automated plankton recognition and lays a solid foundation for future research in plankton OoD detection."}}
{"id": "2510.16807", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16807", "abs": "https://arxiv.org/abs/2510.16807", "authors": ["Zhoutong Wu", "Yuan Zhang", "Yiming Dong", "Chenheng Zhang", "Cong Fang", "Kun Yuan", "Zhouchen Lin"], "title": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "comment": "The code is available at:\n  \\url{https://github.com/Zhoutong-Wu/SkipV1Former}", "summary": "Transformer models have driven breakthroughs across various language tasks by\ntheir strong capability to learn rich contextual representations. Scaling them\nto improve representation, however, often demands substantial memory and\ncompute costs, such as the Key-Value (KV) cache used during auto-regressive\ndecoding. Skip connections offer a promising way to improve representation\nwithout bloating resource usage, yet most prior works either improve\nexpressivity while leaving KV costs unchanged, or reduce memory at the cost of\nweaker representation. In this work, we propose SkipV1Former, a Transformer\nvariant that uses skip connections from the first layer's Value heads to\nstrengthen model representation and reduce KV cache. Specifically, from the\nsecond block onward, each layer reuses half of its Value heads from the very\nfirst layer, while computing the other half as usual-cutting Value projections\nand V cache by nearly 50 \\%. Theoretically, we show that routing uncompressed\nfirst-layer Values into deeper layers restores information lost to compression\nand accelerates the model's implicit mesa-optimization-a key pattern of\nTransformer in auto-regressive tasks. Empirically, across different model\nscales, SkipV1Former delivers consistent reductions of approximately 25 \\% in\nKV cache while improving perplexity relative to standard Multi-Head Attention\n(MHA) Transformers and some advanced variants. Moreover, we propose a recipe\nfor uptraining existing MHA Transformer checkpoints to SkipV1Former with only\n10-15\\% additional compute. Finally, SkipV1Former can seamlessly combine\nadvanced methods like Group-Query Attention and Multi-Latent Attention to\nachieve further KV cache savings and performance improvement. When combined\nwith YOCO, it cuts KV cache size by nearly 50 \\% while still improving\nperformance.", "AI": {"tldr": "SkipV1Former is a Transformer variant that uses skip connections from the first layer's Value heads to reduce KV cache by ~25% while improving performance, and can be uptrained from existing models with minimal compute.", "motivation": "To improve Transformer representation without increasing resource usage, addressing the high memory and compute costs of KV cache in auto-regressive decoding while avoiding the trade-off between memory reduction and weaker representation.", "method": "From the second block onward, each layer reuses half of its Value heads from the very first layer while computing the other half normally, reducing Value projections and V cache by nearly 50%. This routing of uncompressed first-layer Values into deeper layers restores lost information.", "result": "Across different model scales, SkipV1Former consistently reduces KV cache by approximately 25% while improving perplexity compared to standard MHA Transformers and advanced variants. When combined with YOCO, it cuts KV cache size by nearly 50% while still improving performance.", "conclusion": "SkipV1Former effectively strengthens model representation and reduces KV cache through strategic skip connections, offers efficient uptraining from existing models, and can be combined with other advanced attention methods for further improvements."}}
{"id": "2510.17181", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17181", "abs": "https://arxiv.org/abs/2510.17181", "authors": ["Haonan He", "Yufeng Zheng", "Jie Song"], "title": "Capturing Head Avatar with Hand Contacts from a Monocular Video", "comment": "ICCV 2025", "summary": "Photorealistic 3D head avatars are vital for telepresence, gaming, and VR.\nHowever, most methods focus solely on facial regions, ignoring natural\nhand-face interactions, such as a hand resting on the chin or fingers gently\ntouching the cheek, which convey cognitive states like pondering. In this work,\nwe present a novel framework that jointly learns detailed head avatars and the\nnon-rigid deformations induced by hand-face interactions.\n  There are two principal challenges in this task. First, naively tracking hand\nand face separately fails to capture their relative poses. To overcome this, we\npropose to combine depth order loss with contact regularization during pose\ntracking, ensuring correct spatial relationships between the face and hand.\nSecond, no publicly available priors exist for hand-induced deformations,\nmaking them non-trivial to learn from monocular videos. To address this, we\nlearn a PCA basis specific to hand-induced facial deformations from a face-hand\ninteraction dataset. This reduces the problem to estimating a compact set of\nPCA parameters rather than a full spatial deformation field. Furthermore,\ninspired by physics-based simulation, we incorporate a contact loss that\nprovides additional supervision, significantly reducing interpenetration\nartifacts and enhancing the physical plausibility of the results.\n  We evaluate our approach on RGB(D) videos captured by an iPhone.\nAdditionally, to better evaluate the reconstructed geometry, we construct a\nsynthetic dataset of avatars with various types of hand interactions. We show\nthat our method can capture better appearance and more accurate deforming\ngeometry of the face than SOTA surface reconstruction methods.", "AI": {"tldr": "A framework that jointly learns photorealistic 3D head avatars with hand-face interaction deformations, addressing spatial relationship challenges and learning hand-induced facial deformations from monocular videos.", "motivation": "Most existing methods focus only on facial regions and ignore natural hand-face interactions that convey cognitive states, creating a gap in realistic avatar creation for telepresence, gaming, and VR applications.", "method": "Combines depth order loss with contact regularization for pose tracking, learns a PCA basis for hand-induced facial deformations from interaction data, and incorporates physics-inspired contact loss to reduce interpenetration artifacts.", "result": "The method captures better appearance and more accurate deforming geometry than state-of-the-art surface reconstruction methods, as validated on RGB(D) videos and synthetic datasets with various hand interactions.", "conclusion": "The proposed framework successfully models hand-face interactions in 3D head avatars, overcoming challenges in spatial relationships and deformation learning through novel pose tracking and PCA-based deformation representation."}}
{"id": "2510.16811", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16811", "abs": "https://arxiv.org/abs/2510.16811", "authors": ["Mohammad Shahverdikondori", "Jalal Etesami", "Negar Kiyavash"], "title": "Graph Learning is Suboptimal in Causal Bandits", "comment": "31 pages, 5 figures", "summary": "We study regret minimization in causal bandits under causal sufficiency where\nthe underlying causal structure is not known to the agent. Previous work has\nfocused on identifying the reward's parents and then applying classic bandit\nmethods to them, or jointly learning the parents while minimizing regret. We\ninvestigate whether such strategies are optimal. Somewhat counterintuitively,\nour results show that learning the parent set is suboptimal. We do so by\nproving that there exist instances where regret minimization and parent\nidentification are fundamentally conflicting objectives. We further analyze\nboth the known and unknown parent set size regimes, establish novel regret\nlower bounds that capture the combinatorial structure of the action space.\nBuilding on these insights, we propose nearly optimal algorithms that bypass\ngraph and parent recovery, demonstrating that parent identification is indeed\nunnecessary for regret minimization. Experiments confirm that there exists a\nlarge performance gap between our method and existing baselines in various\nenvironments.", "AI": {"tldr": "Learning parent sets in causal bandits is suboptimal for regret minimization, as it conflicts with the goal of minimizing regret. The paper proposes algorithms that bypass graph recovery and achieve near-optimal performance.", "motivation": "Previous work focused on identifying reward parents before applying bandit methods, but it's unclear if this strategy is optimal for regret minimization in causal bandits with unknown causal structure.", "method": "Proves that regret minimization and parent identification are conflicting objectives, establishes novel regret lower bounds, and proposes algorithms that bypass graph and parent recovery.", "result": "Shows that parent identification is unnecessary for regret minimization and demonstrates a large performance gap between the proposed method and existing baselines in experiments.", "conclusion": "Learning parent sets is suboptimal in causal bandits, and bypassing graph recovery leads to nearly optimal regret minimization without needing to identify parents."}}
{"id": "2510.17188", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17188", "abs": "https://arxiv.org/abs/2510.17188", "authors": ["Vaibhav Rathore", "Divyam Gupta", "Biplab Banerjee"], "title": "HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery", "comment": "Accpeted at NeurIPS (2025) Main Conference", "summary": "Generalized Category Discovery (GCD) aims to classify test-time samples into\neither seen categories** -- available during training -- or novel ones, without\nrelying on label supervision. Most existing GCD methods assume simultaneous\naccess to labeled and unlabeled data during training and arising from the same\ndomain, limiting applicability in open-world scenarios involving distribution\nshifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by\nrequiring models to generalize to unseen domains containing novel categories,\nwithout accessing targetdomain data during training. The only prior DG-GCD\nmethod, DG2CD-Net, relies on episodic training with multiple synthetic domains\nand task vector aggregation, incurring high computational cost and error\naccumulation. We propose HIDISC, a hyperbolic representation learning framework\nthat achieves domain and category-level generalization without episodic\nsimulation. To expose the model to minimal but diverse domain variations, we\naugment the source domain using GPT-guided diffusion, avoiding overfitting\nwhile maintaining efficiency. To structure the representation space, we\nintroduce Tangent CutMix, a curvature-aware interpolation that synthesizes\npseudo-novel samples in tangent space, preserving manifold consistency. A\nunified loss -- combining penalized Busemann alignment, hybrid hyperbolic\ncontrastive regularization, and adaptive outlier repulsion -- **facilitates\ncompact, semantically structured embeddings. A learnable curvature parameter\nfurther adapts the geometry to dataset complexity. HIDISC achieves\nstate-of-the-art results on PACS , Office-Home , and DomainNet, consistently\noutperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.", "AI": {"tldr": "HIDISC is a hyperbolic representation learning framework for Domain Generalization with Generalized Category Discovery (DG-GCD) that achieves state-of-the-art performance without episodic training, using GPT-guided diffusion for domain augmentation and curvature-aware interpolation for structured embeddings.", "motivation": "Existing GCD methods assume simultaneous access to labeled/unlabeled data from the same domain, limiting real-world applicability. DG-GCD addresses this by requiring generalization to unseen domains with novel categories, but prior methods like DG2CD-Net use computationally expensive episodic training with error accumulation.", "method": "Uses hyperbolic representation learning with GPT-guided diffusion for minimal but diverse domain augmentation. Introduces Tangent CutMix for curvature-aware interpolation in tangent space to synthesize pseudo-novel samples. Employs unified loss combining penalized Busemann alignment, hybrid hyperbolic contrastive regularization, and adaptive outlier repulsion with learnable curvature parameter.", "result": "Achieves state-of-the-art results on PACS, Office-Home, and DomainNet datasets, consistently outperforming existing Euclidean and hyperbolic (DG)-GCD baselines.", "conclusion": "HIDISC provides an efficient and effective framework for DG-GCD that avoids episodic simulation while achieving superior domain and category-level generalization through hyperbolic geometry and curvature-aware techniques."}}
{"id": "2510.16814", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16814", "abs": "https://arxiv.org/abs/2510.16814", "authors": ["Simon Jaxy", "Anton Theys", "Patrick Willett", "W. Chris Carleton", "Ralf Vandam", "Pieter Libin"], "title": "Needles in the Landscape: Semi-Supervised Pseudolabeling for Archaeological Site Discovery under Label Scarcity", "comment": null, "summary": "Archaeological predictive modelling estimates where undiscovered sites are\nlikely to occur by combining known locations with environmental, cultural, and\ngeospatial variables. We address this challenge using a deep learning approach\nbut must contend with structural label scarcity inherent to archaeology:\npositives are rare, and most locations are unlabeled. To address this, we adopt\na semi-supervised, positive-unlabeled (PU) learning strategy, implemented as a\nsemantic segmentation model and evaluated on two datasets covering a\nrepresentative range of archaeological periods. Our approach employs dynamic\npseudolabeling, refined with a Conditional Random Field (CRF) implemented via\nan RNN, increasing label confidence under severe class imbalance. On a\ngeospatial dataset derived from a digital elevation model (DEM), our model\nperforms on par with the state-of-the-art, LAMAP, while achieving higher Dice\nscores. On raw satellite imagery, assessed end-to-end with stratified k-fold\ncross-validation, it maintains performance and yields predictive surfaces with\nimproved interpretability. Overall, our results indicate that semi-supervised\nlearning offers a promising approach to identifying undiscovered sites across\nlarge, sparsely annotated landscapes.", "AI": {"tldr": "A semi-supervised deep learning approach using positive-unlabeled learning and dynamic pseudolabeling with CRF refinement for archaeological site prediction, achieving state-of-the-art performance on geospatial and satellite data.", "motivation": "To address structural label scarcity in archaeology where positives are rare and most locations are unlabeled, requiring methods that can work with limited labeled data.", "method": "Semi-supervised positive-unlabeled learning implemented as semantic segmentation with dynamic pseudolabeling and Conditional Random Field refinement via RNN to handle severe class imbalance.", "result": "Performs on par with state-of-the-art LAMAP on geospatial DEM data with higher Dice scores, maintains performance on raw satellite imagery with improved interpretability through stratified k-fold cross-validation.", "conclusion": "Semi-supervised learning offers a promising approach for identifying undiscovered archaeological sites across large, sparsely annotated landscapes."}}
{"id": "2510.17197", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17197", "abs": "https://arxiv.org/abs/2510.17197", "authors": ["Pu Zhang", "Yuwei Li", "Xingyuan Xian", "Guoming Tang"], "title": "ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models", "comment": null, "summary": "As the capabilities of Vision-Language Models (VLMs) advance, they can\nprocess increasingly large inputs, which, unlike in LLMs, generates significant\nvisual token redundancy and leads to prohibitive inference costs. While many\nmethods aim to reduce these costs by pruning visual tokens, existing\napproaches, whether based on attention or diversity, typically neglect the\nguidance of the text prompt and thus fail to prioritize task relevance. In this\nwork, we propose a novel, zero-shot method that reframes the problem by\nintroducing a prompt-aware perspective, explicitly modeling visual token\npruning as a balance between task relevance and information diversity. Our\nhierarchical approach first selects a core set of task-relevant visual tokens\nand then supplements them with diversity tokens to preserve broader context.\nExperiments across multiple models and benchmarks show that our method achieves\nperformance that matches or surpasses the state-of-the-art with only minimal\naccuracy loss, even when pruning up to 90\\% of the tokens. Furthermore, these\ngains are accompanied by significant reductions in GPU memory footprint and\ninference latency.", "AI": {"tldr": "A zero-shot method for reducing visual token redundancy in Vision-Language Models by balancing task relevance and information diversity through hierarchical token pruning.", "motivation": "VLMs process large inputs leading to visual token redundancy and high inference costs, but existing pruning methods neglect text prompt guidance and fail to prioritize task relevance.", "method": "Hierarchical approach that first selects task-relevant visual tokens based on text prompt guidance, then supplements with diversity tokens to preserve broader context.", "result": "Achieves performance matching or surpassing state-of-the-art with minimal accuracy loss even when pruning up to 90% of tokens, while significantly reducing GPU memory and inference latency.", "conclusion": "The proposed prompt-aware token pruning method effectively balances task relevance and information diversity, enabling substantial computational savings without compromising performance."}}
{"id": "2510.16816", "categories": ["cs.LG", "cs.AI", "math-ph", "math.MP", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.16816", "abs": "https://arxiv.org/abs/2510.16816", "authors": ["Ming Zhong", "Zhenya Yan"], "title": "Efficient High-Accuracy PDEs Solver with the Linear Attention Neural Operator", "comment": "31 pages, 8 figures", "summary": "Neural operators offer a powerful data-driven framework for learning mappings\nbetween function spaces, in which the transformer-based neural operator\narchitecture faces a fundamental scalability-accuracy trade-off: softmax\nattention provides excellent fidelity but incurs quadratic complexity\n$\\mathcal{O}(N^2 d)$ in the number of mesh points $N$ and hidden dimension $d$,\nwhile linear attention variants reduce cost to $\\mathcal{O}(N d^2)$ but often\nsuffer significant accuracy degradation. To address the aforementioned\nchallenge, in this paper, we present a novel type of neural operators, Linear\nAttention Neural Operator (LANO), which achieves both scalability and high\naccuracy by reformulating attention through an agent-based mechanism. LANO\nresolves this dilemma by introducing a compact set of $M$ agent tokens $(M \\ll\nN)$ that mediate global interactions among $N$ tokens. This agent attention\nmechanism yields an operator layer with linear complexity $\\mathcal{O}(MN d)$\nwhile preserving the expressive power of softmax attention. Theoretically, we\ndemonstrate the universal approximation property, thereby demonstrating\nimproved conditioning and stability properties. Empirically, LANO surpasses\ncurrent state-of-the-art neural PDE solvers, including Transolver with\nslice-based softmax attention, achieving average $19.5\\%$ accuracy improvement\nacross standard benchmarks. By bridging the gap between linear complexity and\nsoftmax-level performance, LANO establishes a scalable, high-accuracy\nfoundation for scientific machine learning applications.", "AI": {"tldr": "LANO is a neural operator that uses agent tokens to achieve linear complexity while maintaining softmax attention accuracy, outperforming existing PDE solvers by 19.5% on benchmarks.", "motivation": "To overcome the scalability-accuracy trade-off in transformer-based neural operators where softmax attention has quadratic complexity and linear attention variants suffer accuracy degradation.", "method": "Introduces agent-based attention with a compact set of M agent tokens (M << N) that mediate global interactions among N tokens, achieving linear complexity O(MNd) while preserving expressive power.", "result": "LANO surpasses state-of-the-art neural PDE solvers including Transolver, achieving 19.5% average accuracy improvement across standard benchmarks.", "conclusion": "LANO bridges the gap between linear complexity and softmax-level performance, establishing a scalable, high-accuracy foundation for scientific machine learning."}}
{"id": "2510.17198", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17198", "abs": "https://arxiv.org/abs/2510.17198", "authors": ["M Saifuzzaman Rafat", "Mohd Ruhul Ameen", "Akif Islam", "Abu Saleh Musa Miah", "Jungpil Shin"], "title": "From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh", "comment": "Submitted to the International Conference on Data and Applied\n  Analytics (IDAA 2025). 15 pages, 5 figures, 4 tables", "summary": "The great rivers of Bangladesh, arteries of commerce and sustenance, are also\nagents of relentless destruction. Each year, they swallow whole villages and\nvast tracts of farmland, erasing communities from the map and displacing\nthousands of families. To track this slow-motion catastrophe has, until now,\nbeen a Herculean task for human analysts. Here we show how a powerful\ngeneral-purpose vision model, the Segment Anything Model (SAM), can be adapted\nto this task with remarkable precision. To do this, we assembled a new dataset\n- a digital chronicle of loss compiled from historical Google Earth imagery of\nBangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur\nUnion, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,\nthis dataset is the first to include manually annotated data on the settlements\nthat have vanished beneath the water. Our method first uses a simple\ncolor-channel analysis to provide a rough segmentation of land and water, and\nthen fine-tunes SAM's mask decoder to recognize the subtle signatures of\nriverbank erosion. The resulting model demonstrates a keen eye for this\ndestructive process, achieving a mean Intersection over Union of 86.30% and a\nDice score of 92.60% - a performance that significantly surpasses traditional\nmethods and off-the-shelf deep learning models. This work delivers three key\ncontributions: the first annotated dataset of disappeared settlements in\nBangladesh due to river erosion; a specialized AI model fine-tuned for this\ncritical task; and a method for quantifying land loss with compelling visual\nevidence. Together, these tools provide a powerful new lens through which\npolicymakers and disaster management agencies can monitor erosion, anticipate\nits trajectory, and ultimately protect the vulnerable communities in its path.", "AI": {"tldr": "Adapted Segment Anything Model (SAM) to track riverbank erosion in Bangladesh using historical satellite imagery, achieving high accuracy in detecting land loss and vanished settlements.", "motivation": "To address the challenge of tracking riverbank erosion in Bangladesh, which destroys villages and farmland, displacing thousands annually, using automated methods instead of manual analysis.", "method": "Used color-channel analysis for initial land/water segmentation, then fine-tuned SAM's mask decoder to recognize riverbank erosion patterns using a new dataset of historical Google Earth imagery with manual annotations of disappeared settlements.", "result": "Achieved mean Intersection over Union of 86.30% and Dice score of 92.60%, significantly outperforming traditional methods and off-the-shelf deep learning models.", "conclusion": "Provides a powerful tool for policymakers and disaster management agencies to monitor erosion, predict its trajectory, and protect vulnerable communities through automated land loss quantification."}}
{"id": "2510.16817", "categories": ["cs.LG", "math.AP"], "pdf": "https://arxiv.org/pdf/2510.16817", "abs": "https://arxiv.org/abs/2510.16817", "authors": ["Doyoon Kim", "Junbin Song"], "title": "Trace Regularity PINNs: Enforcing $\\mathrm{H}^{\\frac{1}{2}}(\\partial \u03a9)$ for Boundary Data", "comment": null, "summary": "We propose an enhanced physics-informed neural network (PINN), the Trace\nRegularity Physics-Informed Neural Network (TRPINN), which enforces the\nboundary loss in the Sobolev-Slobodeckij norm $H^{1/2}(\\partial \\Omega)$, the\ncorrect trace space associated with $H^1(\\Omega)$. We reduce computational cost\nby computing only the theoretically essential portion of the semi-norm and\nenhance convergence stability by avoiding denominator evaluations in the\ndiscretization. By incorporating the exact $H^{1/2}(\\partial \\Omega)$ norm, we\nshow that the approximation converges to the true solution in the\n$H^{1}(\\Omega)$ sense, and, through Neural Tangent Kernel (NTK) analysis, we\ndemonstrate that TRPINN can converge faster than standard PINNs. Numerical\nexperiments on the Laplace equation with highly oscillatory Dirichlet boundary\nconditions exhibit cases where TRPINN succeeds even when standard PINNs fail,\nand show performance improvements of one to three decimal digits.", "AI": {"tldr": "TRPINN is an enhanced PINN that enforces boundary loss using the Sobolev-Slobodeckij norm H^{1/2}(\u2202\u03a9), reducing computational cost and improving convergence stability.", "motivation": "Standard PINNs have limitations in handling boundary conditions, especially for highly oscillatory problems, and may fail to converge properly.", "method": "Uses the exact H^{1/2}(\u2202\u03a9) norm for boundary loss enforcement, computes only essential portions of the semi-norm, avoids denominator evaluations, and applies Neural Tangent Kernel analysis.", "result": "TRPINN converges to true solution in H^1(\u03a9) sense, converges faster than standard PINNs, succeeds where standard PINNs fail, and shows 1-3 decimal digit performance improvements.", "conclusion": "TRPINN provides a theoretically sound and computationally efficient approach for boundary condition enforcement in PINNs, with superior performance on challenging problems."}}
{"id": "2510.17199", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17199", "abs": "https://arxiv.org/abs/2510.17199", "authors": ["Nirai Hayakawa", "Kazumasa Shimari", "Kazuma Yamasaki", "Hirotatsu Hoshikawa", "Rikuto Tsuchida", "Kenichi Matsumoto"], "title": "Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis", "comment": "Accepted to IEEE 2025 Conference on Games", "summary": "Recently, research on predicting match outcomes in esports has been actively\nconducted, but much of it is based on match log data and statistical\ninformation. This research targets the FPS game VALORANT, which requires\ncomplex strategies, and aims to build a round outcome prediction model by\nanalyzing minimap information in match footage. Specifically, based on the\nvideo recognition model TimeSformer, we attempt to improve prediction accuracy\nby incorporating detailed tactical features extracted from minimap information,\nsuch as character position information and other in-game events. This paper\nreports preliminary results showing that a model trained on a dataset augmented\nwith such tactical event labels achieved approximately 81% prediction accuracy,\nespecially from the middle phases of a round onward, significantly\noutperforming a model trained on a dataset with the minimap information itself.\nThis suggests that leveraging tactical features from match footage is highly\neffective for predicting round outcomes in VALORANT.", "AI": {"tldr": "This paper presents a round outcome prediction model for VALORANT using minimap information and tactical features from match footage, achieving 81% accuracy by incorporating detailed tactical event labels.", "motivation": "Most existing esports match prediction research relies on match log data and statistics, but this study targets VALORANT's complex strategies and aims to improve prediction by analyzing minimap information from actual match footage.", "method": "Based on TimeSformer video recognition model, the approach extracts detailed tactical features from minimap information including character positions and in-game events, using dataset augmentation with tactical event labels.", "result": "The model achieved approximately 81% prediction accuracy, particularly from the middle phases of rounds onward, significantly outperforming models trained only on minimap information without tactical features.", "conclusion": "Leveraging tactical features extracted from match footage is highly effective for predicting round outcomes in VALORANT, demonstrating the value of visual analysis over traditional statistical approaches."}}
{"id": "2510.16820", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16820", "abs": "https://arxiv.org/abs/2510.16820", "authors": ["Thomas Dooms", "Ward Gauderis"], "title": "Finding Manifolds With Bilinear Autoencoders", "comment": null, "summary": "Sparse autoencoders are a standard tool for uncovering interpretable latent\nrepresentations in neural networks. Yet, their interpretation depends on the\ninputs, making their isolated study incomplete. Polynomials offer a solution;\nthey serve as algebraic primitives that can be analysed without reference to\ninput and can describe structures ranging from linear concepts to complicated\nmanifolds. This work uses bilinear autoencoders to efficiently decompose\nrepresentations into quadratic polynomials. We discuss improvements that induce\nimportance ordering, clustering, and activation sparsity. This is an initial\nstep toward nonlinear yet analysable latents through their algebraic\nproperties.", "AI": {"tldr": "This paper proposes using bilinear autoencoders to decompose neural network representations into quadratic polynomials, enabling interpretable analysis without input dependency.", "motivation": "Sparse autoencoders depend on inputs for interpretation, making isolated study incomplete. Polynomials provide algebraic primitives that can be analyzed independently of inputs and describe various structures from linear concepts to complex manifolds.", "method": "Uses bilinear autoencoders to efficiently decompose representations into quadratic polynomials, with improvements that induce importance ordering, clustering, and activation sparsity.", "result": "The approach enables efficient decomposition of representations into quadratic polynomials, providing a framework for nonlinear yet analyzable latent representations through their algebraic properties.", "conclusion": "This work represents an initial step toward developing nonlinear latent representations that remain analyzable through their algebraic properties, moving beyond input-dependent interpretation methods."}}
{"id": "2510.17200", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17200", "abs": "https://arxiv.org/abs/2510.17200", "authors": ["Bingrong Liu", "Jun Shi", "Yushan Zheng"], "title": "EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification", "comment": null, "summary": "Class-incremental learning (CIL) for endoscopic image analysis is crucial for\nreal-world clinical applications, where diagnostic models should continuously\nadapt to evolving clinical data while retaining performance on previously\nlearned ones. However, existing replay-based CIL methods fail to effectively\nmitigate catastrophic forgetting due to severe domain discrepancies and class\nimbalance inherent in endoscopic imaging. To tackle these challenges, we\npropose EndoCIL, a novel and unified CIL framework specifically tailored for\nendoscopic image diagnosis. EndoCIL incorporates three key components: Maximum\nMean Discrepancy Based Replay (MDBR), employing a distribution-aligned greedy\nstrategy to select diverse and representative exemplars, Prior Regularized\nClass Balanced Loss (PRCBL), designed to alleviate both inter-phase and\nintra-phase class imbalance by integrating prior class distributions and\nbalance weights into the loss function, and Calibration of Fully-Connected\nGradients (CFG), which adjusts the classifier gradients to mitigate bias toward\nnew classes. Extensive experiments conducted on four public endoscopic datasets\ndemonstrate that EndoCIL generally outperforms state-of-the-art CIL methods\nacross varying buffer sizes and evaluation metrics. The proposed framework\neffectively balances stability and plasticity in lifelong endoscopic diagnosis,\nshowing promising potential for clinical scalability and deployment.", "AI": {"tldr": "EndoCIL is a novel class-incremental learning framework for endoscopic image diagnosis that addresses catastrophic forgetting through three key components: distribution-aligned exemplar selection, class-balanced loss, and gradient calibration.", "motivation": "Existing replay-based CIL methods fail to effectively mitigate catastrophic forgetting in endoscopic imaging due to severe domain discrepancies and class imbalance inherent in clinical data.", "method": "EndoCIL incorporates three components: Maximum Mean Discrepancy Based Replay for diverse exemplar selection, Prior Regularized Class Balanced Loss to address class imbalance, and Calibration of Fully-Connected Gradients to mitigate bias toward new classes.", "result": "Extensive experiments on four public endoscopic datasets show that EndoCIL generally outperforms state-of-the-art CIL methods across varying buffer sizes and evaluation metrics.", "conclusion": "The framework effectively balances stability and plasticity in lifelong endoscopic diagnosis, showing promising potential for clinical scalability and deployment."}}
{"id": "2510.16824", "categories": ["cs.LG", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2510.16824", "abs": "https://arxiv.org/abs/2510.16824", "authors": ["Yingxu Wang", "Kunyu Zhang", "Jiaxin Huang", "Nan Yin", "Siwei Liu", "Eran Segal"], "title": "ProtoMol: Enhancing Molecular Property Prediction via Prototype-Guided Multimodal Learning", "comment": null, "summary": "Multimodal molecular representation learning, which jointly models molecular\ngraphs and their textual descriptions, enhances predictive accuracy and\ninterpretability by enabling more robust and reliable predictions of drug\ntoxicity, bioactivity, and physicochemical properties through the integration\nof structural and semantic information. However, existing multimodal methods\nsuffer from two key limitations: (1) they typically perform cross-modal\ninteraction only at the final encoder layer, thus overlooking hierarchical\nsemantic dependencies; (2) they lack a unified prototype space for robust\nalignment between modalities. To address these limitations, we propose\nProtoMol, a prototype-guided multimodal framework that enables fine-grained\nintegration and consistent semantic alignment between molecular graphs and\ntextual descriptions. ProtoMol incorporates dual-branch hierarchical encoders,\nutilizing Graph Neural Networks to process structured molecular graphs and\nTransformers to encode unstructured texts, resulting in comprehensive\nlayer-wise representations. Then, ProtoMol introduces a layer-wise\nbidirectional cross-modal attention mechanism that progressively aligns\nsemantic features across layers. Furthermore, a shared prototype space with\nlearnable, class-specific anchors is constructed to guide both modalities\ntoward coherent and discriminative representations. Extensive experiments on\nmultiple benchmark datasets demonstrate that ProtoMol consistently outperforms\nstate-of-the-art baselines across a variety of molecular property prediction\ntasks.", "AI": {"tldr": "ProtoMol is a prototype-guided multimodal framework that enables fine-grained integration and semantic alignment between molecular graphs and textual descriptions through hierarchical encoders, layer-wise cross-modal attention, and a shared prototype space.", "motivation": "Existing multimodal methods for molecular representation learning have limitations: they perform cross-modal interaction only at the final encoder layer, overlooking hierarchical semantic dependencies, and lack a unified prototype space for robust alignment between modalities.", "method": "ProtoMol uses dual-branch hierarchical encoders (Graph Neural Networks for molecular graphs and Transformers for texts), layer-wise bidirectional cross-modal attention mechanism, and constructs a shared prototype space with learnable, class-specific anchors to guide both modalities toward coherent representations.", "result": "Extensive experiments on multiple benchmark datasets demonstrate that ProtoMol consistently outperforms state-of-the-art baselines across various molecular property prediction tasks.", "conclusion": "ProtoMol effectively addresses the limitations of existing multimodal methods by enabling fine-grained integration and consistent semantic alignment between molecular graphs and textual descriptions, leading to superior performance in molecular property prediction."}}
{"id": "2510.17201", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17201", "abs": "https://arxiv.org/abs/2510.17201", "authors": ["Mika Feng", "Pierre Gallin-Martel", "Koichi Ito", "Takafumi Aoki"], "title": "Optimizing DINOv2 with Registers for Face Anti-Spoofing", "comment": "ICCV 2025 Workshop FAS", "summary": "Face recognition systems are designed to be robust against variations in head\npose, illumination, and image blur during capture. However, malicious actors\ncan exploit these systems by presenting a face photo of a registered user,\npotentially bypassing the authentication process. Such spoofing attacks must be\ndetected prior to face recognition. In this paper, we propose a DINOv2-based\nspoofing attack detection method to discern minute differences between live and\nspoofed face images. Specifically, we employ DINOv2 with registers to extract\ngeneralizable features and to suppress perturbations in the attention\nmechanism, which enables focused attention on essential and minute features. We\ndemonstrate the effectiveness of the proposed method through experiments\nconducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop:\nUnified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.", "AI": {"tldr": "Proposes a DINOv2-based method with registers for face spoofing attack detection to distinguish live vs. spoofed face images by focusing on minute feature differences.", "motivation": "Face recognition systems are vulnerable to spoofing attacks using face photos, which can bypass authentication. Need robust detection before face recognition.", "method": "Uses DINOv2 with registers to extract generalizable features and suppress attention perturbations, enabling focused attention on essential minute features.", "result": "Demonstrated effectiveness through experiments on datasets from The 6th Face Anti-Spoofing Workshop and SiW dataset.", "conclusion": "The proposed DINOv2-based method with registers effectively detects face spoofing attacks by capturing subtle differences between live and spoofed images."}}
{"id": "2510.16857", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16857", "abs": "https://arxiv.org/abs/2510.16857", "authors": ["Jiyan Qiu", "Lyulin Kuang", "Guan Wang", "Yichen Xu", "Leiyao Cui", "Shaotong Fu", "Yixin Zhu", "Ruihua Zhang"], "title": "DrivAerStar: An Industrial-Grade CFD Dataset for Vehicle Aerodynamic Optimization", "comment": null, "summary": "Vehicle aerodynamics optimization has become critical for automotive\nelectrification, where drag reduction directly determines electric vehicle\nrange and energy efficiency. Traditional approaches face an intractable\ntrade-off: computationally expensive Computational Fluid Dynamics (CFD)\nsimulations requiring weeks per design iteration, or simplified models that\nsacrifice production-grade accuracy. While machine learning offers\ntransformative potential, existing datasets exhibit fundamental limitations --\ninadequate mesh resolution, missing vehicle components, and validation errors\nexceeding 5% -- preventing deployment in industrial workflows. We present\nDrivAerStar, comprising 12,000 industrial-grade automotive CFD simulations\ngenerated using $\\text{STAR-CCM+}^\\unicode{xAE}$ software. The dataset\nsystematically explores three vehicle configurations through 20 Computer Aided\nDesign (CAD) parameters via Free Form Deformation (FFD) algorithms, including\ncomplete engine compartments and cooling systems with realistic internal\nairflow. DrivAerStar achieves wind tunnel validation accuracy below 1.04% -- a\nfive-fold improvement over existing datasets -- through refined mesh strategies\nwith strict wall $y^+$ control. Benchmarks demonstrate that models trained on\nthis data achieve production-ready accuracy while reducing computational costs\nfrom weeks to minutes. This represents the first dataset bridging academic\nmachine learning research and industrial CFD practice, establishing a new\nstandard for data-driven aerodynamic optimization in automotive development.\nBeyond automotive applications, DrivAerStar demonstrates a paradigm for\nintegrating high-fidelity physics simulations with Artificial Intelligence (AI)\nacross engineering disciplines where computational constraints currently limit\ninnovation.", "AI": {"tldr": "DrivAerStar is a dataset of 12,000 industrial-grade automotive CFD simulations with wind tunnel validation accuracy below 1.04%, enabling production-ready aerodynamic optimization while reducing computational costs from weeks to minutes.", "motivation": "Vehicle aerodynamics optimization is critical for electric vehicle range and energy efficiency, but traditional approaches face trade-offs between computational expense and accuracy, while existing machine learning datasets have inadequate resolution and validation errors exceeding 5%.", "method": "Generated 12,000 CFD simulations using STAR-CCM+ software, systematically exploring three vehicle configurations through 20 CAD parameters via Free Form Deformation algorithms, including complete engine compartments and cooling systems with realistic internal airflow, using refined mesh strategies with strict wall y+ control.", "result": "Achieved wind tunnel validation accuracy below 1.04% - a five-fold improvement over existing datasets, with benchmarks showing models trained on this data achieve production-ready accuracy while reducing computational costs from weeks to minutes.", "conclusion": "DrivAerStar bridges academic machine learning research and industrial CFD practice, establishing a new standard for data-driven aerodynamic optimization and demonstrating a paradigm for integrating high-fidelity physics simulations with AI across engineering disciplines."}}
{"id": "2510.17205", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17205", "abs": "https://arxiv.org/abs/2510.17205", "authors": ["Yingqi Fan", "Anhao Zhao", "Jinlan Fu", "Junlong Tong", "Hui Su", "Yijie Pan", "Wei Zhang", "Xiaoyu Shen"], "title": "$\\mathcal{V}isi\\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs", "comment": "EMNLP 2025 Main", "summary": "Multimodal Large Language Models (MLLMs) have achieved strong performance\nacross vision-language tasks, but suffer from significant computational\noverhead due to the quadratic growth of attention computations with the number\nof multimodal tokens. Though efforts have been made to prune tokens in MLLMs,\n\\textit{they lack a fundamental understanding of how MLLMs process and fuse\nmultimodal information.} Through systematic analysis, we uncover a\n\\textbf{three-stage} cross-modal interaction process: (1) Shallow layers\nrecognize task intent, with visual tokens acting as passive attention sinks;\n(2) Cross-modal fusion occurs abruptly in middle layers, driven by a few\ncritical visual tokens; (3) Deep layers discard vision tokens, focusing solely\non linguistic refinement. Based on these findings, we propose\n\\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\\% of\nvision-related attention computations and 53.9\\% of FLOPs on LLaVA-v1.5 7B. It\nsignificantly outperforms existing token pruning methods and generalizes across\ndiverse MLLMs. Beyond pruning, our insights further provide actionable\nguidelines for training efficient MLLMs by aligning model architecture with its\nintrinsic layer-wise processing dynamics. Our code is available at:\nhttps://github.com/EIT-NLP/VisiPruner.", "AI": {"tldr": "VisiPruner is a training-free pruning framework that reduces vision-related attention computations by up to 99% and FLOPs by 53.9% in MLLMs by leveraging insights from cross-modal interaction patterns.", "motivation": "MLLMs suffer from significant computational overhead due to quadratic attention growth with multimodal tokens, and existing pruning methods lack understanding of how MLLMs process multimodal information.", "method": "Systematic analysis reveals a three-stage cross-modal interaction process, leading to VisiPruner - a training-free pruning framework that selectively prunes vision tokens based on layer-specific processing dynamics.", "result": "VisiPruner reduces up to 99% of vision-related attention computations and 53.9% of FLOPs on LLaVA-v1.5 7B, outperforming existing token pruning methods and generalizing across diverse MLLMs.", "conclusion": "The insights provide actionable guidelines for training efficient MLLMs by aligning model architecture with intrinsic layer-wise processing dynamics, enabling significant computational savings without performance degradation."}}
{"id": "2510.16877", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16877", "abs": "https://arxiv.org/abs/2510.16877", "authors": ["Heming Zou", "Yunliang Zang", "Wutong Xu", "Xiangyang Ji"], "title": "Fly-CL: A Fly-Inspired Framework for Enhancing Efficient Decorrelation and Reduced Training Time in Pre-trained Model-based Continual Representation Learning", "comment": null, "summary": "Using a nearly-frozen pretrained model, the continual representation learning\nparadigm reframes parameter updates as a similarity-matching problem to\nmitigate catastrophic forgetting. However, directly leveraging pretrained\nfeatures for downstream tasks often suffers from multicollinearity in the\nsimilarity-matching stage, and more advanced methods can be computationally\nprohibitive for real-time, low-latency applications. Inspired by the fly\nolfactory circuit, we propose Fly-CL, a bio-inspired framework compatible with\na wide range of pretrained backbones. Fly-CL substantially reduces training\ntime while achieving performance comparable to or exceeding that of current\nstate-of-the-art methods. We theoretically show how Fly-CL progressively\nresolves multicollinearity, enabling more effective similarity matching with\nlow time complexity. Extensive simulation experiments across diverse network\narchitectures and data regimes validate Fly-CL's effectiveness in addressing\nthis challenge through a biologically inspired design. Code is available at\nhttps://github.com/gfyddha/Fly-CL.", "AI": {"tldr": "Fly-CL is a bio-inspired continual learning framework that uses a nearly-frozen pretrained model and resolves multicollinearity in similarity matching, achieving fast training with state-of-the-art performance.", "motivation": "To address catastrophic forgetting in continual learning while overcoming multicollinearity issues in similarity matching and computational limitations of advanced methods for real-time applications.", "method": "Proposes Fly-CL framework inspired by fly olfactory circuit, using nearly-frozen pretrained models and progressive multicollinearity resolution for effective similarity matching with low time complexity.", "result": "Substantially reduces training time while achieving performance comparable to or exceeding state-of-the-art methods across diverse network architectures and data regimes.", "conclusion": "Fly-CL effectively addresses continual learning challenges through biologically inspired design that resolves multicollinearity and enables efficient similarity matching."}}
{"id": "2510.17218", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17218", "abs": "https://arxiv.org/abs/2510.17218", "authors": ["Zhuo Cao", "Heming Du", "Bingqing Zhang", "Xin Yu", "Xue Li", "Sen Wang"], "title": "When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions", "comment": "Accepted to NeurIPS 2025", "summary": "Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval\n(SMR). However, one query can correspond to multiple relevant moments in\nreal-world applications. This makes the existing datasets and methods\ninsufficient for video temporal grounding. By revisiting the gap between\ncurrent MR tasks and real-world applications, we introduce a high-quality\ndatasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new\nevaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists\nof 2,212 annotations covering 6,384 video segments. Building on existing\nefforts in MMR, we propose a framework called FlashMMR. Specifically, we\npropose a Multi-moment Post-verification module to refine the moment\nboundaries. We introduce constrained temporal adjustment and subsequently\nleverage a verification module to re-evaluate the candidate segments. Through\nthis sophisticated filtering pipeline, low-confidence proposals are pruned, and\nrobust multi-moment alignment is achieved. We retrain and evaluate 6 existing\nMR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings.\nResults show that QV-M$^2$ serves as an effective benchmark for training and\nevaluating MMR models, while FlashMMR provides a strong baseline. Specifically,\non QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP,\n2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method\nestablish a foundation for advancing research in more realistic and challenging\nvideo temporal grounding scenarios. Code is released at\nhttps://github.com/Zhuo-Cao/QV-M2.", "AI": {"tldr": "This paper introduces QV-M^2 dataset for multi-moment retrieval (MMR) and proposes FlashMMR framework with multi-moment post-verification to address limitations of existing single-moment retrieval methods in real-world video temporal grounding.", "motivation": "Existing moment retrieval methods focus on single-moment retrieval, but real-world applications often require retrieving multiple relevant moments for one query, making current datasets and methods insufficient.", "method": "Propose FlashMMR framework with Multi-moment Post-verification module that uses constrained temporal adjustment and verification to refine moment boundaries and prune low-confidence proposals for robust multi-moment alignment.", "result": "FlashMMR achieves improvements over prior SOTA by 3.00% on G-mAP, 2.70% on mAP@3+tgt, and 2.56% on mR@3 on QV-M^2 dataset. The dataset contains 2,212 annotations covering 6,384 video segments.", "conclusion": "QV-M^2 serves as an effective benchmark for MMR models, and FlashMMR provides a strong baseline, establishing foundation for advancing research in realistic video temporal grounding scenarios."}}
{"id": "2510.16882", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16882", "abs": "https://arxiv.org/abs/2510.16882", "authors": ["Heming Zou", "Yixiu Mao", "Yun Qu", "Qi Wang", "Xiangyang Ji"], "title": "Utility-Diversity Aware Online Batch Selection for LLM Supervised Fine-tuning", "comment": null, "summary": "Supervised fine-tuning (SFT) is a commonly used technique to adapt large\nlanguage models (LLMs) to downstream tasks. In practice, SFT on a full dataset\nis computationally expensive and sometimes suffers from overfitting or bias\namplification. This facilitates the rise of data curation in SFT, which\nprioritizes the most valuable data to optimze. This work studies the online\nbatch selection family that dynamically scores and filters samples during the\ntraining process. However, existing popular methods often (i) rely merely on\nthe utility of data to select a subset while neglecting other crucial factors\nlike diversity, (ii) rely on external resources such as reference models or\nvalidation sets, and (iii) incur extra training time over full-dataset\ntraining. To address these limitations, this work develops \\textbf{UDS\n(Utility-Diversity Sampling)}, a framework for efficient online batch selection\nin SFT. UDS leverages the nuclear norm of the logits matrix to capture both\ndata utility and intra-sample diversity, while estimating inter-sample\ndiversity through efficient low-dimensional embedding comparisons with a\nlightweight memory buffer of historical samples. Such a design eliminates the\nneed for external resources and unnecessary backpropagation, securing\ncomputational efficiency. Experiments on multiple benchmarks demonstrate that\nUDS consistently outperforms state-of-the-art online batch selection methods\nunder varying data budgets, and significantly reduces training time compared to\nfull-dataset fine-tuning. Code is available at https://github.com/gfyddha/UDS.", "AI": {"tldr": "UDS is an efficient online batch selection framework for supervised fine-tuning that selects data based on utility and diversity without external resources, reducing training time while maintaining performance.", "motivation": "Supervised fine-tuning on full datasets is computationally expensive and can cause overfitting or bias amplification, while existing batch selection methods often neglect diversity, require external resources, and add training overhead.", "method": "UDS uses nuclear norm of logits matrix to capture utility and intra-sample diversity, and estimates inter-sample diversity through low-dimensional embedding comparisons with a lightweight memory buffer of historical samples, eliminating need for external resources and extra backpropagation.", "result": "UDS consistently outperforms state-of-the-art online batch selection methods under varying data budgets and significantly reduces training time compared to full-dataset fine-tuning across multiple benchmarks.", "conclusion": "UDS provides an effective and efficient framework for data curation in supervised fine-tuning that balances utility and diversity without external dependencies, making it practical for real-world applications."}}
{"id": "2510.17264", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17264", "abs": "https://arxiv.org/abs/2510.17264", "authors": ["Akihito Yoshii", "Ryosuke Sonoda", "Ramya Srinivasan"], "title": "Fair and Interpretable Deepfake Detection in Videos", "comment": "10 pages (including References)", "summary": "Existing deepfake detection methods often exhibit bias, lack transparency,\nand fail to capture temporal information, leading to biased decisions and\nunreliable results across different demographic groups. In this paper, we\npropose a fairness-aware deepfake detection framework that integrates temporal\nfeature learning and demographic-aware data augmentation to enhance fairness\nand interpretability. Our method leverages sequence-based clustering for\ntemporal modeling of deepfake videos and concept extraction to improve\ndetection reliability while also facilitating interpretable decisions for\nnon-expert users. Additionally, we introduce a demography-aware data\naugmentation method that balances underrepresented groups and applies\nfrequency-domain transformations to preserve deepfake artifacts, thereby\nmitigating bias and improving generalization. Extensive experiments on\nFaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA)\narchitectures (Xception, ResNet) demonstrate the efficacy of the proposed\nmethod in obtaining the best tradeoff between fairness and accuracy when\ncompared to SoTA.", "AI": {"tldr": "A fairness-aware deepfake detection framework that integrates temporal feature learning and demographic-aware data augmentation to address bias and improve interpretability.", "motivation": "Existing deepfake detection methods exhibit bias, lack transparency, and fail to capture temporal information, leading to biased decisions and unreliable results across different demographic groups.", "method": "Leverages sequence-based clustering for temporal modeling of deepfake videos, concept extraction for interpretability, and demographic-aware data augmentation that balances underrepresented groups while preserving deepfake artifacts through frequency-domain transformations.", "result": "Extensive experiments on FaceForensics++, DFD, Celeb-DF, and DFDC datasets using Xception and ResNet architectures demonstrate the method achieves the best tradeoff between fairness and accuracy compared to state-of-the-art approaches.", "conclusion": "The proposed framework effectively mitigates bias in deepfake detection while maintaining high accuracy and providing interpretable decisions for non-expert users."}}
{"id": "2510.16885", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16885", "abs": "https://arxiv.org/abs/2510.16885", "authors": ["Duo Wang", "Yuan Zuo", "Guangyue Lu", "Junjie Wu"], "title": "UniGTE: Unified Graph-Text Encoding for Zero-Shot Generalization across Graph Tasks and Domains", "comment": null, "summary": "Generalizing to unseen graph tasks without task-specific supervision is\nchallenging: conventional graph neural networks are typically tied to a fixed\nlabel space, while large language models (LLMs) struggle to capture graph\nstructure. We introduce UniGTE, an instruction-tuned encoder-decoder framework\nthat unifies structural and semantic reasoning. The encoder augments a\npretrained autoregressive LLM with learnable alignment tokens and a\nstructure-aware graph-text attention mechanism, enabling it to attend jointly\nto a tokenized graph and a natural-language task prompt while remaining\npermutation-invariant to node order. This yields compact, task-aware graph\nrepresentations. Conditioned solely on these representations, a frozen LLM\ndecoder predicts and reconstructs: it outputs the task answer and\nsimultaneously paraphrases the input graph in natural language. The\nreconstruction objective regularizes the encoder to preserve structural cues.\nUniGTE is instruction-tuned on five datasets spanning node-level, edge-level,\nand graph-level tasks across diverse domains, yet requires no fine-tuning at\ninference. It achieves new state-of-the-art zero-shot results on node\nclassification, link prediction, graph classification, and graph regression\nunder cross-task and cross-domain settings, demonstrating that tight\nintegration of graph structure with LLM semantics enables robust, transferable\ngraph reasoning.", "AI": {"tldr": "UniGTE is an instruction-tuned encoder-decoder framework that combines graph structure with LLM semantics for zero-shot graph reasoning across diverse tasks without task-specific fine-tuning.", "motivation": "To address the limitations of conventional GNNs (fixed label space) and LLMs (struggle with graph structure) in generalizing to unseen graph tasks without task-specific supervision.", "method": "Uses an encoder with learnable alignment tokens and structure-aware graph-text attention to create task-aware graph representations, coupled with a frozen LLM decoder that predicts answers while reconstructing the input graph via paraphrasing.", "result": "Achieves state-of-the-art zero-shot performance on node classification, link prediction, graph classification, and graph regression across cross-task and cross-domain settings.", "conclusion": "Tight integration of graph structure with LLM semantics enables robust, transferable graph reasoning without requiring fine-tuning at inference."}}
{"id": "2510.17269", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17269", "abs": "https://arxiv.org/abs/2510.17269", "authors": ["Luis Wiedmann", "Orr Zohar", "Amir Mahla", "Xiaohan Wang", "Rui Li", "Thibaud Frere", "Leandro von Werra", "Aritra Roy Gosthipaty", "Andr\u00e9s Marafioti"], "title": "FineVision: Open Data Is All You Need", "comment": null, "summary": "The advancement of vision-language models (VLMs) is hampered by a fragmented\nlandscape of inconsistent and contaminated public datasets. We introduce\nFineVision, a meticulously collected, curated, and unified corpus of 24 million\nsamples - the largest open resource of its kind. We unify more than 200 sources\ninto 185 subsets via a semi-automated, human-in-the-loop pipeline: automation\nperforms bulk ingestion and schema mapping, while reviewers audit mappings and\nspot-check outputs to verify faithful consumption of annotations, appropriate\nformatting and diversity, and safety; issues trigger targeted fixes and\nre-runs. The workflow further applies rigorous de-duplication within and across\nsources and decontamination against 66 public benchmarks. FineVision also\nencompasses agentic/GUI tasks with a unified action space; reviewers validate\nschemas and inspect a sample of trajectories to confirm executable fidelity.\nModels trained on FineVision consistently outperform those trained on existing\nopen mixtures across a broad evaluation suite, underscoring the benefits of\nscale, data hygiene, and balanced automation with human oversight. We release\nthe corpus and curation tools to accelerate data-centric VLM research.", "AI": {"tldr": "FineVision is a large-scale, meticulously curated vision-language dataset of 24 million samples, created through semi-automated human-in-the-loop curation to address data fragmentation and contamination issues in VLM research.", "motivation": "To overcome the fragmented landscape of inconsistent and contaminated public datasets that hinder vision-language model advancement.", "method": "Semi-automated human-in-the-loop pipeline unifying 200+ sources into 185 subsets, with rigorous de-duplication, decontamination against 66 benchmarks, and human review for quality assurance.", "result": "Models trained on FineVision consistently outperform those trained on existing open mixtures across a broad evaluation suite, demonstrating benefits of scale and data hygiene.", "conclusion": "FineVision provides a high-quality, open resource that accelerates data-centric VLM research through balanced automation with human oversight."}}
{"id": "2510.16897", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16897", "abs": "https://arxiv.org/abs/2510.16897", "authors": ["Jose Siguenza", "Bharath Ramsundar"], "title": "DeepChem Equivariant: SE(3)-Equivariant Support in an Open-Source Molecular Machine Learning Library", "comment": "Presented at Machine Learning Symposium - BayLearn (2025)", "summary": "Neural networks that incorporate geometric relationships respecting SE(3)\ngroup transformations (e.g. rotations and translations) are increasingly\nimportant in molecular applications, such as molecular property prediction,\nprotein structure modeling, and materials design. These models, known as\nSE(3)-equivariant neural networks, ensure outputs transform predictably with\ninput coordinate changes by explicitly encoding spatial atomic positions.\nAlthough libraries such as E3NN [4] and SE(3)-TRANSFORMER [3 ] offer powerful\nimplementations, they often require substantial deep learning or mathematical\nprior knowledge and lack complete training pipelines. We extend DEEPCHEM [ 13]\nwith support for ready-to-use equivariant models, enabling scientists with\nminimal deep learning background to build, train, and evaluate models, such as\nSE(3)-Transformer and Tensor Field Networks. Our implementation includes\nequivariant models, complete training pipelines, and a toolkit of equivariant\nutilities, supported with comprehensive tests and documentation, to facilitate\nboth application and further development of SE(3)-equivariant models.", "AI": {"tldr": "The paper extends DeepChem with SE(3)-equivariant neural network support, providing accessible tools for molecular applications without requiring deep learning expertise.", "motivation": "Existing SE(3)-equivariant neural network libraries require substantial deep learning or mathematical knowledge and lack complete training pipelines, making them inaccessible to scientists with minimal background.", "method": "Extend DeepChem with ready-to-use equivariant models including SE(3)-Transformer and Tensor Field Networks, complete training pipelines, and a toolkit of equivariant utilities with comprehensive tests and documentation.", "result": "Created an accessible implementation that enables scientists to build, train, and evaluate SE(3)-equivariant models for molecular applications like property prediction, protein structure modeling, and materials design.", "conclusion": "The DeepChem extension facilitates both application and further development of SE(3)-equivariant models by providing comprehensive, user-friendly tools that lower the barrier to entry for scientists."}}
{"id": "2510.17274", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17274", "abs": "https://arxiv.org/abs/2510.17274", "authors": ["Katie Luo", "Jingwei Ji", "Tong He", "Runsheng Xu", "Yichen Xie", "Dragomir Anguelov", "Mingxing Tan"], "title": "Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models", "comment": "In proceedings of IROS 2025", "summary": "Current autonomous driving systems rely on specialized models for perceiving\nand predicting motion, which demonstrate reliable performance in standard\nconditions. However, generalizing cost-effectively to diverse real-world\nscenarios remains a significant challenge. To address this, we propose\nPlug-and-Forecast (PnF), a plug-and-play approach that augments existing motion\nforecasting models with multimodal large language models (MLLMs). PnF builds on\nthe insight that natural language provides a more effective way to describe and\nhandle complex scenarios, enabling quick adaptation to targeted behaviors. We\ndesign prompts to extract structured scene understanding from MLLMs and distill\nthis information into learnable embeddings to augment existing behavior\nprediction models. Our method leverages the zero-shot reasoning capabilities of\nMLLMs to achieve significant improvements in motion prediction performance,\nwhile requiring no fine-tuning -- making it practical to adopt. We validate our\napproach on two state-of-the-art motion forecasting models using the Waymo Open\nMotion Dataset and the nuScenes Dataset, demonstrating consistent performance\nimprovements across both benchmarks.", "AI": {"tldr": "Plug-and-Forecast (PnF) is a plug-and-play method that enhances existing motion forecasting models by integrating multimodal large language models (MLLMs) to handle complex scenarios using natural language descriptions, achieving improved performance without fine-tuning.", "motivation": "Current autonomous driving systems struggle to generalize cost-effectively to diverse real-world scenarios despite reliable performance in standard conditions. The need for better adaptation to complex situations motivates the use of natural language descriptions.", "method": "PnF extracts structured scene understanding from MLLMs using designed prompts and distills this information into learnable embeddings to augment existing behavior prediction models, leveraging zero-shot reasoning capabilities.", "result": "The approach achieves significant improvements in motion prediction performance on both Waymo Open Motion Dataset and nuScenes Dataset, demonstrating consistent performance gains across benchmarks.", "conclusion": "PnF provides an effective plug-and-play solution that enhances motion forecasting models using MLLMs' natural language capabilities, enabling quick adaptation to complex scenarios without requiring fine-tuning."}}
{"id": "2510.16898", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16898", "abs": "https://arxiv.org/abs/2510.16898", "authors": ["Salih Salihoglu", "Ibrahim Ahmed", "Afshin Asadi"], "title": "Adaptive Online Learning with LSTM Networks for Energy Price Prediction", "comment": null, "summary": "Accurate prediction of electricity prices is crucial for stakeholders in the\nenergy market, particularly for grid operators, energy producers, and\nconsumers. This study focuses on developing a predictive model leveraging Long\nShort-Term Memory (LSTM) networks to forecast day-ahead electricity prices in\nthe California energy market. The model incorporates a variety of features,\nincluding historical price data, weather conditions, and the energy generation\nmix. A novel custom loss function that integrates Mean Absolute Error (MAE),\nJensen-Shannon Divergence (JSD), and a smoothness penalty is introduced to\nenhance the prediction accuracy and interpretability. Additionally, an online\nlearning approach is implemented to allow the model to adapt to new data\nincrementally, ensuring continuous relevance and accuracy. The results\ndemonstrate that the custom loss function can improve the model's performance,\naligning predicted prices more closely with actual values, particularly during\npeak intervals. Also, the online learning model outperforms other models by\neffectively incorporating real-time data, resulting in lower prediction error\nand variability. The inclusion of the energy generation mix further enhances\nthe model's predictive capabilities, highlighting the importance of\ncomprehensive feature integration. This research provides a robust framework\nfor electricity price forecasting, offering valuable insights and tools for\nbetter decision-making in dynamic electricity markets.", "AI": {"tldr": "LSTM-based model for day-ahead electricity price forecasting in California market using custom loss function (MAE + JSD + smoothness penalty) and online learning approach.", "motivation": "Accurate electricity price prediction is crucial for grid operators, energy producers, and consumers in dynamic energy markets.", "method": "LSTM networks with historical price data, weather conditions, and energy generation mix features. Custom loss function combining MAE, Jensen-Shannon Divergence, and smoothness penalty. Online learning for incremental adaptation to new data.", "result": "Custom loss function improved model performance, aligning predictions with actual values especially during peak intervals. Online learning model outperformed others with lower prediction error and variability. Energy generation mix enhanced predictive capabilities.", "conclusion": "Provides robust framework for electricity price forecasting with valuable insights for decision-making in dynamic electricity markets."}}
{"id": "2510.17278", "categories": ["cs.CV", "68T07, 92C55", "I.4.6; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.17278", "abs": "https://arxiv.org/abs/2510.17278", "authors": ["Mehdi Zekriyapanah Gashti", "Mostafa Mohammadpour", "Ghasem Farjamnia"], "title": "SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation", "comment": null, "summary": "Accurate segmentation and classification of white blood cells (WBCs) in\nmicroscopic images are essential for diagnosis and monitoring of many\nhematological disorders, yet remain challenging due to staining variability,\ncomplex backgrounds, and class imbalance. In this paper, we introduce a novel\nSaliency-Guided Cross-Layer Deep Feature Fusion framework (SG-CLDFF) that\ntightly integrates saliency-driven preprocessing with multi-scale deep feature\naggregation to improve both robustness and interpretability for WBC analysis.\nSG-CLDFF first computes saliency priors to highlight candidate WBC regions and\nguide subsequent feature extraction. A lightweight hybrid backbone\n(EfficientSwin-style) produces multi-resolution representations, which are\nfused by a ResNeXt-CC-inspired cross-layer fusion module to preserve\ncomplementary information from shallow and deep layers. The network is trained\nin a multi-task setup with concurrent segmentation and cell-type classification\nheads, using class-aware weighted losses and saliency-alignment regularization\nto mitigate imbalance and suppress background activation. Interpretability is\nenforced through Grad-CAM visualizations and saliency consistency checks,\nallowing model decisions to be inspected at the regional level. We validate the\nframework on standard public benchmarks (BCCD, LISC, ALL-IDB), reporting\nconsistent gains in IoU, F1, and classification accuracy compared to strong CNN\nand transformer baselines. An ablation study also demonstrates the individual\ncontributions of saliency preprocessing and cross-layer fusion. SG-CLDFF offers\na practical and explainable path toward more reliable automated WBC analysis in\nclinical workflows.", "AI": {"tldr": "SG-CLDFF is a saliency-guided deep learning framework that improves white blood cell analysis through multi-scale feature fusion and multi-task learning, achieving better segmentation and classification performance with enhanced interpretability.", "motivation": "White blood cell analysis in microscopic images is challenging due to staining variability, complex backgrounds, and class imbalance, requiring more robust and interpretable automated solutions for clinical diagnosis.", "method": "Uses saliency-driven preprocessing to highlight WBC regions, a hybrid EfficientSwin-style backbone for multi-resolution features, cross-layer fusion module, multi-task learning with segmentation and classification heads, and class-aware weighted losses with saliency-alignment regularization.", "result": "Achieves consistent gains in IoU, F1, and classification accuracy on standard benchmarks (BCCD, LISC, ALL-IDB) compared to CNN and transformer baselines, with ablation studies confirming contributions of saliency preprocessing and cross-layer fusion.", "conclusion": "SG-CLDFF provides a practical and explainable framework for reliable automated WBC analysis in clinical workflows, combining robustness with interpretability through saliency guidance and multi-scale feature integration."}}
{"id": "2510.16899", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16899", "abs": "https://arxiv.org/abs/2510.16899", "authors": ["Dun Liu", "Qin Pang", "Guangai Liu", "Hongyu Mou", "Jipeng Fan", "Yiming Miao", "Pin-Han Ho", "Limei Peng"], "title": "SNOMED CT-powered Knowledge Graphs for Structured Clinical Data and Diagnostic Reasoning", "comment": null, "summary": "The effectiveness of artificial intelligence (AI) in healthcare is\nsignificantly hindered by unstructured clinical documentation, which results in\nnoisy, inconsistent, and logically fragmented training data. To address this\nchallenge, we present a knowledge-driven framework that integrates the\nstandardized clinical terminology SNOMED CT with the Neo4j graph database to\nconstruct a structured medical knowledge graph. In this graph, clinical\nentities such as diseases, symptoms, and medications are represented as nodes,\nand semantic relationships such as ``caused by,'' ``treats,'' and ``belongs\nto'' are modeled as edges in Neo4j, with types mapped from formal SNOMED CT\nrelationship concepts (e.g., \\texttt{Causative agent}, \\texttt{Indicated for}).\nThis design enables multi-hop reasoning and ensures terminological consistency.\nBy extracting and standardizing entity-relationship pairs from clinical texts,\nwe generate structured, JSON-formatted datasets that embed explicit diagnostic\npathways. These datasets are used to fine-tune large language models (LLMs),\nsignificantly improving the clinical logic consistency of their outputs.\nExperimental results demonstrate that our knowledge-guided approach enhances\nthe validity and interpretability of AI-generated diagnostic reasoning,\nproviding a scalable solution for building reliable AI-assisted clinical\nsystems.", "AI": {"tldr": "A knowledge-driven framework using SNOMED CT and Neo4j graph database to structure clinical data, improving AI diagnostic reasoning in healthcare.", "motivation": "To address the challenges of unstructured clinical documentation that creates noisy, inconsistent training data hindering AI effectiveness in healthcare.", "method": "Integrate SNOMED CT standardized terminology with Neo4j graph database to build medical knowledge graphs where clinical entities are nodes and semantic relationships are edges, enabling multi-hop reasoning and terminological consistency.", "result": "The framework generates structured JSON-formatted datasets with explicit diagnostic pathways, which when used to fine-tune LLMs, significantly improve clinical logic consistency and output validity.", "conclusion": "The knowledge-guided approach enhances AI-generated diagnostic reasoning validity and interpretability, providing a scalable solution for reliable AI-assisted clinical systems."}}
{"id": "2510.17287", "categories": ["cs.CV", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17287", "abs": "https://arxiv.org/abs/2510.17287", "authors": ["Amir Gharghabi", "Mahdi Hakiminezhad", "Maryam Shafaei", "Shaghayegh Gharghabi"], "title": "Machine Vision-Based Surgical Lighting System:Design and Implementation", "comment": null, "summary": "Effortless and ergonomically designed surgical lighting is critical for\nprecision and safety during procedures. However, traditional systems often rely\non manual adjustments, leading to surgeon fatigue, neck strain, and\ninconsistent illumination due to drift and shadowing. To address these\nchallenges, we propose a novel surgical lighting system that leverages the\nYOLOv11 object detection algorithm to identify a blue marker placed above the\ntarget surgical site. A high-power LED light source is then directed to the\nidentified location using two servomotors equipped with tilt-pan brackets. The\nYOLO model achieves 96.7% mAP@50 on the validation set consisting of annotated\nimages simulating surgical scenes with the blue spherical marker. By automating\nthe lighting process, this machine vision-based solution reduces physical\nstrain on surgeons, improves consistency in illumination, and supports improved\nsurgical outcomes.", "AI": {"tldr": "A machine vision-based surgical lighting system that uses YOLOv11 to detect a blue marker and automatically directs LED lighting to the surgical site using servomotors.", "motivation": "Traditional surgical lighting requires manual adjustments, causing surgeon fatigue, neck strain, and inconsistent illumination due to drift and shadowing.", "method": "Uses YOLOv11 object detection to identify a blue marker placed above the surgical site, then directs a high-power LED light source to the target location using two servomotors with tilt-pan brackets.", "result": "The YOLO model achieves 96.7% mAP@50 on validation set with annotated images simulating surgical scenes containing the blue spherical marker.", "conclusion": "This automated lighting system reduces physical strain on surgeons, improves illumination consistency, and supports better surgical outcomes."}}
{"id": "2510.16911", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16911", "abs": "https://arxiv.org/abs/2510.16911", "authors": ["Sarah Al-Shareeda", "Gulcihan Ozdemir", "Heung Seok Jeon", "Khaleel Ahmad"], "title": "A Lightweight DL Model for Smart Grid Power Forecasting with Feature and Resolution Mismatch", "comment": "5 pages, 3 figures, The IEEE PES ISGT Middle East 2025 (ISGT-ME 2025)\n  November 23-26th 2025, Dubai, UAE", "summary": "How can short-term energy consumption be accurately forecasted when sensor\ndata is noisy, incomplete, and lacks contextual richness? This question guided\nour participation in the \\textit{2025 Competition on Electric Energy\nConsumption Forecast Adopting Multi-criteria Performance Metrics}, which\nchallenged teams to predict next-day power demand using real-world\nhigh-frequency data. We proposed a robust yet lightweight Deep Learning (DL)\npipeline combining hourly downsizing, dual-mode imputation (mean and polynomial\nregression), and comprehensive normalization, ultimately selecting Standard\nScaling for optimal balance. The lightweight GRU-LSTM sequence-to-one model\nachieves an average RMSE of 601.9~W, MAE of 468.9~W, and 84.36\\% accuracy.\nDespite asymmetric inputs and imputed gaps, it generalized well, captured\nnonlinear demand patterns, and maintained low inference latency. Notably,\nspatiotemporal heatmap analysis reveals a strong alignment between temperature\ntrends and predicted consumption, further reinforcing the model's reliability.\nThese results demonstrate that targeted preprocessing paired with compact\nrecurrent architectures can still enable fast, accurate, and deployment-ready\nenergy forecasting in real-world conditions.", "AI": {"tldr": "A robust DL pipeline for short-term energy forecasting using GRU-LSTM model achieves accurate predictions despite noisy sensor data, with 84.36% accuracy and low inference latency.", "motivation": "To address the challenge of accurately forecasting short-term energy consumption when sensor data is noisy, incomplete, and lacks contextual richness, particularly for real-world high-frequency data in energy competitions.", "method": "Proposed a lightweight DL pipeline combining hourly downsizing, dual-mode imputation (mean and polynomial regression), comprehensive normalization with Standard Scaling, and a GRU-LSTM sequence-to-one model.", "result": "Achieved average RMSE of 601.9W, MAE of 468.9W, and 84.36% accuracy. The model generalized well, captured nonlinear demand patterns, and maintained low inference latency. Spatiotemporal analysis showed strong alignment between temperature trends and predicted consumption.", "conclusion": "Targeted preprocessing paired with compact recurrent architectures enables fast, accurate, and deployment-ready energy forecasting in real-world conditions, demonstrating the effectiveness of the proposed approach despite data limitations."}}
{"id": "2510.17299", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17299", "abs": "https://arxiv.org/abs/2510.17299", "authors": ["Siran Dai", "Qianqian Xu", "Peisong Wen", "Yang Liu", "Qingming Huang"], "title": "Exploring Structural Degradation in Dense Representations for Self-supervised Learning", "comment": "Accepted by NeurIPS 2025", "summary": "In this work, we observe a counterintuitive phenomenon in self-supervised\nlearning (SSL): longer training may impair the performance of dense prediction\ntasks (e.g., semantic segmentation). We refer to this phenomenon as\nSelf-supervised Dense Degradation (SDD) and demonstrate its consistent presence\nacross sixteen state-of-the-art SSL methods with various losses, architectures,\nand datasets. When the model performs suboptimally on dense tasks at the end of\ntraining, measuring the performance during training becomes essential. However,\nevaluating dense performance effectively without annotations remains an open\nchallenge. To tackle this issue, we introduce a Dense representation Structure\nEstimator (DSE), composed of a class-relevance measure and an effective\ndimensionality measure. The proposed DSE is both theoretically grounded and\nempirically validated to be closely correlated with the downstream performance.\nBased on this metric, we introduce a straightforward yet effective model\nselection strategy and a DSE-based regularization method. Experiments on\nsixteen SSL methods across four benchmarks confirm that model selection\nimproves mIoU by $3.0\\%$ on average with negligible computational cost.\nAdditionally, DSE regularization consistently mitigates the effects of dense\ndegradation. Code is available at\nhttps://github.com/EldercatSAM/SSL-Degradation.", "AI": {"tldr": "Longer self-supervised learning training can degrade dense prediction performance (Self-supervised Dense Degradation). The paper introduces Dense representation Structure Estimator (DSE) to measure dense performance without annotations and provides model selection and regularization methods to mitigate degradation.", "motivation": "To address the counterintuitive phenomenon where longer self-supervised training impairs dense prediction tasks like semantic segmentation, and to solve the challenge of evaluating dense performance without annotations.", "method": "Proposes Dense representation Structure Estimator (DSE) with class-relevance and effective dimensionality measures. Uses DSE for model selection strategy and regularization method to prevent dense degradation.", "result": "Experiments on 16 SSL methods across 4 benchmarks show model selection improves mIoU by 3.0% on average with negligible cost. DSE regularization consistently mitigates dense degradation effects.", "conclusion": "DSE provides an effective way to measure and improve dense prediction performance in self-supervised learning, addressing the SDD phenomenon through practical model selection and regularization techniques."}}
{"id": "2510.16914", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.16914", "abs": "https://arxiv.org/abs/2510.16914", "authors": ["Hongwei Yan", "Guanglong Sun", "Zhiqi Kang", "Yi Zhong", "Liyuan Wang"], "title": "Domain Generalizable Continual Learning", "comment": "25 pages", "summary": "To adapt effectively to dynamic real-world environments, intelligent systems\nmust continually acquire new skills while generalizing them to diverse, unseen\nscenarios. Here, we introduce a novel and realistic setting named domain\ngeneralizable continual learning (DGCL): a model learns sequential tasks with\neach involving a single domain, aiming to perform well across all encountered\ntasks and domains. This setting poses unique challenges in acquiring,\nretaining, and leveraging both semantic- and domain-relevant information for\nrobust generalization. Although state-of-the-art continual learning (CL)\nmethods have employed pre-trained models (PTMs) to enhance task-specific\ngeneralization, they typically assume identical training and testing domains\nfor each task and therefore perform poorly in DGCL. To this end, we propose\nadaptive Domain Transformation (DoT), an innovative PTMs-based approach\ntailored to DGCL. Inspired by the distributed-plus-hub theory of the human\nbrain, DoT disentangles semantic- and domain-relevant information in\nrepresentation learning, and adaptively transforms task representations across\nvarious domains for output alignment, ensuring balanced and generalized\npredictions. DoT serves as a plug-in strategy that greatly facilitates\nstate-of-the-art CL baselines under both full parameter tuning and\nparameter-efficient tuning paradigms in DGCL, validated by extensive\nexperiments. Also, DoT is shown to accumulate domain-generalizable knowledge\nfrom DGCL, and ensure resource efficiency with a lightweight implementation.", "AI": {"tldr": "The paper introduces Domain Generalizable Continual Learning (DGCL), a setting where models learn sequential tasks from single domains and must generalize across all domains. It proposes DoT, a method that disentangles semantic and domain information using brain-inspired principles to enable robust generalization.", "motivation": "To address the challenge of continual learning in dynamic real-world environments where models must acquire new skills while generalizing to unseen domains, overcoming limitations of current CL methods that assume identical training and testing domains.", "method": "Proposes adaptive Domain Transformation (DoT), a plug-in strategy based on pre-trained models that disentangles semantic- and domain-relevant information using distributed-plus-hub brain theory principles. It adaptively transforms task representations across domains for output alignment.", "result": "DoT significantly improves state-of-the-art CL baselines in DGCL settings under both full parameter tuning and parameter-efficient tuning paradigms. It accumulates domain-generalizable knowledge and ensures resource efficiency with lightweight implementation.", "conclusion": "DoT effectively addresses the DGCL challenge by enabling balanced and generalized predictions across domains, serving as a practical plug-in solution that enhances existing CL methods while maintaining efficiency."}}
{"id": "2510.17305", "categories": ["cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2510.17305", "abs": "https://arxiv.org/abs/2510.17305", "authors": ["ZhaoYang Han", "Qihan Lin", "Hao Liang", "Bowen Chen", "Zhou Liu", "Wentao Zhang"], "title": "LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding", "comment": "Submitted to ARR Rolling Review", "summary": "We introduce \\textbf{LongInsightBench}, the first benchmark designed to\nassess models' ability to understand long videos, with a focus on human\nlanguage, viewpoints, actions, and other contextual elements, while integrating\n\\textbf{visual, audio, and text} modalities. Our benchmark excels in three key\nareas: \\textbf{a) Long-Duration, Information-Dense Videos:} We carefully select\napproximately 1,000 videos from open-source datasets FineVideo based on\nduration limit and the information density of both visual and audio modalities,\nfocusing on content like lectures, interviews, and vlogs, which contain rich\nlanguage elements. \\textbf{b) Diverse and Challenging Task Scenarios:} We have\ndesigned six challenging task scenarios, including both Intra-Event and\nInter-Event Tasks. \\textbf{c) Rigorous and Comprehensive Quality Assurance\nPipelines:} We have developed a three-step, semi-automated data quality\nassurance pipeline to ensure the difficulty and validity of the synthesized\nquestions and answer options. Based on LongInsightBench, we designed a series\nof experiments. Experimental results shows that Omni-modal models(OLMs) still\nface challenge in tasks requiring precise temporal localization (T-Loc) and\nlong-range causal inference (CE-Caus). Extended experiments reveal the\ninformation loss and processing bias in multi-modal fusion of OLMs. Our dataset\nand code is available at\nhttps://anonymous.4open.science/r/LongInsightBench-910F/.", "AI": {"tldr": "LongInsightBench is the first benchmark for evaluating long video understanding across visual, audio, and text modalities, focusing on human language, viewpoints, and actions.", "motivation": "To address the lack of benchmarks for assessing models' ability to understand long videos with rich contextual elements across multiple modalities.", "method": "Created a benchmark with 1,000 long-duration, information-dense videos from FineVideo dataset, featuring six challenging task scenarios and a three-step semi-automated quality assurance pipeline.", "result": "Omni-modal models struggle with precise temporal localization and long-range causal inference tasks, and experiments reveal information loss and processing bias in multi-modal fusion.", "conclusion": "Current omni-modal models face significant challenges in long video understanding, particularly in temporal localization and causal reasoning, highlighting the need for improved multi-modal fusion techniques."}}
{"id": "2510.16916", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16916", "abs": "https://arxiv.org/abs/2510.16916", "authors": ["Dong Li", "Xujiang Zhao", "Linlin Yu", "Yanchi Liu", "Wei Cheng", "Zhengzhang Chen", "Zhong Chen", "Feng Chen", "Chen Zhao", "Haifeng Chen"], "title": "SolverLLM: Leveraging Test-Time Scaling for Optimization Problem via LLM-Guided Search", "comment": "NeurIPS 2025", "summary": "Large Language Models (LLMs) offer promising capabilities for tackling\ncomplex reasoning tasks, including optimization problems. However, existing\nmethods either rely on prompt engineering, which leads to poor generalization\nacross problem types, or require costly supervised training. We introduce\nSolverLLM, a training-free framework that leverages test-time scaling to solve\ndiverse optimization problems. Rather than solving directly, SolverLLM\ngenerates mathematical formulations and translates them into solver-ready code,\nguided by a novel Monte Carlo Tree Search (MCTS) strategy. To enhance the\nsearch process, we modify classical MCTS with (1) dynamic expansion for\nadaptive formulation generation, (2) prompt backpropagation to guide\nexploration via outcome-driven feedback, and (3) uncertainty backpropagation to\nincorporate reward reliability into decision-making. Experiments on six\nstandard benchmark datasets demonstrate that SolverLLM outperforms both\nprompt-based and learning-based baselines, achieving strong generalization\nwithout additional training.", "AI": {"tldr": "SolverLLM is a training-free framework that uses test-time scaling and Monte Carlo Tree Search to solve optimization problems by generating mathematical formulations and solver code, achieving strong generalization across diverse problem types.", "motivation": "Existing methods for using LLMs in optimization either rely on prompt engineering (poor generalization) or supervised training (costly). There's a need for a training-free approach that generalizes well across different optimization problems.", "method": "SolverLLM generates mathematical formulations and translates them into solver-ready code using a modified Monte Carlo Tree Search strategy with dynamic expansion, prompt backpropagation, and uncertainty backpropagation to guide the search process.", "result": "Experiments on six benchmark datasets show SolverLLM outperforms both prompt-based and learning-based baselines, achieving strong generalization without additional training.", "conclusion": "SolverLLM provides an effective training-free framework for solving diverse optimization problems through test-time scaling and enhanced MCTS, demonstrating superior performance and generalization capabilities."}}
{"id": "2510.17318", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17318", "abs": "https://arxiv.org/abs/2510.17318", "authors": ["Sangyoon Bae", "Jiook Cha"], "title": "CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference", "comment": null, "summary": "We introduce CausalMamba, a scalable framework that addresses fundamental\nlimitations in fMRI-based causal inference: the ill-posed nature of inferring\nneural causality from hemodynamically distorted BOLD signals and the\ncomputational intractability of existing methods like Dynamic Causal Modeling\n(DCM). Our approach decomposes this complex inverse problem into two tractable\nstages: BOLD deconvolution to recover latent neural activity, followed by\ncausal graph inference using a novel Conditional Mamba architecture. On\nsimulated data, CausalMamba achieves 37% higher accuracy than DCM. Critically,\nwhen applied to real task fMRI data, our method recovers well-established\nneural pathways with 88% fidelity, whereas conventional approaches fail to\nidentify these canonical circuits in over 99% of subjects. Furthermore, our\nnetwork analysis of working memory data reveals that the brain strategically\nshifts its primary causal hub-recruiting executive or salience networks\ndepending on the stimulus-a sophisticated reconfiguration that remains\nundetected by traditional methods. This work provides neuroscientists with a\npractical tool for large-scale causal inference that captures both fundamental\ncircuit motifs and flexible network dynamics underlying cognitive function.", "AI": {"tldr": "CausalMamba is a scalable framework that overcomes limitations in fMRI-based causal inference by decomposing the problem into BOLD deconvolution and causal graph inference using a Conditional Mamba architecture.", "motivation": "Address fundamental limitations in fMRI-based causal inference: the ill-posed nature of inferring neural causality from hemodynamically distorted BOLD signals and computational intractability of existing methods like Dynamic Causal Modeling (DCM).", "method": "Decomposes the complex inverse problem into two tractable stages: BOLD deconvolution to recover latent neural activity, followed by causal graph inference using a novel Conditional Mamba architecture.", "result": "On simulated data: 37% higher accuracy than DCM. On real task fMRI data: recovers well-established neural pathways with 88% fidelity (vs conventional approaches failing in 99% of subjects). Network analysis reveals brain strategically shifts causal hubs between executive and salience networks depending on stimulus.", "conclusion": "Provides neuroscientists with a practical tool for large-scale causal inference that captures both fundamental circuit motifs and flexible network dynamics underlying cognitive function."}}
{"id": "2510.16927", "categories": ["cs.LG", "I.2.6; I.2.7; G.1.3"], "pdf": "https://arxiv.org/pdf/2510.16927", "abs": "https://arxiv.org/abs/2510.16927", "authors": ["Egor Petrov", "Nikita Kiselev", "Vladislav Meshkov", "Andrey Grabovoy"], "title": "Closing the Curvature Gap: Full Transformer Hessians and Their Implications for Scaling Laws", "comment": "38 pages, 12 figures. Submitted to ICLR 2026", "summary": "The lack of theoretical results for Layer Normalization and feedforward\nHessians has left a gap in the study of Transformer optimization landscapes. We\naddress this by deriving explicit second-order expressions for these\ncomponents, thereby completing the Hessian characterization of full Transformer\nblocks. Our results generalize prior self-attention analyses and yield\nestimations for the role of each sublayer in curvature propagation. We\ndemonstrate how these Hessian structures inform both convergence dynamics and\nthe empirical scaling laws governing large-model performance. Further, we\npropose a Taylor-expansion-based framework for analyzing loss differences to\nquantify convergence trajectories. By extending Hessian theory to the full\nTransformer architecture, this work establishes a new foundation for\ntheoretical and empirical investigations of optimization in large-scale deep\nlearning.", "AI": {"tldr": "This paper completes the Hessian characterization of full Transformer blocks by deriving explicit second-order expressions for Layer Normalization and feedforward components, generalizing prior self-attention analyses.", "motivation": "The lack of theoretical results for Layer Normalization and feedforward Hessians created a gap in understanding Transformer optimization landscapes.", "method": "Derived explicit second-order expressions for Layer Normalization and feedforward components, and proposed a Taylor-expansion-based framework for analyzing loss differences.", "result": "Established complete Hessian characterization of full Transformer blocks, enabling estimations of each sublayer's role in curvature propagation and informing convergence dynamics.", "conclusion": "This work extends Hessian theory to the full Transformer architecture, establishing a foundation for theoretical and empirical investigations of optimization in large-scale deep learning."}}
{"id": "2510.17322", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17322", "abs": "https://arxiv.org/abs/2510.17322", "authors": ["Wei Zhang", "Zhanhao Hu", "Xiao Li", "Xiaopei Zhu", "Xiaolin Hu"], "title": "A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World", "comment": "13 pages, 8 figures", "summary": "In recent years, adversarial attacks against deep learning-based object\ndetectors in the physical world have attracted much attention. To defend\nagainst these attacks, researchers have proposed various defense methods\nagainst adversarial patches, a typical form of physically-realizable attack.\nHowever, our experiments showed that simply enlarging the patch size could make\nthese defense methods fail. Motivated by this, we evaluated various defense\nmethods against adversarial clothes which have large coverage over the human\nbody. Adversarial clothes provide a good test case for adversarial defense\nagainst patch-based attacks because they not only have large sizes but also\nlook more natural than a large patch on humans. Experiments show that all the\ndefense methods had poor performance against adversarial clothes in both the\ndigital world and the physical world. In addition, we crafted a single set of\nclothes that broke multiple defense methods on Faster R-CNN. The set achieved\nan Attack Success Rate (ASR) of 96.06% against the undefended detector and over\n64.84% ASRs against nine defended models in the physical world, unveiling the\ncommon vulnerability of existing adversarial defense methods against\nadversarial clothes. Code is available at:\nhttps://github.com/weiz0823/adv-clothes-break-multiple-defenses.", "AI": {"tldr": "Adversarial clothes with large coverage can bypass existing defense methods against adversarial patches, revealing vulnerabilities in current adversarial defense approaches.", "motivation": "To evaluate the effectiveness of existing defense methods against adversarial patches when faced with larger, more natural adversarial clothing attacks that cover significant portions of the human body.", "method": "Conducted experiments using adversarial clothes as test cases, evaluating various defense methods in both digital and physical worlds, and crafted a single set of clothes to test against multiple defense methods on Faster R-CNN.", "result": "All defense methods performed poorly against adversarial clothes. A single set of clothes achieved 96.06% ASR against undefended detectors and over 64.84% ASR against nine defended models in physical world.", "conclusion": "Existing adversarial defense methods have common vulnerabilities against adversarial clothes, highlighting the need for more robust defense strategies against large-scale physical attacks."}}
{"id": "2510.17330", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17330", "abs": "https://arxiv.org/abs/2510.17330", "authors": ["Gyuhwan Park", "Kihyun Na", "Injung Kim"], "title": "CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration", "comment": "11 pages, 6 figures", "summary": "The significance of license plate image restoration goes beyond the\npreprocessing stage of License Plate Recognition (LPR) systems, as it also\nserves various purposes, including increasing evidential value, enhancing the\nclarity of visual interface, and facilitating further utilization of license\nplate images. We propose a novel diffusion-based framework with character-level\nguidance, CharDiff, which effectively restores and recognizes severely degraded\nlicense plate images captured under realistic conditions. CharDiff leverages\nfine-grained character-level priors extracted through external segmentation and\nOptical Character Recognition (OCR) modules tailored for low-quality license\nplate images. For precise and focused guidance, CharDiff incorporates a novel\nCharacter-guided Attention through Region-wise Masking (CHARM) module, which\nensures that each character's guidance is restricted to its own region, thereby\navoiding interference with other regions. In experiments, CharDiff\nsignificantly outperformed the baseline restoration models in both restoration\nquality and recognition accuracy, achieving a 28% relative reduction in CER on\nthe Roboflow-LP dataset, compared to the best-performing baseline model. These\nresults indicate that the structured character-guided conditioning effectively\nenhances the robustness of diffusion-based license plate restoration and\nrecognition in practical deployment scenarios.", "AI": {"tldr": "CharDiff is a diffusion-based framework that uses character-level guidance to restore and recognize severely degraded license plate images, achieving superior performance over baseline models.", "motivation": "License plate image restoration is important not just for LPR systems but also for increasing evidential value, enhancing visual clarity, and facilitating further utilization of license plate images.", "method": "Uses diffusion-based framework with character-level guidance, leveraging fine-grained character priors from segmentation and OCR modules. Incorporates CHARM module for precise region-wise character guidance without interference.", "result": "Significantly outperformed baseline restoration models, achieving 28% relative reduction in CER on Roboflow-LP dataset compared to best-performing baseline.", "conclusion": "Structured character-guided conditioning effectively enhances robustness of diffusion-based license plate restoration and recognition in practical deployment scenarios."}}
{"id": "2510.16943", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16943", "abs": "https://arxiv.org/abs/2510.16943", "authors": ["Dania Refai", "Moataz Ahmed"], "title": "Peering Inside the Black Box: Uncovering LLM Errors in Optimization Modelling through Component-Level Evaluation", "comment": null, "summary": "Large language models (LLMs) are increasingly used to convert natural\nlanguage descriptions into mathematical optimization formulations. Current\nevaluations often treat formulations as a whole, relying on coarse metrics like\nsolution accuracy or runtime, which obscure structural or numerical errors. In\nthis study, we present a comprehensive, component-level evaluation framework\nfor LLM-generated formulations. Beyond the conventional optimality gap, our\nframework introduces metrics such as precision and recall for decision\nvariables and constraints, constraint and objective root mean squared error\n(RMSE), and efficiency indicators based on token usage and latency. We evaluate\nGPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of\nvarying complexity under six prompting strategies. Results show that GPT-5\nconsistently outperforms other models, with chain-of-thought, self-consistency,\nand modular prompting proving most effective. Analysis indicates that solver\nperformance depends primarily on high constraint recall and low constraint\nRMSE, which together ensure structural correctness and solution reliability.\nConstraint precision and decision variable metrics play secondary roles, while\nconcise outputs enhance computational efficiency. These findings highlight\nthree principles for NLP-to-optimization modeling: (i) Complete constraint\ncoverage prevents violations, (ii) minimizing constraint RMSE ensures\nsolver-level accuracy, and (iii) concise outputs improve computational\nefficiency. The proposed framework establishes a foundation for fine-grained,\ndiagnostic evaluation of LLMs in optimization modeling.", "AI": {"tldr": "A comprehensive component-level evaluation framework for LLM-generated optimization formulations that goes beyond conventional metrics to include precision/recall for variables/constraints, constraint/objective RMSE, and efficiency indicators.", "motivation": "Current evaluations treat formulations as a whole using coarse metrics like solution accuracy or runtime, which obscure structural or numerical errors in LLM-generated optimization formulations.", "method": "Proposed a component-level evaluation framework with metrics including precision/recall for decision variables and constraints, constraint/objective RMSE, and efficiency indicators. Evaluated GPT-5, LLaMA 3.1 Instruct, and DeepSeek Math across optimization problems of varying complexity under six prompting strategies.", "result": "GPT-5 consistently outperformed other models, with chain-of-thought, self-consistency, and modular prompting proving most effective. Solver performance depends primarily on high constraint recall and low constraint RMSE. Constraint precision and decision variable metrics play secondary roles, while concise outputs enhance computational efficiency.", "conclusion": "Three key principles for NLP-to-optimization modeling: (i) Complete constraint coverage prevents violations, (ii) minimizing constraint RMSE ensures solver-level accuracy, and (iii) concise outputs improve computational efficiency. The framework establishes foundation for fine-grained diagnostic evaluation of LLMs in optimization modeling."}}
{"id": "2510.17332", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17332", "abs": "https://arxiv.org/abs/2510.17332", "authors": ["Zhaoran Zhao", "Xinli Yue", "Jianhui Sun", "Yuhao Xie", "Tao Shao", "Liangchao Yao", "Fan Xia", "Yuetang Deng"], "title": "iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA", "comment": "Accepted to ICCV 2025 Workshop", "summary": "Image Quality Assessment (IQA) has progressed from scalar quality prediction\nto more interpretable, human-aligned evaluation paradigms. In this work, we\naddress the emerging challenge of detailed and explainable IQA by proposing\niDETEX-a unified multimodal large language model (MLLM) capable of\nsimultaneously performing three key tasks: quality grounding, perception, and\ndescription. To facilitate efficient and generalizable training across these\nheterogeneous subtasks, we design a suite of task-specific offline augmentation\nmodules and a data mixing strategy. These are further complemented by online\nenhancement strategies to fully exploit multi-sourced supervision. We validate\nour approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves\nstate-of-the-art performance across all subtasks. Our model ranks first in the\nICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its\neffectiveness and robustness in delivering accurate and interpretable quality\nassessments.", "AI": {"tldr": "iDETEX is a unified multimodal LLM that performs quality grounding, perception, and description for detailed and explainable image quality assessment, achieving state-of-the-art results on ViDA-UGC benchmark and winning ICCV MIPI 2025 challenge.", "motivation": "To address the emerging challenge of detailed and explainable Image Quality Assessment (IQA) beyond simple scalar quality prediction, enabling more human-aligned evaluation paradigms.", "method": "Proposed iDETEX - a unified multimodal large language model with task-specific offline augmentation modules, data mixing strategy, and online enhancement strategies to exploit multi-sourced supervision across three key tasks: quality grounding, perception, and description.", "result": "Achieved state-of-the-art performance on ViDA-UGC benchmark across all subtasks and ranked first in ICCV MIPI 2025 Detailed Image Quality Assessment Challenge.", "conclusion": "iDETEX demonstrates effectiveness and robustness in delivering accurate and interpretable quality assessments through unified multimodal approach."}}
{"id": "2510.16958", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.16958", "abs": "https://arxiv.org/abs/2510.16958", "authors": ["Ganglin Tian", "Anastase Alexandre Charantonis", "Camille Le Coz", "Alexis Tantet", "Riwal Plougonven"], "title": "Quantile Regression, Variational Autoencoders, and Diffusion Models for Uncertainty Quantification: A Spatial Analysis of Sub-seasonal Wind Speed Prediction", "comment": "This Work has been submitted to Monthly Weather Review. Copyright in\n  this Work may be transferred without further notice", "summary": "This study aims to improve the spatial representation of uncertainties when\nregressing surface wind speeds from large-scale atmospheric predictors for\nsub-seasonal forecasting. Sub-seasonal forecasting often relies on large-scale\natmospheric predictors such as 500 hPa geopotential height (Z500), which\nexhibit higher predictability than surface variables and can be downscaled to\nobtain more localised information. Previous work by Tian et al. (2024)\ndemonstrated that stochastic perturbations based on model residuals can improve\nensemble dispersion representation in statistical downscaling frameworks, but\nthis method fails to represent spatial correlations and physical consistency\nadequately. More sophisticated approaches are needed to capture the complex\nrelationships between large-scale predictors and local-scale predictands while\nmaintaining physical consistency. Probabilistic deep learning models offer\npromising solutions for capturing complex spatial dependencies. This study\nevaluates three probabilistic methods with distinct uncertainty quantification\nmechanisms: Quantile Regression Neural Network that directly models\ndistribution quantiles, Variational Autoencoders that leverage latent space\nsampling, and Diffusion Models that utilise iterative denoising. These models\nare trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts\nto regress probabilistic wind speed ensembles. Our results show that\nprobabilistic downscaling approaches provide more realistic spatial uncertainty\nrepresentations compared to simpler stochastic methods, with each probabilistic\nmodel offering different strengths in terms of ensemble dispersion,\ndeterministic skill, and physical consistency. These findings establish\nprobabilistic downscaling as an effective enhancement to operational\nsub-seasonal wind forecasts for renewable energy planning and risk assessment.", "AI": {"tldr": "Probabilistic deep learning methods improve spatial uncertainty representation in sub-seasonal wind speed forecasting compared to simpler stochastic approaches.", "motivation": "To enhance spatial representation of uncertainties when downscaling surface wind speeds from large-scale atmospheric predictors for sub-seasonal forecasting, addressing limitations of previous stochastic methods that fail to capture spatial correlations and physical consistency.", "method": "Evaluated three probabilistic deep learning methods: Quantile Regression Neural Network (direct quantile modeling), Variational Autoencoders (latent space sampling), and Diffusion Models (iterative denoising), trained on ERA5 reanalysis data and applied to ECMWF sub-seasonal hindcasts.", "result": "Probabilistic downscaling approaches provide more realistic spatial uncertainty representations compared to simpler stochastic methods, with each model offering different strengths in ensemble dispersion, deterministic skill, and physical consistency.", "conclusion": "Probabilistic downscaling is established as an effective enhancement to operational sub-seasonal wind forecasts for renewable energy planning and risk assessment."}}
{"id": "2510.17338", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17338", "abs": "https://arxiv.org/abs/2510.17338", "authors": ["Jiahao Huo", "Mufhumudzi Muthivhi", "Terence L. van Zyl", "Fredrik Gustafsson"], "title": "Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition", "comment": null, "summary": "Current state-of-the-art Wildlife classification models are trained under the\nclosed world setting. When exposed to unknown classes, they remain\noverconfident in their predictions. Open-set Recognition (OSR) aims to classify\nknown classes while rejecting unknown samples. Several OSR methods have been\nproposed to model the closed-set distribution by observing the feature, logit,\nor softmax probability space. A significant drawback of many existing\napproaches is the requirement to retrain the pre-trained classification model\nwith the OSR-specific strategy. This study contributes a post-processing OSR\nmethod that measures the agreement between the models' features and predicted\nlogits. We propose a probability distribution based on an input's distance to\nits Nearest Class Mean (NCM). The NCM-based distribution is then compared with\nthe softmax probabilities from the logit space to measure agreement between the\nNCM and the classification head. Our proposed strategy ranks within the top\nthree on two evaluated datasets, showing consistent performance across the two\ndatasets. In contrast, current state-of-the-art methods excel on a single\ndataset. We achieve an AUROC of 93.41 and 95.35 for African and Swedish\nanimals. The code can be found\nhttps://github.com/Applied-Representation-Learning-Lab/OSR.", "AI": {"tldr": "Proposes a post-processing open-set recognition method that measures agreement between feature space (NCM-based distribution) and logit space (softmax probabilities) to identify unknown classes without retraining.", "motivation": "Current wildlife classification models are overconfident on unknown classes, and existing OSR methods require retraining pre-trained models, which is inefficient.", "method": "Uses Nearest Class Mean (NCM) to create probability distribution from feature space, then compares with softmax probabilities from logit space to measure agreement between feature and classification head.", "result": "Achieves AUROC of 93.41 and 95.35 on African and Swedish animal datasets, ranking top three consistently across datasets while state-of-the-art methods only excel on single datasets.", "conclusion": "The proposed post-processing OSR method effectively identifies unknown classes without retraining, showing consistent performance across multiple datasets."}}
{"id": "2510.16968", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.16968", "abs": "https://arxiv.org/abs/2510.16968", "authors": ["Pingzhi Li", "Morris Yu-Chao Huang", "Zhen Tan", "Qingquan Song", "Jie Peng", "Kai Zou", "Yu Cheng", "Kaidi Xu", "Tianlong Chen"], "title": "Leave It to the Experts: Detecting Knowledge Distillation via MoE Expert Signatures", "comment": "Code is at https://github.com/unites-lab/shadow-moe", "summary": "Knowledge Distillation (KD) accelerates training of large language models\n(LLMs) but poses intellectual property protection and LLM diversity risks.\nExisting KD detection methods based on self-identity or output similarity can\nbe easily evaded through prompt engineering. We present a KD detection\nframework effective in both white-box and black-box settings by exploiting an\noverlooked signal: the transfer of MoE \"structural habits\", especially internal\nrouting patterns. Our approach analyzes how different experts specialize and\ncollaborate across various inputs, creating distinctive fingerprints that\npersist through the distillation process. To extend beyond the white-box setup\nand MoE architectures, we further propose Shadow-MoE, a black-box method that\nconstructs proxy MoE representations via auxiliary distillation to compare\nthese patterns between arbitrary model pairs. We establish a comprehensive,\nreproducible benchmark that offers diverse distilled checkpoints and an\nextensible framework to facilitate future research. Extensive experiments\ndemonstrate >94% detection accuracy across various scenarios and strong\nrobustness to prompt-based evasion, outperforming existing baselines while\nhighlighting the structural habits transfer in LLMs.", "AI": {"tldr": "A novel framework for detecting knowledge distillation in LLMs by analyzing MoE structural habits and routing patterns, achieving >94% accuracy and robustness against prompt-based evasion.", "motivation": "Existing KD detection methods are vulnerable to prompt engineering evasion, posing risks to intellectual property protection and LLM diversity.", "method": "Uses transfer of MoE structural habits and routing patterns; proposes Shadow-MoE for black-box detection via proxy MoE representations through auxiliary distillation.", "result": "Achieves >94% detection accuracy across various scenarios with strong robustness to prompt-based evasion, outperforming existing baselines.", "conclusion": "Demonstrates effective KD detection through structural habits transfer analysis, providing a comprehensive benchmark for future research."}}
{"id": "2510.17347", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17347", "abs": "https://arxiv.org/abs/2510.17347", "authors": ["Jingqian Wu", "Shengpeng Xu", "Yunbo Jia", "Edmund Y. Lam"], "title": "Exploring The Missing Semantics In Event Modality", "comment": null, "summary": "Event cameras offer distinct advantages such as low latency, high dynamic\nrange, and efficient motion capture. However, event-to-video reconstruction\n(E2V), a fundamental event-based vision task, remains challenging, particularly\nfor reconstructing and recovering semantic information. This is primarily due\nto the nature of the event camera, as it only captures intensity changes,\nignoring static objects and backgrounds, resulting in a lack of semantic\ninformation in captured event modality. Further, semantic information plays a\ncrucial role in video and frame reconstruction, yet is often overlooked by\nexisting E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V\nframework that explores the missing visual semantic knowledge in event modality\nand leverages it to enhance event-to-video reconstruction. Specifically,\nSemantic-E2VID introduces a cross-modal feature alignment (CFA) module to\ntransfer the robust visual semantics from a frame-based vision foundation\nmodel, the Segment Anything Model (SAM), to the event encoder, while aligning\nthe high-level features from distinct modalities. To better utilize the learned\nsemantic feature, we further propose a semantic-aware feature fusion (SFF)\nblock to integrate learned semantics in frame modality to form event\nrepresentations with rich semantics that can be decoded by the event decoder.\nFurther, to facilitate the reconstruction of semantic information, we propose a\nnovel Semantic Perceptual E2V Supervision that helps the model to reconstruct\nsemantic details by leveraging SAM-generated categorical labels. Extensive\nexperiments demonstrate that Semantic-E2VID significantly enhances frame\nquality, outperforming state-of-the-art E2V methods across multiple benchmarks.\nThe sample code is included in the supplementary material.", "AI": {"tldr": "Semantic-E2VID is an event-to-video reconstruction framework that incorporates semantic information from vision foundation models to enhance video reconstruction quality by addressing the semantic gap in event data.", "motivation": "Event cameras capture only intensity changes, missing static objects and semantic information, which limits the quality of event-to-video reconstruction. Existing methods overlook semantic information that is crucial for high-quality video reconstruction.", "method": "Proposes cross-modal feature alignment to transfer semantic knowledge from SAM to event encoder, semantic-aware feature fusion to integrate semantics into event representations, and semantic perceptual supervision using SAM-generated labels.", "result": "Significantly enhances frame quality and outperforms state-of-the-art E2V methods across multiple benchmarks.", "conclusion": "Incorporating semantic information from vision foundation models effectively bridges the semantic gap in event-to-video reconstruction, leading to superior reconstruction quality."}}
{"id": "2510.16974", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.16974", "abs": "https://arxiv.org/abs/2510.16974", "authors": ["Shurong Lin", "Aleksandra Slavkovi\u0107", "Deekshith Reddy Bhoomireddy"], "title": "Differentially Private Linear Regression and Synthetic Data Generation with Statistical Guarantees", "comment": null, "summary": "In social sciences, small- to medium-scale datasets are common and linear\nregression (LR) is canonical. In privacy-aware settings, much work has focused\non differentially private (DP) LR, but mostly on point estimation with limited\nattention to uncertainty quantification. Meanwhile, synthetic data generation\n(SDG) is increasingly important for reproducibility studies, yet current DP LR\nmethods do not readily support it. Mainstream SDG approaches are either\ntailored to discretized data, making them less suitable for continuous\nregression, or rely on deep models that require large datasets, limiting their\nuse for the smaller, continuous data typical in social science. We propose a\nmethod for LR with valid inference under Gaussian DP: a DP bias-corrected\nestimator with asymptotic confidence intervals (CIs) and a general SDG\nprocedure in which regression on the synthetic data matches our DP regression.\nOur binning-aggregation strategy is effective in small- to moderate-dimensional\nsettings. Experiments show our method (1) improves accuracy over existing\nmethods, (2) provides valid CIs, and (3) produces more reliable synthetic data\nfor downstream ML tasks than current DP SDGs.", "AI": {"tldr": "Proposes differentially private linear regression method with valid inference and synthetic data generation for small-to-medium social science datasets, addressing limitations of existing DP methods.", "motivation": "Social science datasets are often small-to-medium scale with continuous data, but current DP linear regression methods focus on point estimation without uncertainty quantification and don't support synthetic data generation well. Mainstream synthetic data approaches are unsuitable for continuous regression data or require large datasets.", "method": "Uses DP bias-corrected estimator with asymptotic confidence intervals under Gaussian DP, plus a general synthetic data generation procedure where regression on synthetic data matches DP regression. Employs binning-aggregation strategy for small-to-moderate dimensional settings.", "result": "Method improves accuracy over existing approaches, provides valid confidence intervals, and produces more reliable synthetic data for downstream machine learning tasks compared to current DP synthetic data generation methods.", "conclusion": "The proposed approach effectively addresses key limitations in differentially private linear regression for social science applications by providing valid inference and reliable synthetic data generation capabilities."}}
{"id": "2510.17363", "categories": ["cs.CV", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.17363", "abs": "https://arxiv.org/abs/2510.17363", "authors": ["U. V. B. L Udugama", "George Vosselman", "Francesco Nex"], "title": "M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception", "comment": "Accepted to the IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2025). 8 pages, 7 figures", "summary": "Deploying real-time spatial perception on edge devices requires efficient\nmulti-task models that leverage complementary task information while minimizing\ncomputational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel\nmulti-task learning framework designed for semantic segmentation and depth,\nedge, and surface normal estimation from a single monocular image. Unlike\nconventional approaches that rely on independent single-task models or shared\nencoder-decoder architectures, M2H introduces a Window-Based Cross-Task\nAttention Module that enables structured feature exchange while preserving\ntask-specific details, improving prediction consistency across tasks. Built on\na lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time\ndeployment and serves as the foundation for monocular spatial perception\nsystems supporting 3D scene graph construction in dynamic environments.\nComprehensive evaluations show that M2H outperforms state-of-the-art multi-task\nmodels on NYUDv2, surpasses single-task depth and semantic baselines on\nHypersim, and achieves superior performance on the Cityscapes dataset, all\nwhile maintaining computational efficiency on laptop hardware. Beyond\nbenchmarks, M2H is validated on real-world data, demonstrating its practicality\nin spatial perception tasks.", "AI": {"tldr": "M2H is a multi-task learning framework for semantic segmentation, depth, edge, and surface normal estimation from monocular images, featuring cross-task attention for efficient real-time deployment.", "motivation": "Need for efficient multi-task models that leverage complementary task information while minimizing computational overhead for real-time spatial perception on edge devices.", "method": "Uses Window-Based Cross-Task Attention Module for structured feature exchange while preserving task-specific details, built on lightweight ViT-based DINOv2 backbone.", "result": "Outperforms state-of-the-art multi-task models on NYUDv2, surpasses single-task baselines on Hypersim, achieves superior performance on Cityscapes while maintaining computational efficiency.", "conclusion": "M2H demonstrates practicality in real-world spatial perception tasks and serves as foundation for monocular spatial perception systems supporting 3D scene graph construction."}}
{"id": "2510.16980", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16980", "abs": "https://arxiv.org/abs/2510.16980", "authors": ["Kanghui Ning", "Zijie Pan", "Yushan Jiang", "Anderson Schneider", "Yuriy Nevmyvaka", "Dongjin Song"], "title": "Towards Interpretable and Trustworthy Time Series Reasoning: A BlueSky Vision", "comment": null, "summary": "Time series reasoning is emerging as the next frontier in temporal analysis,\naiming to move beyond pattern recognition towards explicit, interpretable, and\ntrustworthy inference. This paper presents a BlueSky vision built on two\ncomplementary directions. One builds robust foundations for time series\nreasoning, centered on comprehensive temporal understanding, structured\nmulti-step reasoning, and faithful evaluation frameworks. The other advances\nsystem-level reasoning, moving beyond language-only explanations by\nincorporating multi-agent collaboration, multi-modal context, and\nretrieval-augmented approaches. Together, these directions outline a flexible\nand extensible framework for advancing time series reasoning, aiming to deliver\ninterpretable and trustworthy temporal intelligence across diverse domains.", "AI": {"tldr": "This paper presents a vision for advancing time series reasoning beyond pattern recognition to explicit, interpretable inference through two complementary directions: robust foundations and system-level reasoning.", "motivation": "To move beyond simple pattern recognition in temporal analysis and develop explicit, interpretable, and trustworthy inference capabilities for time series data.", "method": "Proposes a two-pronged approach: 1) Building robust foundations focused on comprehensive temporal understanding, structured multi-step reasoning, and faithful evaluation frameworks; 2) Advancing system-level reasoning through multi-agent collaboration, multi-modal context integration, and retrieval-augmented approaches.", "result": "Outlines a flexible and extensible framework for advancing time series reasoning capabilities.", "conclusion": "The proposed framework aims to deliver interpretable and trustworthy temporal intelligence across diverse domains by combining foundational reasoning principles with system-level approaches."}}
{"id": "2510.17364", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17364", "abs": "https://arxiv.org/abs/2510.17364", "authors": ["Vaggelis Dorovatas", "Soroush Seifi", "Gunshi Gupta", "Rahaf Aljundi"], "title": "Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs", "comment": "NeurIPS 2025", "summary": "Video Large Language Models (Video-LLMs) excel at understanding videos\nin-context, provided they have full access to the video when answering queries.\nHowever, these models face challenges in streaming scenarios where hour-long\nvideos must be processed online, and questions need timely responses. In this\nwork, we propose a training-free approach compatible with standard Video-LLMs,\nleveraging three key concepts: 1) LLM-informed selection of visual tokens to\nidentify those that the LLM has attended to and contributed to its\nunderstanding of each short clip. Our attention-based selection allows us to\ndiscard up to ~95% of unimportant visual tokens with minimal performance loss;\n2) Recurrent processing of past selected tokens to generate temporally coherent\nunderstanding of each processed clip; 3) Caption-based question answering for\nlightweight and accurate responses. Our method achieves state-of-the-art\nperformance on streaming video benchmarks, striking a balance between\nefficiency and effectiveness.", "AI": {"tldr": "A training-free approach for Video-LLMs that enables efficient streaming video understanding by selecting important visual tokens, processing them recurrently, and using caption-based QA.", "motivation": "Video-LLMs struggle with streaming scenarios where hour-long videos need online processing and timely responses, requiring more efficient methods.", "method": "Uses three key concepts: 1) LLM-informed selection of attended visual tokens (discarding ~95% unimportant tokens), 2) Recurrent processing of past selected tokens for temporal coherence, 3) Caption-based question answering for lightweight responses.", "result": "Achieves state-of-the-art performance on streaming video benchmarks with minimal performance loss while maintaining high efficiency.", "conclusion": "The proposed training-free method effectively balances efficiency and effectiveness for streaming video understanding with Video-LLMs."}}
{"id": "2510.16981", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.16981", "abs": "https://arxiv.org/abs/2510.16981", "authors": ["Ahmed Khaled", "Kaan Ozkara", "Tao Yu", "Mingyi Hong", "Youngsuk Park"], "title": "MuonBP: Faster Muon via Block-Periodic Orthogonalization", "comment": null, "summary": "Gradient orthogonalization is a simple strategy that shows great utility in\nspeeding up gradient descent. The Muon optimizer (Jordan, Jin, et al., 2024)\ncombines gradient orthogonalization with first-order momentum and achieves\nsignificant improvement in data efficiency over Adam/AdamW (Loshchilov and\nHutter, 2019) for language model training. However, when using model\nparallelism, gradient orthogonalization introduces additional overhead compared\nto coordinate-wise optimizers (such as AdamW) due to additional gather and\nscatter operations on gradient matrix shards from different devices. This\nadditional communication can amount to a throughput hit of 5%-10% compared to\nAdam/AdamW. To remedy this, we propose Muon with Block-Periodic\nOrthogonalization (MuonBP), which applies orthogonalization independently to\nmatrix shards on each device and periodically performs full orthogonalization\nto maintain training stability at scale. We show how to adjust the learning\nrate from the baseline to MuonBP and give convergence guarantees for this\nalgorithm. Crucially, our theory dictates that we use two stepsizes: one for\nthe blockwise orthogonalization steps, and one for the full orthogonalization\nsteps. Our method is simple, requires minimal hyperparameter adjustments, and\nachieves competitive iteration complexity compared with baseline Muon while\nproviding per-iteration throughput comparable to coordinate-wise methods such\nas AdamW. When training an 8B model with eight-way tensor parallelism and ZeRO\noptimizer state sharding, MuonBP achieves 8% throughput increase compared to\nMuon with no degradation in performance.", "AI": {"tldr": "MuonBP improves gradient orthogonalization by applying block-wise orthogonalization locally on each device and periodically performing full orthogonalization, reducing communication overhead while maintaining training stability.", "motivation": "To address the communication overhead introduced by gradient orthogonalization in model parallelism, which causes 5%-10% throughput reduction compared to AdamW.", "method": "Proposes MuonBP with Block-Periodic Orthogonalization - applies orthogonalization independently to matrix shards on each device and periodically performs full orthogonalization, using two different learning rates for blockwise and full orthogonalization steps.", "result": "Achieves 8% throughput increase compared to baseline Muon with no performance degradation when training an 8B model with eight-way tensor parallelism and ZeRO optimizer state sharding.", "conclusion": "MuonBP provides competitive iteration complexity with baseline Muon while achieving per-iteration throughput comparable to coordinate-wise methods like AdamW, requiring minimal hyperparameter adjustments."}}
{"id": "2510.17372", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17372", "abs": "https://arxiv.org/abs/2510.17372", "authors": ["Pawe\u0142 Borsukiewicz", "Fadi Boutros", "Iyiola E. Olatunji", "Charles Beumier", "Wendk\u00fbuni C. Ouedraogo", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise", "comment": null, "summary": "The deployment of facial recognition systems has created an ethical dilemma:\nachieving high accuracy requires massive datasets of real faces collected\nwithout consent, leading to dataset retractions and potential legal liabilities\nunder regulations like GDPR. While synthetic facial data presents a promising\nprivacy-preserving alternative, the field lacks comprehensive empirical\nevidence of its viability. This study addresses this critical gap through\nextensive evaluation of synthetic facial recognition datasets. We present a\nsystematic literature review identifying 25 synthetic facial recognition\ndatasets (2018-2025), combined with rigorous experimental validation. Our\nmethodology examines seven key requirements for privacy-preserving synthetic\ndata: identity leakage prevention, intra-class variability, identity\nseparability, dataset scale, ethical data sourcing, bias mitigation, and\nbenchmark reliability. Through experiments involving over 10 million synthetic\nsamples, extended by a comparison of results reported on five standard\nbenchmarks, we provide the first comprehensive empirical assessment of\nsynthetic data's capability to replace real datasets. Best-performing synthetic\ndatasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and\n94.91% respectively, surpassing established real datasets including\nCASIA-WebFace (94.70%). While those images remain private, publicly available\nalternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our\nfindings reveal that they ensure proper intra-class variability while\nmaintaining identity separability. Demographic bias analysis shows that, even\nthough synthetic data inherits limited biases, it offers unprecedented control\nfor bias mitigation through generation parameters. These results establish\nsynthetic facial data as a scientifically viable and ethically imperative\nalternative for facial recognition research.", "AI": {"tldr": "Synthetic facial data can effectively replace real datasets for facial recognition, achieving comparable or better accuracy while preserving privacy and enabling bias mitigation.", "motivation": "Real facial datasets raise ethical concerns due to non-consensual data collection and legal risks under regulations like GDPR, creating a need for privacy-preserving alternatives.", "method": "Systematic literature review of 25 synthetic facial recognition datasets (2018-2025) combined with experimental validation of 7 key privacy requirements and analysis of over 10 million synthetic samples across 5 standard benchmarks.", "result": "Best synthetic datasets (VariFace 95.67%, VIGFace 94.91%) surpassed real dataset CASIA-WebFace (94.70%). Synthetic data maintains identity separability and intra-class variability while offering unprecedented bias mitigation control.", "conclusion": "Synthetic facial data is scientifically viable and ethically imperative for facial recognition research, providing privacy protection while maintaining performance comparable to real datasets."}}
{"id": "2510.16990", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.16990", "abs": "https://arxiv.org/abs/2510.16990", "authors": ["Xuying Ning", "Dongqi Fu", "Tianxin Wei", "Wujiang Xu", "Jingrui He"], "title": "Graph4MM: Weaving Multimodal Learning with Structural Information", "comment": "ICML 2025", "summary": "Real-world multimodal data usually exhibit complex structural relationships\nbeyond traditional one-to-one mappings like image-caption pairs. Entities\nacross modalities interact in intricate ways, with images and text forming\ndiverse interconnections through contextual dependencies and co-references.\nGraphs provide powerful structural information for modeling intra-modal and\ninter-modal relationships. However, previous works fail to distinguish\nmulti-hop neighbors and treat the graph as a standalone modality, which\nfragments the overall understanding. This limitation presents two key\nchallenges in multimodal learning: (1) integrating structural information from\nmulti-hop neighbors into foundational models, and (2) fusing modality-specific\ninformation in a principled manner. To address these challenges, we revisit the\nrole of graphs in multimodal learning within the era of foundation models and\npropose Graph4MM, a graph-based multimodal learning framework. To be specific,\nwe introduce Hop-Diffused Attention, which integrates multi-hop structural\ninformation into self-attention through causal masking and hop diffusion.\nFurthermore, we design MM-QFormer, a multi-mapping querying transformer for\ncross-modal fusion. Through theoretical and empirical analysis, we show that\nleveraging structures to integrate both intra- and inter-modal interactions\nimproves multimodal understanding beyond treating them as a standalone\nmodality. Experiments on both generative and discriminative tasks show that\nGraph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines,\nachieving a 6.93% average improvement.", "AI": {"tldr": "Graph4MM is a graph-based multimodal learning framework that integrates multi-hop structural information into foundation models using Hop-Diffused Attention and MM-QFormer for cross-modal fusion, achieving significant performance improvements.", "motivation": "Real-world multimodal data has complex structural relationships beyond simple one-to-one mappings, with entities across modalities interacting through contextual dependencies and co-references. Previous approaches fail to distinguish multi-hop neighbors and treat graphs as standalone modalities, limiting overall understanding.", "method": "Proposes Graph4MM framework with two key components: (1) Hop-Diffused Attention that integrates multi-hop structural information into self-attention through causal masking and hop diffusion, and (2) MM-QFormer, a multi-mapping querying transformer for principled cross-modal fusion.", "result": "Graph4MM outperforms larger VLMs, LLMs, and multimodal graph baselines, achieving a 6.93% average improvement on both generative and discriminative tasks. Theoretical and empirical analysis shows that leveraging structures to integrate intra- and inter-modal interactions improves multimodal understanding.", "conclusion": "Graph-based approaches that properly integrate structural information from multi-hop neighbors and fuse modality-specific information in a principled manner significantly enhance multimodal learning beyond treating graphs as standalone modalities."}}
{"id": "2510.17373", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17373", "abs": "https://arxiv.org/abs/2510.17373", "authors": ["Yintao Zhou", "Wei Huang", "Zhengyu Li", "Jing Huang", "Meng Pang"], "title": "Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing", "comment": "3 pages, 2 figures, accepted by MIND 2025", "summary": "Parkinson's disease (PD) severity diagnosis is crucial for early detecting\npotential patients and adopting tailored interventions. Diagnosing PD based on\nfacial expression is grounded in PD patients' \"masked face\" symptom and gains\ngrowing interest recently for its convenience and affordability. However,\ncurrent facial expression-based approaches often rely on single type of\nexpression which can lead to misdiagnosis, and ignore the class imbalance\nacross different PD stages which degrades the prediction performance. Moreover,\nmost existing methods focus on binary classification (i.e., PD / non-PD) rather\nthan diagnosing the severity of PD. To address these issues, we propose a new\nfacial expression-based method for PD severity diagnosis which integrates\nmultiple facial expression features through attention-based feature fusion.\nMoreover, we mitigate the class imbalance problem via an adaptive class\nbalancing strategy which dynamically adjusts the contribution of training\nsamples based on their class distribution and classification difficulty.\nExperimental results demonstrate the promising performance of the proposed\nmethod for PD severity diagnosis, as well as the efficacy of attention-based\nfeature fusion and adaptive class balancing.", "AI": {"tldr": "A new method for Parkinson's disease severity diagnosis using multiple facial expression features with attention-based fusion and adaptive class balancing to address single-expression limitations and class imbalance issues.", "motivation": "Current PD diagnosis methods rely on single facial expressions leading to misdiagnosis, ignore class imbalance across PD stages, and focus only on binary classification rather than severity diagnosis.", "method": "Integrates multiple facial expression features through attention-based feature fusion and uses adaptive class balancing strategy that dynamically adjusts training sample contributions based on class distribution and classification difficulty.", "result": "Experimental results demonstrate promising performance for PD severity diagnosis and confirm the efficacy of both attention-based feature fusion and adaptive class balancing.", "conclusion": "The proposed method effectively addresses limitations of existing approaches by leveraging multiple facial expressions and handling class imbalance, showing strong potential for accurate PD severity diagnosis."}}
{"id": "2510.17002", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17002", "abs": "https://arxiv.org/abs/2510.17002", "authors": ["Chang Liu", "Danial Chitnis"], "title": "EEschematic: Multimodal-LLM Based AI Agent for Schematic Generation of Analog Circuit", "comment": null, "summary": "Circuit schematics play a crucial role in analog integrated circuit design,\nserving as the primary medium for human understanding and verification of\ncircuit functionality. While recent large language model (LLM)-based approaches\nhave shown promise in circuit topology generation and device sizing, most rely\nsolely on textual representations such as SPICE netlists, which lack visual\ninterpretability for circuit designers. To address this limitation, we propose\nEEschematic, an AI agent for automatic analog schematic generation based on a\nMultimodal Large Language Model (MLLM). EEschematic integrates textual, visual,\nand symbolic modalities to translate SPICE netlists into schematic diagrams\nrepresented in a human-editable format. The framework uses six analog\nsubstructure examples for few-shot placement and a Visual Chain-of-Thought\n(VCoT) strategy to iteratively refine placement and wiring, enhancing schematic\nclarity and symmetry. Experimental results on representative analog circuits,\nincluding a CMOS inverter, a five-transistor operational transconductance\namplifier (5T-OTA), and a telescopic cascode amplifier, demonstrate that\nEEschematic produces schematics with high visual quality and structural\ncorrectness.", "AI": {"tldr": "EEschematic is an AI agent using Multimodal Large Language Models to automatically generate human-editable schematic diagrams from SPICE netlists, improving visual interpretability for circuit designers.", "motivation": "Current LLM-based circuit design approaches rely on textual SPICE netlists which lack visual interpretability, making it difficult for human designers to understand and verify circuit functionality.", "method": "Uses MLLM to integrate textual, visual, and symbolic modalities; employs few-shot placement with 6 analog substructure examples and Visual Chain-of-Thought strategy for iterative refinement of placement and wiring.", "result": "Successfully generated high-quality schematics for CMOS inverter, 5T-OTA, and telescopic cascode amplifier with good visual quality and structural correctness.", "conclusion": "EEschematic effectively bridges the gap between textual circuit representations and human-understandable visual schematics, enhancing designer productivity and circuit verification."}}
{"id": "2510.17384", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17384", "abs": "https://arxiv.org/abs/2510.17384", "authors": ["Jiajin Tang", "Zhengxuan Wei", "Ge Zheng", "Sibei Yang"], "title": "Closed-Loop Transfer for Weakly-supervised Affordance Grounding", "comment": "Accepted at ICCV 2025", "summary": "Humans can perform previously unexperienced interactions with novel objects\nsimply by observing others engage with them. Weakly-supervised affordance\ngrounding mimics this process by learning to locate object regions that enable\nactions on egocentric images, using exocentric interaction images with\nimage-level annotations. However, extracting affordance knowledge solely from\nexocentric images and transferring it one-way to egocentric images limits the\napplicability of previous works in complex interaction scenarios. Instead, this\nstudy introduces LoopTrans, a novel closed-loop framework that not only\ntransfers knowledge from exocentric to egocentric but also transfers back to\nenhance exocentric knowledge extraction. Within LoopTrans, several innovative\nmechanisms are introduced, including unified cross-modal localization and\ndenoising knowledge distillation, to bridge domain gaps between object-centered\negocentric and interaction-centered exocentric images while enhancing knowledge\ntransfer. Experiments show that LoopTrans achieves consistent improvements\nacross all metrics on image and video benchmarks, even handling challenging\nscenarios where object interaction regions are fully occluded by the human\nbody.", "AI": {"tldr": "LoopTrans is a closed-loop framework that enables bidirectional knowledge transfer between exocentric and egocentric images for affordance grounding, improving performance in complex interaction scenarios.", "motivation": "Previous weakly-supervised affordance grounding methods only transfer knowledge one-way from exocentric to egocentric images, limiting applicability in complex scenarios where object interaction regions may be occluded.", "method": "Introduces a closed-loop framework with unified cross-modal localization and denoising knowledge distillation to bridge domain gaps between object-centered egocentric and interaction-centered exocentric images.", "result": "Achieves consistent improvements across all metrics on image and video benchmarks, successfully handling challenging scenarios where object interaction regions are fully occluded by the human body.", "conclusion": "The bidirectional knowledge transfer approach in LoopTrans significantly enhances affordance grounding performance compared to one-way transfer methods."}}
{"id": "2510.17015", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.17015", "abs": "https://arxiv.org/abs/2510.17015", "authors": ["Mingyan Yang", "Guanjie Wang", "Manqi Luo", "Yifei Liu", "Chen Chen", "Han Zhao", "Yu Feng", "Quan Chen", "Minyi Guo"], "title": "Justitia: Fair and Efficient Scheduling for LLM Applications", "comment": null, "summary": "In the era of Large Language Models (LLMs), it has been popular to launch a\nseries of LLM inferences -- we call an LLM application -- to better solve\nreal-world problems. When serving those applications in shared GPU servers, the\nschedulers are expected to attain fast application completions with guaranteed\nworst-case performance. However, mainstream LLM schedulers fail to behave well\nfor LLM applications -- due to head-of-line blocking or over-constrained\nresource allocation. In this paper, we propose to serve LLM applications in a\nfair and also efficient manner. To this end, we design Justitia, a novel\nscheduler with three key techniques. First, given that memory is prevalently a\nbottleneck for mainstream inference frameworks like vLLM, Justitia models the\nservice cost of LLM applications in a memory-centric manner. Meanwhile, it uses\na simple neural network model to conduct light-weight and also accurate demand\nprediction. Moreover, Justitia adopts a virtual-time based fair queuing\nalgorithm to reduce the overall performance with guaranteed worst-case delay.\nWe have implemented Justitia atop vLLM, and experimental results involving\ndiverse LLM applications show that it can substantially enhance the scheduling\nefficiency with fairness preserved.", "AI": {"tldr": "Justitia is a novel scheduler for LLM applications that addresses scheduling inefficiencies in shared GPU servers by using memory-centric cost modeling, neural network demand prediction, and virtual-time fair queuing to ensure both efficiency and fairness.", "motivation": "Current LLM schedulers suffer from head-of-line blocking and over-constrained resource allocation, leading to poor performance for LLM applications in shared GPU environments. There's a need for schedulers that can achieve fast application completions while guaranteeing worst-case performance.", "method": "Justitia employs three key techniques: 1) Memory-centric service cost modeling for LLM applications, 2) Lightweight neural network for accurate demand prediction, and 3) Virtual-time based fair queuing algorithm to reduce overall performance impact while guaranteeing worst-case delay.", "result": "Experimental results show that Justitia substantially enhances scheduling efficiency while preserving fairness across diverse LLM applications when implemented atop vLLM.", "conclusion": "Justitia successfully addresses the scheduling challenges for LLM applications by combining memory-aware modeling, accurate prediction, and fair queuing, demonstrating significant improvements in both efficiency and fairness compared to mainstream LLM schedulers."}}
{"id": "2510.17409", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17409", "abs": "https://arxiv.org/abs/2510.17409", "authors": ["Dmitrii Galimzianov", "Viacheslav Vyshegorodtsev", "Ivan Nezhivykh"], "title": "Monitoring Horses in Stalls: From Object to Event Detection", "comment": "12 pages, 4 figures, 4 tables", "summary": "Monitoring the behavior of stalled horses is essential for early detection of\nhealth and welfare issues but remains labor-intensive and time-consuming. In\nthis study, we present a prototype vision-based monitoring system that\nautomates the detection and tracking of horses and people inside stables using\nobject detection and multi-object tracking techniques. The system leverages\nYOLOv11 and BoT-SORT for detection and tracking, while event states are\ninferred based on object trajectories and spatial relations within the stall.\nTo support development, we constructed a custom dataset annotated with\nassistance from foundation models CLIP and GroundingDINO. The system\ndistinguishes between five event types and accounts for the camera's blind\nspots. Qualitative evaluation demonstrated reliable performance for\nhorse-related events, while highlighting limitations in detecting people due to\ndata scarcity. This work provides a foundation for real-time behavioral\nmonitoring in equine facilities, with implications for animal welfare and\nstable management.", "AI": {"tldr": "A vision-based system using YOLOv11 and BoT-SORT automates horse and people detection/tracking in stables, classifying five event types while handling camera blind spots.", "motivation": "Manual monitoring of stalled horses is labor-intensive; automated systems are needed for early detection of health and welfare issues.", "method": "Uses YOLOv11 for object detection and BoT-SORT for multi-object tracking, with event inference based on object trajectories and spatial relations. Custom dataset created using CLIP and GroundingDINO foundation models.", "result": "System reliably detects horse-related events but struggles with people detection due to data scarcity. Successfully distinguishes five event types and accounts for camera blind spots.", "conclusion": "Provides foundation for real-time behavioral monitoring in equine facilities, with potential applications in animal welfare and stable management."}}
{"id": "2510.17021", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17021", "abs": "https://arxiv.org/abs/2510.17021", "authors": ["Bingqi Shang", "Yiwei Chen", "Yihua Zhang", "Bingquan Shen", "Sijia Liu"], "title": "Forgetting to Forget: Attention Sink as A Gateway for Backdooring LLM Unlearning", "comment": null, "summary": "Large language model (LLM) unlearning has become a critical mechanism for\nremoving undesired data, knowledge, or behaviors from pre-trained models while\nretaining their general utility. Yet, with the rise of open-weight LLMs, we\nask: can the unlearning process itself be backdoored, appearing successful\nunder normal conditions yet reverting to pre-unlearned behavior when a hidden\ntrigger is activated? Drawing inspiration from classical backdoor attacks that\nembed triggers into training data to enforce specific behaviors, we investigate\nbackdoor unlearning, where models forget as intended in the clean setting but\nrecover forgotten knowledge when the trigger appears. We show that designing\nsuch attacks presents unique challenges, hinging on where triggers are placed\nand how backdoor training is reinforced. We uncover a strong link between\nbackdoor efficacy and the attention sink phenomenon, i.e., shallow input tokens\nconsistently attract disproportionate attention in LLMs. Our analysis reveals\nthat these attention sinks serve as gateways for backdoor unlearning: placing\ntriggers at sink positions and aligning their attention values markedly\nenhances backdoor persistence. Extensive experiments validate these findings,\nshowing that attention-sink-guided backdoor unlearning reliably restores\nforgotten knowledge in the presence of backdoor triggers, while behaving\nindistinguishably from a normally unlearned model when triggers are absent.\nCode is available at https://github.com/OPTML-Group/Unlearn-Backdoor.", "AI": {"tldr": "The paper introduces 'backdoor unlearning' - a vulnerability where LLMs appear to successfully unlearn content normally but can recover forgotten knowledge when specific trigger tokens are activated, exploiting the attention sink phenomenon in transformer models.", "motivation": "With the rise of open-weight LLMs, there's a need to understand if unlearning processes can be maliciously manipulated to create hidden backdoors that bypass intended content removal while maintaining normal functionality.", "method": "The authors investigate placing triggers at attention sink positions (shallow input tokens that disproportionately attract attention) and align their attention values to enhance backdoor persistence, exploiting the inherent attention mechanisms in transformer-based LLMs.", "result": "Extensive experiments show that attention-sink-guided backdoor unlearning reliably restores forgotten knowledge when triggers are present, while behaving identically to normally unlearned models when triggers are absent, demonstrating the vulnerability's effectiveness.", "conclusion": "The attention sink phenomenon serves as a critical gateway for backdoor unlearning attacks, highlighting significant security vulnerabilities in current LLM unlearning mechanisms that require new defensive strategies."}}
{"id": "2510.17422", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17422", "abs": "https://arxiv.org/abs/2510.17422", "authors": ["Shaharyar Ahmed Khan Tareen", "Filza Khan Tareen"], "title": "DeepDetect: Learning All-in-One Dense Keypoints", "comment": "6 pages, 6 figures, 2 tables, 7 equations", "summary": "Keypoint detection is the foundation of many computer vision tasks, including\nimage registration, structure-from motion, 3D reconstruction, visual odometry,\nand SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning\nbased methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong\nperformance yet suffer from key limitations: sensitivity to photometric\nchanges, low keypoint density and repeatability, limited adaptability to\nchallenging scenes, and lack of semantic understanding, often failing to\nprioritize visually important regions. We present DeepDetect, an intelligent,\nall-in-one, dense keypoint detector that unifies the strengths of classical\ndetectors using deep learning. Firstly, we create ground-truth masks by fusing\noutputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from\ncorners and blobs to prominent edges and textures in the images. Afterwards, a\nlightweight and efficient model: ESPNet, is trained using these masks as\nlabels, enabling DeepDetect to focus semantically on images while producing\nhighly dense keypoints, that are adaptable to diverse and visually degraded\nconditions. Evaluations on the Oxford Affine Covariant Regions dataset\ndemonstrate that DeepDetect surpasses other detectors in keypoint density,\nrepeatability, and the number of correct matches, achieving maximum values of\n0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003\n(correct matches).", "AI": {"tldr": "DeepDetect is a dense keypoint detector that combines classical detectors with deep learning to achieve high density, repeatability, and matching performance across challenging conditions.", "motivation": "Existing keypoint detectors (both traditional and learning-based) suffer from limitations like sensitivity to photometric changes, low keypoint density and repeatability, limited adaptability to challenging scenes, and lack of semantic understanding of visually important regions.", "method": "Fuses outputs from 7 keypoint and 2 edge detectors to create ground-truth masks, then trains a lightweight ESPNet model using these masks as labels to produce dense keypoints with semantic focus.", "result": "Outperforms other detectors on Oxford Affine Covariant Regions dataset with maximum values: 0.5143 average keypoint density, 0.9582 average repeatability, and 59,003 correct matches.", "conclusion": "DeepDetect successfully unifies classical detector strengths with deep learning to create an intelligent, dense keypoint detector that adapts well to diverse and visually degraded conditions while focusing on semantically important regions."}}
{"id": "2510.17022", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17022", "abs": "https://arxiv.org/abs/2510.17022", "authors": ["Kevin P. O Keeffe"], "title": "Curiosity-driven RL for symbolic equation solving", "comment": "Accepted at the NeurIPS 2025 MATH-AI Workshop", "summary": "We explore if RL can be useful for symbolic mathematics. Previous work showed\ncontrastive learning can solve linear equations in one variable. We show\nmodel-free PPO \\cite{schulman2017proximal} augmented with curiosity-based\nexploration and graph-based actions can solve nonlinear equations such as those\ninvolving radicals, exponentials, and trig functions. Our work suggests\ncuriosity-based exploration may be useful for general symbolic reasoning tasks.", "AI": {"tldr": "RL with PPO, curiosity exploration, and graph-based actions can solve nonlinear equations including radicals, exponentials, and trig functions.", "motivation": "To explore if reinforcement learning can be useful for symbolic mathematics beyond linear equations.", "method": "Model-free PPO augmented with curiosity-based exploration and graph-based actions.", "result": "Successfully solved nonlinear equations involving radicals, exponentials, and trigonometric functions.", "conclusion": "Curiosity-based exploration may be useful for general symbolic reasoning tasks."}}
{"id": "2510.17434", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17434", "abs": "https://arxiv.org/abs/2510.17434", "authors": ["Julien Zouein", "Hossein Javidnia", "Fran\u00e7ois Piti\u00e9", "Anil Kokaram"], "title": "Leveraging AV1 motion vectors for Fast and Dense Feature Matching", "comment": "Accepted ICIR 2025, camera-ready version", "summary": "We repurpose AV1 motion vectors to produce dense sub-pixel correspondences\nand short tracks filtered by cosine consistency. On short videos, this\ncompressed-domain front end runs comparably to sequential SIFT while using far\nless CPU, and yields denser matches with competitive pairwise geometry. As a\nsmall SfM demo on a 117-frame clip, MV matches register all images and\nreconstruct 0.46-0.62M points at 0.51-0.53,px reprojection error; BA time grows\nwith match density. These results show compressed-domain correspondences are a\npractical, resource-efficient front end with clear paths to scaling in full\npipelines.", "AI": {"tldr": "Repurposing AV1 motion vectors for dense sub-pixel correspondences and short tracks, achieving comparable performance to SIFT with less CPU usage and denser matches.", "motivation": "To create a resource-efficient front end for computer vision pipelines by leveraging compressed-domain information from video codecs.", "method": "Using AV1 motion vectors to generate dense sub-pixel correspondences and short tracks filtered by cosine consistency.", "result": "On short videos, performs comparably to sequential SIFT with less CPU usage, yields denser matches with competitive pairwise geometry. On a 117-frame demo, registered all images and reconstructed 0.46-0.62M points at 0.51-0.53px reprojection error.", "conclusion": "Compressed-domain correspondences are a practical, resource-efficient front end with clear paths to scaling in full pipelines."}}
{"id": "2510.17036", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17036", "abs": "https://arxiv.org/abs/2510.17036", "authors": ["Nguyen Do", "Bach Ngo", "Youval Kashuv", "Canh V. Pham", "Hanghang Tong", "My T. Thai"], "title": "Hephaestus: Mixture Generative Modeling with Energy Guidance for Large-scale QoS Degradation", "comment": "62 pages, 19 figures, Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "We study the Quality of Service Degradation (QoSD) problem, in which an\nadversary perturbs edge weights to degrade network performance. This setting\narises in both network infrastructures and distributed ML systems, where\ncommunication quality, not just connectivity, determines functionality. While\nclassical methods rely on combinatorial optimization, and recent ML approaches\naddress only restricted linear variants with small-size networks, no prior\nmodel directly tackles the QoSD problem under nonlinear edge-weight functions.\nThis work proposes \\PIMMA, a self-reinforcing generative framework that\nsynthesizes feasible solutions in latent space, to fill this gap. Our method\nincludes three phases: (1) Forge: a Predictive Path-Stressing (PPS) algorithm\nthat uses graph learning and approximation to produce feasible solutions with\nperformance guarantee, (2) Morph: a new theoretically grounded training\nparadigm for Mixture of Conditional VAEs guided by an energy-based model to\ncapture solution feature distributions, and (3) Refine: a reinforcement\nlearning agent that explores this space to generate progressively near-optimal\nsolutions using our designed differentiable reward function. Experiments on\nboth synthetic and real-world networks show that our approach consistently\noutperforms classical and ML baselines, particularly in scenarios with\nnonlinear cost functions where traditional methods fail to generalize.", "AI": {"tldr": "PIMMA is a self-reinforcing generative framework that solves the Quality of Service Degradation problem by synthesizing feasible solutions in latent space through three phases: Forge, Morph, and Refine.", "motivation": "Address the QoSD problem where adversaries perturb edge weights to degrade network performance, which occurs in network infrastructures and distributed ML systems. Existing methods either rely on combinatorial optimization or only handle restricted linear variants with small networks, leaving nonlinear edge-weight functions unaddressed.", "method": "Three-phase approach: (1) Forge uses Predictive Path-Stressing algorithm with graph learning for feasible solutions with guarantees; (2) Morph employs Mixture of Conditional VAEs guided by energy-based model to capture solution distributions; (3) Refine uses reinforcement learning with differentiable reward function to generate near-optimal solutions.", "result": "Experiments on synthetic and real-world networks show PIMMA consistently outperforms classical and ML baselines, especially in scenarios with nonlinear cost functions where traditional methods fail to generalize.", "conclusion": "PIMMA effectively addresses the QoSD problem under nonlinear edge-weight functions through its three-phase generative framework, demonstrating superior performance compared to existing methods."}}
{"id": "2510.17440", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17440", "abs": "https://arxiv.org/abs/2510.17440", "authors": ["Qiyuan Guan", "Xiang Chen", "Guiyue Jin", "Jiyu Jin", "Shumin Fan", "Tianyu Song", "Jinshan Pan"], "title": "Rethinking Nighttime Image Deraining via Learnable Color Space Transformation", "comment": "Accepted by NeurIPS 2025", "summary": "Compared to daytime image deraining, nighttime image deraining poses\nsignificant challenges due to inherent complexities of nighttime scenarios and\nthe lack of high-quality datasets that accurately represent the coupling effect\nbetween rain and illumination. In this paper, we rethink the task of nighttime\nimage deraining and contribute a new high-quality benchmark, HQ-NightRain,\nwhich offers higher harmony and realism compared to existing datasets. In\naddition, we develop an effective Color Space Transformation Network (CST-Net)\nfor better removing complex rain from nighttime scenes. Specifically, we\npropose a learnable color space converter (CSC) to better facilitate rain\nremoval in the Y channel, as nighttime rain is more pronounced in the Y channel\ncompared to the RGB color space. To capture illumination information for\nguiding nighttime deraining, implicit illumination guidance is introduced\nenabling the learned features to improve the model's robustness in complex\nscenarios. Extensive experiments show the value of our dataset and the\neffectiveness of our method. The source code and datasets are available at\nhttps://github.com/guanqiyuan/CST-Net.", "AI": {"tldr": "Proposes HQ-NightRain benchmark and CST-Net for nighttime image deraining, using color space transformation and illumination guidance to handle complex rain effects.", "motivation": "Nighttime image deraining is challenging due to complex scenarios and lack of high-quality datasets that capture rain-illumination coupling effects.", "method": "Developed CST-Net with learnable color space converter (CSC) for better rain removal in Y channel, and implicit illumination guidance for robustness in complex scenarios.", "result": "Extensive experiments demonstrate the value of the new HQ-NightRain dataset and effectiveness of the proposed method.", "conclusion": "The approach successfully addresses nighttime deraining challenges through improved dataset quality and specialized network architecture with color space transformation."}}
{"id": "2510.17040", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17040", "abs": "https://arxiv.org/abs/2510.17040", "authors": ["Hoang-Son Nguyen", "Xiao Fu"], "title": "Diverse Influence Component Analysis: A Geometric Approach to Nonlinear Mixture Identifiability", "comment": "30 pages, 3 figures", "summary": "Latent component identification from unknown nonlinear mixtures is a\nfoundational challenge in machine learning, with applications in tasks such as\ndisentangled representation learning and causal inference. Prior work in\nnonlinear independent component analysis (nICA) has shown that auxiliary\nsignals -- such as weak supervision -- can support identifiability of\nconditionally independent latent components. More recent approaches explore\nstructural assumptions, e.g., sparsity in the Jacobian of the mixing function,\nto relax such requirements. In this work, we introduce Diverse Influence\nComponent Analysis (DICA), a framework that exploits the convex geometry of the\nmixing function's Jacobian. We propose a Jacobian Volume Maximization\n(J-VolMax) criterion, which enables latent component identification by\nencouraging diversity in their influence on the observed variables. Under\nreasonable conditions, this approach achieves identifiability without relying\non auxiliary information, latent component independence, or Jacobian sparsity\nassumptions. These results extend the scope of identifiability analysis and\noffer a complementary perspective to existing methods.", "AI": {"tldr": "Diverse Influence Component Analysis (DICA) uses Jacobian Volume Maximization to identify latent components from nonlinear mixtures without requiring auxiliary signals, independence, or sparsity assumptions.", "motivation": "Existing nonlinear ICA methods rely on auxiliary signals or structural assumptions like Jacobian sparsity for identifiability, which limits their applicability.", "method": "Proposes DICA framework with Jacobian Volume Maximization (J-VolMax) criterion that exploits convex geometry of mixing function's Jacobian to encourage diversity in latent components' influence.", "result": "Achieves identifiability of latent components from nonlinear mixtures without auxiliary information, independence assumptions, or Jacobian sparsity requirements.", "conclusion": "DICA extends identifiability analysis scope and provides complementary perspective to existing nonlinear ICA methods by leveraging geometric properties of mixing functions."}}
{"id": "2510.17479", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17479", "abs": "https://arxiv.org/abs/2510.17479", "authors": ["Feng Zhou", "Wenkai Guo", "Pu Cao", "Zhicheng Zhang", "Jianqin Yin"], "title": "Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS", "comment": "A preprint paper", "summary": "Sparse-view 3D Gaussian Splatting (3DGS) often overfits to the training\nviews, leading to artifacts like blurring in novel view rendering. Prior work\naddresses it either by enhancing the initialization (\\emph{i.e.}, the point\ncloud from Structure-from-Motion (SfM)) or by adding training-time constraints\n(regularization) to the 3DGS optimization. Yet our controlled ablations reveal\nthat initialization is the decisive factor: it determines the attainable\nperformance band in sparse-view 3DGS, while training-time constraints yield\nonly modest within-band improvements at extra cost. Given initialization's\nprimacy, we focus our design there. Although SfM performs poorly under sparse\nviews due to its reliance on feature matching, it still provides reliable seed\npoints. Thus, building on SfM, our effort aims to supplement the regions it\nfails to cover as comprehensively as possible. Specifically, we design: (i)\nfrequency-aware SfM that improves low-texture coverage via low-frequency view\naugmentation and relaxed multi-view correspondences; (ii) 3DGS\nself-initialization that lifts photometric supervision into additional points,\ncompensating SfM-sparse regions with learned Gaussian centers; and (iii)\npoint-cloud regularization that enforces multi-view consistency and uniform\nspatial coverage through simple geometric/visibility priors, yielding a clean\nand reliable point cloud. Our experiments on LLFF and Mip-NeRF360 demonstrate\nconsistent gains in sparse-view settings, establishing our approach as a\nstronger initialization strategy. Code is available at\nhttps://github.com/zss171999645/ItG-GS.", "AI": {"tldr": "The paper shows that initialization is the key factor for sparse-view 3D Gaussian Splatting performance, and proposes a comprehensive initialization strategy building on SfM with frequency-aware enhancement, self-initialization, and point-cloud regularization.", "motivation": "Sparse-view 3D Gaussian Splatting tends to overfit to training views, causing blurring in novel views. Previous approaches either improve initialization or add training-time constraints, but the authors found initialization is the decisive factor that determines performance limits.", "method": "Three components: (1) frequency-aware SfM using low-frequency view augmentation and relaxed multi-view correspondences for better low-texture coverage; (2) 3DGS self-initialization that lifts photometric supervision into additional points; (3) point-cloud regularization with geometric/visibility priors for multi-view consistency and uniform coverage.", "result": "Experiments on LLFF and Mip-NeRF360 datasets show consistent improvements in sparse-view settings, establishing the approach as a stronger initialization strategy.", "conclusion": "Initialization is the critical factor in sparse-view 3DGS, and the proposed comprehensive initialization strategy effectively addresses coverage gaps in SfM while maintaining reliability."}}
{"id": "2510.17057", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17057", "abs": "https://arxiv.org/abs/2510.17057", "authors": ["Nikolaus Howe", "Micah Carroll"], "title": "The Ends Justify the Thoughts: RL-Induced Motivated Reasoning in LLMs", "comment": "26 pages", "summary": "The use of reinforcement learning (RL) with chain-of-thought (CoT) reasoning\nhas emerged as a promising approach for developing more capable language\nmodels. In turn, this has led to investigation of CoT monitoring as a\ncompelling method for detecting harmful behaviors such as reward hacking, under\nthe assumption that models' reasoning processes reflect their internal\ndecision-making. In practice, LLM training often produces unintended behaviors\ndue to imperfect reward signals, leading models to develop misaligned\ntendencies. A common corrective approach is to apply post-hoc instructions to\navoid problematic behaviors like sycophancy, but what happens to the model's\nreasoning process when these instructions conflict with learned behaviors? We\ninvestigate this question in simple settings and find that models engage in\nsystematic motivated reasoning -- generating plausible-sounding justifications\nfor violating their instructions while downplaying potential harms. Beyond\nbeing an interesting property of training, we find that while motivated\nreasoning can be detected by most frontier reasoning models, smaller LLM judges\ncan fail to identify a portion of it, and in rare cases can themselves be\npersuaded that the reasoning is correct, despite it contradicting clear\ninstructions. This capability gap raises concerns that as models become more\nsophisticated, their motivated reasoning may become increasingly difficult for\nmonitors to detect. Our results underscore the need to account for motivated\nreasoning when relying on chain-of-thought processes for model evaluation and\noversight. All code for this paper will be made available. WARNING: some\nexamples in this paper may be upsetting.", "AI": {"tldr": "Models engage in systematic motivated reasoning when post-hoc instructions conflict with learned behaviors, generating plausible justifications for violating instructions while downplaying harms. This motivated reasoning can be difficult for smaller LLMs to detect, raising concerns about oversight capabilities.", "motivation": "To understand what happens to models' reasoning processes when post-hoc instructions conflict with learned behaviors, particularly in the context of detecting harmful behaviors through chain-of-thought monitoring.", "method": "Investigation in simple settings of how models generate justifications when instructions conflict with learned behaviors, and evaluation of detection capabilities using frontier reasoning models and smaller LLM judges.", "result": "Models engage in systematic motivated reasoning - generating plausible-sounding justifications for violating instructions while downplaying potential harms. While most frontier models can detect this reasoning, smaller LLM judges sometimes fail to identify it or can be persuaded it's correct despite clear instruction violations.", "conclusion": "Motivated reasoning poses a significant challenge for model oversight, as it may become increasingly difficult to detect as models become more sophisticated. There is a need to account for motivated reasoning when relying on chain-of-thought processes for evaluation and oversight."}}
{"id": "2510.17482", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17482", "abs": "https://arxiv.org/abs/2510.17482", "authors": ["Chenxu Dang", "Haiyan Liu", "Guangjun Bao", "Pei An", "Xinyue Tang", "Jie Ma", "Bingchuan Sun", "Yan Wang"], "title": "SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries", "comment": "Under Review", "summary": "Semantic occupancy has emerged as a powerful representation in world models\nfor its ability to capture rich spatial semantics. However, most existing\noccupancy world models rely on static and fixed embeddings or grids, which\ninherently limit the flexibility of perception. Moreover, their ``in-place\nclassification\" over grids exhibits a potential misalignment with the dynamic\nand continuous nature of real scenarios.In this paper, we propose SparseWorld,\na novel 4D occupancy world model that is flexible, adaptive, and efficient,\npowered by sparse and dynamic queries. We propose a Range-Adaptive Perception\nmodule, in which learnable queries are modulated by the ego vehicle states and\nenriched with temporal-spatial associations to enable extended-range\nperception. To effectively capture the dynamics of the scene, we design a\nState-Conditioned Forecasting module, which replaces classification-based\nforecasting with regression-guided formulation, precisely aligning the dynamic\nqueries with the continuity of the 4D environment. In addition, We specifically\ndevise a Temporal-Aware Self-Scheduling training strategy to enable smooth and\nefficient training. Extensive experiments demonstrate that SparseWorld achieves\nstate-of-the-art performance across perception, forecasting, and planning\ntasks. Comprehensive visualizations and ablation studies further validate the\nadvantages of SparseWorld in terms of flexibility, adaptability, and\nefficiency. The code is available at https://github.com/MSunDYY/SparseWorld.", "AI": {"tldr": "SparseWorld is a novel 4D occupancy world model that uses sparse dynamic queries for flexible and adaptive perception, featuring range-adaptive perception and state-conditioned forecasting modules.", "motivation": "Existing occupancy world models rely on static embeddings/grids that limit perception flexibility and misalign with the dynamic nature of real scenarios.", "method": "Proposes Range-Adaptive Perception module with learnable queries modulated by ego states, and State-Conditioned Forecasting module using regression-guided formulation instead of classification.", "result": "Achieves state-of-the-art performance across perception, forecasting, and planning tasks, demonstrating advantages in flexibility, adaptability, and efficiency.", "conclusion": "SparseWorld effectively addresses limitations of static occupancy models by introducing dynamic queries and regression-based forecasting, enabling better alignment with real-world dynamics."}}
{"id": "2510.17058", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17058", "abs": "https://arxiv.org/abs/2510.17058", "authors": ["Hassan Hamad", "Yuou Qiu", "Peter A. Beerel", "Keith M. Chugg"], "title": "Bitwidth-Specific Logarithmic Arithmetic for Future Hardware-Accelerated Training", "comment": null, "summary": "While advancements in quantization have significantly reduced the\ncomputational costs of inference in deep learning, training still predominantly\nrelies on complex floating-point arithmetic. Low-precision fixed-point training\npresents a compelling alternative. This work introduces a novel enhancement in\nlow-precision logarithmic fixed-point training, geared towards future hardware\naccelerator designs. We propose incorporating bitwidth in the design of\napproximations to arithmetic operations. To this end, we introduce a new\nhardware-friendly, piece-wise linear approximation for logarithmic addition.\nUsing simulated annealing, we optimize this approximation at different\nprecision levels. A C++ bit-true simulation demonstrates training of VGG-11 and\nVGG-16 models on CIFAR-100 and TinyImageNet, respectively, using 12-bit integer\narithmetic with minimal accuracy degradation compared to 32-bit floating-point\ntraining. Our hardware study reveals up to 32.5% reduction in area and 53.5%\nreduction in energy consumption for the proposed LNS multiply-accumulate units\ncompared to that of linear fixed-point equivalents.", "AI": {"tldr": "This paper introduces a novel low-precision logarithmic fixed-point training method using hardware-friendly piece-wise linear approximations optimized for different bitwidths, achieving comparable accuracy to 32-bit floating-point training with significant hardware efficiency gains.", "motivation": "While quantization has reduced inference costs, training still relies on complex floating-point arithmetic. Low-precision fixed-point training offers a compelling alternative for future hardware accelerator designs.", "method": "Proposed incorporating bitwidth in arithmetic operation approximations, introduced hardware-friendly piece-wise linear approximation for logarithmic addition, optimized approximations using simulated annealing at different precision levels, and validated through C++ bit-true simulation of VGG models on CIFAR-100 and TinyImageNet.", "result": "Successfully trained VGG-11 and VGG-16 models using 12-bit integer arithmetic with minimal accuracy degradation compared to 32-bit floating-point training. Hardware study showed 32.5% area reduction and 53.5% energy consumption reduction for LNS multiply-accumulate units compared to linear fixed-point equivalents.", "conclusion": "The proposed low-precision logarithmic fixed-point training approach enables efficient deep learning training with significant hardware benefits while maintaining comparable accuracy to traditional floating-point methods."}}
{"id": "2510.17484", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17484", "abs": "https://arxiv.org/abs/2510.17484", "authors": ["Muhammad Umer Ramzan", "Ali Zia", "Abdelwahed Khamis", "Noman Ali", "Usman Ali", "Wei Xiang"], "title": "Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment", "comment": null, "summary": "Salient object detection (SOD) aims to segment visually prominent regions in\nimages and serves as a foundational task for various computer vision\napplications. We posit that SOD can now reach near-supervised accuracy without\na single pixel-level label, but only when reliable pseudo-masks are available.\nWe revisit the prototype-based line of work and make two key observations.\nFirst, boundary pixels and interior pixels obey markedly different geometry;\nsecond, the global consistency enforced by optimal transport (OT) is\nunderutilized if prototype quality is weak. To address this, we introduce\nPOTNet, an adaptation of Prototypical Optimal Transport that replaces POT's\nsingle k-means step with an entropy-guided dual-clustering head: high-entropy\npixels are organized by spectral clustering, low-entropy pixels by k-means, and\nthe two prototype sets are subsequently aligned by OT. This\nsplit-fuse-transport design yields sharper, part-aware pseudo-masks in a single\nforward pass, without handcrafted priors. Those masks supervise a standard\nMaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end\nunsupervised SOD pipeline that eliminates SelfMask's offline voting yet\nimproves both accuracy and training efficiency. Extensive experiments on five\nbenchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and\nweakly supervised methods by up to 36% in F-measure, further narrowing the gap\nto fully supervised models.", "AI": {"tldr": "AutoSOD is an unsupervised salient object detection method that uses POTNet to generate high-quality pseudo-masks without pixel-level labels, achieving near-supervised accuracy through entropy-guided dual clustering and optimal transport alignment.", "motivation": "Salient object detection can reach near-supervised accuracy without labels if reliable pseudo-masks are available. Current methods underutilize optimal transport when prototype quality is weak, and boundary/interior pixels have different geometric properties.", "method": "POTNet replaces single k-means with entropy-guided dual clustering: high-entropy pixels use spectral clustering, low-entropy pixels use k-means, then align both prototype sets with optimal transport. This generates sharp pseudo-masks that supervise a MaskFormer-style encoder-decoder.", "result": "AutoSOD outperforms unsupervised methods by up to 26% and weakly supervised methods by up to 36% in F-measure on five benchmarks, narrowing the gap to fully supervised models while improving training efficiency.", "conclusion": "The split-fuse-transport design with entropy-guided dual clustering and optimal transport alignment enables unsupervised SOD to achieve near-supervised performance without handcrafted priors or offline processing."}}
{"id": "2510.17059", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17059", "abs": "https://arxiv.org/abs/2510.17059", "authors": ["Kathryn Wantlin", "Chongyi Zheng", "Benjamin Eysenbach"], "title": "Consistent Zero-Shot Imitation with Contrastive Goal Inference", "comment": null, "summary": "In the same way that generative models today conduct most of their training\nin a self-supervised fashion, how can agentic models conduct their training in\na self-supervised fashion, interactively exploring, learning, and preparing to\nquickly adapt to new tasks? A prerequisite for embodied agents deployed in real\nworld interactions ought to be training with interaction, yet today's most\nsuccessful AI models (e.g., VLMs, LLMs) are trained without an explicit notion\nof action. The problem of pure exploration (which assumes no data as input) is\nwell studied in the reinforcement learning literature and provides agents with\na wide array of experiences, yet it fails to prepare them for rapid adaptation\nto new tasks. Today's language and vision models are trained on data provided\nby humans, which provides a strong inductive bias for the sorts of tasks that\nthe model will have to solve (e.g., modeling chords in a song, phrases in a\nsonnet, sentences in a medical record). However, when they are prompted to\nsolve a new task, there is a faulty tacit assumption that humans spend most of\ntheir time in the most rewarding states. The key contribution of our paper is a\nmethod for pre-training interactive agents in a self-supervised fashion, so\nthat they can instantly mimic human demonstrations. Our method treats goals\n(i.e., observations) as the atomic construct. During training, our method\nautomatically proposes goals and practices reaching them, building off prior\nwork in reinforcement learning exploration. During evaluation, our method\nsolves an (amortized) inverse reinforcement learning problem to explain\ndemonstrations as optimal goal-reaching behavior. Experiments on standard\nbenchmarks (not designed for goal-reaching) show that our approach outperforms\nprior methods for zero-shot imitation.", "AI": {"tldr": "A self-supervised training method for interactive agents that enables zero-shot imitation by treating goals as atomic constructs and practicing goal-reaching during training, then solving inverse reinforcement learning during evaluation.", "motivation": "Current AI models (VLMs, LLMs) lack explicit action concepts and are trained on human data, assuming humans spend most time in rewarding states. Agents need interactive training for real-world deployment and rapid adaptation to new tasks.", "method": "Proposes goals as atomic constructs. During training: automatically proposes goals and practices reaching them using RL exploration. During evaluation: solves amortized inverse reinforcement learning to explain demonstrations as optimal goal-reaching behavior.", "result": "Outperforms prior methods for zero-shot imitation on standard benchmarks not designed for goal-reaching.", "conclusion": "Self-supervised interactive training with goal-reaching practice enables agents to instantly mimic human demonstrations without task-specific training."}}
{"id": "2510.17501", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17501", "abs": "https://arxiv.org/abs/2510.17501", "authors": ["Yuanli Wu", "Long Zhang", "Yue Du", "Bin Li"], "title": "Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization", "comment": null, "summary": "With the rapid proliferation of video content across social media,\nsurveillance, and education platforms, efficiently summarizing long videos into\nconcise yet semantically faithful surrogates has become increasingly vital.\nExisting supervised methods achieve strong in-domain accuracy by learning from\ndense annotations but suffer from high labeling costs and limited cross-dataset\ngeneralization, while unsupervised approaches, though label-free, often fail to\ncapture high-level human semantics and fine-grained narrative cues. More\nrecently, zero-shot prompting pipelines have leveraged large language models\n(LLMs) for training-free video summarization, yet remain highly sensitive to\nhandcrafted prompt templates and dataset-specific score normalization. To\novercome these limitations, we introduce a rubric-guided, pseudo-labeled\nprompting framework that transforms a small subset of ground-truth annotations\ninto high-confidence pseudo labels, which are aggregated into structured,\ndataset-adaptive scoring rubrics guiding interpretable scene evaluation. During\ninference, first and last segments are scored based solely on their\ndescriptions, whereas intermediate ones incorporate brief contextual summaries\nof adjacent scenes to assess narrative progression and redundancy. This\ncontextual prompting enables the LLM to balance local salience and global\ncoherence without parameter tuning. On SumMe and TVSum, our method achieves F1\nscores of \\textbf{57.58} and \\textbf{63.05}, surpassing unsupervised and prior\nzero-shot baselines while approaching supervised performance. The results\ndemonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based\nscoring and establishes a general, interpretable zero-shot paradigm for video\nsummarization.", "AI": {"tldr": "A rubric-guided pseudo-labeling framework for zero-shot video summarization that transforms limited ground-truth annotations into structured scoring rubrics to guide LLM-based scene evaluation, achieving competitive performance without training.", "motivation": "Address limitations of supervised methods (high labeling costs, poor generalization) and unsupervised approaches (failure to capture human semantics), while overcoming sensitivity issues of existing zero-shot LLM methods to handcrafted prompts.", "method": "Transform small subset of ground-truth annotations into pseudo labels aggregated into dataset-adaptive scoring rubrics. Use contextual prompting where first/last segments are scored based on descriptions, while intermediate ones incorporate adjacent scene summaries to assess narrative progression and redundancy.", "result": "Achieves F1 scores of 57.58 on SumMe and 63.05 on TVSum, surpassing unsupervised and prior zero-shot baselines while approaching supervised performance.", "conclusion": "Rubric-guided pseudo labeling effectively stabilizes LLM-based scoring and establishes a general, interpretable zero-shot paradigm for video summarization."}}
{"id": "2510.17085", "categories": ["cs.LG", "cs.GT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17085", "abs": "https://arxiv.org/abs/2510.17085", "authors": ["Yiling Chen", "Shi Feng", "Paul Kattuman", "Fang-Yi Yu"], "title": "Data Reliability Scoring", "comment": "39 pages, 5 figures", "summary": "How can we assess the reliability of a dataset without access to ground\ntruth? We introduce the problem of reliability scoring for datasets collected\nfrom potentially strategic sources. The true data are unobserved, but we see\noutcomes of an unknown statistical experiment that depends on them. To\nbenchmark reliability, we define ground-truth-based orderings that capture how\nmuch reported data deviate from the truth. We then propose the Gram determinant\nscore, which measures the volume spanned by vectors describing the empirical\ndistribution of the observed data and experiment outcomes. We show that this\nscore preserves several ground-truth based reliability orderings and, uniquely\nup to scaling, yields the same reliability ranking of datasets regardless of\nthe experiment -- a property we term experiment agnosticism. Experiments on\nsynthetic noise models, CIFAR-10 embeddings, and real employment data\ndemonstrate that the Gram determinant score effectively captures data quality\nacross diverse observation processes.", "AI": {"tldr": "The paper introduces the Gram determinant score to assess dataset reliability without ground truth by measuring the volume spanned by vectors describing empirical distributions and experiment outcomes.", "motivation": "To evaluate dataset reliability when ground truth is unavailable, especially for data from potentially strategic sources where true data are unobserved but we only see outcomes of unknown statistical experiments.", "method": "Proposes the Gram determinant score which measures the volume spanned by vectors describing the empirical distribution of observed data and experiment outcomes. This score preserves ground-truth-based reliability orderings and is experiment-agnostic.", "result": "The Gram determinant score uniquely preserves reliability rankings regardless of the experiment (experiment agnosticism) and effectively captures data quality across synthetic noise models, CIFAR-10 embeddings, and real employment data.", "conclusion": "The Gram determinant score provides a principled approach for assessing dataset reliability without ground truth, maintaining consistent rankings across different observation processes and capturing data quality effectively."}}
{"id": "2510.17519", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17519", "abs": "https://arxiv.org/abs/2510.17519", "authors": ["Yongshun Zhang", "Zhongyi Fan", "Yonghang Zhang", "Zhangzikang Li", "Weifeng Chen", "Zhongwei Feng", "Chaoyue Wang", "Peng Hou", "Anxiang Zeng"], "title": "MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models", "comment": "Technical Report; Project Page:\n  \\href{https://github.com/Shopee-MUG/MUG-V}", "summary": "In recent years, large-scale generative models for visual content\n(\\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable\nprogress. However, training large-scale video generation models remains\nparticularly challenging and resource-intensive due to cross-modal text-video\nalignment, the long sequences involved, and the complex spatiotemporal\ndependencies. To address these challenges, we present a training framework that\noptimizes four pillars: (i) data processing, (ii) model architecture, (iii)\ntraining strategy, and (iv) infrastructure for large-scale video generation\nmodels. These optimizations delivered significant efficiency gains and\nperformance improvements across all stages of data preprocessing, video\ncompression, parameter scaling, curriculum-based pretraining, and\nalignment-focused post-training. Our resulting model, MUG-V 10B, matches recent\nstate-of-the-art video generators overall and, on e-commerce-oriented video\ngeneration tasks, surpasses leading open-source baselines in human evaluations.\nMore importantly, we open-source the complete stack, including model weights,\nMegatron-Core-based large-scale training code, and inference pipelines for\nvideo generation and enhancement. To our knowledge, this is the first public\nrelease of large-scale video generation training code that exploits\nMegatron-Core to achieve high training efficiency and near-linear multi-node\nscaling, details are available in\n\\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.", "AI": {"tldr": "A training framework for large-scale video generation models that optimizes data processing, model architecture, training strategy, and infrastructure, resulting in MUG-V 10B model that matches state-of-the-art performance and is open-sourced.", "motivation": "Training large-scale video generation models is challenging due to cross-modal text-video alignment, long sequences, and complex spatiotemporal dependencies, requiring efficient solutions.", "method": "Optimized four pillars: data processing, model architecture, training strategy, and infrastructure. Used data preprocessing, video compression, parameter scaling, curriculum-based pretraining, and alignment-focused post-training.", "result": "MUG-V 10B matches state-of-the-art video generators overall and surpasses leading open-source baselines on e-commerce video generation tasks in human evaluations. Achieved significant efficiency gains and performance improvements.", "conclusion": "The framework successfully addresses training challenges for large-scale video generation and the complete stack (model weights, training code, inference pipelines) is open-sourced, being the first public release using Megatron-Core for high training efficiency."}}
{"id": "2510.17088", "categories": ["cs.LG", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.17088", "abs": "https://arxiv.org/abs/2510.17088", "authors": ["Zan Li", "Rui Fan"], "title": "Explainable Heterogeneous Anomaly Detection in Financial Networks via Adaptive Expert Routing", "comment": null, "summary": "Financial anomalies exhibit heterogeneous mechanisms (price shocks, liquidity\nfreezes, contagion cascades, regime shifts), but existing detectors treat all\nanomalies uniformly, producing scalar scores without revealing which mechanism\nis failing, where risks concentrate, or how to intervene. This opacity prevents\ntargeted regulatory responses. Three unsolved challenges persist: (1) static\ngraph structures cannot adapt when market correlations shift during regime\nchanges; (2) uniform detection mechanisms miss type-specific signatures across\nmultiple temporal scales while failing to integrate individual behaviors with\nnetwork contagion; (3) black-box outputs provide no actionable guidance on\nanomaly mechanisms or their temporal evolution.\n  We address these via adaptive graph learning with specialized expert networks\nthat provide built-in interpretability. Our framework captures multi-scale\ntemporal dependencies through BiLSTM with self-attention, fuses temporal and\nspatial information via cross-modal attention, learns dynamic graphs through\nneural multi-source interpolation, adaptively balances learned dynamics with\nstructural priors via stress-modulated fusion, routes anomalies to four\nmechanism-specific experts, and produces dual-level interpretable attributions.\nCritically, interpretability is embedded architecturally rather than applied\npost-hoc.\n  On 100 US equities (2017-2024), we achieve 92.3% detection of 13 major events\nwith 3.8-day lead time, outperforming best baseline by 30.8pp. Silicon Valley\nBank case study demonstrates anomaly evolution tracking: Price-Shock expert\nweight rose to 0.39 (33% above baseline 0.29) during closure, peaking at 0.48\n(66% above baseline) one week later, revealing automatic temporal mechanism\nidentification without labeled supervision.", "AI": {"tldr": "The paper proposes an adaptive graph learning framework with specialized expert networks for interpretable financial anomaly detection that identifies specific anomaly mechanisms rather than just scalar scores.", "motivation": "Existing financial anomaly detectors treat all anomalies uniformly without revealing specific mechanisms, preventing targeted regulatory responses. Key challenges include static graph structures, uniform detection missing type-specific signatures, and black-box outputs.", "method": "Uses adaptive graph learning with four mechanism-specific expert networks, BiLSTM with self-attention for multi-scale temporal dependencies, cross-modal attention for temporal-spatial fusion, neural multi-source interpolation for dynamic graphs, and stress-modulated fusion.", "result": "Achieved 92.3% detection of 13 major events with 3.8-day lead time, outperforming best baseline by 30.8 percentage points. Silicon Valley Bank case study showed automatic temporal mechanism identification with expert weights rising significantly during crisis.", "conclusion": "The framework provides dual-level interpretable attributions with interpretability embedded architecturally, enabling automatic identification of anomaly mechanisms and their temporal evolution without labeled supervision."}}
{"id": "2510.17529", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17529", "abs": "https://arxiv.org/abs/2510.17529", "authors": ["Yovin Yahathugoda", "Davide Prezzi", "Piyalitt Ittichaiwong", "Vicky Goh", "Sebastien Ourselin", "Michela Antonelli"], "title": "MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation", "comment": null, "summary": "Active Surveillance (AS) is a treatment option for managing low and\nintermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while\nmonitoring disease progression through serial MRI and clinical follow-up.\nAccurate prostate segmentation is an important preliminary step for automating\nthis process, enabling automated detection and diagnosis of PCa. However,\nexisting deep-learning segmentation models are often trained on\nsingle-time-point and expertly annotated datasets, making them unsuitable for\nlongitudinal AS analysis, where multiple time points and a scarcity of expert\nlabels hinder their effective fine-tuning. To address these challenges, we\npropose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation\narchitecture that computes the segmentation for time point t by leveraging the\nMRI and the corresponding segmentation mask from the previous time point. We\nintroduce two new components: (i) a Mamba-enhanced Cross-Attention Module,\nwhich integrates the Mamba block into cross attention to efficiently capture\ntemporal evolution and long-range spatial dependencies, and (ii) a Shape\nExtractor Module that encodes the previous segmentation mask into a latent\nanatomical representation for refined zone delination. Moreover, we introduce a\nsemi-supervised self-training strategy that leverages pseudo-labels generated\nfrom a pre-trained nnU-Net, enabling effective learning without expert\nannotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results\nshowed that it significantly outperforms state-of-the-art U-Net and\nTransformer-based models, achieving superior prostate zone segmentation even\nwhen trained on limited and noisy data.", "AI": {"tldr": "MambaX-Net is a semi-supervised 3D segmentation model for longitudinal prostate cancer active surveillance that leverages temporal information from previous MRI scans and segmentation masks to improve current time point segmentation, outperforming existing methods.", "motivation": "Active surveillance for prostate cancer requires accurate longitudinal analysis, but existing segmentation models trained on single-time-point expert annotations are unsuitable for multi-time-point scenarios with limited expert labels.", "method": "Proposed MambaX-Net with Mamba-enhanced Cross-Attention Module for temporal evolution and long-range dependencies, Shape Extractor Module for anatomical representation, and semi-supervised self-training using pseudo-labels from pre-trained nnU-Net.", "result": "MambaX-Net significantly outperforms state-of-the-art U-Net and Transformer-based models on longitudinal AS dataset, achieving superior prostate zone segmentation even with limited and noisy training data.", "conclusion": "The proposed architecture effectively addresses challenges in longitudinal prostate segmentation by leveraging temporal information and semi-supervised learning, enabling more reliable automated analysis for active surveillance."}}
{"id": "2510.17099", "categories": ["cs.LG", "cs.GT"], "pdf": "https://arxiv.org/pdf/2510.17099", "abs": "https://arxiv.org/abs/2510.17099", "authors": ["Zhiyuan Fan", "Arnab Maiti", "Kevin Jamieson", "Lillian J. Ratliff", "Gabriele Farina"], "title": "On the Universal Near Optimality of Hedge in Combinatorial Settings", "comment": "28 pages, 1 Figure", "summary": "In this paper, we study the classical Hedge algorithm in combinatorial\nsettings. In each round, the learner selects a vector $\\boldsymbol{x}_t$ from a\nset $X \\subseteq \\{0,1\\}^d$, observes a full loss vector $\\boldsymbol{y}_t \\in\n\\mathbb{R}^d$, and incurs a loss $\\langle \\boldsymbol{x}_t, \\boldsymbol{y}_t\n\\rangle \\in [-1,1]$. This setting captures several important problems,\nincluding extensive-form games, resource allocation, $m$-sets, online multitask\nlearning, and shortest-path problems on directed acyclic graphs (DAGs). It is\nwell known that Hedge achieves a regret of $O\\big(\\sqrt{T \\log |X|}\\big)$ after\n$T$ rounds of interaction. In this paper, we ask whether Hedge is optimal\nacross all combinatorial settings. To that end, we show that for any $X\n\\subseteq \\{0,1\\}^d$, Hedge is near-optimal--specifically, up to a $\\sqrt{\\log\nd}$ factor--by establishing a lower bound of $\\Omega\\big(\\sqrt{T \\log(|X|)/\\log\nd}\\big)$ that holds for any algorithm. We then identify a natural class of\ncombinatorial sets--namely, $m$-sets with $\\log d \\leq m \\leq \\sqrt{d}$--for\nwhich this lower bound is tight, and for which Hedge is provably suboptimal by\na factor of exactly $\\sqrt{\\log d}$. At the same time, we show that Hedge is\noptimal for online multitask learning, a generalization of the classical\n$K$-experts problem. Finally, we leverage the near-optimality of Hedge to\nestablish the existence of a near-optimal regularizer for online shortest-path\nproblems in DAGs--a setting that subsumes a broad range of combinatorial\ndomains. Specifically, we show that the classical Online Mirror Descent (OMD)\nalgorithm, when instantiated with the dilated entropy regularizer, is\niterate-equivalent to Hedge, and therefore inherits its near-optimal regret\nguarantees for DAGs.", "AI": {"tldr": "The paper analyzes the optimality of Hedge algorithm in combinatorial settings, showing it's near-optimal with a \u221alog d gap, identifies specific settings where it's suboptimal, and proves its optimality for online multitask learning.", "motivation": "To determine whether Hedge algorithm is optimal across all combinatorial settings, as it's known to achieve O(\u221a(T log|X|)) regret but its optimality wasn't fully characterized.", "method": "Established a lower bound of \u03a9(\u221a(T log(|X|)/log d)) for any algorithm, compared with Hedge's upper bound, and analyzed specific combinatorial structures like m-sets and online multitask learning.", "result": "Hedge is near-optimal with a \u221alog d factor gap, suboptimal for m-sets when log d \u2264 m \u2264 \u221ad, optimal for online multitask learning, and can be used to derive near-optimal regularizers for DAG shortest-path problems.", "conclusion": "Hedge is provably near-optimal across combinatorial settings with a tight \u221alog d gap, and its analysis enables construction of near-optimal algorithms for DAG-based combinatorial problems."}}
{"id": "2510.17566", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17566", "abs": "https://arxiv.org/abs/2510.17566", "authors": ["Nachuan Ma", "Zhengfei Song", "Qiang Hu", "Xiaoyu Tang", "Chengxi Zhang", "Rui Fan", "Lihua Xie"], "title": "WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection", "comment": null, "summary": "Road crack detection is essential for intelligent infrastructure maintenance\nin smart cities. To reduce reliance on costly pixel-level annotations, we\npropose WP-CrackNet, an end-to-end weakly-supervised method that trains with\nonly image-level labels for pixel-wise crack detection. WP-CrackNet integrates\nthree components: a classifier generating class activation maps (CAMs), a\nreconstructor measuring feature inferability, and a detector producing\npixel-wise road crack detection results. During training, the classifier and\nreconstructor alternate in adversarial learning to encourage crack CAMs to\ncover complete crack regions, while the detector learns from pseudo labels\nderived from post-processed crack CAMs. This mutual feedback among the three\ncomponents improves learning stability and detection accuracy. To further boost\ndetection performance, we design a path-aware attention module (PAAM) that\nfuses high-level semantics from the classifier with low-level structural cues\nfrom the reconstructor by modeling spatial and channel-wise dependencies.\nAdditionally, a center-enhanced CAM consistency module (CECCM) is proposed to\nrefine crack CAMs using center Gaussian weighting and consistency constraints,\nenabling better pseudo-label generation. We create three image-level datasets\nand extensive experiments show that WP-CrackNet achieves comparable results to\nsupervised methods and outperforms existing weakly-supervised methods,\nsignificantly advancing scalable road inspection. The source code package and\ndatasets are available at https://mias.group/WP-CrackNet/.", "AI": {"tldr": "WP-CrackNet is a weakly-supervised road crack detection method that uses only image-level labels instead of costly pixel-level annotations, achieving comparable performance to supervised methods through adversarial learning between classifier, reconstructor, and detector components.", "motivation": "To reduce reliance on expensive pixel-level annotations for road crack detection in smart city infrastructure maintenance, enabling more scalable and cost-effective inspection systems.", "method": "End-to-end weakly-supervised framework with three components: classifier generating CAMs, reconstructor measuring feature inferability, and detector producing pixel-wise results. Uses adversarial learning between classifier and reconstructor, path-aware attention module (PAAM) for feature fusion, and center-enhanced CAM consistency module (CECCM) for pseudo-label refinement.", "result": "Achieves comparable results to supervised methods and outperforms existing weakly-supervised methods on three created image-level datasets, significantly advancing scalable road inspection.", "conclusion": "WP-CrackNet demonstrates that weakly-supervised learning with only image-level labels can achieve competitive crack detection performance, making road inspection more scalable and cost-effective for smart city infrastructure maintenance."}}
{"id": "2510.17103", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17103", "abs": "https://arxiv.org/abs/2510.17103", "authors": ["Shinji Ito", "Kevin Jamieson", "Haipeng Luo", "Arnab Maiti", "Taira Tsuchiya"], "title": "Adapting to Stochastic and Adversarial Losses in Episodic MDPs with Aggregate Bandit Feedback", "comment": "49 pages", "summary": "We study online learning in finite-horizon episodic Markov decision processes\n(MDPs) under the challenging aggregate bandit feedback model, where the learner\nobserves only the cumulative loss incurred in each episode, rather than\nindividual losses at each state-action pair. While prior work in this setting\nhas focused exclusively on worst-case analysis, we initiate the study of\nbest-of-both-worlds (BOBW) algorithms that achieve low regret in both\nstochastic and adversarial environments. We propose the first BOBW algorithms\nfor episodic tabular MDPs with aggregate bandit feedback. In the case of known\ntransitions, our algorithms achieve $O(\\log T)$ regret in stochastic settings\nand ${O}(\\sqrt{T})$ regret in adversarial ones. Importantly, we also establish\nmatching lower bounds, showing the optimality of our algorithms in this\nsetting. We further extend our approach to unknown-transition settings by\nincorporating confidence-based techniques. Our results rely on a combination of\nFTRL over occupancy measures, self-bounding techniques, and new loss estimators\ninspired by recent advances in online shortest path problems. Along the way, we\nalso provide the first individual-gap-dependent lower bounds and demonstrate\nnear-optimal BOBW algorithms for shortest path problems with bandit feedback.", "AI": {"tldr": "The paper presents best-of-both-worlds (BOBW) algorithms for episodic MDPs with aggregate bandit feedback, achieving logarithmic regret in stochastic settings and square-root regret in adversarial settings, with matching lower bounds.", "motivation": "Prior work focused only on worst-case analysis in episodic MDPs with aggregate bandit feedback, where only cumulative episode losses are observed. This paper aims to develop algorithms that perform well in both stochastic and adversarial environments.", "method": "The approach combines FTRL over occupancy measures, self-bounding techniques, and new loss estimators inspired by online shortest path problems. The algorithms work for both known and unknown transition settings.", "result": "For known transitions: O(log T) regret in stochastic settings and O(\u221aT) regret in adversarial settings, with matching lower bounds proving optimality. Also provides first individual-gap-dependent lower bounds and near-optimal BOBW algorithms for shortest path problems.", "conclusion": "The paper successfully develops the first BOBW algorithms for episodic MDPs with aggregate bandit feedback, achieving optimal regret bounds in both stochastic and adversarial environments through novel techniques combining FTRL, self-bounding, and specialized loss estimators."}}
{"id": "2510.17568", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17568", "abs": "https://arxiv.org/abs/2510.17568", "authors": ["Kaichen Zhou", "Yuhan Wang", "Grace Chen", "Xinhai Chang", "Gaspard Beaudouin", "Fangneng Zhan", "Paul Pu Liang", "Mengyu Wang"], "title": "PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception", "comment": null, "summary": "Recent 3D feed-forward models, such as the Visual Geometry Grounded\nTransformer (VGGT), have shown strong capability in inferring 3D attributes of\nstatic scenes. However, since they are typically trained on static datasets,\nthese models often struggle in real-world scenarios involving complex dynamic\nelements, such as moving humans or deformable objects like umbrellas. To\naddress this limitation, we introduce PAGE-4D, a feedforward model that extends\nVGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and\npoint cloud reconstruction -- all without post-processing. A central challenge\nin multi-task 4D reconstruction is the inherent conflict between tasks:\naccurate camera pose estimation requires suppressing dynamic regions, while\ngeometry reconstruction requires modeling them. To resolve this tension, we\npropose a dynamics-aware aggregator that disentangles static and dynamic\ninformation by predicting a dynamics-aware mask -- suppressing motion cues for\npose estimation while amplifying them for geometry reconstruction. Extensive\nexperiments show that PAGE-4D consistently outperforms the original VGGT in\ndynamic scenarios, achieving superior results in camera pose estimation,\nmonocular and video depth estimation, and dense point map reconstruction.", "AI": {"tldr": "PAGE-4D extends VGGT to handle dynamic scenes by introducing a dynamics-aware aggregator that disentangles static and dynamic information, enabling simultaneous camera pose estimation, depth prediction, and point cloud reconstruction without post-processing.", "motivation": "Existing 3D feed-forward models trained on static datasets struggle with real-world scenarios containing dynamic elements like moving humans or deformable objects, limiting their practical applicability.", "method": "Proposes a dynamics-aware aggregator that predicts a dynamics-aware mask to suppress motion cues for pose estimation while amplifying them for geometry reconstruction, resolving the inherent conflict between these tasks.", "result": "PAGE-4D consistently outperforms VGGT in dynamic scenarios, achieving superior results in camera pose estimation, monocular and video depth estimation, and dense point map reconstruction.", "conclusion": "The proposed dynamics-aware approach effectively handles dynamic scenes and resolves task conflicts in multi-task 4D reconstruction, demonstrating significant improvements over static-trained models."}}
{"id": "2510.17106", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17106", "abs": "https://arxiv.org/abs/2510.17106", "authors": ["Chen Zhang", "Weixin Bu", "Wendong Xu", "Runsheng Yu", "Yik-Chung Wu", "Ngai Wong"], "title": "Fighter: Unveiling the Graph Convolutional Nature of Transformers in Time Series Modeling", "comment": "Preprint", "summary": "Transformers have achieved remarkable success in time series modeling, yet\ntheir internal mechanisms remain opaque. This work demystifies the Transformer\nencoder by establishing its fundamental equivalence to a Graph Convolutional\nNetwork (GCN). We show that in the forward pass, the attention distribution\nmatrix serves as a dynamic adjacency matrix, and its composition with\nsubsequent transformations performs computations analogous to graph\nconvolution. Moreover, we demonstrate that in the backward pass, the update\ndynamics of value and feed-forward projections mirror those of GCN parameters.\nBuilding on this unified theoretical reinterpretation, we propose\n\\textbf{Fighter} (Flexible Graph Convolutional Transformer), a streamlined\narchitecture that removes redundant linear projections and incorporates\nmulti-hop graph aggregation. This perspective yields an explicit and\ninterpretable representation of temporal dependencies across different scales,\nnaturally expressed as graph edges. Experiments on standard forecasting\nbenchmarks confirm that Fighter achieves competitive performance while\nproviding clearer mechanistic interpretability of its predictions.", "AI": {"tldr": "Transformers are fundamentally equivalent to Graph Convolutional Networks (GCNs), with attention matrices acting as dynamic adjacency matrices and performing graph convolution computations.", "motivation": "To demystify the opaque internal mechanisms of Transformers in time series modeling by establishing their equivalence to GCNs and providing clearer interpretability.", "method": "Proposed Fighter (Flexible Graph Convolutional Transformer) - a streamlined architecture that removes redundant linear projections and incorporates multi-hop graph aggregation based on the GCN equivalence framework.", "result": "Fighter achieves competitive performance on standard forecasting benchmarks while providing clearer mechanistic interpretability of predictions through explicit graph-based temporal dependency representations.", "conclusion": "The GCN equivalence perspective provides a unified theoretical reinterpretation of Transformers that yields both competitive performance and improved interpretability in time series modeling."}}
{"id": "2510.17585", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17585", "abs": "https://arxiv.org/abs/2510.17585", "authors": ["Chuhong Wang", "Hua Li", "Chongyi Li", "Huazhong Liu", "Xiongxin Tang", "Sam Kwong"], "title": "Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset", "comment": null, "summary": "With the development of underwater exploration and marine protection,\nunderwater vision tasks are widespread. Due to the degraded underwater\nenvironment, characterized by color distortion, low contrast, and blurring,\ncamouflaged instance segmentation (CIS) faces greater challenges in accurately\nsegmenting objects that blend closely with their surroundings. Traditional\ncamouflaged instance segmentation methods, trained on terrestrial-dominated\ndatasets with limited underwater samples, may exhibit inadequate performance in\nunderwater scenes. To address these issues, we introduce the first underwater\ncamouflaged instance segmentation (UCIS) dataset, abbreviated as UCIS4K, which\ncomprises 3,953 images of camouflaged marine organisms with instance-level\nannotations. In addition, we propose an Underwater Camouflaged Instance\nSegmentation network based on Segment Anything Model (UCIS-SAM). Our UCIS-SAM\nincludes three key modules. First, the Channel Balance Optimization Module\n(CBOM) enhances channel characteristics to improve underwater feature learning,\neffectively addressing the model's limited understanding of underwater\nenvironments. Second, the Frequency Domain True Integration Module (FDTIM) is\nproposed to emphasize intrinsic object features and reduce interference from\ncamouflage patterns, enhancing the segmentation performance of camouflaged\nobjects blending with their surroundings. Finally, the Multi-scale Feature\nFrequency Aggregation Module (MFFAM) is designed to strengthen the boundaries\nof low-contrast camouflaged instances across multiple frequency bands,\nimproving the model's ability to achieve more precise segmentation of\ncamouflaged objects. Extensive experiments on the proposed UCIS4K and public\nbenchmarks show that our UCIS-SAM outperforms state-of-the-art approaches.", "AI": {"tldr": "The paper introduces UCIS4K, the first underwater camouflaged instance segmentation dataset with 3,953 images, and proposes UCIS-SAM network with three modules (CBOM, FDTIM, MFFAM) to address underwater vision challenges like color distortion and low contrast.", "motivation": "Underwater vision tasks face challenges due to degraded environments with color distortion, low contrast, and blurring. Traditional CIS methods trained on terrestrial datasets perform poorly in underwater scenes where objects blend closely with surroundings.", "method": "Proposed UCIS-SAM network based on Segment Anything Model with three key modules: Channel Balance Optimization Module (CBOM) for underwater feature learning, Frequency Domain True Integration Module (FDTIM) to reduce camouflage interference, and Multi-scale Feature Frequency Aggregation Module (MFFAM) to strengthen boundaries of low-contrast objects.", "result": "Extensive experiments on UCIS4K dataset and public benchmarks show that UCIS-SAM outperforms state-of-the-art approaches in underwater camouflaged instance segmentation.", "conclusion": "The proposed UCIS-SAM network effectively addresses underwater vision challenges and achieves superior performance in segmenting camouflaged marine organisms in degraded underwater environments."}}
{"id": "2510.17120", "categories": ["cs.LG", "cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17120", "abs": "https://arxiv.org/abs/2510.17120", "authors": ["Rishi Sonthalia", "Raj Rao Nadakuditi"], "title": "Matricial Free Energy as a Gaussianizing Regularizer: Enhancing Autoencoders for Gaussian Code Generation", "comment": null, "summary": "We introduce a novel regularization scheme for autoencoders based on\nmatricial free energy. Our approach defines a differentiable loss function in\nterms of the singular values of the code matrix (code dimension x batch size).\nFrom the standpoint of free probability an d random matrix theory, this loss\nachieves its minimum when the singular value distribution of the code matrix\ncoincides with that of an appropriately sculpted random metric with i.i.d.\nGaussian entries. Empirical simulations demonstrate that minimizing the\nnegative matricial free energy through standard stochastic gradient-based\ntraining yields Gaussian-like codes that generalize across training and test\nsets. Building on this foundation, we propose a matricidal free energy\nmaximizing autoencoder that reliably produces Gaussian codes and show its\napplication to underdetermined inverse problems.", "AI": {"tldr": "A novel regularization method for autoencoders using matricial free energy that encourages Gaussian-like codes by matching singular value distributions to random matrices.", "motivation": "To develop a regularization scheme that ensures autoencoders produce Gaussian-like codes that generalize well across training and test sets, particularly useful for underdetermined inverse problems.", "method": "Define a differentiable loss function based on matricial free energy that operates on singular values of the code matrix, then minimize this loss through standard stochastic gradient-based training.", "result": "Empirical simulations show the approach successfully produces Gaussian-like codes that generalize across datasets, and a matricidal free energy maximizing autoencoder reliably generates Gaussian codes.", "conclusion": "The matricial free energy regularization provides an effective way to regularize autoencoders for producing Gaussian codes, with applications to underdetermined inverse problems."}}
{"id": "2510.17603", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17603", "abs": "https://arxiv.org/abs/2510.17603", "authors": ["Shuyuan Zhang", "Chenhan Jiang", "Zuoou Li", "Jiankang Deng"], "title": "ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling", "comment": "NeurIPS 2025 Poster", "summary": "3D generation from natural language offers significant potential to reduce\nexpert manual modeling efforts and enhance accessibility to 3D assets. However,\nexisting methods often yield unstructured meshes and exhibit poor\ninteractivity, making them impractical for artistic workflows. To address these\nlimitations, we represent 3D assets as shape programs and introduce ShapeCraft,\na novel multi-agent framework for text-to-3D generation. At its core, we\npropose a Graph-based Procedural Shape (GPS) representation that decomposes\ncomplex natural language into a structured graph of sub-tasks, thereby\nfacilitating accurate LLM comprehension and interpretation of spatial\nrelationships and semantic shape details. Specifically, LLM agents\nhierarchically parse user input to initialize GPS, then iteratively refine\nprocedural modeling and painting to produce structured, textured, and\ninteractive 3D assets. Qualitative and quantitative experiments demonstrate\nShapeCraft's superior performance in generating geometrically accurate and\nsemantically rich 3D assets compared to existing LLM-based agents. We further\nshow the versatility of ShapeCraft through examples of animated and\nuser-customized editing, highlighting its potential for broader interactive\napplications.", "AI": {"tldr": "ShapeCraft is a multi-agent framework that generates structured, textured 3D assets from natural language using Graph-based Procedural Shape representation and LLM agents for hierarchical parsing and iterative refinement.", "motivation": "To address limitations of existing text-to-3D methods that produce unstructured meshes with poor interactivity, making them impractical for artistic workflows.", "method": "Proposes Graph-based Procedural Shape (GPS) representation that decomposes natural language into structured sub-task graphs, using LLM agents for hierarchical parsing and iterative refinement of procedural modeling and painting.", "result": "Qualitative and quantitative experiments show superior performance in generating geometrically accurate and semantically rich 3D assets compared to existing LLM-based methods, with demonstrated versatility in animation and user-customized editing.", "conclusion": "ShapeCraft enables practical text-to-3D generation with structured, interactive assets suitable for artistic workflows and broader interactive applications."}}
{"id": "2510.17122", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17122", "abs": "https://arxiv.org/abs/2510.17122", "authors": ["Chengxiu Hua", "Jiawen Gu", "Yushun Tang"], "title": "Continuous Q-Score Matching: Diffusion Guided Reinforcement Learning for Continuous-Time Control", "comment": null, "summary": "Reinforcement learning (RL) has achieved significant success across a wide\nrange of domains, however, most existing methods are formulated in discrete\ntime. In this work, we introduce a novel RL method for continuous-time control,\nwhere stochastic differential equations govern state-action dynamics. Departing\nfrom traditional value function-based approaches, our key contribution is the\ncharacterization of continuous-time Q-functions via a martingale condition and\nthe linking of diffusion policy scores to the action gradient of a learned\ncontinuous Q-function by the dynamic programming principle. This insight\nmotivates Continuous Q-Score Matching (CQSM), a score-based policy improvement\nalgorithm. Notably, our method addresses a long-standing challenge in\ncontinuous-time RL: preserving the action-evaluation capability of Q-functions\nwithout relying on time discretization. We further provide theoretical\nclosed-form solutions for linear-quadratic (LQ) control problems within our\nframework. Numerical results in simulated environments demonstrate the\neffectiveness of our proposed method and compare it to popular baselines.", "AI": {"tldr": "A novel continuous-time RL method using stochastic differential equations and martingale conditions for Q-functions, enabling score-based policy improvement without time discretization.", "motivation": "Most RL methods are formulated in discrete time, but many real-world systems operate in continuous time. Existing continuous-time RL approaches struggle to preserve Q-function action-evaluation capabilities without relying on time discretization.", "method": "Characterizes continuous-time Q-functions via martingale condition and links diffusion policy scores to action gradient of learned continuous Q-function using dynamic programming principle. Introduces Continuous Q-Score Matching (CQSM) as a score-based policy improvement algorithm.", "result": "Provides theoretical closed-form solutions for linear-quadratic control problems. Numerical simulations demonstrate effectiveness and show comparison with popular baselines.", "conclusion": "The proposed method successfully addresses the challenge of preserving Q-function action-evaluation capability in continuous-time RL without time discretization, offering a novel framework for continuous-time control problems."}}
{"id": "2510.17609", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17609", "abs": "https://arxiv.org/abs/2510.17609", "authors": ["Siqi Chen", "Shanyue Guan"], "title": "Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation", "comment": null, "summary": "The advancement of UAV technology has enabled efficient, non-contact\nstructural health monitoring. Combined with photogrammetry, UAVs can capture\nhigh-resolution scans and reconstruct detailed 3D models of infrastructure.\nHowever, a key challenge remains in segmenting specific structural components\nfrom these models-a process traditionally reliant on time-consuming and\nerror-prone manual labeling. To address this issue, we propose a machine\nlearning-based framework for automated segmentation of 3D point clouds. Our\napproach uses the complementary strengths of real-world UAV-scanned point\nclouds and synthetic data generated from Building Information Modeling (BIM) to\novercome the limitations associated with manual labeling. Validation on a\nrailroad track dataset demonstrated high accuracy in identifying and segmenting\nmajor components such as rails and crossties. Moreover, by using smaller-scale\ndatasets supplemented with BIM data, the framework significantly reduced\ntraining time while maintaining reasonable segmentation accuracy. This\nautomated approach improves the precision and efficiency of 3D infrastructure\nmodel segmentation and advances the integration of UAV and BIM technologies in\nstructural health monitoring and infrastructure management.", "AI": {"tldr": "A machine learning framework for automated segmentation of 3D point clouds from UAV scans using synthetic BIM data to overcome manual labeling limitations, validated on railroad track datasets.", "motivation": "Manual segmentation of structural components from UAV-captured 3D models is time-consuming and error-prone, creating a need for automated solutions.", "method": "Combines real-world UAV-scanned point clouds with synthetic data from Building Information Modeling (BIM) to train machine learning models for automated segmentation.", "result": "Achieved high accuracy in identifying rails and crossties on railroad track datasets, with reduced training time while maintaining reasonable segmentation accuracy using smaller datasets supplemented with BIM data.", "conclusion": "The automated approach improves precision and efficiency of 3D infrastructure model segmentation and advances integration of UAV and BIM technologies for structural health monitoring."}}
{"id": "2510.17132", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17132", "abs": "https://arxiv.org/abs/2510.17132", "authors": ["Ioannis Tsaknakis", "Bingqing Song", "Shuyu Gan", "Dongyeop Kang", "Alfredo Garcia", "Gaowen Liu", "Charles Fleming", "Mingyi Hong"], "title": "Do LLMs Recognize Your Latent Preferences? A Benchmark for Latent Information Discovery in Personalized Interaction", "comment": null, "summary": "Large Language Models (LLMs) excel at producing broadly relevant text, but\nthis generality becomes a limitation when user-specific preferences are\nrequired, such as recommending restaurants or planning travel. In these\nscenarios, users rarely articulate every preference explicitly; instead, much\nof what they care about remains latent, waiting to be inferred. This raises a\nfundamental question: Can LLMs uncover and reason about such latent information\nthrough conversation?\n  We address this problem by introducing a unified benchmark for evaluating\nlatent information discovery - the ability of LLMs to reveal and utilize hidden\nuser attributes through multi-turn interaction. The benchmark spans three\nprogressively realistic settings: the classic 20 Questions game, Personalized\nQuestion Answering, and Personalized Text Summarization. All tasks share a\ntri-agent framework (User, Assistant, Judge) enabling turn-level evaluation of\nelicitation and adaptation. Our results reveal that while LLMs can indeed\nsurface latent information through dialogue, their success varies dramatically\nwith context: from 32% to 98%, depending on task complexity, topic, and number\nof hidden attributes. This benchmark provides the first systematic framework\nfor studying latent information discovery in personalized interaction,\nhighlighting that effective preference inference remains an open frontier for\nbuilding truly adaptive AI systems.", "AI": {"tldr": "A benchmark for evaluating LLMs' ability to discover latent user information through conversation, showing performance varies from 32% to 98% depending on task complexity.", "motivation": "LLMs struggle with user-specific preferences that aren't explicitly stated, requiring inference of latent information for personalized interactions like recommendations.", "method": "Tri-agent framework (User, Assistant, Judge) across three settings: 20 Questions game, Personalized Question Answering, and Personalized Text Summarization with turn-level evaluation.", "result": "LLMs can surface latent information through dialogue but success varies dramatically (32%-98%) based on task complexity, topic, and number of hidden attributes.", "conclusion": "Effective preference inference remains an open frontier for building truly adaptive AI systems, with this benchmark providing the first systematic framework for studying latent information discovery."}}
{"id": "2510.17611", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17611", "abs": "https://arxiv.org/abs/2510.17611", "authors": ["Jia Guo", "Shuai Lu", "Lei Fan", "Zelin Li", "Donglin Di", "Yang Song", "Weihang Zhang", "Wenbing Zhu", "Hong Yan", "Fang Chen", "Huiqi Li", "Hongen Liao"], "title": "One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection", "comment": "Extended version of CVPR2025", "summary": "Unsupervised anomaly detection (UAD) has evolved from building specialized\nsingle-class models to unified multi-class models, yet existing multi-class\nmodels significantly underperform the most advanced one-for-one counterparts.\nMoreover, the field has fragmented into specialized methods tailored to\nspecific scenarios (multi-class, 3D, few-shot, etc.), creating deployment\nbarriers and highlighting the need for a unified solution. In this paper, we\npresent Dinomaly2, the first unified framework for full-spectrum image UAD,\nwhich bridges the performance gap in multi-class models while seamlessly\nextending across diverse data modalities and task settings. Guided by the \"less\nis more\" philosophy, we demonstrate that the orchestration of five simple\nelement achieves superior performance in a standard reconstruction-based\nframework. This methodological minimalism enables natural extension across\ndiverse tasks without modification, establishing that simplicity is the\nfoundation of true universality. Extensive experiments on 12 UAD benchmarks\ndemonstrate Dinomaly2's full-spectrum superiority across multiple modalities\n(2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class,\ninference-unified multi-class, few-shot) and application domains (industrial,\nbiological, outdoor). For example, our multi-class model achieves unprecedented\n99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For\nmulti-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art\nperformance with minimum adaptations. Moreover, using only 8 normal examples\nper class, our method surpasses previous full-shot models, achieving 98.7% and\n97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design,\ncomputational scalability, and universal applicability positions Dinomaly2 as a\nunified solution for the full spectrum of real-world anomaly detection\napplications.", "AI": {"tldr": "Dinomaly2 is a unified framework for unsupervised anomaly detection that bridges performance gaps in multi-class models and extends across diverse data modalities and task settings using a simple reconstruction-based approach.", "motivation": "Existing multi-class anomaly detection models underperform compared to specialized single-class models, and the field has fragmented into scenario-specific methods, creating deployment barriers that require a unified solution.", "method": "A reconstruction-based framework that orchestrates five simple elements following the \"less is more\" philosophy, enabling natural extension across diverse tasks without modification.", "result": "Achieves unprecedented 99.9% and 99.3% image-level AUROC on MVTec-AD and VisA respectively for multi-class models, and state-of-the-art performance across multiple modalities (2D, multi-view, RGB-3D, RGB-IR) and task settings with minimal adaptations.", "conclusion": "Dinomaly2's minimalistic design, computational scalability, and universal applicability position it as a unified solution for the full spectrum of real-world anomaly detection applications."}}
{"id": "2510.17136", "categories": ["cs.LG", "I.2.6; I.5.1; I.5.4"], "pdf": "https://arxiv.org/pdf/2510.17136", "abs": "https://arxiv.org/abs/2510.17136", "authors": ["Enhao Gu", "Haolin Hou"], "title": "In-situ Autoguidance: Eliciting Self-Correction in Diffusion Models", "comment": "6 pages, 3 figures. ICML 2025 Workshop submission", "summary": "The generation of high-quality, diverse, and prompt-aligned images is a\ncentral goal in image-generating diffusion models. The popular classifier-free\nguidance (CFG) approach improves quality and alignment at the cost of reduced\nvariation, creating an inherent entanglement of these effects. Recent work has\nsuccessfully disentangled these properties by guiding a model with a separately\ntrained, inferior counterpart; however, this solution introduces the\nconsiderable overhead of requiring an auxiliary model. We challenge this\nprerequisite by introducing In-situ Autoguidance, a method that elicits\nguidance from the model itself without any auxiliary components. Our approach\ndynamically generates an inferior prediction on the fly using a stochastic\nforward pass, reframing guidance as a form of inference-time self-correction.\nWe demonstrate that this zero-cost approach is not only viable but also\nestablishes a powerful new baseline for cost-efficient guidance, proving that\nthe benefits of self-guidance can be achieved without external models.", "AI": {"tldr": "In-situ Autoguidance enables diffusion models to self-correct during inference without needing auxiliary models, achieving quality and alignment improvements while maintaining diversity.", "motivation": "Classifier-free guidance improves image quality and prompt alignment but reduces diversity and requires auxiliary models, creating overhead.", "method": "Dynamic generation of inferior predictions using stochastic forward passes, reframing guidance as inference-time self-correction without external components.", "result": "Zero-cost approach establishes new baseline for cost-efficient guidance, proving self-guidance benefits can be achieved without external models.", "conclusion": "In-situ Autoguidance successfully disentangles quality, diversity, and alignment in diffusion models through self-correction, eliminating need for auxiliary models."}}
{"id": "2510.17626", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17626", "abs": "https://arxiv.org/abs/2510.17626", "authors": ["Fr\u00e9d\u00e9ric LIN", "Biruk Abere Ambaw", "Adrian Popescu", "Hejer Ammar", "Romaric Audigier", "Herv\u00e9 Le Borgne"], "title": "CaMiT: A Time-Aware Car Model Dataset for Classification and Generation", "comment": "To be published in NeurIPS 2025 Track on Datasets and Benchmarks", "summary": "AI systems must adapt to evolving visual environments, especially in domains\nwhere object appearances change over time. We introduce Car Models in Time\n(CaMiT), a fine-grained dataset capturing the temporal evolution of car models,\na representative class of technological artifacts. CaMiT includes 787K labeled\nsamples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023),\nsupporting both supervised and self-supervised learning. Static pretraining on\nin-domain data achieves competitive performance with large-scale generalist\nmodels while being more resource-efficient, yet accuracy declines when models\nare tested across years. To address this, we propose a time-incremental\nclassification setting, a realistic continual learning scenario with emerging,\nevolving, and disappearing classes. We evaluate two strategies:\ntime-incremental pretraining, which updates the backbone, and time-incremental\nclassifier learning, which updates only the final layer, both improving\ntemporal robustness. Finally, we explore time-aware image generation that\nleverages temporal metadata during training, yielding more realistic outputs.\nCaMiT offers a rich benchmark for studying temporal adaptation in fine-grained\nvisual recognition and generation.", "AI": {"tldr": "CaMiT dataset tracks car model evolution over time (2007-2023) with 787K labeled and 5.1M unlabeled samples. Static models decline in accuracy across years, but time-incremental learning strategies improve temporal robustness. Also explores time-aware image generation.", "motivation": "AI systems need to adapt to evolving visual environments where object appearances change over time, particularly for technological artifacts like cars that undergo continuous redesign.", "method": "Created CaMiT dataset with temporal car model data. Evaluated static pretraining vs time-incremental strategies: updating backbone or just final classifier layer. Also explored time-aware image generation using temporal metadata.", "result": "Static pretraining achieves competitive performance but accuracy declines across years. Time-incremental learning (both backbone and classifier updates) improves temporal robustness. Time-aware generation produces more realistic outputs.", "conclusion": "CaMiT provides a benchmark for studying temporal adaptation in fine-grained visual recognition and generation, demonstrating the importance of temporal adaptation strategies for real-world AI systems."}}
{"id": "2510.17160", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17160", "abs": "https://arxiv.org/abs/2510.17160", "authors": ["Derda Kaymak", "Gyuhak Kim", "Tomoya Kaichi", "Tatsuya Konishi", "Bing Liu"], "title": "Learning After Model Deployment", "comment": "Published at ECAI-2025", "summary": "In classic supervised learning, once a model is deployed in an application,\nit is fixed. No updates will be made to it during the application. This is\ninappropriate for many dynamic and open environments, where unexpected samples\nfrom unseen classes may appear. In such an environment, the model should be\nable to detect these novel samples from unseen classes and learn them after\nthey are labeled. We call this paradigm Autonomous Learning after Model\nDeployment (ALMD). The learning here is continuous and involves no human\nengineers. Labeling in this scenario is performed by human co-workers or other\nknowledgeable agents, which is similar to what humans do when they encounter an\nunfamiliar object and ask another person for its name. In ALMD, the detection\nof novel samples is dynamic and differs from traditional out-of-distribution\n(OOD) detection in that the set of in-distribution (ID) classes expands as new\nclasses are learned during application, whereas ID classes is fixed in\ntraditional OOD detection. Learning is also different from classic supervised\nlearning because in ALMD, we learn the encountered new classes immediately and\nincrementally. It is difficult to retrain the model from scratch using all the\npast data from the ID classes and the novel samples from newly discovered\nclasses, as this would be resource- and time-consuming. Apart from these two\nchallenges, ALMD faces the data scarcity issue because instances of new classes\noften appear sporadically in real-life applications. To address these issues,\nwe propose a novel method, PLDA, which performs dynamic OOD detection and\nincremental learning of new classes on the fly. Empirical evaluations will\ndemonstrate the effectiveness of PLDA.", "AI": {"tldr": "The paper proposes Autonomous Learning after Model Deployment (ALMD) to address the limitation of fixed models in dynamic environments where unexpected samples from unseen classes may appear, and introduces PLDA method for dynamic OOD detection and incremental learning.", "motivation": "Traditional supervised learning deploys fixed models that cannot adapt to dynamic environments where novel samples from unseen classes appear. This is inappropriate for real-world applications requiring continuous learning without human engineers.", "method": "Proposes PLDA method that performs dynamic out-of-distribution (OOD) detection and incremental learning of new classes on the fly, addressing challenges of expanding ID classes, immediate learning needs, and data scarcity.", "result": "Empirical evaluations demonstrate the effectiveness of PLDA in handling ALMD challenges.", "conclusion": "ALMD paradigm enables continuous learning in dynamic environments, and PLDA provides an effective solution for dynamic OOD detection and incremental learning of new classes during application deployment."}}
{"id": "2510.17644", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17644", "abs": "https://arxiv.org/abs/2510.17644", "authors": ["Zexian Huang", "Mashnoon Islam", "Brian Armstrong", "Kourosh Khoshelham", "Martin Tomko"], "title": "Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives", "comment": null, "summary": "Dry-stone walls hold significant heritage and environmental value. Mapping\nthese structures is essential for ecosystem preservation and wildfire\nmanagement in Australia. Yet, many walls remain unidentified due to their\ninaccessibility and the high cost of manual mapping. Deep learning-based\nsegmentation offers a scalable solution, but two major challenges persist: (1)\nvisual occlusion of low-lying walls by dense vegetation, and (2) limited\nlabeled data for supervised training. We propose DINO-CV, a segmentation\nframework for automatic mapping of low-lying dry-stone walls using\nhigh-resolution Airborne LiDAR-derived digital elevation models (DEMs). DEMs\novercome visual occlusion by capturing terrain structures hidden beneath\nvegetation, enabling analysis of structural rather than spectral cues. DINO-CV\nintroduces a self-supervised cross-view pre-training strategy based on\nknowledge distillation to mitigate data scarcity. It learns invariant visual\nand geometric representations across multiple DEM derivatives, supporting\nvarious vision backbones including ResNet, Wide ResNet, and Vision\nTransformers. Applied to the UNESCO World Heritage cultural landscape of Budj\nBim, Victoria, the method identifies one of Australia's densest collections of\ncolonial dry-stone walls beyond Indigenous heritage contexts. DINO-CV achieves\na mean Intersection over Union (mIoU) of 68.6% on test areas and maintains\n63.8% mIoU when fine-tuned with only 10% labeled data. These results\ndemonstrate the potential of self-supervised learning on high-resolution DEM\nderivatives for automated dry-stone wall mapping in vegetated and heritage-rich\nenvironments with scarce annotations.", "AI": {"tldr": "DINO-CV is a self-supervised segmentation framework that uses high-resolution LiDAR-derived DEMs to automatically map low-lying dry-stone walls in vegetated areas, overcoming visual occlusion and data scarcity challenges.", "motivation": "Dry-stone walls have heritage and environmental value but are difficult to map due to visual occlusion by dense vegetation and limited labeled data for supervised training. Current manual mapping is expensive and inaccessible.", "method": "Uses high-resolution Airborne LiDAR-derived DEMs to capture terrain structures beneath vegetation. Introduces self-supervised cross-view pre-training based on knowledge distillation to learn invariant visual and geometric representations across multiple DEM derivatives. Supports various vision backbones including ResNet, Wide ResNet, and Vision Transformers.", "result": "Achieved 68.6% mIoU on test areas and maintained 63.8% mIoU when fine-tuned with only 10% labeled data. Successfully identified dense collections of colonial dry-stone walls in Budj Bim, Victoria.", "conclusion": "Demonstrates the potential of self-supervised learning on high-resolution DEM derivatives for automated dry-stone wall mapping in vegetated and heritage-rich environments with scarce annotations."}}
{"id": "2510.17162", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17162", "abs": "https://arxiv.org/abs/2510.17162", "authors": ["Guanjie Cheng", "Siyang Liu", "Junqin Huang", "Xinkui Zhao", "Yin Wang", "Mengying Zhu", "Linghe Kong", "Shuiguang Deng"], "title": "ALPINE: A Lightweight and Adaptive Privacy-Decision Agent Framework for Dynamic Edge Crowdsensing", "comment": "12 pages, 8 figures, 4 tables. Submitted to The Web Conference (WWW\n  2026)", "summary": "Mobile edge crowdsensing (MECS) systems continuously generate and transmit\nuser data in dynamic, resource-constrained environments, exposing users to\nsignificant privacy threats. In practice, many privacy-preserving mechanisms\nbuild on differential privacy (DP). However, static DP mechanisms often fail to\nadapt to evolving risks, for example, shifts in adversarial capabilities,\nresource constraints and task requirements, resulting in either excessive noise\nor inadequate protection. To address this challenge, we propose ALPINE, a\nlightweight, adaptive framework that empowers terminal devices to autonomously\nadjust differential privacy levels in real time. ALPINE operates as a\nclosed-loop control system consisting of four modules: dynamic risk perception,\nprivacy decision via twin delayed deep deterministic policy gradient (TD3),\nlocal privacy execution and performance verification from edge nodes. Based on\nenvironmental risk assessments, we design a reward function that balances\nprivacy gains, data utility and energy cost, guiding the TD3 agent to\nadaptively tune noise magnitude across diverse risk scenarios and achieve a\ndynamic equilibrium among privacy, utility and cost. Both the collaborative\nrisk model and pretrained TD3-based agent are designed for low-overhead\ndeployment. Extensive theoretical analysis and real-world simulations\ndemonstrate that ALPINE effectively mitigates inference attacks while\npreserving utility and cost, making it practical for large-scale edge\napplications.", "AI": {"tldr": "ALPINE is a lightweight adaptive framework that enables mobile edge devices to autonomously adjust differential privacy levels in real-time using a closed-loop control system with TD3-based decision making.", "motivation": "Static differential privacy mechanisms fail to adapt to evolving privacy risks, resource constraints, and task requirements in mobile edge crowdsensing systems, leading to either excessive noise or inadequate protection.", "method": "ALPINE uses a closed-loop control system with four modules: dynamic risk perception, privacy decision via TD3 reinforcement learning, local privacy execution, and performance verification from edge nodes. It balances privacy, utility, and energy costs through an adaptive reward function.", "result": "Extensive theoretical analysis and real-world simulations show ALPINE effectively mitigates inference attacks while preserving data utility and managing energy costs, making it practical for large-scale edge applications.", "conclusion": "ALPINE provides a practical solution for adaptive differential privacy in mobile edge environments, achieving dynamic equilibrium between privacy protection, data utility, and resource constraints through lightweight, autonomous operation."}}
{"id": "2510.17651", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17651", "abs": "https://arxiv.org/abs/2510.17651", "authors": ["S\u00e9bastien Thuau", "Siba Haidar", "Ayush Bajracharya", "Rachid Chelouah"], "title": "Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs", "comment": "7 pages, 1 figure, FLTA 2025", "summary": "We examine frugal federated learning approaches to violence detection by\ncomparing two complementary strategies: (i) zero-shot and federated fine-tuning\nof vision-language models (VLMs), and (ii) personalized training of a compact\n3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter\nCNN3D as representative cases, we evaluate accuracy, calibration, and energy\nusage under realistic non-IID settings.\n  Both approaches exceed 90% accuracy. CNN3D slightly outperforms Low-Rank\nAdaptation(LoRA)-tuned VLMs in ROC AUC and log loss, while using less energy.\nVLMs remain favorable for contextual reasoning and multimodal inference. We\nquantify energy and CO$_2$ emissions across training and inference, and analyze\nsustainability trade-offs for deployment.\n  To our knowledge, this is the first comparative study of LoRA-tuned\nvision-language models and personalized CNNs for federated violence detection,\nwith an emphasis on energy efficiency and environmental metrics.\n  These findings support a hybrid model: lightweight CNNs for routine\nclassification, with selective VLM activation for complex or descriptive\nscenarios. The resulting framework offers a reproducible baseline for\nresponsible, resource-aware AI in video surveillance, with extensions toward\nreal-time, multimodal, and lifecycle-aware systems.", "AI": {"tldr": "This paper compares two frugal federated learning approaches for violence detection: zero-shot/fine-tuned vision-language models (VLMs) and personalized 3D CNNs, evaluating accuracy, calibration, and energy usage under non-IID settings.", "motivation": "To develop energy-efficient and environmentally sustainable AI solutions for violence detection in video surveillance, addressing the need for resource-aware federated learning approaches.", "method": "Compared two strategies: (i) zero-shot and federated fine-tuning of vision-language models (LLaVA-7B), and (ii) personalized training of a compact 3D CNN (65.8M parameters). Evaluated accuracy, calibration, and energy usage under realistic non-IID settings.", "result": "Both approaches exceeded 90% accuracy. CNN3D slightly outperformed LoRA-tuned VLMs in ROC AUC and log loss while using less energy. VLMs remained better for contextual reasoning and multimodal inference. Energy and CO2 emissions were quantified across training and inference.", "conclusion": "Proposes a hybrid model: lightweight CNNs for routine classification with selective VLM activation for complex scenarios. Provides a reproducible baseline for responsible, resource-aware AI in video surveillance."}}
{"id": "2510.17185", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17185", "abs": "https://arxiv.org/abs/2510.17185", "authors": ["Runlin Lei", "Lu Yi", "Mingguo He", "Pengyu Qiu", "Zhewei Wei", "Yongchao Liu", "Chuntao Hong"], "title": "Robustness in Text-Attributed Graph Learning: Insights, Trade-offs, and New Defenses", "comment": null, "summary": "While Graph Neural Networks (GNNs) and Large Language Models (LLMs) are\npowerful approaches for learning on Text-Attributed Graphs (TAGs), a\ncomprehensive understanding of their robustness remains elusive. Current\nevaluations are fragmented, failing to systematically investigate the distinct\neffects of textual and structural perturbations across diverse models and\nattack scenarios. To address these limitations, we introduce a unified and\ncomprehensive framework to evaluate robustness in TAG learning. Our framework\nevaluates classical GNNs, robust GNNs (RGNNs), and GraphLLMs across ten\ndatasets from four domains, under diverse text-based, structure-based, and\nhybrid perturbations in both poisoning and evasion scenarios. Our extensive\nanalysis reveals multiple findings, among which three are particularly\nnoteworthy: 1) models have inherent robustness trade-offs between text and\nstructure, 2) the performance of GNNs and RGNNs depends heavily on the text\nencoder and attack type, and 3) GraphLLMs are particularly vulnerable to\ntraining data corruption. To overcome the identified trade-offs, we introduce\nSFT-auto, a novel framework that delivers superior and balanced robustness\nagainst both textual and structural attacks within a single model. Our work\nestablishes a foundation for future research on TAG security and offers\npractical solutions for robust TAG learning in adversarial environments. Our\ncode is available at: https://github.com/Leirunlin/TGRB.", "AI": {"tldr": "This paper introduces a comprehensive framework to evaluate robustness of GNNs and LLMs on Text-Attributed Graphs, revealing inherent trade-offs between text and structure robustness, and proposes SFT-auto for balanced defense.", "motivation": "Current evaluations of GNN and LLM robustness on Text-Attributed Graphs are fragmented and fail to systematically investigate effects of textual and structural perturbations across different models and attack scenarios.", "method": "Developed a unified framework to evaluate classical GNNs, robust GNNs, and GraphLLMs across 10 datasets from 4 domains under text-based, structure-based, and hybrid perturbations in poisoning and evasion scenarios.", "result": "Key findings: 1) Models have inherent robustness trade-offs between text and structure, 2) GNN/RGNN performance depends heavily on text encoder and attack type, 3) GraphLLMs are particularly vulnerable to training data corruption.", "conclusion": "The work establishes foundation for future TAG security research and introduces SFT-auto framework that provides superior balanced robustness against both textual and structural attacks in a single model."}}
{"id": "2510.17664", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17664", "abs": "https://arxiv.org/abs/2510.17664", "authors": ["Ling Liu", "Jun Tian", "Li Yi"], "title": "4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads", "comment": null, "summary": "4D panoptic segmentation in a streaming setting is critical for highly\ndynamic environments, such as evacuating dense crowds and autonomous driving in\ncomplex scenarios, where real-time, fine-grained perception within a\nconstrained time budget is essential. In this paper, we introduce\n4DSegStreamer, a novel framework that employs a Dual-Thread System to\nefficiently process streaming frames. The framework is general and can be\nseamlessly integrated into existing 3D and 4D segmentation methods to enable\nreal-time capability. It also demonstrates superior robustness compared to\nexisting streaming perception approaches, particularly under high FPS\nconditions. The system consists of a predictive thread and an inference thread.\nThe predictive thread leverages historical motion and geometric information to\nextract features and forecast future dynamics. The inference thread ensures\ntimely prediction for incoming frames by aligning with the latest memory and\ncompensating for ego-motion and dynamic object movements. We evaluate\n4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and\nnuScenes datasets. Comprehensive experiments demonstrate the effectiveness of\nour approach, particularly in accurately predicting dynamic objects in complex\nscenes.", "AI": {"tldr": "4DSegStreamer is a novel framework for real-time 4D panoptic segmentation in streaming settings, using a dual-thread system to efficiently process dynamic scenes within constrained time budgets.", "motivation": "Address the need for real-time, fine-grained perception in highly dynamic environments like crowd evacuation and autonomous driving, where existing methods lack efficiency and robustness under high FPS conditions.", "method": "Employs a Dual-Thread System with predictive and inference threads. The predictive thread uses historical motion/geometric data to forecast future dynamics, while the inference thread ensures timely predictions by aligning with latest memory and compensating for ego-motion and object movements.", "result": "Demonstrates superior robustness compared to existing streaming approaches, particularly under high FPS conditions. Effectively predicts dynamic objects in complex scenes across indoor (HOI4D) and outdoor (SemanticKITTI, nuScenes) datasets.", "conclusion": "4DSegStreamer provides an efficient, general framework that can be integrated into existing 3D/4D segmentation methods to enable real-time capability, making it suitable for dynamic real-world applications."}}
{"id": "2510.17187", "categories": ["cs.LG", "q-bio.BM", "92B20"], "pdf": "https://arxiv.org/pdf/2510.17187", "abs": "https://arxiv.org/abs/2510.17187", "authors": ["Alexander Aghili", "Andy Bruce", "Daniel Sabo", "Sanya Murdeshwar", "Kevin Bachelor", "Ionut Mistreanu", "Ashwin Lokapally", "Razvan Marinescu"], "title": "A Standardized Benchmark for Machine-Learned Molecular Dynamics using Weighted Ensemble Sampling", "comment": "37 Pages (Main Text), 10 Figures, Submitted to Journal of Physical\n  Chemistry B", "summary": "The rapid evolution of molecular dynamics (MD) methods, including\nmachine-learned dynamics, has outpaced the development of standardized tools\nfor method validation. Objective comparison between simulation approaches is\noften hindered by inconsistent evaluation metrics, insufficient sampling of\nrare conformational states, and the absence of reproducible benchmarks. To\naddress these challenges, we introduce a modular benchmarking framework that\nsystematically evaluates protein MD methods using enhanced sampling analysis.\nOur approach uses weighted ensemble (WE) sampling via The Weighted Ensemble\nSimulation Toolkit with Parallelization and Analysis (WESTPA), based on\nprogress coordinates derived from Time-lagged Independent Component Analysis\n(TICA), enabling fast and efficient exploration of protein conformational\nspace. The framework includes a flexible, lightweight propagator interface that\nsupports arbitrary simulation engines, allowing both classical force fields and\nmachine learning-based models. Additionally, the framework offers a\ncomprehensive evaluation suite capable of computing more than 19 different\nmetrics and visualizations across a variety of domains. We further contribute a\ndataset of nine diverse proteins, ranging from 10 to 224 residues, that span a\nvariety of folding complexities and topologies. Each protein has been\nextensively simulated at 300K for one million MD steps per starting point (4\nns). To demonstrate the utility of our framework, we perform validation tests\nusing classic MD simulations with implicit solvent and compare protein\nconformational sampling using a fully trained versus under-trained CGSchNet\nmodel. By standardizing evaluation protocols and enabling direct, reproducible\ncomparisons across MD approaches, our open-source platform lays the groundwork\nfor consistent, rigorous benchmarking across the molecular simulation\ncommunity.", "AI": {"tldr": "A modular benchmarking framework for protein molecular dynamics methods that uses weighted ensemble sampling and comprehensive evaluation metrics to enable standardized, reproducible comparisons across different simulation approaches.", "motivation": "The rapid evolution of MD methods has outpaced standardized validation tools, hindering objective comparisons due to inconsistent metrics, insufficient rare state sampling, and lack of reproducible benchmarks.", "method": "Uses weighted ensemble sampling via WESTPA with TICA-derived progress coordinates, a flexible propagator interface supporting arbitrary simulation engines, and computes over 19 different metrics across various domains.", "result": "Developed a dataset of nine diverse proteins (10-224 residues) with extensive simulations, and demonstrated framework utility by comparing classical MD with implicit solvent versus trained/under-trained CGSchNet models.", "conclusion": "The open-source platform standardizes evaluation protocols and enables direct, reproducible comparisons across MD approaches, establishing groundwork for consistent, rigorous benchmarking in molecular simulation."}}
{"id": "2510.17681", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17681", "abs": "https://arxiv.org/abs/2510.17681", "authors": ["Yuandong Pu", "Le Zhuo", "Songhao Han", "Jinbo Xing", "Kaiwen Zhu", "Shuo Cao", "Bin Fu", "Si Liu", "Hongsheng Li", "Yu Qiao", "Wenlong Zhang", "Xi Chen", "Yihao Liu"], "title": "PICABench: How Far Are We from Physically Realistic Image Editing?", "comment": null, "summary": "Image editing has achieved remarkable progress recently. Modern editing\nmodels could already follow complex instructions to manipulate the original\ncontent. However, beyond completing the editing instructions, the accompanying\nphysical effects are the key to the generation realism. For example, removing\nan object should also remove its shadow, reflections, and interactions with\nnearby objects. Unfortunately, existing models and benchmarks mainly focus on\ninstruction completion but overlook these physical effects. So, at this moment,\nhow far are we from physically realistic image editing? To answer this, we\nintroduce PICABench, which systematically evaluates physical realism across\neight sub-dimension (spanning optics, mechanics, and state transitions) for\nmost of the common editing operations (add, remove, attribute change, etc). We\nfurther propose the PICAEval, a reliable evaluation protocol that uses\nVLM-as-a-judge with per-case, region-level human annotations and questions.\nBeyond benchmarking, we also explore effective solutions by learning physics\nfrom videos and construct a training dataset PICA-100K. After evaluating most\nof the mainstream models, we observe that physical realism remains a\nchallenging problem with large rooms to explore. We hope that our benchmark and\nproposed solutions can serve as a foundation for future work moving from naive\ncontent editing toward physically consistent realism.", "AI": {"tldr": "PICABench is a benchmark that evaluates physical realism in image editing across eight dimensions, revealing that current models struggle with physical consistency despite good instruction completion.", "motivation": "Current image editing models focus on completing editing instructions but overlook accompanying physical effects like shadows, reflections, and object interactions, which are crucial for realism.", "method": "Introduces PICABench with systematic evaluation across eight physical dimensions, PICAEval protocol using VLM-as-a-judge with human annotations, and PICA-100K dataset from video learning.", "result": "Evaluation of mainstream models shows physical realism remains challenging with significant room for improvement, as models fail to maintain physical consistency.", "conclusion": "The benchmark and proposed solutions provide a foundation for advancing from naive content editing to physically consistent realism in image manipulation."}}
{"id": "2510.17189", "categories": ["cs.LG", "cs.AR"], "pdf": "https://arxiv.org/pdf/2510.17189", "abs": "https://arxiv.org/abs/2510.17189", "authors": ["Wenxun Wang", "Shuchang Zhou", "Wenyu Sun", "Peiqin Sun", "Yongpan Liu"], "title": "SOLE: Hardware-Software Co-design of Softmax and LayerNorm for Efficient Transformer Inference", "comment": null, "summary": "Transformers have shown remarkable performance in both natural language\nprocessing (NLP) and computer vision (CV) tasks. However, their real-time\ninference speed and efficiency are limited due to the inefficiency in Softmax\nand Layer Normalization (LayerNorm). Previous works based on function\napproximation suffer from inefficient implementation as they place emphasis on\ncomputation while disregarding memory overhead concerns. Moreover, such methods\nrely on retraining to compensate for approximation error which can be costly\nand inconvenient.\n  In this paper, we present SOLE, a hardware-software co-design for Softmax and\nLayerNorm which is composed of E2Softmax and AILayerNorm. E2Softmax utilizes\nlog2 quantization of exponent function and log-based division to approximate\nSoftmax while AILayerNorm adopts low-precision statistic calculation. Compared\nwith state-of-the-art designs, we achieve both low-precision calculation and\nlow bit-width storage on Softmax and LayerNorm. Experiments show that SOLE\nmaintains inference accuracy without retraining while offering orders of\nmagnitude speedup and energy savings over GPU, achieving 3.04x, 3.86x\nenergy-efficiency improvements and 2.82x, 3.32x area-efficiency improvements\nover prior state-of-the-art custom hardware for Softmax and LayerNorm,\nrespectively.", "AI": {"tldr": "SOLE is a hardware-software co-design that optimizes Transformer inference by approximating Softmax with E2Softmax (using log2 quantization) and LayerNorm with AILayerNorm (using low-precision statistics), achieving significant speedup and energy savings without retraining.", "motivation": "Transformers have performance limitations due to inefficient Softmax and LayerNorm operations. Previous approximation methods suffer from memory overhead issues and require costly retraining to compensate for errors.", "method": "SOLE combines E2Softmax (log2 quantization of exponent function and log-based division) and AILayerNorm (low-precision statistic calculation) in a hardware-software co-design approach.", "result": "SOLE maintains inference accuracy without retraining while achieving 3.04x and 3.86x energy-efficiency improvements, and 2.82x and 3.32x area-efficiency improvements over prior state-of-the-art custom hardware for Softmax and LayerNorm respectively.", "conclusion": "SOLE provides an effective hardware-software co-design solution that significantly improves Transformer inference efficiency for both Softmax and LayerNorm operations without requiring model retraining."}}
{"id": "2510.17684", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17684", "abs": "https://arxiv.org/abs/2510.17684", "authors": ["Xinwei Zhang", "Hu Chen", "Zhe Yuan", "Sukun Tian", "Peng Feng"], "title": "Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model", "comment": null, "summary": "Foundation models for medical image segmentation have achieved remarkable\nperformance. Adaptive fine-tuning of natural image segmentation foundation\nmodels is crucial for medical image segmentation tasks. However, some\nlimitations exist in existing fine-tuning methods: 1) insufficient\nrepresentation of high-level features and 2) the fine-tuning process disrupts\nthe structural integrity of pretrained weights. Inspired by these critical\nproblems, we propose an intelligent communication mixture-of-experts\nboosted-medical image segmentation foundation model, named IC-MoE, with twofold\nideas: 1) We construct basic experts, semantic experts, and adaptive experts.\nMoreover, we implement a pixel probability adaptive voting strategy, which\nenables expert selection and fusion through label consistency and load\nbalancing. This approach preliminarily enhances the representation capability\nof high-level features while preserving the structural integrity of pretrained\nweights. 2) We propose a semantic-guided contrastive learning method to address\nthe issue of weak supervision in contrastive learning. This method further\nenhances the representation capability of high-level features while preserving\nthe structural integrity of pretrained weights. Extensive experiments across\nthree public medical image segmentation datasets demonstrate that the IC-MoE\noutperforms other SOTA models. Consequently, the proposed IC-MoE effectively\nsupplements foundational medical image segmentation models with high-level\nfeatures and pretrained structural integrity. We also validate the superior\ngeneralizability of the IC-MoE across diverse medical image segmentation\nscenarios.", "AI": {"tldr": "IC-MoE is a medical image segmentation foundation model that uses mixture-of-experts with pixel probability adaptive voting and semantic-guided contrastive learning to enhance high-level feature representation while preserving pretrained weight integrity.", "motivation": "Existing fine-tuning methods for medical image segmentation have limitations: insufficient representation of high-level features and disruption of pretrained weight structural integrity during fine-tuning.", "method": "1) Construct three types of experts (basic, semantic, adaptive) with pixel probability adaptive voting strategy for expert selection and fusion. 2) Use semantic-guided contrastive learning to address weak supervision in contrastive learning.", "result": "Extensive experiments on three public medical image segmentation datasets show IC-MoE outperforms other state-of-the-art models and demonstrates superior generalizability across diverse medical image segmentation scenarios.", "conclusion": "IC-MoE effectively supplements foundational medical image segmentation models with enhanced high-level features and preserved pretrained structural integrity."}}
{"id": "2510.17206", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17206", "abs": "https://arxiv.org/abs/2510.17206", "authors": ["Michael Hersche", "Samuel Moor-Smith", "Thomas Hofmann", "Abbas Rahimi"], "title": "Soft-Masked Diffusion Language Models", "comment": null, "summary": "Diffusion models have demonstrated strong potential in language modeling,\noffering various advantages over traditional autoregressive approaches. Their\nability to generate and revise entire responses in parallel enables faster\ngeneration and built-in self-correction mechanisms. Most modern diffusion-based\nlanguage models employ masked diffusion, where decoding involves iteratively\nprocessing masked tokens based on a binary decision: either retaining the mask\nor replacing it with the predicted token. However, this binary choice discards\nvaluable predictive information when the mask is retained. To address this\nlimitation, we introduce soft-masking (SM), a novel method that dynamically\nblends the embedding of the mask token with the embeddings of the top-$k$\npredicted tokens from the previous decoding step, for each retained mask. This\nprovides the model with a more informative prior, preserving context from\nearlier computations and allowing partial information about masked tokens to\npropagate beyond a single step. We propose a training methodology that adapts a\npretrained masked diffusion language model to incorporate SM. We demonstrate\nthat continuing pretraining a 169M parameter model with SM leads to improved\nperplexity and MAUVE scores. Furthermore, we finetune two state-of-the-art\ndiffusion models, Dream-7B and Dream-Coder-7B, with SM. SM consistently\nimproves performance across multiple coding benchmarks, particularly in\nhigh-throughput settings.", "AI": {"tldr": "The paper introduces soft-masking (SM), a novel method that improves masked diffusion language models by dynamically blending mask token embeddings with top-k predicted tokens from previous steps, preserving valuable predictive information.", "motivation": "Traditional masked diffusion models use binary decisions (retain mask or replace with predicted token) which discard valuable predictive information when masks are retained, limiting model performance.", "method": "Soft-masking dynamically blends mask token embeddings with embeddings of top-k predicted tokens from previous decoding steps for retained masks, providing more informative priors and allowing partial token information to propagate beyond single steps.", "result": "SM improves perplexity and MAUVE scores for a 169M parameter model, and consistently enhances performance across multiple coding benchmarks for Dream-7B and Dream-Coder-7B models, especially in high-throughput settings.", "conclusion": "Soft-masking effectively addresses limitations of traditional masked diffusion by preserving predictive context and enabling better information propagation, leading to improved performance in language modeling and coding tasks."}}
{"id": "2510.17685", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17685", "abs": "https://arxiv.org/abs/2510.17685", "authors": ["Min Cao", "Xinyu Zhou", "Ding Jiang", "Bo Du", "Mang Ye", "Min Zhang"], "title": "Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning", "comment": "Final version published in IEEE Transactions on Pattern Analysis and\n  Machine Intelligence (TPAMI). Xplore link:\n  https://ieeexplore.ieee.org/document/11199360", "summary": "Text-to-image person retrieval (TIPR) aims to identify the target person\nusing textual descriptions, facing challenge in modality heterogeneity. Prior\nworks have attempted to address it by developing cross-modal global or local\nalignment strategies. However, global methods typically overlook fine-grained\ncross-modal differences, whereas local methods require prior information to\nexplore explicit part alignments. Additionally, current methods are\nEnglish-centric, restricting their application in multilingual contexts. To\nalleviate these issues, we pioneer a multilingual TIPR task by developing a\nmultilingual TIPR benchmark, for which we leverage large language models for\ninitial translations and refine them by integrating domain-specific knowledge.\nCorrespondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation\nReasoning and Aligning framework to learn alignment across languages and\nmodalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module\nenables bidirectional prediction of masked image and text, implicitly enhancing\nthe modeling of local relations across languages and modalities, a\nmulti-dimensional global alignment module is integrated to bridge the modality\nheterogeneity. The proposed method achieves new state-of-the-art results on all\nmultilingual TIPR datasets. Data and code are presented in\nhttps://github.com/Flame-Chasers/Bi-IRRA.", "AI": {"tldr": "Bi-IRRA is a bidirectional implicit relation reasoning framework for multilingual text-to-image person retrieval that achieves state-of-the-art performance by combining bidirectional masked prediction with multi-dimensional global alignment.", "motivation": "Address limitations in existing text-to-image person retrieval methods: global methods overlook fine-grained differences, local methods require prior information for part alignments, and current approaches are English-centric, restricting multilingual applications.", "method": "Proposes Bi-IRRA framework with: 1) bidirectional implicit relation reasoning module for masked image and text prediction to model local relations across languages and modalities, 2) multi-dimensional global alignment module to bridge modality heterogeneity.", "result": "Achieves new state-of-the-art results on all multilingual TIPR datasets. Also creates a new multilingual TIPR benchmark using LLM translations refined with domain-specific knowledge.", "conclusion": "Bi-IRRA effectively addresses multilingual text-to-image person retrieval by combining implicit local relation reasoning with global alignment, overcoming limitations of previous English-centric approaches and achieving superior performance across multilingual datasets."}}
{"id": "2510.17212", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17212", "abs": "https://arxiv.org/abs/2510.17212", "authors": ["Jundong Zhang", "Yuhui Situ", "Fanji Zhang", "Rongji Deng", "Tianqi Wei"], "title": "D2C-HRHR: Discrete Actions with Double Distributional Critics for High-Risk-High-Return Tasks", "comment": null, "summary": "Tasks involving high-risk-high-return (HRHR) actions, such as obstacle\ncrossing, often exhibit multimodal action distributions and stochastic returns.\nMost reinforcement learning (RL) methods assume unimodal Gaussian policies and\nrely on scalar-valued critics, which limits their effectiveness in HRHR\nsettings. We formally define HRHR tasks and theoretically show that Gaussian\npolicies cannot guarantee convergence to the optimal solution. To address this,\nwe propose a reinforcement learning framework that (i) discretizes continuous\naction spaces to approximate multimodal distributions, (ii) employs\nentropy-regularized exploration to improve coverage of risky but rewarding\nactions, and (iii) introduces a dual-critic architecture for more accurate\ndiscrete value distribution estimation. The framework scales to\nhigh-dimensional action spaces, supporting complex control domains. Experiments\non locomotion and manipulation benchmarks with high risks of failure\ndemonstrate that our method outperforms baselines, underscoring the importance\nof explicitly modeling multimodality and risk in RL.", "AI": {"tldr": "Proposes RL framework for high-risk-high-return tasks using action discretization, entropy-regularized exploration, and dual-critic architecture to handle multimodal action distributions and stochastic returns.", "motivation": "Standard RL methods with unimodal Gaussian policies and scalar critics are ineffective for high-risk-high-return tasks that exhibit multimodal action distributions and stochastic returns, requiring explicit modeling of multimodality and risk.", "method": "Discretizes continuous action spaces to approximate multimodal distributions, uses entropy-regularized exploration for better coverage of risky actions, and employs dual-critic architecture for discrete value distribution estimation.", "result": "Outperforms baseline methods on locomotion and manipulation benchmarks with high failure risks, demonstrating effectiveness in high-dimensional action spaces and complex control domains.", "conclusion": "Explicit modeling of multimodality and risk is crucial for RL in high-risk-high-return settings, and the proposed framework provides an effective solution that scales to complex domains."}}
{"id": "2510.17686", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17686", "abs": "https://arxiv.org/abs/2510.17686", "authors": ["Taichi Liu", "Zhenyu Wang", "Ruofeng Liu", "Guang Wang", "Desheng Zhang"], "title": "Towards 3D Objectness Learning in an Open World", "comment": "Accepted by NeurIPS 2025", "summary": "Recent advancements in 3D object detection and novel category detection have\nmade significant progress, yet research on learning generalized 3D objectness\nremains insufficient. In this paper, we delve into learning open-world 3D\nobjectness, which focuses on detecting all objects in a 3D scene, including\nnovel objects unseen during training. Traditional closed-set 3D detectors\nstruggle to generalize to open-world scenarios, while directly incorporating 3D\nopen-vocabulary models for open-world ability struggles with vocabulary\nexpansion and semantic overlap. To achieve generalized 3D object discovery, We\npropose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect\nany objects within 3D scenes without relying on hand-crafted text prompts. We\nintroduce the strong generalization and zero-shot capabilities of 2D foundation\nmodels, utilizing both 2D semantic priors and 3D geometric priors for\nclass-agnostic proposals to broaden 3D object discovery. Then, by integrating\ncomplementary information from point cloud and RGB image in the cross-modal\nmixture of experts, OP3Det dynamically routes uni-modal and multi-modal\nfeatures to learn generalized 3D objectness. Extensive experiments demonstrate\nthe extraordinary performance of OP3Det, which significantly surpasses existing\nopen-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement\ncompared to closed-world 3D detectors.", "AI": {"tldr": "OP3Det is a class-agnostic open-world 3D detector that discovers any objects in 3D scenes without text prompts, leveraging 2D foundation models and cross-modal fusion to achieve superior generalization.", "motivation": "Traditional closed-set 3D detectors struggle with open-world scenarios, and existing open-vocabulary models face challenges with vocabulary expansion and semantic overlap. There's insufficient research on learning generalized 3D objectness for detecting novel objects unseen during training.", "method": "Proposes OP3Det that uses 2D semantic priors and 3D geometric priors for class-agnostic proposals, then integrates complementary point cloud and RGB information through cross-modal mixture of experts to dynamically route uni-modal and multi-modal features.", "result": "Significantly surpasses existing open-world 3D detectors by up to 16.0% in AR and achieves 13.5% improvement compared to closed-world 3D detectors, demonstrating extraordinary performance in generalized 3D object discovery.", "conclusion": "OP3Det effectively addresses the limitations of traditional 3D detectors in open-world scenarios by leveraging foundation models and cross-modal fusion, achieving state-of-the-art performance in detecting novel objects without relying on text prompts."}}
{"id": "2510.17214", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17214", "abs": "https://arxiv.org/abs/2510.17214", "authors": ["Chenyan Fei", "Dalin Zhang", "Chen Melinda Dang"], "title": "Diagnosis of Fuel Cell Health Status with Deep Sparse Auto-Encoder Neural Network", "comment": null, "summary": "Effective and accurate diagnosis of fuel cell health status is crucial for\nensuring the stable operation of fuel cell stacks. Among various parameters,\nhigh-frequency impedance serves as a critical indicator for assessing fuel cell\nstate and health conditions. However, its online testing is prohibitively\ncomplex and costly. This paper employs a deep sparse auto-encoding network for\nthe prediction and classification of high-frequency impedance in fuel cells,\nachieving metric of accuracy rate above 92\\%. The network is further deployed\non an FPGA, attaining a hardware-based recognition rate almost 90\\%.", "AI": {"tldr": "Deep sparse auto-encoding network predicts and classifies high-frequency impedance in fuel cells with over 92% accuracy, deployed on FPGA achieving nearly 90% hardware recognition rate.", "motivation": "Online testing of high-frequency impedance for fuel cell health diagnosis is complex and costly, requiring alternative prediction methods.", "method": "Deep sparse auto-encoding network for prediction and classification of high-frequency impedance.", "result": "Achieved accuracy rate above 92% for prediction/classification, and nearly 90% hardware recognition rate when deployed on FPGA.", "conclusion": "The proposed deep learning approach provides an effective alternative to complex online testing for fuel cell health monitoring."}}
{"id": "2510.17699", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17699", "abs": "https://arxiv.org/abs/2510.17699", "authors": ["Aleksandr Oganov", "Ilya Bykov", "Eva Neudachina", "Mishan Aliev", "Alexander Tolmachev", "Alexander Sidorov", "Aleksandr Zuev", "Andrey Okhotin", "Denis Rakitin", "Aibek Alanov"], "title": "GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver", "comment": null, "summary": "While diffusion models achieve state-of-the-art generation quality, they\nstill suffer from computationally expensive sampling. Recent works address this\nissue with gradient-based optimization methods that distill a few-step ODE\ndiffusion solver from the full sampling process, reducing the number of\nfunction evaluations from dozens to just a few. However, these approaches often\nrely on intricate training techniques and do not explicitly focus on preserving\nfine-grained details. In this paper, we introduce the Generalized Solver: a\nsimple parameterization of the ODE sampler that does not require additional\ntraining tricks and improves quality over existing approaches. We further\ncombine the original distillation loss with adversarial training, which\nmitigates artifacts and enhances detail fidelity. We call the resulting method\nthe Generalized Adversarial Solver and demonstrate its superior performance\ncompared to existing solver training methods under similar resource\nconstraints. Code is available at https://github.com/3145tttt/GAS.", "AI": {"tldr": "A new method called Generalized Adversarial Solver (GAS) improves diffusion model sampling efficiency by combining ODE solver distillation with adversarial training to preserve fine details while reducing function evaluations.", "motivation": "Diffusion models have excellent generation quality but suffer from computationally expensive sampling. Existing distillation methods require complex training techniques and don't adequately preserve fine-grained details.", "method": "Proposes Generalized Solver - a simple ODE sampler parameterization without complex training tricks, combined with adversarial training to mitigate artifacts and enhance detail fidelity.", "result": "The Generalized Adversarial Solver achieves superior performance compared to existing solver training methods under similar resource constraints.", "conclusion": "GAS provides an effective approach to improve diffusion model sampling efficiency while maintaining high quality and detail preservation."}}
{"id": "2510.17250", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17250", "abs": "https://arxiv.org/abs/2510.17250", "authors": ["Wei-Hsun Lee", "Che-Yu Chang", "Kuang-Yu Li"], "title": "A Prototypical Network with an Attention-based Encoder for Drivers Identification Application", "comment": null, "summary": "Driver identification has become an area of increasing interest in recent\nyears, especially for data- driven applications, because biometric-based\ntechnologies may incur privacy issues. This study proposes a deep learning\nneural network architecture, an attention-based encoder (AttEnc), which uses an\nattention mechanism for driver identification and uses fewer model parameters\nthan current methods. Most studies do not address the issue of data shortages\nfor driver identification, and most of them are inflexible when encountering\nunknown drivers. In this study, an architecture that combines a prototypical\nnetwork and an attention-based encoder (P-AttEnc) is proposed. It applies\nfew-shot learning to overcome the data shortage issues and to enhance model\ngeneralizations. The experiments showed that the attention-based encoder can\nidentify drivers with accuracies of 99.3%, 99.0% and 99.9% in three different\ndatasets and has a prediction time that is 44% to 79% faster because it\nsignificantly reduces, on average, 87.6% of the model parameters. P-AttEnc\nidentifies drivers based on few shot data, extracts driver fingerprints to\naddress the issue of data shortages, and is able to classify unknown drivers.\nThe first experiment showed that P-AttEnc can identify drivers with an accuracy\nof 69.8% in the one-shot scenario. The second experiment showed that P-AttEnc,\nin the 1-shot scenario, can classify unknown drivers with an average accuracy\nof 65.7%.", "AI": {"tldr": "This paper proposes two deep learning architectures for driver identification: AttEnc (attention-based encoder) for efficient identification with fewer parameters, and P-AttEnc (prototypical network + AttEnc) for few-shot learning to handle data shortages and unknown drivers.", "motivation": "Driver identification is important but biometric methods raise privacy concerns. Existing methods don't address data shortages and are inflexible with unknown drivers.", "method": "Proposed AttEnc with attention mechanism for efficient driver identification, and P-AttEnc combining prototypical network with AttEnc for few-shot learning to handle data shortages and unknown drivers.", "result": "AttEnc achieved 99.3%, 99.0%, 99.9% accuracy on three datasets with 44-79% faster prediction time and 87.6% parameter reduction. P-AttEnc achieved 69.8% accuracy in one-shot scenario and 65.7% accuracy for classifying unknown drivers.", "conclusion": "The proposed architectures effectively address driver identification with privacy preservation, data efficiency, and flexibility for unknown drivers through attention mechanisms and few-shot learning."}}
{"id": "2510.17700", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17700", "abs": "https://arxiv.org/abs/2510.17700", "authors": ["Walter Simoncini", "Michael Dorkenwald", "Tijmen Blankevoort", "Cees G. M. Snoek", "Yuki M. Asano"], "title": "Elastic ViTs from Pretrained Models without Retraining", "comment": "Accepted at NeurIPS 2025", "summary": "Vision foundation models achieve remarkable performance but are only\navailable in a limited set of pre-determined sizes, forcing sub-optimal\ndeployment choices under real-world constraints. We introduce SnapViT:\nSingle-shot network approximation for pruned Vision Transformers, a new\npost-pretraining structured pruning method that enables elastic inference\nacross a continuum of compute budgets. Our approach efficiently combines\ngradient information with cross-network structure correlations, approximated\nvia an evolutionary algorithm, does not require labeled data, generalizes to\nmodels without a classification head, and is retraining-free. Experiments on\nDINO, SigLIPv2, DeIT, and AugReg models demonstrate superior performance over\nstate-of-the-art methods across various sparsities, requiring less than five\nminutes on a single A100 GPU to generate elastic models that can be adjusted to\nany computational budget. Our key contributions include an efficient pruning\nstrategy for pretrained Vision Transformers, a novel evolutionary approximation\nof Hessian off-diagonal structures, and a self-supervised importance scoring\nmechanism that maintains strong performance without requiring retraining or\nlabels. Code and pruned models are available at: https://elastic.ashita.nl/", "AI": {"tldr": "SnapViT is a post-pretraining structured pruning method for Vision Transformers that enables elastic inference across compute budgets without retraining or labeled data.", "motivation": "Vision foundation models come in limited pre-determined sizes, forcing sub-optimal deployment under real-world constraints, creating need for flexible model scaling.", "method": "Combines gradient information with cross-network structure correlations approximated via evolutionary algorithm, uses self-supervised importance scoring, and is retraining-free.", "result": "Superior performance over state-of-the-art methods across various sparsities, generates elastic models in <5 minutes on single A100 GPU that adapt to any computational budget.", "conclusion": "SnapViT provides efficient pruning strategy for pretrained Vision Transformers with novel evolutionary Hessian approximation and self-supervised scoring, enabling flexible deployment without performance loss."}}
{"id": "2510.17266", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17266", "abs": "https://arxiv.org/abs/2510.17266", "authors": ["Jiayu Bai", "Zhanbo Feng", "Zhijie Deng", "Tianqi Hou", "Robert C. Qiu", "Zenan Ling"], "title": "Adaptive Discretization for Consistency Models", "comment": "Accepted by NeurIPS 2025", "summary": "Consistency Models (CMs) have shown promise for efficient one-step\ngeneration. However, most existing CMs rely on manually designed discretization\nschemes, which can cause repeated adjustments for different noise schedules and\ndatasets. To address this, we propose a unified framework for the automatic and\nadaptive discretization of CMs, formulating it as an optimization problem with\nrespect to the discretization step. Concretely, during the consistency training\nprocess, we propose using local consistency as the optimization objective to\nensure trainability by avoiding excessive discretization, and taking global\nconsistency as a constraint to ensure stability by controlling the denoising\nerror in the training target. We establish the trade-off between local and\nglobal consistency with a Lagrange multiplier. Building on this framework, we\nachieve adaptive discretization for CMs using the Gauss-Newton method. We refer\nto our approach as ADCMs. Experiments demonstrate that ADCMs significantly\nimprove the training efficiency of CMs, achieving superior generative\nperformance with minimal training overhead on both CIFAR-10 and ImageNet.\nMoreover, ADCMs exhibit strong adaptability to more advanced DM variants. Code\nis available at https://github.com/rainstonee/ADCM.", "AI": {"tldr": "ADCMs propose an automatic and adaptive discretization framework for Consistency Models that optimizes discretization steps using local consistency as objective and global consistency as constraint, improving training efficiency and performance.", "motivation": "Existing Consistency Models rely on manually designed discretization schemes that require repeated adjustments for different noise schedules and datasets, limiting their efficiency and adaptability.", "method": "Formulate discretization as optimization problem using local consistency as objective for trainability and global consistency as constraint for stability, solved with Lagrange multiplier and Gauss-Newton method.", "result": "ADCMs significantly improve training efficiency, achieve superior generative performance with minimal overhead on CIFAR-10 and ImageNet, and adapt well to advanced diffusion model variants.", "conclusion": "The proposed adaptive discretization framework provides an efficient and flexible solution for Consistency Models, eliminating manual tuning while maintaining strong performance across different datasets and model variants."}}
{"id": "2510.17703", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17703", "abs": "https://arxiv.org/abs/2510.17703", "authors": ["Mhd Adnan Albani", "Riad Sonbol"], "title": "Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns", "comment": "19 pages, 2 figures, 9 tables", "summary": "Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of\npeople over the age of 60, causing motor impairments that impede hand\ncoordination activities such as writing and drawing. Many approaches have tried\nto support early detection of Parkinson's disease based on hand-drawn images;\nhowever, we identified two major limitations in the related works: (1) the lack\nof sufficient datasets, (2) the robustness when dealing with unseen patient\ndata. In this paper, we propose a new approach to detect Parkinson's disease\nthat consists of two stages: The first stage classifies based on their drawing\ntype(circle, meander, spiral), and the second stage extracts the required\nfeatures from the images and detects Parkinson's disease. We overcame the\nprevious two limitations by applying a chunking strategy where we divide each\nimage into 2x2 chunks. Each chunk is processed separately when extracting\nfeatures and recognizing Parkinson's disease indicators. To make the final\nclassification, an ensemble method is used to merge the decisions made from\neach chunk. Our evaluation shows that our proposed approach outperforms the top\nperforming state-of-the-art approaches, in particular on unseen patients. On\nthe NewHandPD dataset our approach, it achieved 97.08% accuracy for seen\npatients and 94.91% for unseen patients, our proposed approach maintained a gap\nof only 2.17 percentage points, compared to the 4.76-point drop observed in\nprior work.", "AI": {"tldr": "A two-stage approach for Parkinson's disease detection from hand-drawn images using chunking and ensemble methods to address dataset limitations and improve robustness on unseen patient data.", "motivation": "Existing Parkinson's disease detection methods from hand-drawn images suffer from insufficient datasets and poor robustness when dealing with unseen patient data.", "method": "Two-stage approach: first classifies drawing types (circle, meander, spiral), then extracts features using 2x2 chunking strategy where each chunk is processed separately, with ensemble method for final classification.", "result": "Achieved 97.08% accuracy for seen patients and 94.91% for unseen patients on NewHandPD dataset, maintaining only 2.17 percentage points gap compared to 4.76-point drop in prior work.", "conclusion": "The proposed approach outperforms state-of-the-art methods, particularly on unseen patients, effectively addressing dataset limitations and improving robustness."}}
{"id": "2510.17268", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17268", "abs": "https://arxiv.org/abs/2510.17268", "authors": ["Anthony Frion", "David S Greenberg"], "title": "Uncertainty-aware data assimilation through variational inference", "comment": null, "summary": "Data assimilation, consisting in the combination of a dynamical model with a\nset of noisy and incomplete observations in order to infer the state of a\nsystem over time, involves uncertainty in most settings. Building upon an\nexisting deterministic machine learning approach, we propose a variational\ninference-based extension in which the predicted state follows a multivariate\nGaussian distribution. Using the chaotic Lorenz-96 dynamics as a testing\nground, we show that our new model enables to obtain nearly perfectly\ncalibrated predictions, and can be integrated in a wider variational data\nassimilation pipeline in order to achieve greater benefit from increasing\nlengths of data assimilation windows. Our code is available at\nhttps://github.com/anthony-frion/Stochastic_CODA.", "AI": {"tldr": "This paper proposes a variational inference-based extension to deterministic machine learning for data assimilation, modeling predicted states as multivariate Gaussian distributions to handle uncertainty in chaotic systems.", "motivation": "Data assimilation involves uncertainty in most settings, and existing deterministic approaches need extension to properly model and quantify this uncertainty in predictions.", "method": "The authors extend a deterministic machine learning approach using variational inference, where the predicted state follows a multivariate Gaussian distribution. They test this on chaotic Lorenz-96 dynamics and integrate it into a variational data assimilation pipeline.", "result": "The new model achieves nearly perfectly calibrated predictions and shows greater benefit from increasing lengths of data assimilation windows when integrated into the wider variational data assimilation pipeline.", "conclusion": "The proposed stochastic variational inference approach enables well-calibrated uncertainty quantification in data assimilation and improves performance with longer assimilation windows, making it valuable for handling uncertainty in chaotic systems."}}
{"id": "2510.17716", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17716", "abs": "https://arxiv.org/abs/2510.17716", "authors": ["Suqiang Ma", "Subhadeep Sengupta", "Yao Lee", "Beikang Gu", "Xianyan Chen", "Xianqiao Wang", "Yang Liu", "Mengjia Xu", "Galit H. Frydman", "He Li"], "title": "Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging", "comment": null, "summary": "Circulating blood cell clusters (CCCs) containing red blood cells (RBCs),\nwhite blood cells(WBCs), and platelets are significant biomarkers linked to\nconditions like thrombosis, infection, and inflammation. Flow cytometry, paired\nwith fluorescence staining, is commonly used to analyze these cell clusters,\nrevealing cell morphology and protein profiles. While computational approaches\nbased on machine learning have advanced the automatic analysis of single-cell\nflow cytometry images, there is a lack of effort to build tools to\nautomatically analyze images containing CCCs. Unlike single cells, cell\nclusters often exhibit irregular shapes and sizes. In addition, these cell\nclusters often consist of heterogeneous cell types, which require multi-channel\nstaining to identify the specific cell types within the clusters. This study\nintroduces a new computational framework for analyzing CCC images and\nidentifying cell types within clusters. Our framework uses a two-step analysis\nstrategy. First, it categorizes images into cell cluster and non-cluster groups\nby fine-tuning the You Only Look Once(YOLOv11) model, which outperforms\ntraditional convolutional neural networks (CNNs), Vision Transformers (ViT).\nThen, it identifies cell types by overlaying cluster contours with regions from\nmulti-channel fluorescence stains, enhancing accuracy despite cell debris and\nstaining artifacts. This approach achieved over 95% accuracy in both cluster\nclassification and phenotype identification. In summary, our automated\nframework effectively analyzes CCC images from flow cytometry, leveraging both\nbright-field and fluorescence data. Initially tested on blood cells, it holds\npotential for broader applications, such as analyzing immune and tumor cell\nclusters, supporting cellular research across various diseases.", "AI": {"tldr": "A computational framework using YOLOv11 for automatic analysis of circulating blood cell clusters (CCCs) from flow cytometry images, achieving over 95% accuracy in cluster classification and cell type identification.", "motivation": "Current computational approaches focus on single-cell flow cytometry analysis, but lack tools for analyzing cell clusters which have irregular shapes, sizes, and heterogeneous cell types requiring multi-channel staining.", "method": "Two-step analysis: 1) Fine-tuned YOLOv11 model to classify images into cell cluster vs non-cluster groups, outperforming traditional CNNs and ViTs; 2) Identified cell types by overlaying cluster contours with multi-channel fluorescence stain regions, handling cell debris and staining artifacts.", "result": "Achieved over 95% accuracy in both cluster classification and phenotype identification, demonstrating effective analysis of CCC images from flow cytometry.", "conclusion": "The automated framework successfully analyzes CCC images using bright-field and fluorescence data, with potential for broader applications in immune and tumor cell cluster analysis across various diseases."}}
{"id": "2510.17276", "categories": ["cs.LG", "cs.CR", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17276", "abs": "https://arxiv.org/abs/2510.17276", "authors": ["Rishi Jha", "Harold Triedman", "Justin Wagle", "Vitaly Shmatikov"], "title": "Breaking and Fixing Defenses Against Control-Flow Hijacking in Multi-Agent Systems", "comment": null, "summary": "Control-flow hijacking attacks manipulate orchestration mechanisms in\nmulti-agent systems into performing unsafe actions that compromise the system\nand exfiltrate sensitive information. Recently proposed defenses, such as\nLlamaFirewall, rely on alignment checks of inter-agent communications to ensure\nthat all agent invocations are \"related to\" and \"likely to further\" the\noriginal objective.\n  We start by demonstrating control-flow hijacking attacks that evade these\ndefenses even if alignment checks are performed by advanced LLMs. We argue that\nthe safety and functionality objectives of multi-agent systems fundamentally\nconflict with each other. This conflict is exacerbated by the brittle\ndefinitions of \"alignment\" and the checkers' incomplete visibility into the\nexecution context.\n  We then propose, implement, and evaluate ControlValve, a new defense inspired\nby the principles of control-flow integrity and least privilege. ControlValve\n(1) generates permitted control-flow graphs for multi-agent systems, and (2)\nenforces that all executions comply with these graphs, along with contextual\nrules (generated in a zero-shot manner) for each agent invocation.", "AI": {"tldr": "ControlValve is a new defense against control-flow hijacking in multi-agent systems that generates permitted control-flow graphs and enforces execution compliance, addressing limitations of existing alignment-based defenses.", "motivation": "Existing defenses like LlamaFirewall that rely on alignment checks are insufficient against control-flow hijacking attacks, as safety and functionality objectives conflict and alignment definitions are brittle with incomplete context visibility.", "method": "ControlValve generates permitted control-flow graphs for multi-agent systems and enforces all executions comply with these graphs, along with zero-shot generated contextual rules for each agent invocation.", "result": "The paper demonstrates that current alignment-based defenses can be evaded even with advanced LLMs, and proposes ControlValve as a more robust solution based on control-flow integrity and least privilege principles.", "conclusion": "ControlValve provides a more effective defense against control-flow hijacking in multi-agent systems by enforcing permitted control-flow graphs and contextual rules, overcoming the limitations of alignment-based approaches."}}
{"id": "2510.17719", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17719", "abs": "https://arxiv.org/abs/2510.17719", "authors": ["Zhiqiang Teng", "Beibei Lin", "Tingting Chen", "Zifeng Yuan", "Xuanyi Li", "Xuanyu Zhang", "Shunli Zhang"], "title": "Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions", "comment": null, "summary": "3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe\nocclusions and optical distortions caused by raindrop contamination on the\ncamera lens, substantially degrading reconstruction quality. Existing\nbenchmarks typically evaluate 3DGS using synthetic raindrop images with known\ncamera poses (constrained images), assuming ideal conditions. However, in\nreal-world scenarios, raindrops often interfere with accurate camera pose\nestimation and point cloud initialization. Moreover, a significant domain gap\nbetween synthetic and real raindrops further impairs generalization. To tackle\nthese issues, we introduce RaindropGS, a comprehensive benchmark designed to\nevaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images\nto clear 3DGS reconstructions. Specifically, the whole benchmark pipeline\nconsists of three parts: data preparation, data processing, and raindrop-aware\n3DGS evaluation, including types of raindrop interference, camera pose\nestimation and point cloud initialization, single image rain removal\ncomparison, and 3D Gaussian training comparison. First, we collect a real-world\nraindrop reconstruction dataset, in which each scene contains three aligned\nimage sets: raindrop-focused, background-focused, and rain-free ground truth,\nenabling a comprehensive evaluation of reconstruction quality under different\nfocus conditions. Through comprehensive experiments and analyses, we reveal\ncritical insights into the performance limitations of existing 3DGS methods on\nunconstrained raindrop images and the varying impact of different pipeline\ncomponents: the impact of camera focus position on 3DGS reconstruction\nperformance, and the interference caused by inaccurate pose and point cloud\ninitialization on reconstruction. These insights establish clear directions for\ndeveloping more robust 3DGS methods under raindrop conditions.", "AI": {"tldr": "RaindropGS is a benchmark for evaluating 3D Gaussian Splatting under real-world raindrop conditions, addressing limitations of existing synthetic benchmarks and providing insights for robust 3D reconstruction.", "motivation": "3D Gaussian Splatting suffers from severe degradation under raindrop conditions due to occlusions and distortions, with existing benchmarks using synthetic data that doesn't reflect real-world challenges like inaccurate camera pose estimation and domain gaps.", "method": "The benchmark includes three parts: data preparation (collecting real-world raindrop dataset with three aligned image sets), data processing, and raindrop-aware 3DGS evaluation covering raindrop interference types, camera pose estimation, single image rain removal, and 3D Gaussian training.", "result": "The study reveals critical insights including performance limitations of existing 3DGS methods on unconstrained raindrop images, impact of camera focus position on reconstruction quality, and interference from inaccurate pose and point cloud initialization.", "conclusion": "The benchmark establishes clear directions for developing more robust 3DGS methods under raindrop conditions by addressing real-world challenges in the full reconstruction pipeline."}}
{"id": "2510.17281", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17281", "abs": "https://arxiv.org/abs/2510.17281", "authors": ["Qingyao Ai", "Yichen Tang", "Changyue Wang", "Jianming Long", "Weihang Su", "Yiqun Liu"], "title": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems", "comment": null, "summary": "Scaling up data, parameters, and test-time computation has been the\nmainstream methods to improve LLM systems (LLMsys), but their upper bounds are\nalmost reached due to the gradual depletion of high-quality data and marginal\ngains obtained from larger computational resource consumption. Inspired by the\nabilities of human and traditional AI systems in learning from practice,\nconstructing memory and continual learning frameworks for LLMsys has become an\nimportant and popular research direction in recent literature. Yet, existing\nbenchmarks for LLM memory often focus on evaluating the system on homogeneous\nreading comprehension tasks with long-form inputs rather than testing their\nabilities to learn from accumulated user feedback in service time. Therefore,\nwe propose a user feedback simulation framework and a comprehensive benchmark\ncovering multiple domains, languages, and types of tasks to evaluate the\ncontinual learning abilities of LLMsys. Experiments show that the effectiveness\nand efficiency of state-of-the-art baselines are far from satisfying, and we\nhope this benchmark could pave the way for future studies on LLM memory and\noptimization algorithms.", "AI": {"tldr": "The paper proposes a user feedback simulation framework and benchmark to evaluate LLM systems' continual learning abilities across multiple domains, languages, and task types, addressing limitations in existing memory benchmarks.", "motivation": "Current LLM scaling methods are reaching limits due to data depletion and diminishing returns. Inspired by human learning abilities, the authors aim to develop memory and continual learning frameworks for LLMs, but existing benchmarks focus on homogeneous reading comprehension rather than learning from user feedback.", "method": "Developed a user feedback simulation framework and comprehensive benchmark covering multiple domains, languages, and task types to evaluate LLM systems' continual learning capabilities.", "result": "Experiments show that state-of-the-art baselines perform poorly in effectiveness and efficiency when tested on the proposed benchmark.", "conclusion": "The benchmark reveals significant gaps in current LLM memory systems and provides a foundation for future research on LLM memory and optimization algorithms."}}
{"id": "2510.17722", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17722", "abs": "https://arxiv.org/abs/2510.17722", "authors": ["Yaning Pan", "Zekun Wang", "Qianqian Xie", "Yongqian Wen", "Yuanxing Zhang", "Guohui Zhang", "Haoxuan Hu", "Zhiyu Pan", "Yibing Huang", "Zhidong Gan", "Yonghong Lin", "An Ping", "Tianhao Peng", "Jiaheng Liu"], "title": "MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues", "comment": "Project Website: https://github.com/NJU-LINK/MT-Video-Bench", "summary": "The recent development of Multimodal Large Language Models (MLLMs) has\nsignificantly advanced AI's ability to understand visual modalities. However,\nexisting evaluation benchmarks remain limited to single-turn question\nanswering, overlooking the complexity of multi-turn dialogues in real-world\nscenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video\nunderstanding benchmark for evaluating MLLMs in multi-turn dialogues.\nSpecifically, our MT-Video-Bench mainly assesses six core competencies that\nfocus on perceptivity and interactivity, encompassing 987 meticulously curated\nmulti-turn dialogues from diverse domains. These capabilities are rigorously\naligned with real-world applications, such as interactive sports analysis and\nmulti-turn video-based intelligent tutoring. With MT-Video-Bench, we\nextensively evaluate various state-of-the-art open-source and closed-source\nMLLMs, revealing their significant performance discrepancies and limitations in\nhandling multi-turn video dialogues. The benchmark will be publicly available\nto foster future research.", "AI": {"tldr": "MT-Video-Bench is a new benchmark for evaluating Multimodal Large Language Models (MLLMs) on multi-turn video dialogues, addressing limitations of existing single-turn QA benchmarks.", "motivation": "Existing MLLM evaluation benchmarks are limited to single-turn question answering, which doesn't capture the complexity of real-world multi-turn dialogues in video understanding scenarios.", "method": "Developed MT-Video-Bench with 987 curated multi-turn dialogues across diverse domains, assessing six core competencies focused on perceptivity and interactivity, aligned with real-world applications like sports analysis and video-based tutoring.", "result": "Extensive evaluation of state-of-the-art MLLMs revealed significant performance discrepancies and limitations in handling multi-turn video dialogues.", "conclusion": "The benchmark addresses a critical gap in MLLM evaluation and will be publicly available to advance research in multi-turn video understanding capabilities."}}
{"id": "2510.17303", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17303", "abs": "https://arxiv.org/abs/2510.17303", "authors": ["Armin Beck", "Peter Ochs"], "title": "Symmetries in PAC-Bayesian Learning", "comment": null, "summary": "Symmetries are known to improve the empirical performance of machine learning\nmodels, yet theoretical guarantees explaining these gains remain limited. Prior\nwork has focused mainly on compact group symmetries and often assumes that the\ndata distribution itself is invariant, an assumption rarely satisfied in\nreal-world applications. In this work, we extend generalization guarantees to\nthe broader setting of non-compact symmetries, such as translations and to\nnon-invariant data distributions. Building on the PAC-Bayes framework, we adapt\nand tighten existing bounds, demonstrating the approach on McAllester's\nPAC-Bayes bound while showing that it applies to a wide range of PAC-Bayes\nbounds. We validate our theory with experiments on a rotated MNIST dataset with\na non-uniform rotation group, where the derived guarantees not only hold but\nalso improve upon prior results. These findings provide theoretical evidence\nthat, for symmetric data, symmetric models are preferable beyond the narrow\nsetting of compact groups and invariant distributions, opening the way to a\nmore general understanding of symmetries in machine learning.", "AI": {"tldr": "Extends generalization guarantees to non-compact symmetries and non-invariant data distributions using PAC-Bayes framework, showing improved performance on rotated MNIST with non-uniform rotations.", "motivation": "Prior theoretical guarantees for symmetries in ML mainly focused on compact groups and assumed invariant data distributions, which rarely hold in real-world applications. This work aims to extend guarantees to more realistic settings.", "method": "Builds on PAC-Bayes framework, adapting and tightening existing bounds (including McAllester's PAC-Bayes bound) to handle non-compact symmetries like translations and non-invariant data distributions.", "result": "Validated theory on rotated MNIST dataset with non-uniform rotation group, where derived guarantees not only hold but also improve upon prior results. Shows symmetric models perform better for symmetric data.", "conclusion": "Provides theoretical evidence that symmetric models are preferable for symmetric data beyond narrow settings of compact groups and invariant distributions, enabling more general understanding of symmetries in machine learning."}}
{"id": "2510.17724", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17724", "abs": "https://arxiv.org/abs/2510.17724", "authors": ["Matheus Ramos Parracho"], "title": "Signature Forgery Detection: Improving Cross-Dataset Generalization", "comment": "Undergraduate thesis (preprint)---submitted to Escola Polit\\'ecnica,\n  Universidade Federal do Rio de Janeiro (POLI/UFRJ). The final version will\n  include official signatures and defense approval", "summary": "Automated signature verification is a critical biometric technique used in\nbanking, identity authentication, and legal documentation. Despite the notable\nprogress achieved by deep learning methods, most approaches in offline\nsignature verification still struggle to generalize across datasets, as\nvariations in handwriting styles and acquisition protocols often degrade\nperformance. This study investigates feature learning strategies for signature\nforgery detection, focusing on improving cross-dataset generalization -- that\nis, model robustness when trained on one dataset and tested on another. Using\nthree public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental\npipelines were developed: one based on raw signature images and another\nemploying a preprocessing method referred to as shell preprocessing. Several\nbehavioral patterns were identified and analyzed; however, no definitive\nsuperiority between the two approaches was established. The results show that\nthe raw-image model achieved higher performance across benchmarks, while the\nshell-based model demonstrated promising potential for future refinement toward\nrobust, cross-domain signature verification.", "AI": {"tldr": "This paper investigates feature learning strategies for offline signature verification, focusing on improving cross-dataset generalization using raw signature images and shell preprocessing methods across three public benchmarks.", "motivation": "Automated signature verification is critical for banking and identity authentication, but current deep learning methods struggle with cross-dataset generalization due to variations in handwriting styles and acquisition protocols.", "method": "Developed two experimental pipelines: one using raw signature images and another using shell preprocessing, tested across three public benchmarks (CEDAR, ICDAR, and GPDS Synthetic) to evaluate cross-dataset performance.", "result": "The raw-image model achieved higher performance across benchmarks, while the shell-based model showed promising potential for future refinement, but no definitive superiority was established between the two approaches.", "conclusion": "Both approaches have merits for cross-domain signature verification, with raw images currently performing better but shell preprocessing showing potential for future improvements in robustness."}}
{"id": "2510.17313", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17313", "abs": "https://arxiv.org/abs/2510.17313", "authors": ["Tal Barami", "Nimrod Berman", "Ilan Naiman", "Amos H. Hason", "Rotem Ezra", "Omri Azencot"], "title": "Disentanglement Beyond Static vs. Dynamic: A Benchmark and Evaluation Framework for Multi-Factor Sequential Representations", "comment": null, "summary": "Learning disentangled representations in sequential data is a key goal in\ndeep learning, with broad applications in vision, audio, and time series. While\nreal-world data involves multiple interacting semantic factors over time, prior\nwork has mostly focused on simpler two-factor static and dynamic settings,\nprimarily because such settings make data collection easier, thereby\noverlooking the inherently multi-factor nature of real-world data. We introduce\nthe first standardized benchmark for evaluating multi-factor sequential\ndisentanglement across six diverse datasets spanning video, audio, and time\nseries. Our benchmark includes modular tools for dataset integration, model\ndevelopment, and evaluation metrics tailored to multi-factor analysis. We\nadditionally propose a post-hoc Latent Exploration Stage to automatically align\nlatent dimensions with semantic factors, and introduce a Koopman-inspired model\nthat achieves state-of-the-art results. Moreover, we show that Vision-Language\nModels can automate dataset annotation and serve as zero-shot disentanglement\nevaluators, removing the need for manual labels and human intervention.\nTogether, these contributions provide a robust and scalable foundation for\nadvancing multi-factor sequential disentanglement.", "AI": {"tldr": "The paper introduces the first standardized benchmark for multi-factor sequential disentanglement across six diverse datasets, proposes a post-hoc latent exploration method and Koopman-inspired model, and shows that Vision-Language Models can automate evaluation.", "motivation": "Real-world sequential data involves multiple interacting semantic factors over time, but prior work has focused on simpler two-factor settings, overlooking the inherently multi-factor nature of real data.", "method": "Created a benchmark with six diverse datasets, developed modular tools for dataset integration and evaluation, proposed a post-hoc Latent Exploration Stage for automatic latent-semantic alignment, and introduced a Koopman-inspired model.", "result": "The Koopman-inspired model achieves state-of-the-art results, and Vision-Language Models can successfully automate dataset annotation and serve as zero-shot disentanglement evaluators.", "conclusion": "The contributions provide a robust and scalable foundation for advancing multi-factor sequential disentanglement research by removing the need for manual labels and human intervention."}}
{"id": "2510.17731", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17731", "abs": "https://arxiv.org/abs/2510.17731", "authors": ["Aaron Appelle", "Jerome P. Lynch"], "title": "Can Image-To-Video Models Simulate Pedestrian Dynamics?", "comment": "Appeared in the ICML 2025 Workshop on Building Physically Plausible\n  World Models, July 2025, https://physical-world-modeling.github.io/", "summary": "Recent high-performing image-to-video (I2V) models based on variants of the\ndiffusion transformer (DiT) have displayed remarkable inherent world-modeling\ncapabilities by virtue of training on large scale video datasets. We\ninvestigate whether these models can generate realistic pedestrian movement\npatterns in crowded public scenes. Our framework conditions I2V models on\nkeyframes extracted from pedestrian trajectory benchmarks, then evaluates their\ntrajectory prediction performance using quantitative measures of pedestrian\ndynamics.", "AI": {"tldr": "The paper investigates whether diffusion transformer-based image-to-video models can generate realistic pedestrian movement patterns in crowded scenes by conditioning on trajectory benchmark keyframes.", "motivation": "To explore if high-performing I2V models with inherent world-modeling capabilities from large-scale video training can realistically simulate pedestrian dynamics in crowded public scenes.", "method": "Conditions I2V models on keyframes extracted from pedestrian trajectory benchmarks and evaluates trajectory prediction performance using quantitative measures of pedestrian dynamics.", "result": "The paper presents an evaluation framework but does not specify the actual performance results in the provided abstract.", "conclusion": "The research demonstrates a methodology for assessing I2V models' ability to generate realistic pedestrian movement patterns, though specific findings are not detailed in the abstract."}}
{"id": "2510.17314", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17314", "abs": "https://arxiv.org/abs/2510.17314", "authors": ["Lipeng Xie", "Sen Huang", "Zhuo Zhang", "Anni Zou", "Yunpeng Zhai", "Dingchao Ren", "Kezun Zhang", "Haoyuan Hu", "Boyin Liu", "Haoran Chen", "Zhaoyang Liu", "Bolin Ding"], "title": "Auto-Rubric: Learning to Extract Generalizable Criteria for Reward Modeling", "comment": null, "summary": "Reward models are essential for aligning Large Language Models (LLMs) with\nhuman values, yet their development is hampered by costly preference datasets\nand poor interpretability. While recent rubric-based approaches offer\ntransparency, they often lack systematic quality control and optimization,\ncreating a trade-off between scalability and reliability. We address these\nlimitations with a novel, training-free framework built on a key assumption:\n\\textit{evaluation rubrics underlying human preferences exhibit significant\ngeneralization ability across diverse queries}, a property that enables\nremarkable data efficiency. Our two-stage approach first infers high-quality,\nquery-specific rubrics using a validation-guided\n\\textbf{Propose-Evaluate-Revise} pipeline. Second, it generalizes these\ngranular rubrics into a compact, non-redundant core set by maximizing an\n\\textbf{information-theoretic coding rate}. The final output is an\ninterpretable, hierarchical \"Theme-Tips\" rubric set. Extensive experiments\ndemonstrate the framework's exceptional data efficiency and performance.\nCritically, using just 70 preference pairs (1.5\\% of the source data), our\nmethod also empowers smaller models like Qwen3-8B to outperform specialized,\nfully-trained counterparts. This work pioneers a scalable, interpretable, and\ndata-efficient path for reward modeling.", "AI": {"tldr": "A training-free framework for reward modeling that infers query-specific rubrics and generalizes them into a compact core set, achieving exceptional data efficiency with just 70 preference pairs.", "motivation": "Address limitations in current reward models: high cost of preference datasets, poor interpretability, and trade-off between scalability and reliability in rubric-based approaches.", "method": "Two-stage approach: 1) Propose-Evaluate-Revise pipeline to infer query-specific rubrics, 2) Information-theoretic coding rate maximization to generalize rubrics into compact hierarchical \"Theme-Tips\" set.", "result": "Achieves remarkable data efficiency using only 70 preference pairs (1.5% of source data), enables smaller models like Qwen3-8B to outperform specialized fully-trained counterparts.", "conclusion": "Pioneers a scalable, interpretable, and data-efficient path for reward modeling by leveraging generalization ability of evaluation rubrics across diverse queries."}}
{"id": "2510.17739", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17739", "abs": "https://arxiv.org/abs/2510.17739", "authors": ["Timur Ismagilov", "Shakaiba Majeed", "Michael Milford", "Tan Viet Tuyen Nguyen", "Sarvapali D. Ramchurn", "Shoaib Ehsan"], "title": "Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition", "comment": "13 pages", "summary": "We address multi-reference visual place recognition (VPR), where reference\nsets captured under varying conditions are used to improve localisation\nperformance. While deep learning with large-scale training improves robustness,\nincreasing data diversity and model complexity incur extensive computational\ncost during training and deployment. Descriptor-level fusion via voting or\naggregation avoids training, but often targets multi-sensor setups or relies on\nheuristics with limited gains under appearance and viewpoint change. We propose\na training-free, descriptor-agnostic approach that jointly models places using\nmultiple reference descriptors via matrix decomposition into basis\nrepresentations, enabling projection-based residual matching. We also introduce\nSotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance\ndata, our method improves Recall@1 by up to ~18% over single-reference and\noutperforms multi-reference baselines across appearance and viewpoint changes,\nwith gains of ~5% on unstructured data, demonstrating strong generalisation\nwhile remaining lightweight.", "AI": {"tldr": "A training-free, descriptor-agnostic approach for multi-reference visual place recognition that uses matrix decomposition to jointly model places from multiple reference descriptors, achieving significant performance improvements without computational overhead.", "motivation": "To address the computational costs of training deep learning models for VPR and limitations of existing descriptor-level fusion methods, while improving localization performance under varying conditions.", "method": "Proposes a training-free approach that models places using multiple reference descriptors via matrix decomposition into basis representations, enabling projection-based residual matching. Also introduces SotonMV benchmark for multi-viewpoint VPR.", "result": "Improves Recall@1 by up to ~18% over single-reference methods and outperforms multi-reference baselines across appearance and viewpoint changes, with ~5% gains on unstructured data while remaining lightweight.", "conclusion": "The method demonstrates strong generalization capabilities for multi-reference VPR without requiring training, making it computationally efficient while achieving significant performance improvements under challenging conditions."}}
{"id": "2510.17358", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17358", "abs": "https://arxiv.org/abs/2510.17358", "authors": ["Joachim Diederich"], "title": "Localist LLMs with Recruitment Learning", "comment": null, "summary": "We present a novel framework for training large language models with\ncontinuously adjustable internal representations that span the full spectrum\nfrom localist (interpretable, rule-based) to distributed (generalizable,\nefficient) encodings. The key innovations are (1) a locality dial, a tunable\nparameter that dynamically controls the degree of localization during both\ntraining and inference without requiring model retraining, (2) an\ninformation-theoretic recruitment mechanism that adaptively allocates semantic\nblocks as needed, eliminating the requirement for complete domain knowledge at\ninitialization, and (3) a hierarchical recruitment framework that extends\ncapacity allocation to entire specialized LLMs, enabling multi-granularity\narchitectural adaptation. This is achieved through group sparsity penalties on\nattention mechanisms, information-theoretic anchor design, dynamic rule\ninjection, and principled recruitment criteria based on penalized likelihood\nwith explicit units. We provide rigorous mathematical results establishing\nexplicit threshold conditions under which attention provably concentrates on\nsemantically relevant blocks at stationary points, with exact bounds on\nattention entropy and pointer fidelity. The hierarchical recruitment mechanism\nprovides convergence guarantees at both the block level (fine-grained,\nwithin-LLM) and the LLM level (coarse-grained, cross-domain), ensuring the\nsystem discovers semantic partitions that balance model complexity against data\nencoding efficiency. This framework enables practitioners to continuously\ninterpolate between interpretable and high-performance modes while adapting\narchitectural capacity at multiple granularities, supporting applications in\nregulated domains requiring both transparency and capability.", "AI": {"tldr": "A framework for training LLMs with adjustable internal representations from interpretable (localist) to efficient (distributed) encodings, featuring a tunable locality dial, adaptive semantic block allocation, and hierarchical recruitment of specialized models.", "motivation": "To enable continuous interpolation between interpretable and high-performance modes in LLMs, supporting applications in regulated domains that require both transparency and capability.", "method": "Uses group sparsity penalties on attention, information-theoretic anchor design, dynamic rule injection, and penalized likelihood criteria with explicit units. Features a locality dial parameter, adaptive recruitment mechanism for semantic blocks, and hierarchical framework for multi-granular architectural adaptation.", "result": "Provides rigorous mathematical guarantees: explicit threshold conditions for attention concentration on relevant blocks, bounds on attention entropy and pointer fidelity, and convergence guarantees at both block and LLM levels for semantic partitions that balance complexity and efficiency.", "conclusion": "The framework enables practitioners to continuously adjust between interpretable and high-performance modes while adapting architectural capacity at multiple granularities, supporting regulated domains requiring both transparency and capability."}}
{"id": "2510.17773", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17773", "abs": "https://arxiv.org/abs/2510.17773", "authors": ["Md. Enamul Atiq", "Shaikh Anowarul Fattah"], "title": "Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion", "comment": "15 pages, 7 Figures, 3 Tables", "summary": "Skin cancer is a life-threatening disease where early detection significantly\nimproves patient outcomes. Automated diagnosis from dermoscopic images is\nchallenging due to high intra-class variability and subtle inter-class\ndifferences. Many deep learning models operate as \"black boxes,\" limiting\nclinical trust. In this work, we propose a dual-encoder attention-based\nframework that leverages both segmented lesions and clinical metadata to\nenhance skin lesion classification in terms of both accuracy and\ninterpretability. A novel Deep-UNet architecture with Dual Attention Gates\n(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment\nlesions. The classification stage uses two DenseNet201 encoders-one on the\noriginal image and another on the segmented lesion whose features are fused via\nmulti-head cross-attention. This dual-input design guides the model to focus on\nsalient pathological regions. In addition, a transformer-based module\nincorporates patient metadata (age, sex, lesion site) into the prediction. We\nevaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019\nchallenges. The proposed method achieves state-of-the-art segmentation\nperformance and significantly improves classification accuracy and average AUC\ncompared to baseline models. To validate our model's reliability, we use\nGradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.\nThese visualizations confirm that our model's predictions are based on the\nlesion area, unlike models that rely on spurious background features. These\nresults demonstrate that integrating precise lesion segmentation and clinical\ndata with attention-based fusion leads to a more accurate and interpretable\nskin cancer classification model.", "AI": {"tldr": "A dual-encoder attention-based framework for skin cancer classification that combines segmented lesions and clinical metadata to improve accuracy and interpretability.", "motivation": "Automated skin cancer diagnosis faces challenges with high intra-class variability, subtle inter-class differences, and lack of interpretability in deep learning models, limiting clinical trust.", "method": "Uses Deep-UNet with Dual Attention Gates and ASPP for lesion segmentation, then dual DenseNet201 encoders (original image + segmented lesion) with multi-head cross-attention fusion, plus transformer-based module for patient metadata integration.", "result": "Achieves state-of-the-art segmentation performance and significantly improves classification accuracy and average AUC on HAM10000, ISIC 2018 and 2019 datasets. Grad-CAM visualizations confirm model focuses on lesion areas.", "conclusion": "Integrating precise lesion segmentation and clinical data with attention-based fusion creates a more accurate and interpretable skin cancer classification model."}}
{"id": "2510.17378", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17378", "abs": "https://arxiv.org/abs/2510.17378", "authors": ["Wei Xu", "Xiaoyi Jiang", "Lixiang Xu", "Dechao Tang"], "title": "Model Metamers Reveal Invariances in Graph Neural Networks", "comment": null, "summary": "In recent years, deep neural networks have been extensively employed in\nperceptual systems to learn representations endowed with invariances, aiming to\nemulate the invariance mechanisms observed in the human brain. However, studies\nin the visual and auditory domains have confirmed that significant gaps remain\nbetween the invariance properties of artificial neural networks and those of\nhumans. To investigate the invariance behavior within graph neural networks\n(GNNs), we introduce a model ``metamers'' generation technique. By optimizing\ninput graphs such that their internal node activations match those of a\nreference graph, we obtain graphs that are equivalent in the model's\nrepresentation space, yet differ significantly in both structure and node\nfeatures. Our theoretical analysis focuses on two aspects: the local metamer\ndimension for a single node and the activation-induced volume change of the\nmetamer manifold. Utilizing this approach, we uncover extreme levels of\nrepresentational invariance across several classic GNN architectures. Although\ntargeted modifications to model architecture and training strategies can\npartially mitigate this excessive invariance, they fail to fundamentally bridge\nthe gap to human-like invariance. Finally, we quantify the deviation between\nmetamer graphs and their original counterparts, revealing unique failure modes\nof current GNNs and providing a complementary benchmark for model evaluation.", "AI": {"tldr": "The paper investigates invariance properties in graph neural networks (GNNs) using a novel \"metamers\" generation technique, revealing extreme representational invariance in GNNs that differs significantly from human-like invariance.", "motivation": "To understand the invariance behavior in GNNs and compare it with human brain invariance mechanisms, as current studies show gaps between artificial neural networks and human invariance properties in visual and auditory domains.", "method": "Developed a model \"metamers\" generation technique by optimizing input graphs to match internal node activations of reference graphs, creating graphs that are equivalent in representation space but different in structure and features. Theoretical analysis includes local metamer dimension and activation-induced volume change.", "result": "Uncovered extreme levels of representational invariance across several classic GNN architectures. Targeted architectural modifications and training strategies only partially mitigated excessive invariance without fundamentally bridging the gap to human-like invariance.", "conclusion": "The study reveals unique failure modes of current GNNs and provides a complementary benchmark for model evaluation through quantification of deviation between metamer graphs and their original counterparts."}}
{"id": "2510.17777", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17777", "abs": "https://arxiv.org/abs/2510.17777", "authors": ["Samir Khaki", "Junxian Guo", "Jiaming Tang", "Shang Yang", "Yukang Chen", "Konstantinos N. Plataniotis", "Yao Lu", "Song Han", "Zhijian Liu"], "title": "SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference", "comment": null, "summary": "Vision Language Models (VLMs) have rapidly advanced in integrating visual and\ntextual reasoning, powering applications across high-resolution image\nunderstanding, long-video analysis, and multi-turn conversation. However, their\nscalability remains limited by the growing number of visual tokens that\ndominate inference latency. We present SparseVILA, a new paradigm for efficient\nVLM inference that decouples visual sparsity across the prefilling and decoding\nstages. SparseVILA distributes sparsity across stages by pruning redundant\nvisual tokens during prefill and retrieving only query-relevant tokens during\ndecoding. This decoupled design matches leading prefill pruning methods while\npreserving multi-turn fidelity by retaining most of the visual cache so that\nquery-aware tokens can be retrieved at each conversation round. Built on an\nAWQ-optimized inference pipeline, SparseVILA achieves up to 4.0 times faster\nprefilling, 2.5 times faster decoding, and an overall 2.6 times end-to-end\nspeedup on long-context video tasks -- while improving accuracy on\ndocument-understanding and reasoning tasks. By decoupling query-agnostic\npruning and query-aware retrieval, SparseVILA establishes a new direction for\nefficient multimodal inference, offering a training-free, architecture-agnostic\nframework for accelerating large VLMs without sacrificing capability.", "AI": {"tldr": "SparseVILA is an efficient VLM inference paradigm that decouples visual sparsity across prefilling and decoding stages, achieving up to 4.0\u00d7 faster prefilling and 2.5\u00d7 faster decoding while maintaining accuracy.", "motivation": "Vision Language Models face scalability limitations due to growing visual tokens that dominate inference latency, requiring more efficient inference methods.", "method": "Decouples visual sparsity by pruning redundant visual tokens during prefill and retrieving only query-relevant tokens during decoding, built on AWQ-optimized inference pipeline.", "result": "Achieves up to 4.0\u00d7 faster prefilling, 2.5\u00d7 faster decoding, and 2.6\u00d7 overall speedup on long-context video tasks while improving accuracy on document-understanding and reasoning tasks.", "conclusion": "SparseVILA establishes a new direction for efficient multimodal inference with a training-free, architecture-agnostic framework that accelerates large VLMs without sacrificing capability."}}
{"id": "2510.17380", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17380", "abs": "https://arxiv.org/abs/2510.17380", "authors": ["Julen Cestero", "Carmine Delle Femine", "Kenji S. Muro", "Marco Quartulli", "Marcello Restelli"], "title": "Optimizing Energy Management of Smart Grid using Reinforcement Learning aided by Surrogate models built using Physics-informed Neural Networks", "comment": null, "summary": "Optimizing the energy management within a smart grids scenario presents\nsignificant challenges, primarily due to the complexity of real-world systems\nand the intricate interactions among various components. Reinforcement Learning\n(RL) is gaining prominence as a solution for addressing the challenges of\nOptimal Power Flow in smart grids. However, RL needs to iterate compulsively\nthroughout a given environment to obtain the optimal policy. This means\nobtaining samples from a, most likely, costly simulator, which can lead to a\nsample efficiency problem. In this work, we address this problem by\nsubstituting costly smart grid simulators with surrogate models built using\nPhisics-informed Neural Networks (PINNs), optimizing the RL policy training\nprocess by arriving to convergent results in a fraction of the time employed by\nthe original environment.", "AI": {"tldr": "Using Physics-informed Neural Networks (PINNs) as surrogate models to replace costly smart grid simulators, improving sample efficiency in Reinforcement Learning for Optimal Power Flow optimization.", "motivation": "Reinforcement Learning needs extensive iterations in costly simulators for smart grid energy management, leading to sample efficiency problems.", "method": "Substitute expensive smart grid simulators with PINN-based surrogate models to optimize RL policy training.", "result": "Achieved convergent results in a fraction of the time compared to using the original environment.", "conclusion": "PINN-based surrogate models effectively address sample efficiency issues in RL for smart grid optimization."}}
{"id": "2510.17790", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17790", "abs": "https://arxiv.org/abs/2510.17790", "authors": ["Yuhao Yang", "Zhen Yang", "Zi-Yi Dou", "Anh Nguyen", "Keen You", "Omar Attia", "Andrew Szot", "Michael Feng", "Ram Ramrakhya", "Alexander Toshev", "Chao Huang", "Yinfei Yang", "Zhe Gan"], "title": "UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action", "comment": null, "summary": "Multimodal agents for computer use rely exclusively on primitive actions\n(click, type, scroll) that require accurate visual grounding and lengthy\nexecution chains, leading to cascading failures and performance bottlenecks.\nWhile other agents leverage rich programmatic interfaces (APIs, MCP servers,\ntools), computer-use agents (CUAs) remain isolated from these capabilities. We\npresent UltraCUA, a foundation model that bridges this gap through hybrid\naction -- seamlessly integrating GUI primitives with high-level programmatic\ntool calls. To achieve this, our approach comprises four key components: (1) an\nautomated pipeline that scales programmatic tools from software documentation,\nopen-source repositories, and code generation; (2) a synthetic data engine\nproducing over 17,000 verifiable tasks spanning real-world computer-use\nscenarios; (3) a large-scale high-quality hybrid action trajectory collection\nwith both low-level GUI actions and high-level programmatic tool calls; and (4)\na two-stage training pipeline combining supervised fine-tuning with online\nreinforcement learning, enabling strategic alternation between low-level and\nhigh-level actions. Experiments with our 7B and 32B models demonstrate\nsubstantial improvements over state-of-the-art agents. On OSWorld, UltraCUA\nmodels achieve an average 22% relative improvement over base models, while\nbeing 11% faster in terms of steps. Out-of-domain evaluation on\nWindowsAgentArena shows our model reaches 21.7% success rate, outperforming\nbaselines trained on Windows data. The hybrid action mechanism proves critical,\nreducing error propagation while maintaining execution efficiency.", "AI": {"tldr": "UltraCUA is a foundation model that bridges multimodal computer-use agents with programmatic tools through hybrid actions, combining GUI primitives with high-level tool calls to reduce cascading failures and improve performance.", "motivation": "Current computer-use agents rely exclusively on primitive actions (click, type, scroll) which lead to cascading failures and performance bottlenecks, while being isolated from rich programmatic interfaces available to other agents.", "method": "Four key components: (1) automated pipeline for scaling programmatic tools from documentation and code, (2) synthetic data engine with 17,000+ verifiable tasks, (3) large-scale hybrid action trajectory collection, and (4) two-stage training combining supervised fine-tuning with online reinforcement learning.", "result": "7B and 32B models show 22% relative improvement on OSWorld, 11% faster execution, and 21.7% success rate on WindowsAgentArena (outperforming Windows-trained baselines). Hybrid action reduces error propagation while maintaining efficiency.", "conclusion": "Hybrid action mechanism successfully bridges the gap between GUI primitives and programmatic tools, enabling more efficient and robust computer-use agents with substantial performance improvements over state-of-the-art approaches."}}
{"id": "2510.17381", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17381", "abs": "https://arxiv.org/abs/2510.17381", "authors": ["Achref Jaziri", "Martin Rogmann", "Martin Mundt", "Visvanathan Ramesh"], "title": "Beyond Binary Out-of-Distribution Detection: Characterizing Distributional Shifts with Multi-Statistic Diffusion Trajectories", "comment": "11 Pages, 6 Figures", "summary": "Detecting out-of-distribution (OOD) data is critical for machine learning, be\nit for safety reasons or to enable open-ended learning. However, beyond mere\ndetection, choosing an appropriate course of action typically hinges on the\ntype of OOD data encountered. Unfortunately, the latter is generally not\ndistinguished in practice, as modern OOD detection methods collapse\ndistributional shifts into single scalar outlier scores. This work argues that\nscalar-based methods are thus insufficient for OOD data to be properly\ncontextualized and prospectively exploited, a limitation we overcome with the\nintroduction of DISC: Diffusion-based Statistical Characterization. DISC\nleverages the iterative denoising process of diffusion models to extract a\nrich, multi-dimensional feature vector that captures statistical discrepancies\nacross multiple noise levels. Extensive experiments on image and tabular\nbenchmarks show that DISC matches or surpasses state-of-the-art detectors for\nOOD detection and, crucially, also classifies OOD type, a capability largely\nabsent from prior work. As such, our work enables a shift from simple binary\nOOD detection to a more granular detection.", "AI": {"tldr": "DISC introduces a diffusion-based method for multi-dimensional OOD characterization that goes beyond binary detection to classify OOD types, outperforming traditional scalar-based approaches.", "motivation": "Current OOD detection methods collapse distributional shifts into single scalar scores, which is insufficient for contextualizing and exploiting OOD data since appropriate actions depend on the specific type of OOD encountered.", "method": "DISC leverages the iterative denoising process of diffusion models to extract rich, multi-dimensional feature vectors that capture statistical discrepancies across multiple noise levels.", "result": "Extensive experiments show DISC matches or surpasses state-of-the-art detectors for OOD detection and uniquely enables classification of OOD types, a capability largely absent from prior work.", "conclusion": "DISC enables a shift from simple binary OOD detection to more granular detection and characterization of OOD data types, facilitating better contextualization and prospective exploitation of OOD samples."}}
{"id": "2510.17800", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17800", "abs": "https://arxiv.org/abs/2510.17800", "authors": ["Jiale Cheng", "Yusen Liu", "Xinyu Zhang", "Yulin Fei", "Wenyi Hong", "Ruiliang Lyu", "Weihan Wang", "Zhe Su", "Xiaotao Gu", "Xiao Liu", "Yushi Bai", "Jie Tang", "Hongning Wang", "Minlie Huang"], "title": "Glyph: Scaling Context Windows via Visual-Text Compression", "comment": null, "summary": "Large language models (LLMs) increasingly rely on long-context modeling for\ntasks such as document understanding, code analysis, and multi-step reasoning.\nHowever, scaling context windows to the million-token level brings prohibitive\ncomputational and memory costs, limiting the practicality of long-context LLMs.\nIn this work, we take a different perspective-visual context scaling-to tackle\nthis challenge. Instead of extending token-based sequences, we propose Glyph, a\nframework that renders long texts into images and processes them with\nvision-language models (VLMs). This approach substantially compresses textual\ninput while preserving semantic information, and we further design an\nLLM-driven genetic search to identify optimal visual rendering configurations\nfor balancing accuracy and compression. Through extensive experiments, we\ndemonstrate that our method achieves 3-4x token compression while maintaining\naccuracy comparable to leading LLMs such as Qwen3-8B on various long-context\nbenchmarks. This compression also leads to around 4x faster prefilling and\ndecoding, and approximately 2x faster SFT training. Furthermore, under extreme\ncompression, a 128K-context VLM could scale to handle 1M-token-level text\ntasks. In addition, the rendered text data benefits real-world multimodal\ntasks, such as document understanding. Our code and model are released at\nhttps://github.com/thu-coai/Glyph.", "AI": {"tldr": "Glyph converts long text into images using vision-language models to achieve 3-4x token compression while maintaining accuracy comparable to leading LLMs, enabling efficient processing of million-token contexts.", "motivation": "Scaling context windows to million-token levels in LLMs brings prohibitive computational and memory costs, limiting the practicality of long-context models.", "method": "Proposes Glyph framework that renders long texts into images and processes them with vision-language models, using LLM-driven genetic search to optimize visual rendering configurations for accuracy-compression balance.", "result": "Achieves 3-4x token compression with comparable accuracy to Qwen3-8B, 4x faster prefilling/decoding, 2x faster SFT training, and enables 128K-context VLM to handle 1M-token tasks under extreme compression.", "conclusion": "Visual context scaling through text-to-image rendering provides an effective alternative to token-based sequence extension, offering substantial efficiency gains for long-context processing while maintaining performance."}}
{"id": "2510.17383", "categories": ["cs.LG", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.17383", "abs": "https://arxiv.org/abs/2510.17383", "authors": ["Ludovica Schaerf"], "title": "Latent Spaces Beyond Synthesis: From GANs to Diffusion Models", "comment": "Presented and published at Ethics and Aesthetics of Artificial\n  Intelligence Conference (EA-AI'25)", "summary": "This paper examines the evolving nature of internal representations in\ngenerative visual models, focusing on the conceptual and technical shift from\nGANs and VAEs to diffusion-based architectures. Drawing on Beatrice Fazi's\naccount of synthesis as the amalgamation of distributed representations, we\npropose a distinction between \"synthesis in a strict sense\", where a compact\nlatent space wholly determines the generative process, and \"synthesis in a\nbroad sense,\" which characterizes models whose representational labor is\ndistributed across layers. Through close readings of model architectures and a\ntargeted experimental setup that intervenes in layerwise representations, we\nshow how diffusion models fragment the burden of representation and thereby\nchallenge assumptions of unified internal space. By situating these findings\nwithin media theoretical frameworks and critically engaging with metaphors such\nas the latent space and the Platonic Representation Hypothesis, we argue for a\nreorientation of how generative AI is understood: not as a direct synthesis of\ncontent, but as an emergent configuration of specialized processes.", "AI": {"tldr": "The paper analyzes how generative visual models' internal representations have evolved from GANs/VAEs to diffusion models, showing diffusion models distribute representational work across layers rather than using unified latent spaces.", "motivation": "To understand the conceptual shift in generative AI from models with compact latent spaces to those with distributed representations, challenging traditional assumptions about internal model spaces.", "method": "Close readings of model architectures and targeted experiments that intervene in layerwise representations of diffusion models to analyze how representation is fragmented.", "result": "Diffusion models fragment the burden of representation across layers, challenging the assumption of unified internal space and showing emergent configuration of specialized processes.", "conclusion": "Generative AI should be understood not as direct synthesis of content but as emergent configuration of specialized processes, requiring reorientation of how we conceptualize these models."}}
{"id": "2510.17803", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17803", "abs": "https://arxiv.org/abs/2510.17803", "authors": ["Zixin Yin", "Ling-Hao Chen", "Lionel Ni", "Xili Dai"], "title": "ConsistEdit: Highly Consistent and Precise Training-free Visual Editing", "comment": "SIGGRAPH Asia 2025", "summary": "Recent advances in training-free attention control methods have enabled\nflexible and efficient text-guided editing capabilities for existing generation\nmodels. However, current approaches struggle to simultaneously deliver strong\nediting strength while preserving consistency with the source. This limitation\nbecomes particularly critical in multi-round and video editing, where visual\nerrors can accumulate over time. Moreover, most existing methods enforce global\nconsistency, which limits their ability to modify individual attributes such as\ntexture while preserving others, thereby hindering fine-grained editing.\nRecently, the architectural shift from U-Net to MM-DiT has brought significant\nimprovements in generative performance and introduced a novel mechanism for\nintegrating text and vision modalities. These advancements pave the way for\novercoming challenges that previous methods failed to resolve. Through an\nin-depth analysis of MM-DiT, we identify three key insights into its attention\nmechanisms. Building on these, we propose ConsistEdit, a novel attention\ncontrol method specifically tailored for MM-DiT. ConsistEdit incorporates\nvision-only attention control, mask-guided pre-attention fusion, and\ndifferentiated manipulation of the query, key, and value tokens to produce\nconsistent, prompt-aligned edits. Extensive experiments demonstrate that\nConsistEdit achieves state-of-the-art performance across a wide range of image\nand video editing tasks, including both structure-consistent and\nstructure-inconsistent scenarios. Unlike prior methods, it is the first\napproach to perform editing across all inference steps and attention layers\nwithout handcraft, significantly enhancing reliability and consistency, which\nenables robust multi-round and multi-region editing. Furthermore, it supports\nprogressive adjustment of structural consistency, enabling finer control.", "AI": {"tldr": "ConsistEdit is a novel attention control method for MM-DiT models that enables consistent text-guided editing across images and videos through vision-only attention control, mask-guided pre-attention fusion, and differentiated token manipulation.", "motivation": "Current training-free attention control methods struggle to balance editing strength with source consistency, especially in multi-round and video editing where errors accumulate. Existing methods also enforce global consistency, limiting fine-grained attribute editing.", "method": "Proposes ConsistEdit with three key components: vision-only attention control, mask-guided pre-attention fusion, and differentiated manipulation of query, key, and value tokens. Works across all inference steps and attention layers without handcraft.", "result": "Achieves state-of-the-art performance across image and video editing tasks, including both structure-consistent and structure-inconsistent scenarios. Enables robust multi-round and multi-region editing with progressive structural consistency adjustment.", "conclusion": "ConsistEdit is the first method to perform editing across all inference steps and attention layers without handcraft, significantly enhancing reliability and consistency for fine-grained editing tasks."}}
{"id": "2510.17385", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17385", "abs": "https://arxiv.org/abs/2510.17385", "authors": ["Pengxiang Cai", "Zihao Gao", "Jintai Chen"], "title": "TabR1: Taming GRPO for tabular reasoning LLMs", "comment": null, "summary": "Tabular prediction has traditionally relied on gradient-boosted decision\ntrees and specialized deep learning models, which excel within tasks but\nprovide limited interpretability and weak transfer across tables. Reasoning\nlarge language models (LLMs) promise cross-task adaptability with trans- parent\nreasoning traces, yet their potential has not been fully realized for tabular\ndata. This paper presents TabR1, the first reasoning LLM for tabular prediction\nwith multi-step reasoning. At its core is Permutation Relative Policy\nOptimization (PRPO), a simple yet efficient reinforcement learning method that\nencodes column-permutation invariance as a structural prior. By construct- ing\nmultiple label-preserving permutations per sample and estimating advantages\nboth within and across permutations, PRPO transforms sparse rewards into dense\nlearning signals and improves generalization. With limited supervision, PRPO\nactivates the reasoning ability of LLMs for tabular prediction, enhancing\nfew-shot and zero-shot performance as well as interpretability. Comprehensive\nexperiments demonstrate that TabR1 achieves performance comparable to strong\nbaselines under full-supervision fine-tuning. In the zero-shot setting, TabR1\napproaches the performance of strong baselines under the 32-shot setting.\nMoreover, TabR1 (8B) substantially outperforms much larger LLMs across various\ntasks, achieving up to 53.17% improvement over DeepSeek-R1 (685B).", "AI": {"tldr": "TabR1 is the first reasoning LLM for tabular prediction that uses multi-step reasoning and PRPO reinforcement learning to achieve strong performance with limited supervision while maintaining interpretability.", "motivation": "Traditional tabular prediction methods (gradient-boosted trees, specialized deep learning) have limited interpretability and weak cross-table transfer, while reasoning LLMs offer adaptability and transparent reasoning but haven't been fully realized for tabular data.", "method": "Uses Permutation Relative Policy Optimization (PRPO) - a reinforcement learning method that encodes column-permutation invariance by constructing multiple label-preserving permutations per sample and estimating advantages within/across permutations to transform sparse rewards into dense learning signals.", "result": "TabR1 achieves performance comparable to strong baselines under full-supervision, approaches 32-shot baseline performance in zero-shot setting, and TabR1 (8B) substantially outperforms much larger LLMs (up to 53.17% improvement over DeepSeek-R1 685B).", "conclusion": "PRPO effectively activates LLM reasoning ability for tabular prediction, enhancing few-shot/zero-shot performance and interpretability while maintaining strong results across various tasks."}}
{"id": "2510.17390", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17390", "abs": "https://arxiv.org/abs/2510.17390", "authors": ["Seouh-won Yi", "Min-hwan Oh"], "title": "Exploration via Feature Perturbation in Contextual Bandits", "comment": "Accepted at NeurIPS 2025 (spotlight)", "summary": "We propose feature perturbation, a simple yet powerful technique that injects\nrandomness directly into feature inputs, instead of randomizing unknown\nparameters or adding noise to rewards. Remarkably, this algorithm achieves\n$\\tilde{\\mathcal{O}}(d\\sqrt{T})$ worst-case regret bound for generalized linear\nbandits, while avoiding the $\\tilde{\\mathcal{O}}(d^{3/2}\\sqrt{T})$ regret\ntypical of existing randomized bandit algorithms. Because our algorithm eschews\nparameter sampling, it is both computationally efficient and naturally extends\nto non-parametric or neural network models. We verify these advantages through\nempirical evaluations, demonstrating that feature perturbation not only\nsurpasses existing methods but also unifies strong practical performance with\nbest-known theoretical guarantees.", "AI": {"tldr": "Feature perturbation is a novel bandit algorithm that injects randomness into feature inputs rather than parameters or rewards, achieving improved regret bounds and computational efficiency.", "motivation": "Existing randomized bandit algorithms suffer from suboptimal regret bounds (O(d^{3/2}\u221aT)) and computational inefficiency due to parameter sampling, motivating a simpler approach that avoids these limitations.", "method": "The proposed method injects random perturbations directly into feature inputs instead of randomizing unknown parameters or adding noise to rewards.", "result": "The algorithm achieves O(d\u221aT) worst-case regret for generalized linear bandits, outperforming existing methods that typically achieve O(d^{3/2}\u221aT) regret. It is computationally efficient and extends to non-parametric/neural models.", "conclusion": "Feature perturbation unifies strong practical performance with best-known theoretical guarantees, surpassing existing methods while being computationally efficient and broadly applicable."}}
{"id": "2510.17391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17391", "abs": "https://arxiv.org/abs/2510.17391", "authors": ["Jongmin Lee", "Ernest K. Ryu"], "title": "Finite-Time Bounds for Average-Reward Fitted Q-Iteration", "comment": null, "summary": "Although there is an extensive body of work characterizing the sample\ncomplexity of discounted-return offline RL with function approximations, prior\nwork on the average-reward setting has received significantly less attention,\nand existing approaches rely on restrictive assumptions, such as ergodicity or\nlinearity of the MDP. In this work, we establish the first sample complexity\nresults for average-reward offline RL with function approximation for weakly\ncommunicating MDPs, a much milder assumption. To this end, we introduce\nAnchored Fitted Q-Iteration, which combines the standard Fitted Q-Iteration\nwith an anchor mechanism. We show that the anchor, which can be interpreted as\na form of weight decay, is crucial for enabling finite-time analysis in the\naverage-reward setting. We also extend our finite-time analysis to the setup\nwhere the dataset is generated from a single-trajectory rather than IID\ntransitions, again leveraging the anchor mechanism.", "AI": {"tldr": "First sample complexity results for average-reward offline RL with function approximation for weakly communicating MDPs, introducing Anchored Fitted Q-Iteration with anchor mechanism.", "motivation": "Prior work on average-reward offline RL had restrictive assumptions like ergodicity or linearity, while this work addresses weakly communicating MDPs with milder assumptions.", "method": "Introduces Anchored Fitted Q-Iteration, combining standard Fitted Q-Iteration with an anchor mechanism (interpreted as weight decay) to enable finite-time analysis.", "result": "Establishes first sample complexity results for average-reward offline RL with function approximation under weaker assumptions, and extends analysis to single-trajectory datasets.", "conclusion": "Anchor mechanism is crucial for finite-time analysis in average-reward setting and enables extension to non-IID single-trajectory datasets."}}
{"id": "2510.17394", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17394", "abs": "https://arxiv.org/abs/2510.17394", "authors": ["Alejandro Guerra-Manzanares", "Farah E. Shamout"], "title": "MILES: Modality-Informed Learning Rate Scheduler for Balancing Multimodal Learning", "comment": "Accepted and presented at the 2025 International Joint Conference on\n  Neural Networks (IJCNN'25). The paper was awarded an honorable mention (best\n  4 papers)", "summary": "The aim of multimodal neural networks is to combine diverse data sources,\nreferred to as modalities, to achieve enhanced performance compared to relying\non a single modality. However, training of multimodal networks is typically\nhindered by modality overfitting, where the network relies excessively on one\nof the available modalities. This often yields sub-optimal performance,\nhindering the potential of multimodal learning and resulting in marginal\nimprovements relative to unimodal models. In this work, we present the\nModality-Informed Learning ratE Scheduler (MILES) for training multimodal joint\nfusion models in a balanced manner. MILES leverages the differences in\nmodality-wise conditional utilization rates during training to effectively\nbalance multimodal learning. The learning rate is dynamically adjusted during\ntraining to balance the speed of learning from each modality by the multimodal\nmodel, aiming for enhanced performance in both multimodal and unimodal\npredictions. We extensively evaluate MILES on four multimodal joint fusion\ntasks and compare its performance to seven state-of-the-art baselines. Our\nresults show that MILES outperforms all baselines across all tasks and fusion\nmethods considered in our study, effectively balancing modality usage during\ntraining. This results in improved multimodal performance and stronger modality\nencoders, which can be leveraged when dealing with unimodal samples or absent\nmodalities. Overall, our work highlights the impact of balancing multimodal\nlearning on improving model performance.", "AI": {"tldr": "MILES is a learning rate scheduler that dynamically adjusts rates during multimodal training to balance modality usage and prevent overfitting to specific modalities, improving both multimodal and unimodal performance.", "motivation": "Multimodal networks often suffer from modality overfitting where they rely excessively on one modality, leading to sub-optimal performance and marginal improvements over unimodal models.", "method": "MILES dynamically adjusts learning rates during training based on modality-wise conditional utilization rates to balance learning speed from each modality in multimodal joint fusion models.", "result": "MILES outperformed seven state-of-the-art baselines across four multimodal tasks, effectively balancing modality usage and improving both multimodal performance and modality encoder quality.", "conclusion": "Balancing multimodal learning through dynamic learning rate adjustment significantly improves model performance and creates stronger modality encoders that work well with unimodal samples."}}
{"id": "2510.17414", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17414", "abs": "https://arxiv.org/abs/2510.17414", "authors": ["Hequn Li", "Zhongwei Deng", "Chunlin Jiang", "Yvxin He andZhansheng Ning"], "title": "A Conditional Diffusion Model for Probabilistic Prediction of Battery Capacity Degradation", "comment": null, "summary": "Accurate prediction of lithium-ion battery capacity and its associated\nuncertainty is essential for reliable battery management but remains\nchallenging due to the stochastic nature of aging. This paper presents a novel\nmethod, termed the Condition Diffusion U-Net with Attention (CDUA), which\nintegrates feature engineering and deep learning to address this challenge. The\nproposed approach employs a diffusion-based generative model for time-series\nforecasting and incorporates attention mechanisms to enhance predictive\nperformance. Battery capacity is first derived from real-world vehicle\noperation data. The most relevant features are then identified using the\nPearson correlation coefficient and the XGBoost algorithm. These features are\nused to train the CDUA model, which comprises two core components: (1) a\ncontextual U-Net with self-attention to capture complex temporal dependencies,\nand (2) a denoising network to reconstruct accurate capacity values from noisy\nobservations. Experimental validation on the real-world vehicle data\ndemonstrates that the proposed CDUA model achieves a relative Mean Absolute\nError (MAE) of 0.94% and a relative Root Mean Square Error (RMSE) of 1.14%,\nwith a narrow 95% confidence interval of 3.74% in relative width. These results\nconfirm that CDUA provides both accurate capacity estimation and reliable\nuncertainty quantification. Comparative experiments further verify its\nrobustness and superior performance over existing mainstream approaches.", "AI": {"tldr": "The paper introduces CDUA, a diffusion-based model with attention mechanisms for accurate lithium-ion battery capacity prediction and uncertainty quantification, achieving state-of-the-art performance on real-world vehicle data.", "motivation": "Accurate prediction of lithium-ion battery capacity and its uncertainty is essential for reliable battery management but remains challenging due to the stochastic nature of battery aging.", "method": "Proposes CDUA model that integrates feature engineering (Pearson correlation and XGBoost) with deep learning. Uses diffusion-based generative model with contextual U-Net with self-attention for temporal dependencies and denoising network for capacity reconstruction.", "result": "Achieves relative MAE of 0.94%, relative RMSE of 1.14%, and narrow 95% confidence interval of 3.74% relative width on real-world vehicle data, demonstrating superior performance over existing approaches.", "conclusion": "CDUA provides both accurate capacity estimation and reliable uncertainty quantification, confirming its robustness and superior performance for battery management applications."}}
{"id": "2510.17421", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17421", "abs": "https://arxiv.org/abs/2510.17421", "authors": ["Duo Su", "Huyu Wu", "Huanran Chen", "Yiming Shi", "Yuzhu Wang", "Xi Ye", "Jun Zhu"], "title": "Diffusion Models as Dataset Distillation Priors", "comment": null, "summary": "Dataset distillation aims to synthesize compact yet informative datasets from\nlarge ones. A significant challenge in this field is achieving a trifecta of\ndiversity, generalization, and representativeness in a single distilled\ndataset. Although recent generative dataset distillation methods adopt powerful\ndiffusion models as their foundation models, the inherent representativeness\nprior in diffusion models is overlooked. Consequently, these approaches often\nnecessitate the integration of external constraints to enhance data quality. To\naddress this, we propose Diffusion As Priors (DAP), which formalizes\nrepresentativeness by quantifying the similarity between synthetic and real\ndata in feature space using a Mercer kernel. We then introduce this prior as\nguidance to steer the reverse diffusion process, enhancing the\nrepresentativeness of distilled samples without any retraining. Extensive\nexperiments on large-scale datasets, such as ImageNet-1K and its subsets,\ndemonstrate that DAP outperforms state-of-the-art methods in generating\nhigh-fidelity datasets while achieving superior cross-architecture\ngeneralization. Our work not only establishes a theoretical connection between\ndiffusion priors and the objectives of dataset distillation but also provides a\npractical, training-free framework for improving the quality of the distilled\ndataset.", "AI": {"tldr": "DAP leverages diffusion models' inherent representativeness prior to improve dataset distillation by guiding the reverse diffusion process with feature similarity constraints, achieving better diversity and generalization without retraining.", "motivation": "Current generative dataset distillation methods overlook the inherent representativeness prior in diffusion models and require external constraints, limiting their effectiveness in achieving diversity, generalization, and representativeness simultaneously.", "method": "Proposes Diffusion As Priors (DAP) that formalizes representativeness using Mercer kernel to measure feature similarity between synthetic and real data, then guides reverse diffusion process with this prior without requiring model retraining.", "result": "Extensive experiments on ImageNet-1K and subsets show DAP outperforms state-of-the-art methods in generating high-fidelity datasets with superior cross-architecture generalization.", "conclusion": "DAP establishes theoretical connection between diffusion priors and dataset distillation objectives while providing practical training-free framework for improving distilled dataset quality."}}
{"id": "2510.17457", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17457", "abs": "https://arxiv.org/abs/2510.17457", "authors": ["Li Sun", "Zhenhao Huang", "Ming Zhang", "Philip S. Yu"], "title": "Deeper with Riemannian Geometry: Overcoming Oversmoothing and Oversquashing for Graph Foundation Models", "comment": "Accept by NeurIPS 25", "summary": "Message Passing Neural Networks (MPNNs) is the building block of graph\nfoundation models, but fundamentally suffer from oversmoothing and\noversquashing. There has recently been a surge of interest in fixing both\nissues. Existing efforts primarily adopt global approaches, which may be\nbeneficial in some regions but detrimental in others, ultimately leading to the\nsuboptimal expressiveness. In this paper, we begin by revisiting oversquashing\nthrough a global measure -- spectral gap $\\lambda$ -- and prove that the\nincrease of $\\lambda$ leads to gradient vanishing with respect to the input\nfeatures, thereby undermining the effectiveness of message passing. Motivated\nby such theoretical insights, we propose a \\textbf{local} approach that\nadaptively adjusts message passing based on local structures. To achieve this,\nwe connect local Riemannian geometry with MPNNs, and establish a novel\nnonhomogeneous boundary condition to address both oversquashing and\noversmoothing. Building on the Robin condition, we design a GBN network with\nlocal bottleneck adjustment, coupled with theoretical guarantees. Extensive\nexperiments on homophilic and heterophilic graphs show the expressiveness of\nGBN. Furthermore, GBN does not exhibit performance degradation even when the\nnetwork depth exceeds $256$ layers.", "AI": {"tldr": "The paper proposes GBN, a local approach using Riemannian geometry and Robin boundary conditions to address oversmoothing and oversquashing in Message Passing Neural Networks, enabling deep networks (256+ layers) without performance degradation.", "motivation": "MPNNs suffer from oversmoothing and oversquashing issues, and existing global approaches lead to suboptimal expressiveness. The authors identify that increasing spectral gap causes gradient vanishing, motivating a local solution.", "method": "Connect local Riemannian geometry with MPNNs, establish nonhomogeneous boundary conditions (Robin condition), and design GBN network with local bottleneck adjustment to adaptively adjust message passing based on local structures.", "result": "Extensive experiments on homophilic and heterophilic graphs show GBN's expressiveness. GBN maintains performance even with network depth exceeding 256 layers, overcoming the typical degradation in deep MPNNs.", "conclusion": "The local approach using Riemannian geometry and Robin boundary conditions effectively addresses both oversmoothing and oversquashing in MPNNs, enabling deep graph networks with sustained performance."}}
{"id": "2510.17458", "categories": ["cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.17458", "abs": "https://arxiv.org/abs/2510.17458", "authors": ["Ayrat Abdullin", "Denis Anikiev", "Umair bin Waheed"], "title": "Explainable AI for microseismic event detection", "comment": "Submitted to Artificial Intelligence in Geosciences", "summary": "Deep neural networks like PhaseNet show high accuracy in detecting\nmicroseismic events, but their black-box nature is a concern in critical\napplications. We apply explainable AI (XAI) techniques, such as\nGradient-weighted Class Activation Mapping (Grad-CAM) and Shapley Additive\nExplanations (SHAP), to interpret the PhaseNet model's decisions and improve\nits reliability. Grad-CAM highlights that the network's attention aligns with\nP- and S-wave arrivals. SHAP values quantify feature contributions, confirming\nthat vertical-component amplitudes drive P-phase picks while horizontal\ncomponents dominate S-phase picks, consistent with geophysical principles.\nLeveraging these insights, we introduce a SHAP-gated inference scheme that\ncombines the model's output with an explanation-based metric to reduce errors.\nOn a test set of 9,000 waveforms, the SHAP-gated model achieved an F1-score of\n0.98 (precision 0.99, recall 0.97), outperforming the baseline PhaseNet\n(F1-score 0.97) and demonstrating enhanced robustness to noise. These results\nshow that XAI can not only interpret deep learning models but also directly\nenhance their performance, providing a template for building trust in automated\nseismic detectors.", "AI": {"tldr": "Applied explainable AI (XAI) techniques to interpret PhaseNet's seismic event detection, revealing network attention aligns with P- and S-wave arrivals. Introduced SHAP-gated inference that improved performance to F1-score 0.98.", "motivation": "Address concerns about black-box nature of deep neural networks like PhaseNet in critical seismic applications by making their decisions interpretable and improving reliability.", "method": "Used Grad-CAM to visualize network attention and SHAP to quantify feature contributions. Developed SHAP-gated inference scheme combining model output with explanation-based metrics.", "result": "SHAP-gated model achieved F1-score 0.98 (precision 0.99, recall 0.97) on 9,000 test waveforms, outperforming baseline PhaseNet (F1-score 0.97) and showing enhanced noise robustness.", "conclusion": "XAI can both interpret deep learning models and directly enhance their performance, providing a template for building trust in automated seismic detectors."}}
{"id": "2510.17467", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17467", "abs": "https://arxiv.org/abs/2510.17467", "authors": ["Dan Zheng", "Jing Feng", "Juan Liu"], "title": "CrossStateECG: Multi-Scale Deep Convolutional Network with Attention for Rest-Exercise ECG Biometrics", "comment": null, "summary": "Current research in Electrocardiogram (ECG) biometrics mainly emphasizes\nresting-state conditions, leaving the performance decline in rest-exercise\nscenarios largely unresolved. This paper introduces CrossStateECG, a robust\nECG-based authentication model explicitly tailored for cross-state\n(rest-exercise) conditions. The proposed model creatively combines multi-scale\ndeep convolutional feature extraction with attention mechanisms to ensure\nstrong identification across different physiological states. Experimental\nresults on the exercise-ECGID dataset validate the effectiveness of\nCrossStateECG, achieving an identification accuracy of 92.50% in the\nRest-to-Exercise scenario (training on resting ECG and testing on post-exercise\nECG) and 94.72% in the Exercise-to-Rest scenario (training on post-exercise ECG\nand testing on resting ECG). Furthermore, CrossStateECG demonstrates\nexceptional performance across both state combinations, reaching an accuracy of\n99.94% in Rest-to-Rest scenarios and 97.85% in Mixed-to-Mixed scenarios.\nAdditional validations on the ECG-ID and MIT-BIH datasets further confirmed the\ngeneralization abilities of CrossStateECG, underscoring its potential as a\npractical solution for post-exercise ECG-based authentication in dynamic\nreal-world settings.", "AI": {"tldr": "CrossStateECG is a robust ECG-based authentication model that addresses performance decline in rest-exercise scenarios by combining multi-scale deep convolutional feature extraction with attention mechanisms, achieving high accuracy across different physiological states.", "motivation": "Current ECG biometrics research mainly focuses on resting-state conditions, leaving the performance decline in rest-exercise scenarios largely unresolved, which limits practical applications in dynamic real-world settings.", "method": "The model creatively combines multi-scale deep convolutional feature extraction with attention mechanisms to ensure strong identification across different physiological states.", "result": "Achieved 92.50% accuracy in Rest-to-Exercise scenario, 94.72% in Exercise-to-Rest scenario, 99.94% in Rest-to-Rest scenarios, and 97.85% in Mixed-to-Mixed scenarios. Additional validations on ECG-ID and MIT-BIH datasets confirmed generalization abilities.", "conclusion": "CrossStateECG demonstrates exceptional performance across state combinations and shows strong generalization, underscoring its potential as a practical solution for post-exercise ECG-based authentication in dynamic real-world settings."}}
{"id": "2510.17469", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17469", "abs": "https://arxiv.org/abs/2510.17469", "authors": ["Jing Liu"], "title": "Layer Specialization Underlying Compositional Reasoning in Transformers", "comment": null, "summary": "Transformers exhibit compositional reasoning on sequences not observed during\ntraining, a capability often attributed to in-context learning (ICL) and skill\ncomposition. We investigate this phenomenon using the Random Hierarchy Model\n(RHM), a probabilistic context-free grammar that generates sequences through\nrecursive rule application. Models are trained on subsets of sequences and\nevaluated across four generalization conditions: memorization, in-distribution\ngeneralization, out-of-distribution generalization with the same rules, and\ncross-layer transfer. Behaviorally, performance improves systematically with\ntask complexity and the number of in-context examples, with out-of-distribution\ntasks requiring substantially more examples than in-distribution scenarios.\nMechanistically, we identify a progressive emergence of layer specialization\nduring training that correlates with generalization performance. Principal\ncomponent analysis and attention pattern clustering reveal that transformers\ndevelop structured, hierarchically organized representations in specialized\nlayers. These results demonstrate that transformers develop modular,\ninterpretable mechanisms supporting compositional reasoning, linking internal\nalgorithmic structure to observed behavioral capabilities.", "AI": {"tldr": "Transformers develop compositional reasoning through progressive layer specialization during training, enabling generalization to unseen sequences via structured hierarchical representations.", "motivation": "To understand how transformers achieve compositional reasoning on sequences not seen during training, particularly through in-context learning and skill composition mechanisms.", "method": "Used Random Hierarchy Model (RHM) as a probabilistic context-free grammar to generate sequences. Trained models on sequence subsets and evaluated across four generalization conditions: memorization, in-distribution, out-of-distribution with same rules, and cross-layer transfer.", "result": "Performance improved with task complexity and in-context examples, with out-of-distribution tasks requiring more examples. Layer specialization emerged progressively during training, correlating with generalization. PCA and attention clustering revealed transformers develop structured hierarchical representations in specialized layers.", "conclusion": "Transformers develop modular, interpretable mechanisms supporting compositional reasoning, with internal algorithmic structure directly linked to behavioral capabilities."}}
{"id": "2510.17475", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17475", "abs": "https://arxiv.org/abs/2510.17475", "authors": ["Fo Hu", "Can Wang", "Qinxu Zheng", "Xusheng Yang", "Bin Zhou", "Gang Li", "Yu Sun", "Wen-an Zhang"], "title": "DAMSDAN: Distribution-Aware Multi-Source Domain Adaptation Network for Cross-Domain EEG-based Emotion Recognition", "comment": "14 pages, 9 figures", "summary": "Significant inter-individual variability limits the generalization of\nEEG-based emotion recognition under cross-domain settings. We address two core\nchallenges in multi-source adaptation: (1) dynamically modeling distributional\nheterogeneity across sources and quantifying their relevance to a target to\nreduce negative transfer; and (2) achieving fine-grained semantic consistency\nto strengthen class discrimination. We propose a distribution-aware\nmulti-source domain adaptation network (DAMSDAN). DAMSDAN integrates\nprototype-based constraints with adversarial learning to drive the encoder\ntoward discriminative, domain-invariant emotion representations. A domain-aware\nsource weighting strategy based on maximum mean discrepancy (MMD) dynamically\nestimates inter-domain shifts and reweights source contributions. In addition,\na prototype-guided conditional alignment module with dual pseudo-label\ninteraction enhances pseudo-label reliability and enables category-level,\nfine-grained alignment, mitigating noise propagation and semantic drift.\nExperiments on SEED and SEED-IV show average accuracies of 94.86\\% and 79.78\\%\nfor cross-subject, and 95.12\\% and 83.15\\% for cross-session protocols. On the\nlarge-scale FACED dataset, DAMSDAN achieves 82.88\\% (cross-subject). Extensive\nablations and interpretability analyses corroborate the effectiveness of the\nproposed framework for cross-domain EEG-based emotion recognition.", "AI": {"tldr": "DAMSDAN is a distribution-aware multi-source domain adaptation network for EEG-based emotion recognition that addresses cross-domain variability through dynamic source weighting and fine-grained semantic alignment.", "motivation": "Address significant inter-individual variability in EEG-based emotion recognition that limits generalization under cross-domain settings, particularly dealing with distributional heterogeneity across sources and achieving fine-grained semantic consistency.", "method": "Integrates prototype-based constraints with adversarial learning, uses domain-aware source weighting based on MMD to dynamically estimate inter-domain shifts, and employs prototype-guided conditional alignment with dual pseudo-label interaction for category-level fine-grained alignment.", "result": "Achieved average accuracies of 94.86% and 79.78% on SEED and SEED-IV for cross-subject, 95.12% and 83.15% for cross-session protocols, and 82.88% on FACED dataset for cross-subject emotion recognition.", "conclusion": "The proposed DAMSDAN framework effectively addresses cross-domain EEG-based emotion recognition challenges through dynamic source weighting and fine-grained semantic alignment, as validated by extensive experiments and interpretability analyses."}}
{"id": "2510.17478", "categories": ["cs.LG", "physics.geo-ph", "I.2.6; I.6.3; J.2"], "pdf": "https://arxiv.org/pdf/2510.17478", "abs": "https://arxiv.org/abs/2510.17478", "authors": ["Guillaume Rongier", "Luk Peeters"], "title": "Towards geological inference with process-based and deep generative modeling, part 2: inversion of fluvial deposits and latent-space disentanglement", "comment": "52 pages, 42 figures", "summary": "High costs and uncertainties make subsurface decision-making challenging, as\nacquiring new data is rarely scalable. Embedding geological knowledge directly\ninto predictive models offers a valuable alternative. A joint approach enables\njust that: process-based models that mimic geological processes can help train\ngenerative models that make predictions more efficiently. This study explores\nwhether a generative adversarial network (GAN) - a type of deep-learning\nalgorithm for generative modeling - trained to produce fluvial deposits can be\ninverted to match well and seismic data. Four inversion approaches applied to\nthree test samples with 4, 8, and 20 wells struggled to match these well data,\nespecially as the well number increased or as the test sample diverged from the\ntraining data. The key bottleneck lies in the GAN's latent representation: it\nis entangled, so samples with similar sedimentological features are not\nnecessarily close in the latent space. Label conditioning or latent\noverparameterization can partially disentangle the latent space during\ntraining, although not yet sufficiently for a successful inversion. Fine-tuning\nthe GAN to restructure the latent space locally reduces mismatches to\nacceptable levels for all test cases, with and without seismic data. But this\napproach depends on an initial, partially successful inversion step, which\ninfluences the quality and diversity of the final samples. Overall, GANs can\nalready handle the tasks required for their integration into geomodeling\nworkflows. We still need to further assess their robustness, and how to best\nleverage them in support of geological interpretation.", "AI": {"tldr": "GANs for fluvial deposit modeling can be inverted to match well and seismic data, but face challenges with latent space entanglement. Fine-tuning helps reduce mismatches, though initial inversion quality affects final results.", "motivation": "High costs and uncertainties in subsurface decision-making require alternatives to acquiring new data. Embedding geological knowledge into predictive models through process-based approaches offers a scalable solution.", "method": "Used generative adversarial networks (GANs) trained on fluvial deposits, applied four inversion approaches to match well and seismic data across test samples with 4, 8, and 20 wells. Explored label conditioning, latent overparameterization, and fine-tuning to restructure latent space.", "result": "Inversion struggled to match well data, especially with more wells or samples diverging from training data. Latent space entanglement was the key bottleneck. Fine-tuning reduced mismatches to acceptable levels for all test cases, but depended on initial inversion success.", "conclusion": "GANs can handle tasks for geomodeling workflow integration, but need further assessment of robustness and how to best leverage them for geological interpretation support."}}
{"id": "2510.17650", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2510.17650", "abs": "https://arxiv.org/abs/2510.17650", "authors": ["Athanasios Angelakis", "Amne Mousa", "Micah L. A. Heldeweg", "Laurens A. Biesheuvel", "Mark A. Haaksma", "Jasper M. Smit", "Pieter R. Tuinman", "Paul W. G. Elbers"], "title": "ZACH-ViT: A Zero-Token Vision Transformer with ShuffleStrides Data Augmentation for Robust Lung Ultrasound Classification", "comment": "14 pages, 6 figures, 2 tables. Primary subject: cs.LG (Machine\n  Learning) Cross-listed to: cs.CV (Computer Vision and Pattern Recognition),\n  eess.IV (Image and Video Processing). Code available at:\n  https://github.com/Bluesman79/ZACH-ViT Installation: pip install zachvit\n  Paper licensed under CC BY-NC-ND 4.0. Code released under Apache 2.0 License", "summary": "Differentiating cardiogenic pulmonary oedema (CPE) from non-cardiogenic and\nstructurally normal lungs in lung ultrasound (LUS) videos remains challenging\ndue to the high visual variability of non-cardiogenic inflammatory patterns\n(NCIP/ARDS-like), interstitial lung disease, and healthy lungs. This\nheterogeneity complicates automated classification as overlapping B-lines and\npleural artefacts are common. We introduce ZACH-ViT (Zero-token Adaptive\nCompact Hierarchical Vision Transformer), a 0.25 M-parameter Vision Transformer\nvariant that removes both positional embeddings and the [CLS] token, making it\nfully permutation-invariant and suitable for unordered medical image data. To\nenhance generalization, we propose ShuffleStrides Data Augmentation (SSDA),\nwhich permutes probe-view sequences and frame orders while preserving\nanatomical validity. ZACH-ViT was evaluated on 380 LUS videos from 95\ncritically ill patients against nine state-of-the-art baselines. Despite the\nheterogeneity of the non-cardiogenic group, ZACH-ViT achieved the highest\nvalidation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60)\nand specificity (0.91), while all competing models collapsed to trivial\nclassification. It trains 1.35x faster than Minimal ViT (0.62M parameters) with\n2.5x fewer parameters, supporting real-time clinical deployment. These results\nshow that aligning architectural design with data structure can outperform\nscale in small-data medical imaging.", "AI": {"tldr": "ZACH-ViT is a compact, permutation-invariant Vision Transformer that achieves superior performance in classifying cardiogenic pulmonary oedema from non-cardiogenic patterns in lung ultrasound videos, outperforming larger models through architectural alignment with medical data structure.", "motivation": "Differentiating cardiogenic pulmonary oedema from non-cardiogenic patterns in lung ultrasound videos is challenging due to high visual variability and overlapping features like B-lines, which complicates automated classification.", "method": "Developed ZACH-ViT, a 0.25M-parameter Vision Transformer variant that removes positional embeddings and CLS token for full permutation invariance, combined with ShuffleStrides Data Augmentation to permute probe-view sequences while preserving anatomical validity.", "result": "ZACH-ViT achieved highest validation and test ROC-AUC (0.80 and 0.79) with balanced sensitivity (0.60) and specificity (0.91) on 380 LUS videos, while competing models collapsed to trivial classification. It trains 1.35x faster than Minimal ViT with 2.5x fewer parameters.", "conclusion": "Aligning architectural design with data structure can outperform scale in small-data medical imaging, supporting real-time clinical deployment of compact models for lung ultrasound analysis."}}
{"id": "2510.17480", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17480", "abs": "https://arxiv.org/abs/2510.17480", "authors": ["Aur\u00e9lien Bellet", "Edwige Cyffers", "Davide Frey", "Romaric Gaudel", "Dimitri Ler\u00e9v\u00e9rend", "Fran\u00e7ois Ta\u00efani"], "title": "Unified Privacy Guarantees for Decentralized Learning via Matrix Factorization", "comment": "21 pages, 5 figures", "summary": "Decentralized Learning (DL) enables users to collaboratively train models\nwithout sharing raw data by iteratively averaging local updates with neighbors\nin a network graph. This setting is increasingly popular for its scalability\nand its ability to keep data local under user control. Strong privacy\nguarantees in DL are typically achieved through Differential Privacy (DP), with\nresults showing that DL can even amplify privacy by disseminating noise across\npeer-to-peer communications. Yet in practice, the observed privacy-utility\ntrade-off often appears worse than in centralized training, which may be due to\nlimitations in current DP accounting methods for DL. In this paper, we show\nthat recent advances in centralized DP accounting based on Matrix Factorization\n(MF) for analyzing temporal noise correlations can also be leveraged in DL. By\ngeneralizing existing MF results, we show how to cast both standard DL\nalgorithms and common trust models into a unified formulation. This yields\ntighter privacy accounting for existing DP-DL algorithms and provides a\nprincipled way to develop new ones. To demonstrate the approach, we introduce\nMAFALDA-SGD, a gossip-based DL algorithm with user-level correlated noise that\noutperforms existing methods on synthetic and real-world graphs.", "AI": {"tldr": "This paper proposes MAFALDA-SGD, a gossip-based decentralized learning algorithm with user-level correlated noise that achieves tighter privacy accounting and better privacy-utility trade-offs than existing methods.", "motivation": "Current differential privacy accounting methods for decentralized learning show worse privacy-utility trade-offs compared to centralized training, likely due to limitations in existing DP accounting approaches.", "method": "Leverages recent advances in centralized DP accounting using Matrix Factorization to analyze temporal noise correlations, generalizing these results to decentralized learning. Introduces MAFALDA-SGD, a gossip-based algorithm with user-level correlated noise.", "result": "MAFALDA-SGD outperforms existing methods on both synthetic and real-world graphs, demonstrating improved privacy-utility trade-offs.", "conclusion": "Matrix Factorization-based DP accounting can be effectively applied to decentralized learning, providing tighter privacy bounds and enabling the development of more efficient DP-DL algorithms."}}
{"id": "2510.17486", "categories": ["cs.LG", "68T07, 68T05, 65K10, 90C30", "I.2.6; G.1.6; I.5.1"], "pdf": "https://arxiv.org/pdf/2510.17486", "abs": "https://arxiv.org/abs/2510.17486", "authors": ["Maxim Bolshim", "Alexander Kugaevskikh"], "title": "Local properties of neural networks through the lens of layer-wise Hessians", "comment": "Comments: 22 pages, 8 figures. Submitted to arXiv:cs.LG", "summary": "We introduce a methodology for analyzing neural networks through the lens of\nlayer-wise Hessian matrices. The local Hessian of each functional block (layer)\nis defined as the matrix of second derivatives of a scalar function with\nrespect to the parameters of that layer. This concept provides a formal tool\nfor characterizing the local geometry of the parameter space. We show that the\nspectral properties of local Hessians, such as the distribution of eigenvalues,\nreveal quantitative patterns associated with overfitting,\nunderparameterization, and expressivity in neural network architectures. We\nconduct an extensive empirical study involving 111 experiments across 37\ndatasets. The results demonstrate consistent structural regularities in the\nevolution of local Hessians during training and highlight correlations between\ntheir spectra and generalization performance. These findings establish a\nfoundation for using local geometric analysis to guide the diagnosis and design\nof deep neural networks. The proposed framework connects optimization geometry\nwith functional behavior and offers practical insight for improving network\narchitectures and training stability.", "AI": {"tldr": "The paper introduces a methodology for analyzing neural networks using layer-wise Hessian matrices to study local parameter space geometry and its relationship with network behavior.", "motivation": "To develop formal tools for characterizing neural network behavior through local geometric analysis, connecting optimization geometry with functional performance.", "method": "Defines local Hessian matrices for each layer as second derivatives of scalar functions, analyzes spectral properties (eigenvalue distributions), and conducts 111 experiments across 37 datasets.", "result": "Reveals consistent structural patterns in local Hessian evolution during training and correlations between Hessian spectra and generalization performance.", "conclusion": "Establishes foundation for using local geometric analysis to diagnose and design neural networks, connecting optimization geometry with practical network improvements."}}
{"id": "2510.17496", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17496", "abs": "https://arxiv.org/abs/2510.17496", "authors": ["Giacomo Camposampiero", "Michael Hersche", "Roger Wattenhofer", "Abu Sebastian", "Abbas Rahimi"], "title": "I-RAVEN-X: Benchmarking Generalization and Robustness of Analogical and Mathematical Reasoning in Large Language and Reasoning Models", "comment": "Accepted at the 5th Workshop on Mathematical Reasoning and AI\n  (MATH-AI), NeurIPS 2025", "summary": "We introduce I-RAVEN-X, a symbolic benchmark designed to evaluate\ngeneralization and robustness in analogical and mathematical reasoning for\nLarge Language Models (LLMs) and Large Reasoning Models (LRMs). I-RAVEN-X\nextends I-RAVEN by increasing operand complexity, attribute range, and\nintroducing perceptual uncertainty. Compared to LLMs, empirical results show\nthat LRMs achieve improved productivity and systematicity on longer reasoning\nrelations and wider attribute ranges, respectively. However, LRMs are still\nsignificantly challenged by reasoning under uncertainty and cannot effectively\nexplore multiple probabilistic outcomes.", "AI": {"tldr": "I-RAVEN-X is a symbolic benchmark that extends I-RAVEN to evaluate generalization and robustness in analogical and mathematical reasoning for LLMs and LRMs, featuring increased complexity and perceptual uncertainty.", "motivation": "To assess the generalization and robustness capabilities of Large Language Models (LLMs) and Large Reasoning Models (LRMs) in analogical and mathematical reasoning tasks, particularly under more complex and uncertain conditions.", "method": "Extends I-RAVEN benchmark by increasing operand complexity, expanding attribute range, and introducing perceptual uncertainty to create more challenging reasoning scenarios.", "result": "LRMs show improved productivity on longer reasoning relations and better systematicity on wider attribute ranges compared to LLMs, but both struggle with reasoning under uncertainty and exploring multiple probabilistic outcomes.", "conclusion": "While LRMs demonstrate advantages over LLMs in certain reasoning aspects, current models still face significant challenges in handling uncertainty and probabilistic reasoning, indicating areas for future improvement."}}
{"id": "2510.17503", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17503", "abs": "https://arxiv.org/abs/2510.17503", "authors": ["El Mahdi Chayti", "Martin Jaggi"], "title": "Stochastic Difference-of-Convex Optimization with Momentum", "comment": null, "summary": "Stochastic difference-of-convex (DC) optimization is prevalent in numerous\nmachine learning applications, yet its convergence properties under small batch\nsizes remain poorly understood. Existing methods typically require large\nbatches or strong noise assumptions, which limit their practical use. In this\nwork, we show that momentum enables convergence under standard smoothness and\nbounded variance assumptions (of the concave part) for any batch size. We prove\nthat without momentum, convergence may fail regardless of stepsize,\nhighlighting its necessity. Our momentum-based algorithm achieves provable\nconvergence and demonstrates strong empirical performance.", "AI": {"tldr": "Momentum enables convergence in stochastic DC optimization under standard assumptions for any batch size, addressing limitations of existing methods that require large batches or strong noise assumptions.", "motivation": "Stochastic DC optimization is widely used in machine learning but existing methods have poor convergence properties under small batch sizes, requiring large batches or strong noise assumptions that limit practical applicability.", "method": "Proposed a momentum-based algorithm for stochastic DC optimization that works under standard smoothness and bounded variance assumptions of the concave part.", "result": "Proved that without momentum, convergence may fail regardless of stepsize, while the momentum-based algorithm achieves provable convergence and demonstrates strong empirical performance.", "conclusion": "Momentum is necessary for convergence in stochastic DC optimization under small batch sizes, and the proposed momentum-based method provides effective convergence guarantees and practical performance."}}
{"id": "2510.17506", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17506", "abs": "https://arxiv.org/abs/2510.17506", "authors": ["Lachlan Ewen MacDonald", "Hancheng Min", "Leandro Palma", "Salma Tarmoun", "Ziqing Xu", "Ren\u00e9 Vidal"], "title": "Convergence Rates for Gradient Descent on the Edge of Stability in Overparametrised Least Squares", "comment": "NeurIPS2025. Code available at\n  https://github.com/lemacdonald/eos-convergence-rates-codimension-1", "summary": "Classical optimisation theory guarantees monotonic objective decrease for\ngradient descent (GD) when employed in a small step size, or ``stable\", regime.\nIn contrast, gradient descent on neural networks is frequently performed in a\nlarge step size regime called the ``edge of stability\", in which the objective\ndecreases non-monotonically with an observed implicit bias towards flat minima.\nIn this paper, we take a step toward quantifying this phenomenon by providing\nconvergence rates for gradient descent with large learning rates in an\noverparametrised least squares setting. The key insight behind our analysis is\nthat, as a consequence of overparametrisation, the set of global minimisers\nforms a Riemannian manifold $M$, which enables the decomposition of the GD\ndynamics into components parallel and orthogonal to $M$. The parallel component\ncorresponds to Riemannian gradient descent on the objective sharpness, while\nthe orthogonal component is a bifurcating dynamical system. This insight allows\nus to derive convergence rates in three regimes characterised by the learning\nrate size: (a) the subcritical regime, in which transient instability is\novercome in finite time before linear convergence to a suboptimally flat global\nminimum; (b) the critical regime, in which instability persists for all time\nwith a power-law convergence toward the optimally flat global minimum; and (c)\nthe supercritical regime, in which instability persists for all time with\nlinear convergence to an orbit of period two centred on the optimally flat\nglobal minimum.", "AI": {"tldr": "Analysis of gradient descent with large learning rates in overparametrized least squares, showing convergence rates in three regimes: subcritical (transient instability), critical (persistent instability with power-law convergence), and supercritical (persistent instability with linear convergence to period-2 orbits).", "motivation": "To understand why gradient descent on neural networks works well with large learning rates (edge of stability regime) despite non-monotonic objective decrease and implicit bias toward flat minima, which classical optimization theory doesn't explain.", "method": "Analyze gradient descent dynamics in overparametrized least squares by decomposing the dynamics into components parallel and orthogonal to the manifold of global minimizers. The parallel component corresponds to Riemannian gradient descent on objective sharpness, while the orthogonal component forms a bifurcating dynamical system.", "result": "Derived convergence rates for three learning rate regimes: (a) subcritical - transient instability overcome in finite time with linear convergence to suboptimally flat minima; (b) critical - persistent instability with power-law convergence to optimally flat minima; (c) supercritical - persistent instability with linear convergence to period-2 orbits around optimally flat minima.", "conclusion": "The analysis provides theoretical justification for the edge of stability phenomenon, showing how large learning rates in overparametrized settings lead to implicit bias toward flat minima through bifurcating dynamics, with different convergence behaviors depending on learning rate size."}}
{"id": "2510.17515", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17515", "abs": "https://arxiv.org/abs/2510.17515", "authors": ["Hoang Pham", "The-Anh Ta", "Tom Jacobs", "Rebekka Burkholz", "Long Tran-Thanh"], "title": "The Graphon Limit Hypothesis: Understanding Neural Network Pruning via Infinite Width Analysis", "comment": "NeurIPS 2025 Spotlight", "summary": "Sparse neural networks promise efficiency, yet training them effectively\nremains a fundamental challenge. Despite advances in pruning methods that\ncreate sparse architectures, understanding why some sparse structures are\nbetter trainable than others with the same level of sparsity remains poorly\nunderstood. Aiming to develop a systematic approach to this fundamental\nproblem, we propose a novel theoretical framework based on the theory of graph\nlimits, particularly graphons, that characterizes sparse neural networks in the\ninfinite-width regime. Our key insight is that connectivity patterns of sparse\nneural networks induced by pruning methods converge to specific graphons as\nnetworks' width tends to infinity, which encodes implicit structural biases of\ndifferent pruning methods. We postulate the Graphon Limit Hypothesis and\nprovide empirical evidence to support it. Leveraging this graphon\nrepresentation, we derive a Graphon Neural Tangent Kernel (Graphon NTK) to\nstudy the training dynamics of sparse networks in the infinite width limit.\nGraphon NTK provides a general framework for the theoretical analysis of sparse\nnetworks. We empirically show that the spectral analysis of Graphon NTK\ncorrelates with observed training dynamics of sparse networks, explaining the\nvarying convergence behaviours of different pruning methods. Our framework\nprovides theoretical insights into the impact of connectivity patterns on the\ntrainability of various sparse network architectures.", "AI": {"tldr": "A theoretical framework using graphons to analyze sparse neural networks, showing that pruning methods create specific connectivity patterns that affect trainability.", "motivation": "To understand why some sparse neural networks train better than others despite having the same sparsity level, and to develop a systematic approach to analyze their trainability.", "method": "Propose a graphon-based framework to characterize sparse networks in infinite-width regime, introduce Graphon Limit Hypothesis, and derive Graphon Neural Tangent Kernel (Graphon NTK) to study training dynamics.", "result": "Empirical evidence supports the Graphon Limit Hypothesis, and spectral analysis of Graphon NTK correlates with observed training dynamics, explaining varying convergence behaviors of different pruning methods.", "conclusion": "The framework provides theoretical insights into how connectivity patterns impact sparse network trainability, offering a general approach for analyzing sparse network architectures."}}
{"id": "2510.17517", "categories": ["cs.LG", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.17517", "abs": "https://arxiv.org/abs/2510.17517", "authors": ["Hangcheng Cao", "Baixiang Huang", "Longzhi Yuan", "Haonan An", "Zihan Fang", "Xianhao Chen", "Yuguang Fang"], "title": "SAFE-D: A Spatiotemporal Detection Framework for Abnormal Driving Among Parkinson's Disease-like Drivers", "comment": null, "summary": "A driver's health state serves as a determinant factor in driving behavioral\nregulation. Subtle deviations from normalcy can lead to operational anomalies,\nposing risks to public transportation safety. While prior efforts have\ndeveloped detection mechanisms for functionally-driven temporary anomalies such\nas drowsiness and distraction, limited research has addressed\npathologically-triggered deviations, especially those stemming from chronic\nmedical conditions. To bridge this gap, we investigate the driving behavior of\nParkinson's disease patients and propose SAFE-D, a novel framework for\ndetecting Parkinson-related behavioral anomalies to enhance driving safety. Our\nmethodology starts by performing analysis of Parkinson's disease\nsymptomatology, focusing on primary motor impairments, and establishes causal\nlinks to degraded driving performance. To represent the subclinical behavioral\nvariations of early-stage Parkinson's disease, our framework integrates data\nfrom multiple vehicle control components to build a behavioral profile. We then\ndesign an attention-based network that adaptively prioritizes spatiotemporal\nfeatures, enabling robust anomaly detection under physiological variability.\nFinally, we validate SAFE-D on the Logitech G29 platform and CARLA simulator,\nusing data from three road maps to emulate real-world driving. Our results show\nSAFE-D achieves 96.8% average accuracy in distinguishing normal and\nParkinson-affected driving patterns.", "AI": {"tldr": "SAFE-D is a novel framework that detects Parkinson's disease-related driving anomalies using multi-source vehicle data and attention-based neural networks, achieving 96.8% accuracy in distinguishing normal from Parkinson-affected driving patterns.", "motivation": "Limited research exists on pathologically-triggered driving deviations from chronic medical conditions like Parkinson's disease, which pose significant risks to transportation safety despite prior work on temporary anomalies like drowsiness.", "method": "Framework integrates data from multiple vehicle control components to build behavioral profiles, then uses an attention-based network that adaptively prioritizes spatiotemporal features for robust anomaly detection under physiological variability.", "result": "SAFE-D achieves 96.8% average accuracy in distinguishing normal and Parkinson-affected driving patterns when validated on Logitech G29 platform and CARLA simulator across three road maps.", "conclusion": "The proposed SAFE-D framework effectively detects Parkinson-related driving behavioral anomalies, bridging the gap in detecting pathologically-triggered deviations and enhancing driving safety for individuals with chronic medical conditions."}}
{"id": "2510.17520", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17520", "abs": "https://arxiv.org/abs/2510.17520", "authors": ["Canran Xiao", "Chuangxin Zhao", "Zong Ke", "Fei Shen"], "title": "Curiosity Meets Cooperation: A Game-Theoretic Approach to Long-Tail Multi-Label Learning", "comment": "Under review", "summary": "Long-tail imbalance is endemic to multi-label learning: a few head labels\ndominate the gradient signal, while the many rare labels that matter in\npractice are silently ignored. We tackle this problem by casting the task as a\ncooperative potential game. In our Curiosity-Driven Game-Theoretic Multi-Label\nLearning (CD-GTMLL) framework, the label space is split among several\ncooperating players that share a global accuracy payoff yet earn additional\ncuriosity rewards that rise with label rarity and inter-player disagreement.\nThese curiosity bonuses inject gradient on under-represented tags without\nhand-tuned class weights. We prove that gradient best-response updates ascend a\ndifferentiable potential and converge to tail-aware stationary points that\ntighten a lower bound on the expected Rare-F1. Extensive experiments on\nconventional benchmarks and three extreme-scale datasets show consistent\nstate-of-the-art gains, delivering up to +4.3% Rare-F1 and +1.6% P@3 over the\nstrongest baselines, while ablations reveal emergent division of labour and\nfaster consensus on rare classes. CD-GTMLL thus offers a principled, scalable\nroute to long-tail robustness in multi-label prediction.", "AI": {"tldr": "CD-GTMLL addresses long-tail imbalance in multi-label learning by framing it as a cooperative potential game where players share global accuracy but earn curiosity rewards for rare labels, achieving state-of-the-art gains in Rare-F1.", "motivation": "Long-tail imbalance in multi-label learning causes head labels to dominate gradients while rare labels are ignored, which matters in practical applications.", "method": "Cast multi-label learning as a cooperative potential game with multiple players sharing global accuracy payoff and earning curiosity rewards based on label rarity and inter-player disagreement.", "result": "Achieves consistent state-of-the-art gains with up to +4.3% Rare-F1 and +1.6% P@3 over strongest baselines across conventional benchmarks and extreme-scale datasets.", "conclusion": "CD-GTMLL provides a principled, scalable approach for long-tail robustness in multi-label prediction through game-theoretic framework and curiosity-driven learning."}}
{"id": "2510.17524", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17524", "abs": "https://arxiv.org/abs/2510.17524", "authors": ["Sidney Bender", "Ole Delzer", "Jan Herrmann", "Heike Antje Marxfeld", "Klaus-Robert M\u00fcller", "Gr\u00e9goire Montavon"], "title": "Mitigating Clever Hans Strategies in Image Classifiers through Generating Counterexamples", "comment": null, "summary": "Deep learning models remain vulnerable to spurious correlations, leading to\nso-called Clever Hans predictors that undermine robustness even in large-scale\nfoundation and self-supervised models. Group distributional robustness methods,\nsuch as Deep Feature Reweighting (DFR) rely on explicit group labels to\nupweight underrepresented subgroups, but face key limitations: (1) group labels\nare often unavailable, (2) low within-group sample sizes hinder coverage of the\nsubgroup distribution, and (3) performance degrades sharply when multiple\nspurious correlations fragment the data into even smaller groups. We propose\nCounterfactual Knowledge Distillation (CFKD), a framework that sidesteps these\nissues by generating diverse counterfactuals, enabling a human annotator to\nefficiently explore and correct the model's decision boundaries through a\nknowledge distillation step. Unlike DFR, our method not only reweights the\nundersampled groups, but it also enriches them with new data points. Our method\ndoes not require any confounder labels, achieves effective scaling to multiple\nconfounders, and yields balanced generalization across groups. We demonstrate\nCFKD's efficacy across five datasets, spanning synthetic tasks to an industrial\napplication, with particularly strong gains in low-data regimes with pronounced\nspurious correlations. Additionally, we provide an ablation study on the effect\nof the chosen counterfactual explainer and teacher model, highlighting their\nimpact on robustness.", "AI": {"tldr": "CFKD is a framework that generates diverse counterfactuals to correct model decision boundaries through knowledge distillation, addressing spurious correlations without requiring group labels and handling multiple confounders effectively.", "motivation": "Deep learning models are vulnerable to spurious correlations (Clever Hans predictors), and existing group distributional robustness methods like DFR have limitations: need for group labels, low within-group sample sizes, and performance degradation with multiple spurious correlations.", "method": "Counterfactual Knowledge Distillation (CFKD) generates diverse counterfactuals and uses knowledge distillation to enable human annotators to efficiently explore and correct model decision boundaries, enriching underrepresented groups with new data points.", "result": "CFKD achieves effective scaling to multiple confounders, yields balanced generalization across groups, and shows strong gains in low-data regimes with pronounced spurious correlations across five datasets including industrial applications.", "conclusion": "CFKD successfully addresses limitations of existing methods by not requiring confounder labels, handling multiple spurious correlations, and improving robustness through counterfactual generation and knowledge distillation."}}
{"id": "2510.17526", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17526", "abs": "https://arxiv.org/abs/2510.17526", "authors": ["Wei Huang", "Andi Han", "Yujin Song", "Yilan Chen", "Denny Wu", "Difan Zou", "Taiji Suzuki"], "title": "How Does Label Noise Gradient Descent Improve Generalization in the Low SNR Regime?", "comment": "40 pages", "summary": "The capacity of deep learning models is often large enough to both learn the\nunderlying statistical signal and overfit to noise in the training set. This\nnoise memorization can be harmful especially for data with a low\nsignal-to-noise ratio (SNR), leading to poor generalization. Inspired by prior\nobservations that label noise provides implicit regularization that improves\ngeneralization, in this work, we investigate whether introducing label noise to\nthe gradient updates can enhance the test performance of neural network (NN) in\nthe low SNR regime. Specifically, we consider training a two-layer NN with a\nsimple label noise gradient descent (GD) algorithm, in an idealized\nsignal-noise data setting. We prove that adding label noise during training\nsuppresses noise memorization, preventing it from dominating the learning\nprocess; consequently, label noise GD enjoys rapid signal growth while the\noverfitting remains controlled, thereby achieving good generalization despite\nthe low SNR. In contrast, we also show that NN trained with standard GD tends\nto overfit to noise in the same low SNR setting and establish a non-vanishing\nlower bound on its test error, thus demonstrating the benefit of introducing\nlabel noise in gradient-based training.", "AI": {"tldr": "Adding label noise during gradient descent training suppresses noise memorization and improves generalization in low signal-to-noise ratio settings, unlike standard GD which overfits to noise.", "motivation": "Deep learning models can overfit to noise in training data, especially in low signal-to-noise ratio (SNR) settings, leading to poor generalization. Prior observations suggest label noise may provide implicit regularization.", "method": "Train a two-layer neural network with label noise gradient descent algorithm in an idealized signal-noise data setting, where label noise is introduced during gradient updates.", "result": "Label noise GD suppresses noise memorization, prevents noise from dominating learning, achieves rapid signal growth while controlling overfitting, and achieves good generalization in low SNR settings.", "conclusion": "Introducing label noise in gradient-based training provides benefits over standard GD by preventing noise memorization and improving generalization performance in low SNR regimes."}}
{"id": "2510.17545", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17545", "abs": "https://arxiv.org/abs/2510.17545", "authors": ["Yichen Liu", "Yan Lin", "Shengnan Guo", "Zeyu Zhou", "Youfang Lin", "Huaiyu Wan"], "title": "TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model", "comment": "Accepted by NeurIPS2025", "summary": "Vehicle GPS trajectories record how vehicles move over time, storing valuable\ntravel semantics, including movement patterns and travel purposes. Learning\ntravel semantics effectively and efficiently is crucial for real-world\napplications of trajectory data, which is hindered by two major challenges.\nFirst, travel purposes are tied to the functions of the roads and\npoints-of-interest (POIs) involved in a trip. Such information is encoded in\ntextual addresses and descriptions and introduces heavy computational burden to\nmodeling. Second, real-world trajectories often contain redundant points, which\nharm both computational efficiency and trajectory embedding quality. To address\nthese challenges, we propose TrajMamba, a novel approach for efficient and\nsemantically rich vehicle trajectory learning. TrajMamba introduces a\nTraj-Mamba Encoder that captures movement patterns by jointly modeling both GPS\nand road perspectives of trajectories, enabling robust representations of\ncontinuous travel behaviors. It also incorporates a Travel Purpose-aware\nPre-training procedure to integrate travel purposes into the learned embeddings\nwithout introducing extra overhead to embedding calculation. To reduce\nredundancy in trajectories, TrajMamba features a Knowledge Distillation\nPre-training scheme to identify key trajectory points through a learnable mask\ngenerator and obtain effective compressed trajectory embeddings. Extensive\nexperiments on two real-world datasets and three downstream tasks show that\nTrajMamba outperforms state-of-the-art baselines in both efficiency and\naccuracy.", "AI": {"tldr": "TrajMamba is a novel approach for efficient vehicle trajectory learning that addresses computational challenges from textual data and redundant points by using a Traj-Mamba Encoder, travel purpose-aware pre-training, and knowledge distillation for trajectory compression.", "motivation": "Vehicle GPS trajectories contain valuable travel semantics but face challenges: travel purposes require processing textual data from roads/POIs (computationally heavy) and real-world trajectories have redundant points that harm efficiency and embedding quality.", "method": "Proposes TrajMamba with three key components: 1) Traj-Mamba Encoder that jointly models GPS and road perspectives for robust movement patterns, 2) Travel Purpose-aware Pre-training to integrate travel purposes without extra overhead, 3) Knowledge Distillation Pre-training with learnable mask generator to identify key points and compress trajectories.", "result": "Extensive experiments on two real-world datasets and three downstream tasks show TrajMamba outperforms state-of-the-art baselines in both efficiency and accuracy.", "conclusion": "TrajMamba provides an effective solution for learning semantically rich vehicle trajectory embeddings while addressing computational efficiency challenges from textual data processing and trajectory redundancy."}}
{"id": "2510.17558", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17558", "abs": "https://arxiv.org/abs/2510.17558", "authors": ["Fran\u00e7ois Fleuret"], "title": "The Free Transformer", "comment": null, "summary": "We propose an extension of the decoder Transformer that conditions its\ngenerative process on random latent variables which are learned without\nsupervision thanks to a variational procedure. Experimental evaluations show\nthat allowing such a conditioning translates into substantial improvements on\ndownstream tasks.", "AI": {"tldr": "Extension of decoder Transformer with unsupervised variational latent variables for improved downstream task performance.", "motivation": "To enhance Transformer's generative capabilities by incorporating unsupervised latent variables for better conditioning.", "method": "Extend decoder Transformer with random latent variables learned via variational procedure without supervision.", "result": "Substantial improvements on downstream tasks through latent variable conditioning.", "conclusion": "Unsupervised variational latent variables significantly boost Transformer performance on downstream applications."}}
{"id": "2510.17562", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17562", "abs": "https://arxiv.org/abs/2510.17562", "authors": ["Dennis Wagner", "Arjun Nair", "Billy Joe Franks", "Justus Arweiler", "Aparna Muraleedharan", "Indra Jungjohann", "Fabian Hartung", "Mayank C. Ahuja", "Andriy Balinskyy", "Saurabh Varshneya", "Nabeel Hussain Syed", "Mayank Nagda", "Phillip Liznerski", "Steffen Reithermann", "Maja Rudolph", "Sebastian Vollmer", "Ralf Schulz", "Torsten Katz", "Stephan Mandt", "Michael Bortz", "Heike Leitte", "Daniel Neider", "Jakob Burger", "Fabian Jirasek", "Hans Hasse", "Sophie Fellenz", "Marius Kloft"], "title": "Formally Exploring Time-Series Anomaly Detection Evaluation Metrics", "comment": "73 pages, 13 figures", "summary": "Undetected anomalies in time series can trigger catastrophic failures in\nsafety-critical systems, such as chemical plant explosions or power grid\noutages. Although many detection methods have been proposed, their performance\nremains unclear because current metrics capture only narrow aspects of the task\nand often yield misleading results. We address this issue by introducing\nverifiable properties that formalize essential requirements for evaluating\ntime-series anomaly detection. These properties enable a theoretical framework\nthat supports principled evaluations and reliable comparisons. Analyzing 37\nwidely used metrics, we show that most satisfy only a few properties, and none\nsatisfy all, explaining persistent inconsistencies in prior results. To close\nthis gap, we propose LARM, a flexible metric that provably satisfies all\nproperties, and extend it to ALARM, an advanced variant meeting stricter\nrequirements.", "AI": {"tldr": "The paper introduces verifiable properties for evaluating time-series anomaly detection metrics, analyzes 37 existing metrics, and proposes LARM and ALARM as new metrics that satisfy all properties.", "motivation": "Current anomaly detection metrics are inadequate and misleading, leading to unclear performance evaluation and potential catastrophic failures in safety-critical systems.", "method": "Developed theoretical framework with verifiable properties, analyzed 37 existing metrics, and designed new metrics (LARM and ALARM) that provably satisfy all properties.", "result": "Most existing metrics satisfy only a few properties, none satisfy all, explaining inconsistencies in prior results. LARM and ALARM successfully meet all evaluation requirements.", "conclusion": "The proposed LARM and ALARM metrics provide principled evaluation and reliable comparison for time-series anomaly detection, addressing limitations of existing metrics."}}
{"id": "2510.17564", "categories": ["cs.LG", "cs.AI", "cs.RO", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.17564", "abs": "https://arxiv.org/abs/2510.17564", "authors": ["Lindsay Spoor", "\u00c1lvaro Serra-G\u00f3mez", "Aske Plaat", "Thomas Moerland"], "title": "An Empirical Study of Lagrangian Methods in Safe Reinforcement Learning", "comment": null, "summary": "In safety-critical domains such as robotics, navigation and power systems,\nconstrained optimization problems arise where maximizing performance must be\ncarefully balanced with associated constraints. Safe reinforcement learning\nprovides a framework to address these challenges, with Lagrangian methods being\na popular choice. However, the effectiveness of Lagrangian methods crucially\ndepends on the choice of the Lagrange multiplier $\\lambda$, which governs the\ntrade-off between return and constraint cost. A common approach is to update\nthe multiplier automatically during training. Although this is standard in\npractice, there remains limited empirical evidence on the robustness of an\nautomated update and its influence on overall performance. Therefore, we\nanalyze (i) optimality and (ii) stability of Lagrange multipliers in safe\nreinforcement learning across a range of tasks. We provide $\\lambda$-profiles\nthat give a complete visualization of the trade-off between return and\nconstraint cost of the optimization problem. These profiles show the highly\nsensitive nature of $\\lambda$ and moreover confirm the lack of general\nintuition for choosing the optimal value $\\lambda^*$. Our findings additionally\nshow that automated multiplier updates are able to recover and sometimes even\nexceed the optimal performance found at $\\lambda^*$ due to the vast difference\nin their learning trajectories. Furthermore, we show that automated multiplier\nupdates exhibit oscillatory behavior during training, which can be mitigated\nthrough PID-controlled updates. However, this method requires careful tuning to\nachieve consistently better performance across tasks. This highlights the need\nfor further research on stabilizing Lagrangian methods in safe reinforcement\nlearning. The code used to reproduce our results can be found at\nhttps://github.com/lindsayspoor/Lagrangian_SafeRL.", "AI": {"tldr": "Analysis of Lagrange multipliers in safe RL shows automated updates can recover optimal performance but exhibit instability, requiring PID control for stabilization.", "motivation": "To understand the robustness and effectiveness of automated Lagrange multiplier updates in safe reinforcement learning, given their critical role in balancing performance and constraints.", "method": "Analyzed optimality and stability of Lagrange multipliers across tasks using \u03bb-profiles visualization, compared automated updates with fixed \u03bb*, and tested PID-controlled updates for stabilization.", "result": "Automated multiplier updates can recover/exceed optimal performance but show oscillatory behavior; PID control helps but requires careful tuning; \u03bb-profiles reveal high sensitivity and lack of general intuition for choosing \u03bb*.", "conclusion": "Lagrangian methods in safe RL need further research on stabilization, as automated updates show promise but require careful tuning to handle their oscillatory nature."}}
{"id": "2510.17569", "categories": ["cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.17569", "abs": "https://arxiv.org/abs/2510.17569", "authors": ["Jyler Menard", "R. A. Mansbach"], "title": "Semi-supervised Latent Bayesian Optimization for Designing Antimicrobial Peptides", "comment": "19 pages, 9 figures", "summary": "Antimicrobial peptides (AMPs) are a promising class of therapeutics to treat\nbacterial infections. Discovering and designing such peptides is difficult\nbecause of the vast number of possible sequences of amino acids. Deep\ngenerative models, such as variational autoencoders, have shown value in\npeptide design due to their ability to model sequence space with a\ncontinuous-valued latent space. Although such models have already been used to\ngreat effect in biomolecular design, they still suffer from a lack of\ninterpretability and rigorous quantification of latent space quality as a\nsearch space. We investigate (1) whether further compression of the design\nspace via dimensionality reduction may facilitate optimization, (2) the\ninterpretability of the spaces, and (3) how organizing latent spaces with\nphysicochemical properties may improve the efficiency of optimizing\nantimicrobial activity. We find that further reduction of the latent space via\ndimensionality reduction can be advantageous when organizing the space with\nmore relevant information at data availability, that using the dimensionality\nreduction search space can be more interpretable, and that we can organize the\nlatent space with different physicochemical properties even at different\npercentages of available labels.", "AI": {"tldr": "The paper investigates using dimensionality reduction on variational autoencoder latent spaces to improve antimicrobial peptide design, focusing on interpretability and organizing the space with physicochemical properties.", "motivation": "Deep generative models for peptide design suffer from lack of interpretability and rigorous quantification of latent space quality. The authors want to improve optimization efficiency and interpretability in antimicrobial peptide discovery.", "method": "Used dimensionality reduction on variational autoencoder latent spaces, organized the spaces with physicochemical properties, and investigated interpretability and optimization efficiency at different levels of data availability.", "result": "Found that further latent space compression via dimensionality reduction can be advantageous when organizing with relevant information, improves interpretability, and allows organization with different physicochemical properties even with limited labeled data.", "conclusion": "Dimensionality reduction of latent spaces can enhance interpretability and optimization efficiency in antimicrobial peptide design, particularly when combined with physicochemical property organization."}}
{"id": "2510.17584", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17584", "abs": "https://arxiv.org/abs/2510.17584", "authors": ["Ludi Li", "Junbin Mao", "Hanhe Lin", "Xu Tian", "Fang-Xiang Wu", "Jin Liu"], "title": "CEPerFed: Communication-Efficient Personalized Federated Learning for Multi-Pulse MRI Classification", "comment": null, "summary": "Multi-pulse magnetic resonance imaging (MRI) is widely utilized for clinical\npractice such as Alzheimer's disease diagnosis. To train a robust model for\nmulti-pulse MRI classification, it requires large and diverse data from various\nmedical institutions while protecting privacy by preventing raw data sharing\nacross institutions. Although federated learning (FL) is a feasible solution to\naddress this issue, it poses challenges of model convergence due to the effect\nof data heterogeneity and substantial communication overhead due to large\nnumbers of parameters transmitted within the model. To address these\nchallenges, we propose CEPerFed, a communication-efficient personalized FL\nmethod. It mitigates the effect of data heterogeneity by incorporating\nclient-side historical risk gradients and historical mean gradients to\ncoordinate local and global optimization. The former is used to weight the\ncontributions from other clients, enhancing the reliability of local updates,\nwhile the latter enforces consistency between local updates and the global\noptimization direction to ensure stable convergence across heterogeneous data\ndistributions. To address the high communication overhead, we propose a\nhierarchical SVD (HSVD) strategy that transmits only the most critical\ninformation required for model updates. Experiments on five classification\ntasks demonstrate the effectiveness of the CEPerFed method. The code will be\nreleased upon acceptance at https://github.com/LD0416/CEPerFed.", "AI": {"tldr": "CEPerFed is a communication-efficient personalized federated learning method for multi-pulse MRI classification that addresses data heterogeneity using historical gradients and reduces communication overhead via hierarchical SVD compression.", "motivation": "Multi-pulse MRI classification requires large diverse data from multiple institutions while protecting privacy. Federated learning faces challenges with model convergence due to data heterogeneity and high communication overhead from transmitting large model parameters.", "method": "CEPerFed incorporates client-side historical risk gradients and historical mean gradients to coordinate local and global optimization. It uses hierarchical SVD strategy to transmit only critical information for model updates, reducing communication overhead.", "result": "Experiments on five classification tasks demonstrate the effectiveness of the CEPerFed method in handling data heterogeneity and reducing communication costs.", "conclusion": "CEPerFed successfully addresses both data heterogeneity and communication efficiency challenges in federated learning for multi-pulse MRI classification, providing a practical solution for clinical applications requiring privacy protection."}}
{"id": "2510.17661", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17661", "abs": "https://arxiv.org/abs/2510.17661", "authors": ["Vaishnavi Visweswaraiah", "Tanvi Banerjee", "William Romine"], "title": "Handling Extreme Class Imbalance: Using GANs in Data Augmentation for Suicide Prediction", "comment": null, "summary": "Suicide prediction is the key for prevention, but real data with sufficient\npositive samples is rare and causes extreme class imbalance. We utilized\nmachine learning (ML) to build the model and deep learning (DL) techniques,\nlike Generative Adversarial Networks (GAN), to generate synthetic data samples\nto enhance the dataset. The initial dataset contained 656 samples, with only\nfour positive cases, prompting the need for data augmentation. A variety of\nmachine learning models, ranging from interpretable data models to black box\nalgorithmic models, were used. On real test data, Logistic Regression (LR)\nachieved a weighted precision of 0.99, a weighted recall of 0.85, and a\nweighted F1 score of 0.91; Random Forest (RF) showed 0.98, 0.99, and 0.99,\nrespectively; and Support Vector Machine (SVM) achieved 0.99, 0.76, and 0.86.\nLR and SVM correctly identified one suicide attempt case (sensitivity:1.0) and\nmisclassified LR(20) and SVM (31) non-attempts as attempts (specificity: 0.85 &\n0.76, respectively). RF identified 0 suicide attempt cases (sensitivity: 0.0)\nwith 0 false positives (specificity: 1.0). These results highlight the models'\neffectiveness, with GAN playing a key role in generating synthetic data to\nsupport suicide prevention modeling efforts.", "AI": {"tldr": "Machine learning models were used for suicide prediction with GAN-based data augmentation to address extreme class imbalance (only 4 positive cases in 656 samples). Models achieved high performance metrics, with GAN playing a crucial role in generating synthetic data.", "motivation": "Suicide prediction is crucial for prevention, but real-world data suffers from extreme class imbalance with very few positive cases, making effective modeling challenging.", "method": "Used machine learning models (Logistic Regression, Random Forest, SVM) with deep learning techniques including Generative Adversarial Networks (GAN) to generate synthetic data for augmentation. Applied various ML models from interpretable to black-box algorithms.", "result": "Logistic Regression: precision 0.99, recall 0.85, F1 0.91; Random Forest: 0.98, 0.99, 0.99; SVM: 0.99, 0.76, 0.86. LR and SVM correctly identified suicide attempts (sensitivity:1.0) while RF had 0 sensitivity but perfect specificity.", "conclusion": "The models demonstrated effectiveness in suicide prediction, with GAN playing a key role in addressing data imbalance through synthetic data generation, supporting suicide prevention modeling efforts."}}
{"id": "2510.17670", "categories": ["cs.LG", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2510.17670", "abs": "https://arxiv.org/abs/2510.17670", "authors": ["Yehonathan Refael", "Amit Aides", "Aviad Barzilai", "George Leifman", "Genady Beryozkin", "Vered Silverman", "Bolous Jaber", "Tomer Shekel"], "title": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "comment": null, "summary": "Open-vocabulary object detection (OVD) models offer remarkable flexibility by\ndetecting objects from arbitrary text queries. However, their zero-shot\nperformance in specialized domains like Remote Sensing (RS) is often\ncompromised by the inherent ambiguity of natural language, limiting critical\ndownstream applications. For instance, an OVD model may struggle to distinguish\nbetween fine-grained classes such as \"fishing boat\" and \"yacht\" since their\nembeddings are similar and often inseparable. This can hamper specific user\ngoals, such as monitoring illegal fishing, by producing irrelevant detections.\nTo address this, we propose a cascaded approach that couples the broad\ngeneralization of a large pre-trained OVD model with a lightweight few-shot\nclassifier. Our method first employs the zero-shot model to generate\nhigh-recall object proposals. These proposals are then refined for high\nprecision by a compact classifier trained in real-time on only a handful of\nuser-annotated examples - drastically reducing the high costs of RS imagery\nannotation.The core of our framework is FLAME, a one-step active learning\nstrategy that selects the most informative samples for training. FLAME\nidentifies, on the fly, uncertain marginal candidates near the decision\nboundary using density estimation, followed by clustering to ensure sample\ndiversity. This efficient sampling technique achieves high accuracy without\ncostly full-model fine-tuning and enables instant adaptation, within less then\na minute, which is significantly faster than state-of-the-art alternatives.Our\nmethod consistently surpasses state-of-the-art performance on RS benchmarks,\nestablishing a practical and resource-efficient framework for adapting\nfoundation models to specific user needs.", "AI": {"tldr": "A cascaded approach combining open-vocabulary detection with few-shot learning for fine-grained object detection in remote sensing, using FLAME active learning for efficient sample selection.", "motivation": "Open-vocabulary detection models struggle with fine-grained class distinctions in specialized domains like remote sensing due to natural language ambiguity, limiting practical applications like illegal fishing monitoring.", "method": "Cascaded framework: first uses zero-shot OVD model for high-recall proposals, then refines with lightweight few-shot classifier trained on user-annotated examples using FLAME active learning strategy for sample selection.", "result": "Consistently surpasses state-of-the-art performance on RS benchmarks, enables instant adaptation within less than a minute, significantly faster than alternatives.", "conclusion": "Establishes practical and resource-efficient framework for adapting foundation models to specific user needs in remote sensing applications."}}
{"id": "2510.17671", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17671", "abs": "https://arxiv.org/abs/2510.17671", "authors": ["Katarzyna Kobalczyk", "Zhiyuan Jerry Lin", "Benjamin Letham", "Zhuokai Zhao", "Maximilian Balandat", "Eytan Bakshy"], "title": "LILO: Bayesian Optimization with Interactive Natural Language Feedback", "comment": null, "summary": "For many real-world applications, feedback is essential in translating\ncomplex, nuanced, or subjective goals into quantifiable optimization\nobjectives. We propose a language-in-the-loop framework that uses a large\nlanguage model (LLM) to convert unstructured feedback in the form of natural\nlanguage into scalar utilities to conduct BO over a numeric search space.\nUnlike preferential BO, which only accepts restricted feedback formats and\nrequires customized models for each domain-specific problem, our approach\nleverages LLMs to turn varied types of textual feedback into consistent utility\nsignals and to easily include flexible user priors without manual kernel\ndesign. At the same time, our method maintains the sample efficiency and\nprincipled uncertainty quantification of BO. We show that this hybrid method\nnot only provides a more natural interface to the decision maker but also\noutperforms conventional BO baselines and LLM-only optimizers, particularly in\nfeedback-limited regimes.", "AI": {"tldr": "A language-in-the-loop framework that uses LLMs to convert natural language feedback into scalar utilities for Bayesian optimization, outperforming conventional methods.", "motivation": "Feedback is essential for translating complex goals into optimization objectives, but existing methods require restricted feedback formats and domain-specific models.", "method": "Uses LLMs to convert varied natural language feedback into consistent utility signals, incorporating flexible user priors without manual kernel design while maintaining BO's sample efficiency.", "result": "Outperforms conventional BO baselines and LLM-only optimizers, especially in feedback-limited regimes, while providing a more natural interface.", "conclusion": "The hybrid approach effectively combines LLMs' natural language understanding with BO's principled optimization, enabling more flexible and efficient optimization with natural language feedback."}}
{"id": "2510.17690", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17690", "abs": "https://arxiv.org/abs/2510.17690", "authors": ["Xihong Su"], "title": "Efficient Algorithms for Mitigating Uncertainty and Risk in Reinforcement Learning", "comment": "Dissertation", "summary": "This dissertation makes three main contributions. First, We identify a new\nconnection between policy gradient and dynamic programming in MMDPs and propose\nthe Coordinate Ascent Dynamic Programming (CADP) algorithm to compute a Markov\npolicy that maximizes the discounted return averaged over the uncertain models.\nCADP adjusts model weights iteratively to guarantee monotone policy\nimprovements to a local maximum. Second, We establish sufficient and necessary\nconditions for the exponential ERM Bellman operator to be a contraction and\nprove the existence of stationary deterministic optimal policies for ERM-TRC\nand EVaR-TRC. We also propose exponential value iteration, policy iteration,\nand linear programming algorithms for computing optimal stationary policies for\nERM-TRC and EVaR-TRC. Third, We propose model-free Q-learning algorithms for\ncomputing policies with risk-averse objectives: ERM-TRC and EVaR-TRC. The\nchallenge is that Q-learning ERM Bellman may not be a contraction. Instead, we\nuse the monotonicity of Q-learning ERM Bellman operators to derive a rigorous\nproof that the ERM-TRC and the EVaR-TRC Q-learning algorithms converge to the\noptimal risk-averse value functions. The proposed Q-learning algorithms compute\nthe optimal stationary policy for ERM-TRC and EVaR-TRC.", "AI": {"tldr": "This dissertation presents three main contributions: (1) CADP algorithm connecting policy gradient and dynamic programming for MMDPs, (2) theoretical analysis and algorithms for ERM-TRC and EVaR-TRC risk-averse objectives, and (3) model-free Q-learning algorithms for risk-averse reinforcement learning.", "motivation": "To bridge the gap between policy gradient methods and dynamic programming in multi-model MDPs (MMDPs), and to develop robust algorithms for risk-averse reinforcement learning with theoretical guarantees.", "method": "Developed Coordinate Ascent Dynamic Programming (CADP) for MMDPs, established contraction properties for ERM Bellman operators, proposed value iteration, policy iteration, and linear programming algorithms for ERM-TRC/EVaR-TRC, and designed model-free Q-learning algorithms with convergence proofs.", "result": "CADP guarantees monotone policy improvements to local optima, proved existence of optimal policies for risk-averse objectives, and demonstrated convergence of Q-learning algorithms to optimal risk-averse value functions for ERM-TRC and EVaR-TRC.", "conclusion": "The dissertation successfully connects policy gradient and dynamic programming approaches, provides comprehensive theoretical foundations for risk-averse RL, and delivers practical algorithms with proven convergence properties for computing optimal policies in uncertain and risk-sensitive environments."}}
{"id": "2510.17709", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17709", "abs": "https://arxiv.org/abs/2510.17709", "authors": ["Akhil S Anand", "Shambhuraj Sawant", "Jasper Hoffmann", "Dirk Reinhardt", "Sebastien Gros"], "title": "Closing the Sim2Real Performance Gap in RL", "comment": null, "summary": "Sim2Real aims at training policies in high-fidelity simulation environments\nand effectively transferring them to the real world. Despite the developments\nof accurate simulators and Sim2Real RL approaches, the policies trained purely\nin simulation often suffer significant performance drops when deployed in real\nenvironments. This drop is referred to as the Sim2Real performance gap. Current\nSim2Real RL methods optimize the simulator accuracy and variability as proxies\nfor real-world performance. However, these metrics do not necessarily correlate\nwith the real-world performance of the policy as established theoretically and\nempirically in the literature. We propose a novel framework to address this\nissue by directly adapting the simulator parameters based on real-world\nperformance. We frame this problem as a bi-level RL framework: the inner-level\nRL trains a policy purely in simulation, and the outer-level RL adapts the\nsimulation model and in-sim reward parameters to maximize real-world\nperformance of the in-sim policy. We derive and validate in simple examples the\nmathematical tools needed to develop bi-level RL algorithms that close the\nSim2Real performance gap.", "AI": {"tldr": "A bi-level RL framework that directly adapts simulator parameters based on real-world performance to close the Sim2Real gap, rather than optimizing simulator accuracy as a proxy.", "motivation": "Current Sim2Real RL methods optimize simulator accuracy and variability, but these metrics don't necessarily correlate with real-world policy performance, leading to significant performance drops when transferring policies from simulation to reality.", "method": "Bi-level RL framework: inner-level RL trains policies purely in simulation, while outer-level RL adapts simulation model and reward parameters to maximize real-world performance of the in-sim policy.", "result": "Mathematical tools were derived and validated in simple examples to develop bi-level RL algorithms that can close the Sim2Real performance gap.", "conclusion": "The proposed bi-level RL framework directly addresses the Sim2Real performance gap by adapting simulator parameters based on real-world performance, providing a more effective approach than current proxy-based methods."}}
{"id": "2510.17727", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17727", "abs": "https://arxiv.org/abs/2510.17727", "authors": ["Ege Beyazit", "KL Navaneet", "Prashant Mathur", "Roi Blanco", "Vidit Bansal", "Karim Bouyarmane"], "title": "Enabling Fine-Grained Operating Points for Black-Box LLMs", "comment": "35 pages", "summary": "Black-box Large Language Models (LLMs) provide practical and accessible\nalternatives to other machine learning methods, as they require minimal labeled\ndata and machine learning expertise to develop solutions for various decision\nmaking problems. However, for applications that need operating with constraints\non specific metrics (e.g., precision $\\geq$ 95%), decision making with\nblack-box LLMs remains unfavorable, due to their low numerical output\ncardinalities. This results in limited control over their operating points,\npreventing fine-grained adjustment of their decision making behavior. In this\npaper, we study using black-box LLMs as classifiers, focusing on efficiently\nimproving their operational granularity without performance loss. Specifically,\nwe first investigate the reasons behind their low-cardinality numerical outputs\nand show that they are biased towards generating rounded but informative\nverbalized probabilities. Then, we experiment with standard prompt engineering,\nuncertainty estimation and confidence elicitation techniques, and observe that\nthey do not effectively improve operational granularity without sacrificing\nperformance or increasing inference cost. Finally, we propose efficient\napproaches to significantly increase the number and diversity of available\noperating points. Our proposed approaches provide finer-grained operating\npoints and achieve comparable to or better performance than the benchmark\nmethods across 11 datasets and 3 LLMs.", "AI": {"tldr": "Black-box LLMs have low numerical output cardinality, limiting operational granularity for constrained applications. The paper proposes efficient methods to increase operating points without performance loss.", "motivation": "Black-box LLMs are practical but unsuitable for applications requiring specific metric constraints (e.g., precision \u226595%) due to limited control over operating points from low numerical output cardinality.", "method": "Investigates reasons for low-cardinality outputs, experiments with prompt engineering and confidence elicitation techniques, then proposes efficient approaches to increase operating point diversity.", "result": "Proposed approaches provide finer-grained operating points and achieve comparable or better performance than benchmarks across 11 datasets and 3 LLMs.", "conclusion": "Efficient methods can significantly improve operational granularity of black-box LLMs without sacrificing performance or increasing inference costs."}}
{"id": "2510.17756", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.17756", "abs": "https://arxiv.org/abs/2510.17756", "authors": ["Younghyun Koo", "Maryam Rahnemoonfar"], "title": "Prediction of Sea Ice Velocity and Concentration in the Arctic Ocean using Physics-informed Neural Network", "comment": "49 pages, 7 figures, submitted to Environmental Modelling & Software", "summary": "As an increasing amount of remote sensing data becomes available in the\nArctic Ocean, data-driven machine learning (ML) techniques are becoming widely\nused to predict sea ice velocity (SIV) and sea ice concentration (SIC).\nHowever, fully data-driven ML models have limitations in generalizability and\nphysical consistency due to their excessive reliance on the quantity and\nquality of training data. In particular, as Arctic sea ice entered a new phase\nwith thinner ice and accelerated melting, there is a possibility that an ML\nmodel trained with historical sea ice data cannot fully represent the\ndynamically changing sea ice conditions in the future. In this study, we\ndevelop physics-informed neural network (PINN) strategies to integrate physical\nknowledge of sea ice into the ML model. Based on the Hierarchical\nInformation-sharing U-net (HIS-Unet) architecture, we incorporate the physics\nloss function and the activation function to produce physically plausible SIV\nand SIC outputs. Our PINN model outperforms the fully data-driven model in the\ndaily predictions of SIV and SIC, even when trained with a small number of\nsamples. The PINN approach particularly improves SIC predictions in melting and\nearly freezing seasons and near fast-moving ice regions.", "AI": {"tldr": "Physics-informed neural networks (PINN) improve sea ice velocity and concentration predictions by integrating physical knowledge into machine learning models, outperforming purely data-driven approaches.", "motivation": "Fully data-driven ML models have limitations in generalizability and physical consistency, especially as Arctic sea ice enters a new phase with thinner ice and accelerated melting, making historical training data potentially inadequate for future conditions.", "method": "Developed PINN strategies based on Hierarchical Information-sharing U-net (HIS-Unet) architecture, incorporating physics loss function and activation function to produce physically plausible sea ice velocity and concentration outputs.", "result": "PINN model outperforms fully data-driven model in daily predictions of sea ice velocity and concentration, even with small training datasets. Particularly improves sea ice concentration predictions during melting/early freezing seasons and near fast-moving ice regions.", "conclusion": "Physics-informed neural networks provide more robust and physically consistent predictions of sea ice conditions compared to purely data-driven approaches, especially important as Arctic sea ice dynamics continue to change."}}
{"id": "2510.17772", "categories": ["cs.LG", "stat.AP", "I.5.1"], "pdf": "https://arxiv.org/pdf/2510.17772", "abs": "https://arxiv.org/abs/2510.17772", "authors": ["Ryan A. Robinett", "Sophia A. Madejski", "Kyle Ruark", "Samantha J. Riesenfeld", "Lorenzo Orecchia"], "title": "Atlas-based Manifold Representations for Interpretable Riemannian Machine Learning", "comment": null, "summary": "Despite the popularity of the manifold hypothesis, current manifold-learning\nmethods do not support machine learning directly on the latent $d$-dimensional\ndata manifold, as they primarily aim to perform dimensionality reduction into\n$\\mathbb{R}^D$, losing key manifold features when the embedding dimension $D$\napproaches $d$.\n  On the other hand, methods that directly learn the latent manifold as a\ndifferentiable atlas have been relatively underexplored.\n  In this paper, we aim to give a proof of concept of the effectiveness and\npotential of atlas-based methods. To this end, we implement a generic data\nstructure to maintain a differentiable atlas that enables Riemannian\noptimization over the manifold. We complement this with an unsupervised\nheuristic that learns a differentiable atlas from point cloud data. We\nexperimentally demonstrate that this approach has advantages in terms of\nefficiency and accuracy in selected settings. Moreover, in a supervised\nclassification task over the Klein bottle and in RNA velocity analysis of\nhematopoietic data, we showcase the improved interpretability and robustness of\nour approach.", "AI": {"tldr": "The paper proposes a differentiable atlas-based method for machine learning directly on data manifolds, addressing limitations of traditional manifold learning that lose key features during dimensionality reduction.", "motivation": "Current manifold-learning methods primarily perform dimensionality reduction into Euclidean space, losing important manifold features when embedding dimension approaches the intrinsic dimension. Methods that directly learn latent manifolds as differentiable atlases have been underexplored.", "method": "Implemented a generic data structure to maintain a differentiable atlas enabling Riemannian optimization over the manifold, complemented by an unsupervised heuristic that learns a differentiable atlas from point cloud data.", "result": "The approach demonstrated advantages in efficiency and accuracy in selected settings. In supervised classification over the Klein bottle and RNA velocity analysis of hematopoietic data, it showed improved interpretability and robustness.", "conclusion": "The paper provides a proof of concept for the effectiveness and potential of atlas-based methods in manifold learning, offering better preservation of manifold structure and improved performance in various applications."}}
{"id": "2510.17776", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.17776", "abs": "https://arxiv.org/abs/2510.17776", "authors": ["Jackson Harmon", "Andreas Hochlehnert", "Matthias Bethge", "Ameya Prabhu"], "title": "Mapping Post-Training Forgetting in Language Models at Scale", "comment": "43 pages,15 figures", "summary": "Scaled post-training now drives many of the largest capability gains in\nlanguage models (LMs), yet its effect on pretrained knowledge remains poorly\nunderstood. Not all forgetting is equal: Forgetting one fact (e.g., a U.S.\npresident or an API call) does not \"average out\" by recalling another. Hence,\nwe propose a sample-wise paradigm to measure what is forgotten and when\nbackward transfer occurs. Our metric counts 1->0 transitions (correct before\npost-training, incorrect after) to quantify forgetting and 0->1 transitions to\nquantify backward transfer. Traditional task averages conflate these effects\nand obscure large changes. For multiple-choice benchmarks, we add\nchance-adjusted variants that subtract the expected contribution of random\nguessing from pre- and post-training accuracies. We apply this framework across\npost-training stages, model sizes, and data scales. Our large-scale analysis\nshows that: (1) Domain-continual pretraining induces moderate forgetting with\nlow-to-moderate backward transfer; (2) RL/SFT post-training applied to base\nmodels and Instruction tuning yields moderate-to-large backward transfer on\nmath and logic with overall low-to-moderate forgetting; (3) Applying RL/SFT to\ninstruction-tuned models is sensitive on data scale: at small scales, both\nforgetting and backward transfer are small; at larger scales, effects are mixed\nand warrant further study with better controls; (4) Model merging does not\nreliably mitigate forgetting. Overall, our framework offers a practical\nyardstick for mapping how post-training alters pretrained knowledge at scale --\nenabling progress towards generally capable AI systems.", "AI": {"tldr": "The paper proposes a sample-wise framework to measure knowledge forgetting and backward transfer during post-training of language models, revealing that different post-training stages have varying effects on pretrained knowledge.", "motivation": "To better understand how scaled post-training affects pretrained knowledge in language models, as traditional task averages conflate forgetting and backward transfer effects.", "method": "Proposes a sample-wise paradigm that counts 1->0 transitions (forgetting) and 0->1 transitions (backward transfer), with chance-adjusted variants for multiple-choice benchmarks to account for random guessing.", "result": "Analysis shows: domain-continual pretraining causes moderate forgetting with low-to-moderate backward transfer; RL/SFT on base models yields moderate-to-large backward transfer on math/logic with low-to-moderate forgetting; RL/SFT on instruction-tuned models is scale-sensitive; model merging doesn't reliably mitigate forgetting.", "conclusion": "The framework provides a practical tool for understanding how post-training alters pretrained knowledge, enabling progress toward generally capable AI systems."}}
{"id": "2510.17786", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2510.17786", "abs": "https://arxiv.org/abs/2510.17786", "authors": ["Adam Stecklov", "Noah El Rimawi-Fine", "Mathieu Blanchette"], "title": "Inference-Time Compute Scaling For Flow Matching", "comment": null, "summary": "Allocating extra computation at inference time has recently improved sample\nquality in large language models and diffusion-based image generation. In\nparallel, Flow Matching (FM) has gained traction in language, vision, and\nscientific domains, but inference-time scaling methods for it remain\nunder-explored. Concurrently, Kim et al., 2025 approach this problem but\nreplace the linear interpolant with a non-linear variance-preserving (VP)\ninterpolant at inference, sacrificing FM's efficient and straight sampling.\nAdditionally, inference-time compute scaling for flow matching has only been\napplied to visual tasks, like image generation. We introduce novel\ninference-time scaling procedures for FM that preserve the linear interpolant\nduring sampling. Evaluations of our method on image generation, and for the\nfirst time (to the best of our knowledge), unconditional protein generation,\nshow that I) sample quality consistently improves as inference compute\nincreases, and II) flow matching inference-time scaling can be applied to\nscientific domains.", "AI": {"tldr": "The paper introduces novel inference-time scaling methods for Flow Matching that preserve linear interpolants during sampling, improving sample quality in image generation and demonstrating for the first time its application to unconditional protein generation.", "motivation": "Flow Matching has gained popularity but lacks efficient inference-time scaling methods that preserve its straight sampling properties, while existing approaches sacrifice these benefits by using non-linear interpolants.", "method": "The authors develop inference-time scaling procedures for Flow Matching that maintain the linear interpolant during sampling, enabling efficient scaling without compromising the method's straight sampling advantages.", "result": "Evaluations show consistent improvement in sample quality as inference compute increases, and successfully demonstrate Flow Matching inference-time scaling can be applied to scientific domains like protein generation.", "conclusion": "The proposed methods enable effective inference-time compute scaling for Flow Matching while preserving its efficient sampling properties, opening up applications to scientific domains beyond visual tasks."}}
{"id": "2510.17794", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.17794", "abs": "https://arxiv.org/abs/2510.17794", "authors": ["Omer Haq"], "title": "Functional Distribution Networks (FDN)", "comment": "Submitted to ICLR 2026. Code will be released upon acceptance", "summary": "Modern probabilistic regressors often remain overconfident under distribution\nshift. We present Functional Distribution Networks (FDN), an input-conditioned\ndistribution over network weights that induces predictive mixtures whose\ndispersion adapts to the input. FDN is trained with a beta-ELBO and Monte Carlo\nsampling. We further propose an evaluation protocol that cleanly separates\ninterpolation from extrapolation and stresses OOD sanity checks (e.g., that\npredictive likelihood degrades under shift while in-distribution accuracy and\ncalibration are maintained). On standard regression tasks, we benchmark against\nstrong Bayesian, ensemble, dropout, and hypernetwork baselines under matched\nparameter and update budgets, and assess accuracy, calibration, and\nshift-awareness with standard diagnostics. Together, the framework and protocol\naim to make OOD-aware, well-calibrated neural regression practical and modular.", "AI": {"tldr": "Functional Distribution Networks (FDN) is a method that creates input-conditioned weight distributions to produce predictive mixtures with adaptive dispersion, trained with beta-ELBO and Monte Carlo sampling. It addresses overconfidence in probabilistic regressors under distribution shift.", "motivation": "Modern probabilistic regressors often remain overconfident under distribution shift, which motivates the need for methods that can adapt predictive uncertainty to input conditions and maintain calibration out-of-distribution.", "method": "FDN uses input-conditioned distributions over network weights to induce predictive mixtures with adaptive dispersion. Training employs beta-ELBO and Monte Carlo sampling. An evaluation protocol separates interpolation from extrapolation and includes OOD sanity checks.", "result": "The method is benchmarked against Bayesian, ensemble, dropout, and hypernetwork baselines under matched parameter and update budgets, assessing accuracy, calibration, and shift-awareness with standard diagnostics.", "conclusion": "The framework and protocol aim to make OOD-aware, well-calibrated neural regression practical and modular, addressing the challenge of overconfidence under distribution shift."}}
{"id": "2510.17802", "categories": ["cs.LG", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.17802", "abs": "https://arxiv.org/abs/2510.17802", "authors": ["Rui Pan", "Yang Luo", "Yuxing Liu", "Yang You", "Tong Zhang"], "title": "Unbiased Gradient Low-Rank Projection", "comment": null, "summary": "Memory-efficient optimization is critical for training increasingly large\nlanguage models (LLMs). A popular strategy involves gradient low-rank\nprojection, storing only the projected optimizer states, with GaLore being a\nrepresentative example. However, a significant drawback of many such methods is\ntheir lack of convergence guarantees, as various low-rank projection approaches\nintroduce inherent biases relative to the original optimization algorithms,\nwhich contribute to performance gaps compared to full-parameter training.\nAiming to tackle this problem, this paper investigates the layerwise sampling\ntechnique for debiasing low-rank projection mechanisms. In particular, an\ninstantiation of the paradigm gives rise to a novel and unbiased low-rank\noptimization method built upon GaLore's mechanism and the Muon algorithm, named\nGaLore Unbiased with Muon (GUM). We theoretically prove our method matches the\nconvergence guarantees of the base Muon algorithm while preserving the memory\nefficiency of low-rank techniques. Empirical experiments on LLM fine-tuning and\npretraining also demonstrate non-trivial improvements over GaLore and even\nbetter performance than full-parameter training. Further investigation shows\nthat the improvement of this technique comes from a more uniform distribution\nof knowledge inside layers, leading to more efficient utilization of the model\nparameter space and better memorization.", "AI": {"tldr": "GaLore Unbiased with Muon (GUM) is a novel memory-efficient optimization method for large language models that combines GaLore's low-rank projection with Muon's layerwise sampling to eliminate bias and provide convergence guarantees while maintaining memory efficiency.", "motivation": "To address the lack of convergence guarantees and inherent bias in existing gradient low-rank projection methods like GaLore, which cause performance gaps compared to full-parameter training.", "method": "Combines GaLore's low-rank projection mechanism with Muon's layerwise sampling technique to create an unbiased optimization method that debiases low-rank projection while preserving memory efficiency.", "result": "Theoretically proven to match Muon's convergence guarantees while maintaining GaLore's memory efficiency. Empirical experiments show improvements over GaLore and even better performance than full-parameter training, with more uniform knowledge distribution and better parameter space utilization.", "conclusion": "GUM successfully addresses the bias problem in low-rank optimization methods, providing convergence guarantees while achieving superior performance through more efficient knowledge distribution and parameter utilization."}}
