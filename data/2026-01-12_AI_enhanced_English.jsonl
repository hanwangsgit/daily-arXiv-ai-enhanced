{"id": "2601.05296", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.05296", "abs": "https://arxiv.org/abs/2601.05296", "authors": ["Jiyuan Zhang", "Yining Liu", "Siqi Yan", "Lisen Deng", "Jennifer Cao", "Shuqi Yang", "Min Ni", "Bi Xue", "Shen Li"], "title": "MoEBlaze: Breaking the Memory Wall for Efficient MoE Training on Modern GPUs", "comment": null, "summary": "The pervasive \"memory wall\" bottleneck is significantly amplified in modern large-scale Mixture-of-Experts (MoE) architectures. MoE's inherent architectural sparsity leads to sparse arithmetic compute and also introduces substantial activation memory overheads -- driven by large token routing buffers and the need to materialize and buffer intermediate tensors. This memory pressure limits the maximum batch size and sequence length that can fit on GPUs, and also results in excessive data movements that hinders performance and efficient model scaling. We present MoEBlaze, a memory-efficient MoE training framework that addresses these issues through a co-designed system approach: (i) an end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (ii) co-designed kernels with smart activation checkpoint to mitigate memory footprint while simultaneously achieving better performance. We demonstrate that MoEBlaze can achieve over 4x speedups and over 50% memory savings compared to existing MoE frameworks.", "AI": {"tldr": "MoEBlaze: A memory-efficient MoE training framework that reduces activation memory overhead by 50% and achieves 4x speedups through co-designed system optimizations.", "motivation": "Modern Mixture-of-Experts (MoE) architectures suffer from severe \"memory wall\" bottlenecks due to sparse arithmetic compute and substantial activation memory overheads from token routing buffers and intermediate tensor materialization, limiting batch size, sequence length, and causing excessive data movements.", "method": "Co-designed system approach with: (1) end-to-end token dispatch and MoE training method with optimized data structures to eliminate intermediate buffers and activation materializing, and (2) co-designed kernels with smart activation checkpoint to reduce memory footprint while improving performance.", "result": "MoEBlaze achieves over 4x speedups and over 50% memory savings compared to existing MoE frameworks.", "conclusion": "MoEBlaze effectively addresses the memory bottleneck in MoE training through systematic co-design, enabling more efficient model scaling and better performance."}}
{"id": "2601.05300", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05300", "abs": "https://arxiv.org/abs/2601.05300", "authors": ["Susmit Das"], "title": "TIME: Temporally Intelligent Meta-reasoning Engine for Context Triggered Explicit Reasoning", "comment": "14 pages, 3 figures with 27 page appendix. See https://github.com/The-Coherence-Initiative/TIME and https://github.com/The-Coherence-Initiative/TIMEBench for associated code", "summary": "Reasoning oriented large language models often expose explicit \"thinking\" as long, turn-global traces at the start of every response, either always on or toggled externally at inference time. While useful for arithmetic, programming, and problem solving, this design is costly, blurs claim level auditability, and cannot re-trigger explicit reasoning once the model begins presenting. Dialogue models are also largely blind to temporal structure, treating replies after seconds and replies after weeks as equivalent unless time is stated in text. We introduce TIME, the Temporally Intelligent Meta-reasoning Engine, a behavioral alignment framework that treats explicit reasoning as a context sensitive resource driven by discourse and temporal cues. TIME augments dialogue with optional ISO 8601 <time> tags, tick turns that represent silent gaps, and short <think> blocks that can appear anywhere in a reply. A four-phase curriculum including a small, maximally diverse full-batch alignment step trains Qwen3 dense models to invoke brief, in-place reasoning bursts and keep user facing text compact. We evaluate with TIMEBench, a temporally grounded dialogue benchmark probing chronology, commonsense under gaps and offsets, anomaly detection, and continuity. Across 4B to 32B scales, TIME improves TIMEBench scores over base Qwen3 in both thinking and no-thinking modes while reducing reasoning tokens by about an order of magnitude. Our training data and code are available at https://github.com/The-Coherence-Initiative/TIME and TIMEBench is available at https://github.com/The-Coherence-Initiative/TIMEBench", "AI": {"tldr": "TIME framework enables dialogue models to use brief, context-sensitive reasoning bursts triggered by temporal cues, reducing reasoning tokens by 10x while improving performance on temporal reasoning tasks.", "motivation": "Current LLMs use long, turn-global reasoning traces that are costly, reduce auditability, and cannot be re-triggered. Dialogue models also lack temporal awareness, treating all replies as equivalent regardless of time gaps.", "method": "Introduces TIME framework with ISO 8601 time tags, tick turns for silent gaps, and short <think> blocks anywhere in replies. Uses 4-phase curriculum including full-batch alignment to train Qwen3 models for in-place reasoning bursts.", "result": "TIME improves TIMEBench scores over base Qwen3 across 4B to 32B scales in both thinking and no-thinking modes while reducing reasoning tokens by about 10x.", "conclusion": "TIME demonstrates that explicit reasoning can be made context-sensitive and temporally aware, enabling more efficient and temporally grounded dialogue systems."}}
{"id": "2601.05304", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05304", "abs": "https://arxiv.org/abs/2601.05304", "authors": ["Jaehong Oh"], "title": "Ontology Neural Networks for Topologically Conditioned Constraint Satisfaction", "comment": "12 pages, 11 figures", "summary": "Neuro-symbolic reasoning systems face fundamental challenges in maintaining semantic coherence while satisfying physical and logical constraints. Building upon our previous work on Ontology Neural Networks, we present an enhanced framework that integrates topological conditioning with gradient stabilization mechanisms. The approach employs Forman-Ricci curvature to capture graph topology, Deep Delta Learning for stable rank-one perturbations during constraint projection, and Covariance Matrix Adaptation Evolution Strategy for parameter optimization. Experimental evaluation across multiple problem sizes demonstrates that the method achieves mean energy reduction to 1.15 compared to baseline values of 11.68, with 95 percent success rate in constraint satisfaction tasks. The framework exhibits seed-independent convergence and graceful scaling behavior up to twenty-node problems, suggesting that topological structure can inform gradient-based optimization without sacrificing interpretability or computational efficiency.", "AI": {"tldr": "Enhanced neuro-symbolic framework integrates topological conditioning with gradient stabilization, achieving 95% constraint satisfaction and significant energy reduction compared to baselines.", "motivation": "Neuro-symbolic reasoning systems struggle to maintain semantic coherence while satisfying physical and logical constraints, requiring improved methods that balance optimization with interpretability.", "method": "Combines Forman-Ricci curvature for graph topology capture, Deep Delta Learning for stable rank-one perturbations during constraint projection, and Covariance Matrix Adaptation Evolution Strategy for parameter optimization.", "result": "Achieves mean energy reduction to 1.15 (vs baseline 11.68), 95% success rate in constraint satisfaction, seed-independent convergence, and graceful scaling up to twenty-node problems.", "conclusion": "Topological structure can effectively inform gradient-based optimization in neuro-symbolic systems without sacrificing interpretability or computational efficiency."}}
{"id": "2601.05276", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05276", "abs": "https://arxiv.org/abs/2601.05276", "authors": ["Nicholas R. Rasmussen", "Rodrigue Rizk", "Longwei Wang", "Arun Singh", "KC Santosh"], "title": "Channel Selected Stratified Nested Cross Validation for Clinically Relevant EEG Based Parkinsons Disease Detection", "comment": "Submitted to IEEE Conference -> posting to Arxiv as normal", "summary": "The early detection of Parkinsons disease remains a critical challenge in clinical neuroscience, with electroencephalography offering a noninvasive and scalable pathway toward population level screening. While machine learning has shown promise in this domain, many reported results suffer from methodological flaws, most notably patient level data leakage, inflating performance estimates and limiting clinical translation. To address these modeling pitfalls, we propose a unified evaluation framework grounded in nested cross validation and incorporating three complementary safeguards: (i) patient level stratification to eliminate subject overlap and ensure unbiased generalization, (ii) multi layered windowing to harmonize heterogeneous EEG recordings while preserving temporal dynamics, and (iii) inner loop channel selection to enable principled feature reduction without information leakage. Applied across three independent datasets with a heterogeneous number of channels, a convolutional neural network trained under this framework achieved 80.6% accuracy and demonstrated state of the art performance under held out population block testing, comparable to other methods in the literature. This performance underscores the necessity of nested cross validation as a safeguard against bias and as a principled means of selecting the most relevant information for patient level decisions, providing a reproducible foundation that can extend to other biomedical signal analysis domains.", "AI": {"tldr": "A unified evaluation framework using nested cross-validation with patient-level safeguards achieves 80.6% accuracy for Parkinson's disease detection from EEG, addressing data leakage issues in previous ML approaches.", "motivation": "Early detection of Parkinson's disease is clinically important but challenging. While EEG offers non-invasive screening potential, existing machine learning approaches suffer from methodological flaws like patient-level data leakage that inflate performance estimates and limit clinical translation.", "method": "Proposed a unified evaluation framework based on nested cross-validation with three safeguards: (1) patient-level stratification to eliminate subject overlap, (2) multi-layered windowing to harmonize heterogeneous EEG recordings while preserving temporal dynamics, and (3) inner-loop channel selection for principled feature reduction without information leakage.", "result": "Applied across three independent datasets with varying channel numbers, a CNN trained under this framework achieved 80.6% accuracy and demonstrated state-of-the-art performance under held-out population block testing, comparable to other methods in literature.", "conclusion": "Nested cross-validation is essential as a safeguard against bias and for selecting relevant information for patient-level decisions. The framework provides a reproducible foundation that can extend to other biomedical signal analysis domains."}}
{"id": "2601.05394", "categories": ["cs.CV", "cs.GR", "cs.MM", "eess.IV"], "pdf": "https://arxiv.org/pdf/2601.05394", "abs": "https://arxiv.org/abs/2601.05394", "authors": ["Yuang Shi", "Simone Gasparini", "G\u00e9raldine Morin", "Wei Tsang Ooi"], "title": "Sketch&Patch++: Efficient Structure-Aware 3D Gaussian Representation", "comment": null, "summary": "We observe that Gaussians exhibit distinct roles and characteristics analogous to traditional artistic techniques -- like how artists first sketch outlines before filling in broader areas with color, some Gaussians capture high-frequency features such as edges and contours, while others represent broader, smoother regions analogous to brush strokes that add volume and depth. Based on this observation, we propose a hybrid representation that categorizes Gaussians into (i) Sketch Gaussians, which represent high-frequency, boundary-defining features, and (ii) Patch Gaussians, which cover low-frequency, smooth regions. This semantic separation naturally enables layered progressive streaming, where the compact Sketch Gaussians establish the structural skeleton before Patch Gaussians incrementally refine volumetric detail.\n  In this work, we extend our previous method to arbitrary 3D scenes by proposing a novel hierarchical adaptive categorization framework that operates directly on the 3DGS representation. Our approach employs multi-criteria density-based clustering, combined with adaptive quality-driven refinement. This method eliminates dependency on external 3D line primitives while ensuring optimal parametric encoding effectiveness. Our comprehensive evaluation across diverse scenes, including both man-made and natural environments, demonstrates that our method achieves up to 1.74 dB improvement in PSNR, 6.7% in SSIM, and 41.4% in LPIPS at equivalent model sizes compared to uniform pruning baselines. For indoor scenes, our method can maintain visual quality with only 0.5\\% of the original model size. This structure-aware representation enables efficient storage, adaptive streaming, and rendering of high-fidelity 3D content across bandwidth-constrained networks and resource-limited devices.", "AI": {"tldr": "A hybrid Gaussian representation that separates 3D Gaussians into Sketch (high-frequency edges) and Patch (low-frequency regions) categories, enabling progressive streaming and efficient compression for 3D Gaussian Splatting.", "motivation": "Traditional 3D Gaussian representations treat all Gaussians uniformly, missing the opportunity for semantic separation that could enable more efficient streaming and compression. The authors observe that Gaussians naturally serve different roles similar to artistic techniques - some define structural outlines while others fill in volumetric details.", "method": "Proposes a hierarchical adaptive categorization framework using multi-criteria density-based clustering with adaptive quality-driven refinement. The method categorizes Gaussians into two types: (1) Sketch Gaussians for high-frequency boundary features, and (2) Patch Gaussians for low-frequency smooth regions, enabling layered progressive streaming.", "result": "Achieves up to 1.74 dB PSNR improvement, 6.7% SSIM improvement, and 41.4% LPIPS improvement at equivalent model sizes compared to uniform pruning baselines. For indoor scenes, maintains visual quality with only 0.5% of original model size.", "conclusion": "The structure-aware Gaussian representation enables efficient storage, adaptive streaming, and high-fidelity rendering across bandwidth-constrained networks and resource-limited devices, extending 3D Gaussian Splatting to arbitrary scenes without dependency on external 3D line primitives."}}
{"id": "2601.05352", "categories": ["cs.LG", "cs.CR", "cs.IR", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.05352", "abs": "https://arxiv.org/abs/2601.05352", "authors": ["Tianrun Yu", "Kaixiang Zhao", "Cheng Zhang", "Anjun Gao", "Yueyang Quan", "Zhuqing Liu", "Minghong Fang"], "title": "When the Server Steps In: Calibrated Updates for Fair Federated Learning", "comment": null, "summary": "Federated learning (FL) has emerged as a transformative distributed learning paradigm, enabling multiple clients to collaboratively train a global model under the coordination of a central server without sharing their raw training data. While FL offers notable advantages, it faces critical challenges in ensuring fairness across diverse demographic groups. To address these fairness concerns, various fairness-aware debiasing methods have been proposed. However, many of these approaches either require modifications to clients' training protocols or lack flexibility in their aggregation strategies. In this work, we address these limitations by introducing EquFL, a novel server-side debiasing method designed to mitigate bias in FL systems. EquFL operates by allowing the server to generate a single calibrated update after receiving model updates from the clients. This calibrated update is then integrated with the aggregated client updates to produce an adjusted global model that reduces bias. Theoretically, we establish that EquFL converges to the optimal global model achieved by FedAvg and effectively reduces fairness loss over training rounds. Empirically, we demonstrate that EquFL significantly mitigates bias within the system, showcasing its practical effectiveness.", "AI": {"tldr": "EquFL is a server-side debiasing method for federated learning that reduces bias without modifying client training protocols, using calibrated updates to adjust the global model.", "motivation": "Federated learning faces fairness challenges across demographic groups, and existing debiasing methods either require client protocol modifications or lack flexible aggregation strategies.", "method": "EquFL is a server-side method where the server generates a single calibrated update after receiving client model updates, then integrates this with aggregated client updates to produce an adjusted global model that reduces bias.", "result": "Theoretically, EquFL converges to the optimal global model achieved by FedAvg and reduces fairness loss over training rounds. Empirically, it significantly mitigates bias within the system.", "conclusion": "EquFL provides an effective server-side solution for bias mitigation in federated learning that maintains compatibility with existing client protocols while offering flexible aggregation."}}
{"id": "2601.05323", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05323", "abs": "https://arxiv.org/abs/2601.05323", "authors": ["Mohammad Ali Vahedifar", "Qi Zhang"], "title": "Discrete Mode Decomposition Meets Shapley Value: Robust Signal Prediction in Tactile Internet", "comment": "This paper has been accepted at IEEE INFOCOM 2026", "summary": "Tactile Internet (TI) requires ultra-low latency and high reliability to ensure stability and transparency in touch-enabled teleoperation. However, variable delays and packet loss present significant challenges to maintaining immersive haptic communication. To address this, we propose a predictive framework that integrates Discrete Mode Decomposition (DMD) with Shapley Mode Value (SMV) for accurate and timely haptic signal prediction. DMD decomposes haptic signals into interpretable intrinsic modes, while SMV evaluates each mode's contribution to prediction accuracy, which is well-aligned with the goal-oriented semantic communication. Integrating SMV with DMD further accelerates inference, enabling efficient communication and smooth teleoperation even under adverse network conditions.\n  Extensive experiments show that DMD+SMV, combined with a Transformer architecture, outperforms baseline methods significantly. It achieves 98.9% accuracy for 1-sample prediction and 92.5% for 100-sample prediction, as well as extremely low inference latency: 0.056 ms and 2 ms, respectively. These results demonstrate that the proposed framework has strong potential to ease the stringent latency and reliability requirements of TI without compromising performance, highlighting its feasibility for real-world deployment in TI systems.", "AI": {"tldr": "A predictive framework combining Discrete Mode Decomposition (DMD) with Shapley Mode Value (SMV) for haptic signal prediction in Tactile Internet, achieving high accuracy and ultra-low latency to overcome network challenges.", "motivation": "Tactile Internet requires ultra-low latency and high reliability for stable teleoperation, but faces challenges from variable delays and packet loss in haptic communication. There's a need for accurate and timely haptic signal prediction to maintain immersive touch-enabled experiences under adverse network conditions.", "method": "Proposes a predictive framework integrating Discrete Mode Decomposition (DMD) with Shapley Mode Value (SMV). DMD decomposes haptic signals into interpretable intrinsic modes, while SMV evaluates each mode's contribution to prediction accuracy. This integration accelerates inference and enables efficient communication. The approach is combined with a Transformer architecture for implementation.", "result": "Extensive experiments show DMD+SMV with Transformer outperforms baselines significantly: 98.9% accuracy for 1-sample prediction, 92.5% for 100-sample prediction, with extremely low inference latency of 0.056 ms and 2 ms respectively. The framework demonstrates strong potential to ease stringent latency and reliability requirements of Tactile Internet.", "conclusion": "The proposed framework effectively addresses Tactile Internet challenges by providing accurate haptic signal prediction with ultra-low latency, highlighting its feasibility for real-world deployment in TI systems without compromising performance."}}
{"id": "2601.05923", "categories": ["eess.SP", "cs.AI", "cs.LG", "eess.IV", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.05923", "abs": "https://arxiv.org/abs/2601.05923", "authors": ["E. Middell", "L. Carlton", "S. Moradi", "T. Codina", "T. Fischer", "J. Cutler", "S. Kelley", "J. Behrendt", "T. Dissanayake", "N. Harmening", "M. A. Y\u00fccel", "D. A. Boas", "A. von L\u00fchmann"], "title": "Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world", "comment": "33 pages main manuscript, 180 pages Supplementary Tutorial Notebooks, 12 figures, 6 tables, under review in SPIE Neurophotonics", "summary": "Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging.", "AI": {"tldr": "Cedalion is a Python-based open-source framework that unifies model-based and data-driven analysis of fNIRS/DOT data, integrating various analysis methods within standardized, reproducible workflows compatible with ML frameworks.", "motivation": "Current fNIRS/DOT analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning workflows. There's a need for unified tools that support wearable, multimodal neuroimaging in real-world settings.", "method": "Developed a Python-based open-source framework integrating forward modelling, photogrammetric optode co-registration, signal processing, GLM analysis, DOT image reconstruction, and ML-based methods within a single standardized architecture. Adheres to SNIRF and BIDS standards, supports cloud-executable notebooks, and provides containerized workflows.", "result": "Created Cedalion framework that implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction. Provides seven fully executable tutorial notebooks demonstrating core features. Enables seamless multimodal fusion with EEG, MEG, and physiological data through integration with scikit-learn and PyTorch.", "conclusion": "Cedalion offers an open, transparent, and community-extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for both laboratory-based and real-world neuroimaging applications."}}
{"id": "2601.05336", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05336", "abs": "https://arxiv.org/abs/2601.05336", "authors": ["Tracey Yee Hsin Tay", "Xu Yan", "Jonathan Ouyang", "Daniel Wu", "William Jiang", "Jonathan Kao", "Yuchen Cui"], "title": "Intent at a Glance: Gaze-Guided Robotic Manipulation via Foundation Models", "comment": "Accepted to 2025 RSS Robot Planning in the Era of Foundation Models (FM4RoboPlan) Workshop", "summary": "Designing intuitive interfaces for robotic control remains a central challenge in enabling effective human-robot interaction, particularly in assistive care settings. Eye gaze offers a fast, non-intrusive, and intent-rich input modality, making it an attractive channel for conveying user goals. In this work, we present GAMMA (Gaze Assisted Manipulation for Modular Autonomy), a system that leverages ego-centric gaze tracking and a vision-language model to infer user intent and autonomously execute robotic manipulation tasks. By contextualizing gaze fixations within the scene, the system maps visual attention to high-level semantic understanding, enabling skill selection and parameterization without task-specific training. We evaluate GAMMA on a range of table-top manipulation tasks and compare it against baseline gaze-based control without reasoning. Results demonstrate that GAMMA provides robust, intuitive, and generalizable control, highlighting the potential of combining foundation models and gaze for natural and scalable robot autonomy. Project website: https://gamma0.vercel.app/", "AI": {"tldr": "GAMMA is a gaze-based robotic control system that uses ego-centric gaze tracking and vision-language models to infer user intent and autonomously execute manipulation tasks without task-specific training.", "motivation": "Eye gaze offers a fast, non-intrusive, intent-rich input modality for human-robot interaction, but designing intuitive interfaces for robotic control remains challenging, especially in assistive care settings.", "method": "GAMMA leverages ego-centric gaze tracking and vision-language models to contextualize gaze fixations within the scene, mapping visual attention to high-level semantic understanding for skill selection and parameterization.", "result": "Evaluation on table-top manipulation tasks shows GAMMA provides robust, intuitive, and generalizable control compared to baseline gaze-based control without reasoning.", "conclusion": "Combining foundation models and gaze enables natural and scalable robot autonomy, demonstrating the potential of this approach for effective human-robot interaction."}}
{"id": "2601.05280", "categories": ["cs.IT", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05280", "abs": "https://arxiv.org/abs/2601.05280", "authors": ["Hector Zenil"], "title": "On the Limits of Self-Improving in LLMs and Why AGI, ASI and the Singularity Are Not Near Without Symbolic Model Synthesis", "comment": "26 pages", "summary": "We formalise recursive self-training in Large Language Models (LLMs) and Generative AI as a discrete-time dynamical system and prove that, as training data become increasingly self-generated ($\u03b1_t \\to 0$), the system undergoes inevitably degenerative dynamics. We derive two fundamental failure modes: (1) Entropy Decay, where finite sampling effects cause a monotonic loss of distributional diversity (mode collapse), and (2) Variance Amplification, where the loss of external grounding causes the model's representation of truth to drift as a random walk, bounded only by the support diameter. We show these behaviours are not contingent on architecture but are consequences of distributional learning on finite samples. We further argue that Reinforcement Learning with imperfect verifiers suffers similar semantic collapse. To overcome these limits, we propose a path involving symbolic regression and program synthesis guided by Algorithmic Probability. The Coding Theorem Method (CTM) allows for identifying generative mechanisms rather than mere correlations, escaping the data-processing inequality that binds standard statistical learning. We conclude that while purely distributional learning leads to model collapse, hybrid neurosymbolic approaches offer a coherent framework for sustained self-improvement.", "AI": {"tldr": "Recursive self-training in LLMs leads to degenerative dynamics with two failure modes: entropy decay (mode collapse) and variance amplification (truth drift). Pure distributional learning causes model collapse, but hybrid neurosymbolic approaches with algorithmic probability offer a path to sustained self-improvement.", "motivation": "To understand the fundamental limitations of recursive self-training in LLMs and generative AI, where models are trained on increasingly self-generated data, and to identify why this leads to degenerative dynamics and model collapse.", "method": "Formalize recursive self-training as a discrete-time dynamical system, analyze failure modes mathematically, prove degenerative dynamics as training data becomes self-generated, and propose symbolic regression and program synthesis guided by Algorithmic Probability using the Coding Theorem Method (CTM).", "result": "Proved that as \u03b1_t \u2192 0 (increasingly self-generated data), the system undergoes inevitable degenerative dynamics with two fundamental failure modes: (1) Entropy Decay causing monotonic loss of distributional diversity (mode collapse), and (2) Variance Amplification causing the model's representation of truth to drift as a random walk bounded only by support diameter.", "conclusion": "Pure distributional learning on finite samples inevitably leads to model collapse, but hybrid neurosymbolic approaches that identify generative mechanisms through algorithmic probability (rather than mere correlations) can escape the data-processing inequality and enable sustained self-improvement."}}
{"id": "2601.05328", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05328", "abs": "https://arxiv.org/abs/2601.05328", "authors": ["Fenil R. Doshi", "Thomas Fel", "Talia Konkle", "George Alvarez"], "title": "Bi-Orthogonal Factor Decomposition for Vision Transformers", "comment": null, "summary": "Self-attention is the central computational primitive of Vision Transformers, yet we lack a principled understanding of what information attention mechanisms exchange between tokens. Attention maps describe where weight mass concentrates; they do not reveal whether queries and keys trade position, content, or both. We introduce Bi-orthogonal Factor Decomposition (BFD), a two-stage analytical framework: first, an ANOVA-based decomposition statistically disentangles token activations into orthogonal positional and content factors; second, SVD of the query-key interaction matrix QK^T exposes bi-orthogonal modes that reveal how these factors mediate communication. After validating proper isolation of position and content, we apply BFD to state-of-the-art vision models and uncover three phenomena.(i) Attention operates primarily through content. Content-content interactions dominate attention energy, followed by content-position coupling. DINOv2 allocates more energy to content-position than supervised models and distributes computation across a richer mode spectrum. (ii) Attention mechanisms exhibit specialization: heads differentiate into content-content, content-position, and position-position operators, while singular modes within heads show analogous specialization. (iii) DINOv2's superior holistic shape processing emerges from intermediate layers that simultaneously preserve positional structure while contextually enriching semantic content.\n  Overall, BFD exposes how tokens interact through attention and which informational factors - positional or semantic - mediate their communication, yielding practical insights into vision transformer mechanisms.", "AI": {"tldr": "BFD is a framework that decomposes attention into orthogonal positional and content factors, revealing that attention primarily operates through content interactions, with specialized heads for different factor combinations.", "motivation": "Self-attention is central to Vision Transformers but lacks principled understanding of what information (position vs. content) attention mechanisms exchange between tokens. Attention maps show where weight concentrates but don't reveal whether queries and keys trade position, content, or both.", "method": "Bi-orthogonal Factor Decomposition (BFD): two-stage analytical framework: 1) ANOVA-based decomposition statistically disentangles token activations into orthogonal positional and content factors; 2) SVD of query-key interaction matrix QK^T exposes bi-orthogonal modes revealing how these factors mediate communication.", "result": "Three key findings: 1) Attention operates primarily through content (content-content interactions dominate, followed by content-position coupling; DINOv2 allocates more energy to content-position than supervised models). 2) Attention mechanisms exhibit specialization: heads differentiate into content-content, content-position, and position-position operators. 3) DINOv2's superior holistic shape processing emerges from intermediate layers preserving positional structure while contextually enriching semantic content.", "conclusion": "BFD exposes how tokens interact through attention and which informational factors (positional or semantic) mediate their communication, yielding practical insights into vision transformer mechanisms and revealing fundamental differences between self-supervised and supervised models."}}
{"id": "2601.05256", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05256", "abs": "https://arxiv.org/abs/2601.05256", "authors": ["Eirini Baltzi", "Tilemachos Moumouris", "Athena Psalta", "Vasileios Tsironis", "Konstantinos Karantzalos"], "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring", "comment": null, "summary": "Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.", "AI": {"tldr": "NAIAD is an agentic AI assistant that provides holistic inland water monitoring using Earth Observation data through a single-prompt natural language interface, combining LLMs with external analytical tools.", "motivation": "Existing water monitoring methods address isolated sub-problems separately (cyanobacteria, chlorophyll, etc.), lacking a comprehensive solution. There's a need for a holistic approach that serves both experts and non-experts.", "method": "Uses agentic AI assistant with LLMs and external tools via Retrieval-Augmented Generation (RAG), LLM reasoning, tool orchestration, computational graph execution, and agentic reflection. Integrates weather data, Sentinel-2 imagery, remote-sensing indices (NDCI), chlorophyll-a estimation, and platforms like CyFi.", "result": "Achieves over 77% correctness and 85% relevancy on dedicated benchmark across multiple user-expertise levels. Shows strong adaptability and robustness. Gemma 3 (27B) and Qwen 2.5 (14B) offer best balance between computational efficiency and reasoning performance.", "conclusion": "NAIAD provides a unified, accessible solution for inland water monitoring that overcomes fragmentation of existing approaches, demonstrating effective integration of LLMs with domain-specific tools for actionable insights."}}
{"id": "2601.05353", "categories": ["cs.LG", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05353", "abs": "https://arxiv.org/abs/2601.05353", "authors": ["Shovito Barua Soumma", "Hassan Ghasemzadeh"], "title": "GlyRAG: Context-Aware Retrieval-Augmented Framework for Blood Glucose Forecasting", "comment": null, "summary": "Accurate forecasting of blood glucose from CGM is essential for preventing dysglycemic events, thus enabling proactive diabetes management. However, current forecasting models treat blood glucose readings captured using CGMs as a numerical sequence, either ignoring context or relying on additional sensors/modalities that are difficult to collect and deploy at scale. Recently, LLMs have shown promise for time-series forecasting tasks, yet their role as agentic context extractors in diabetes care remains largely unexplored. To address these limitations, we propose GlyRAG, a context-aware, retrieval-augmented forecasting framework that derives semantic understanding of blood glucose dynamics directly from CGM traces without requiring additional sensor modalities. GlyRAG employs an LLM as a contextualization agent to generate clinical summaries. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer architecture with a cross translation loss aligining textual and physiological embeddings. A retrieval module then identifies similar historical episodes in the learned embedding space and uses cross-attention to integrate these case-based analogues prior to making a forecasting inference. Extensive evaluations on two T1D cohorts show that GlyRAG consistently outperforms state-of-the art methods, achieving up to 39% lower RMSE and a further 1.7% reduction in RMSE over the baseline. Clinical evaluation shows that GlyRAG places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts. These results indicate that LLM-based contextualization and retrieval over CGM traces can enhance the accuracy and clinical reliability of long-horizon glucose forecasting without the need for extra sensors, thus supporting future agentic decision-support tools for diabetes management.", "AI": {"tldr": "GlyRAG is a context-aware, retrieval-augmented forecasting framework that uses LLMs to extract semantic understanding from CGM traces for improved blood glucose forecasting without additional sensors.", "motivation": "Current glucose forecasting models treat CGM data as numerical sequences, ignoring clinical context or requiring additional sensors that are difficult to collect at scale. LLMs show promise for time-series forecasting but their role as agentic context extractors in diabetes care remains unexplored.", "method": "GlyRAG uses an LLM as a contextualization agent to generate clinical summaries from CGM traces. These summaries are embedded by a language model and fused with patch-based glucose representations in a multimodal transformer with cross translation loss. A retrieval module identifies similar historical episodes and uses cross-attention to integrate case-based analogues before forecasting.", "result": "GlyRAG outperforms state-of-the-art methods on two T1D cohorts, achieving up to 39% lower RMSE and a further 1.7% reduction over baseline. It places 85% predictions in safe zones and achieves 51% improvement in predicting dysglycemic events across both cohorts.", "conclusion": "LLM-based contextualization and retrieval over CGM traces can enhance accuracy and clinical reliability of long-horizon glucose forecasting without extra sensors, supporting future agentic decision-support tools for diabetes management."}}
{"id": "2601.05440", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.05440", "abs": "https://arxiv.org/abs/2601.05440", "authors": ["William Bjorndahl", "Mark O'Hair", "Ben Zoghi", "Joseph Camp"], "title": "SPARK: Sparse Parametric Antenna Representation using Kernels", "comment": "Accepted to IEEE INFOCOM 2026", "summary": "Channel state information (CSI) acquisition and feedback overhead grows with the number of antennas, users, and reported subbands. This growth becomes a bottleneck for many antenna and reconfigurable intelligent surface (RIS) systems as arrays and user densities scale. Practical CSI feedback and beam management rely on codebooks, where beams are selected via indices rather than explicitly transmitting radiation patterns. Hardware-aware operation requires an explicit representation of the measured antenna/RIS response, yet high-fidelity measured patterns are high-dimensional and costly to handle. We present SPARK (Sparse Parametric Antenna Representation using Kernels), a training-free compression model that decomposes patterns into a smooth global base and sparse localized lobes. For 3D patterns, SPARK uses low-order spherical harmonics for global directivity and anisotropic Gaussian kernels for localized features. For RIS 1D azimuth cuts, it uses a Fourier-series base with 1D Gaussians. On patterns from the AERPAW testbed and a public RIS dataset, SPARK achieves up to 2.8$\\times$ and 10.4$\\times$ reductions in reconstruction MSE over baselines, respectively. Simulation shows that amortizing a compact pattern description and reporting sparse path descriptors can produce 12.65% mean uplink goodput gain under a fixed uplink budget. Overall, SPARK turns dense patterns into compact, parametric models for scalable, hardware-aware beam management.", "AI": {"tldr": "SPARK is a training-free compression model that decomposes antenna/RIS radiation patterns into smooth global bases and sparse localized lobes, achieving significant MSE reduction and enabling scalable beam management.", "motivation": "CSI acquisition and feedback overhead grows with antenna/user scaling, becoming a bottleneck for many antenna and RIS systems. Hardware-aware operation requires explicit representation of measured antenna/RIS response, but high-fidelity patterns are high-dimensional and costly to handle.", "method": "SPARK decomposes patterns into a smooth global base and sparse localized lobes. For 3D patterns, it uses low-order spherical harmonics for global directivity and anisotropic Gaussian kernels for localized features. For RIS 1D azimuth cuts, it uses Fourier-series base with 1D Gaussians.", "result": "On AERPAW testbed and public RIS dataset patterns, SPARK achieves up to 2.8\u00d7 and 10.4\u00d7 reductions in reconstruction MSE over baselines. Simulation shows 12.65% mean uplink goodput gain under fixed uplink budget by amortizing compact pattern descriptions and reporting sparse path descriptors.", "conclusion": "SPARK transforms dense radiation patterns into compact, parametric models for scalable, hardware-aware beam management, addressing CSI feedback bottlenecks in large-scale antenna and RIS systems."}}
{"id": "2601.05356", "categories": ["cs.RO", "cs.AI", "cs.MA", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.05356", "abs": "https://arxiv.org/abs/2601.05356", "authors": ["Brian Hsu", "Priyanka V Setty", "Rory M Butler", "Ryan Lewis", "Casey Stone", "Rebecca Weinberg", "Thomas Brettin", "Rick Stevens", "Ian Foster", "Arvind Ramanathan"], "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling", "comment": "43 pages, 8 figures, submitted to RSC Digital Discovery. Equal contribution: B. Hsu, P.V. Setty, R.M. Butler. Corresponding author: A. Ramanathan", "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.", "AI": {"tldr": "PRISM is an AI framework that automates experimental protocol design using language-model agents to generate, refine, and validate protocols for robotic lab execution.", "motivation": "Automating experimental protocol design and execution is a fundamental bottleneck in realizing self-driving laboratories. Current approaches require significant human intervention between steps and lack integrated validation systems.", "method": "PRISM uses language-model-based agents to: 1) Gather experimental procedures from web sources, 2) Convert them into structured steps through planning-critique-validation loops, 3) Translate to Argonne MADSci format for robotic coordination, and 4) Validate in NVIDIA Omniverse digital-twin environment before execution.", "result": "The framework successfully generated protocols for Luna qPCR amplification and Cell Painting case studies. It demonstrated practical end-to-end workflow bridging language-based protocol generation, simulation validation, and automated robotic execution without human intervention.", "conclusion": "PRISM represents a significant step toward self-driving laboratories by automating protocol design, validation, and execution through intelligent simulation modeling and multi-agent coordination of off-the-shelf robotic instruments."}}
{"id": "2601.05281", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05281", "abs": "https://arxiv.org/abs/2601.05281", "authors": ["Yujie Ling", "Zan Li", "Lei Guan", "Zheng Zhang", "Dusit Niyato"], "title": "Multi-User Covert Communications via Intelligent Spectrum Control", "comment": "5 pages, 5 figures, journal article", "summary": "This paper investigates the performance of multi-user covert communications over a fixed bandwidth in a multi-cell scenario with both eavesdroppers and malicious jammers. We propose an intelligent spectrum control (ISC) scheme that combines high-accuracy spectrum sensing with AI-assisted real-time decision-making to generate time-frequency dynamic occupation patterns for multiple legitimate users. The scheme can proactively avoid external interference and intra-system co-channel collisions, thereby improving covertness and reliability. Within this framework, we derive closed-form expressions for the detection error probability (DEP) of the eavesdropper and the reliable transmission probability (RTP) of legitimate users under multi-user joint detection. We then analytically optimize the transmission power that can maximize the covert rate (CR), as well as the maximum number of users that can access the system covertly and concurrently under given covertness and reliability constraints. Simulation results confirm the tight match between the analytical and Monte Carlo curves, and show that the proposed scheme can achieve a higher DEP, a larger RTP, and a greater multi-user capacity than the benchmark scheme.", "AI": {"tldr": "Proposes an intelligent spectrum control scheme for multi-user covert communications in multi-cell scenarios with eavesdroppers and jammers, using AI-assisted decision-making to optimize time-frequency patterns and maximize covert capacity.", "motivation": "Addresses the challenge of secure multi-user covert communications in hostile environments with both eavesdroppers and malicious jammers, where traditional fixed spectrum allocation leads to poor covertness and reliability due to interference and collisions.", "method": "Intelligent Spectrum Control (ISC) scheme combining high-accuracy spectrum sensing with AI-assisted real-time decision-making to generate dynamic time-frequency occupation patterns, enabling proactive avoidance of external interference and intra-system co-channel collisions.", "result": "Derived closed-form expressions for eavesdropper detection error probability (DEP) and legitimate user reliable transmission probability (RTP), analytically optimized transmission power to maximize covert rate, and determined maximum number of users that can access covertly under constraints.", "conclusion": "The proposed ISC scheme significantly outperforms benchmark methods, achieving higher DEP (better covertness), larger RTP (better reliability), and greater multi-user capacity, with analytical results closely matching simulation outcomes."}}
{"id": "2601.05344", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05344", "abs": "https://arxiv.org/abs/2601.05344", "authors": ["Sagi Eppel"], "title": "Coding the Visual World: From Image to Simulation Using Vision Language Models", "comment": null, "summary": "The ability to construct mental models of the world is a central aspect of understanding. Similarly, visual understanding can be viewed as the ability to construct a representative model of the system depicted in an image. This work explores the capacity of Vision Language Models (VLMs) to recognize and simulate the systems and mechanisms depicted in images using the Im2Sim methodology. The VLM is given a natural image of a real-world system (e.g., cities, clouds, vegetation) and is tasked with describing the system and writing code that simulates and generates it. This generative code is then executed to produce a synthetic image, which is compared against the original. This approach is tested on various complex emergent systems, ranging from physical systems (waves, lights, clouds) to vegetation, cities, materials, and geological formations. Through analysis of the models and images generated by the VLMs, we examine their understanding of the systems in images. The results show that leading VLMs (GPT, Gemini) demonstrate the capacity to understand and model complex, multi-component systems across multiple layers of abstraction and a wide range of domains. At the same time, the VLMs exhibit limited ability to replicate fine details and low-level arrangements of patterns in the image. These findings reveal an interesting asymmetry: VLMs combine high-level, deep visual understanding of images with limited perception of fine details.", "AI": {"tldr": "VLMs can generate code to simulate complex systems from images but struggle with fine details, showing an asymmetry between high-level understanding and low-level perception.", "motivation": "To explore whether Vision Language Models (VLMs) can understand and simulate the underlying systems and mechanisms depicted in images, similar to how humans construct mental models of the world.", "method": "Using the Im2Sim methodology: VLMs are given natural images of real-world systems and tasked with describing the system and writing code to simulate it. The generated code is executed to produce synthetic images that are compared against the original.", "result": "Leading VLMs (GPT, Gemini) demonstrate capacity to understand and model complex, multi-component systems across multiple abstraction layers and domains (physical systems, vegetation, cities, materials, geological formations). However, they exhibit limited ability to replicate fine details and low-level pattern arrangements.", "conclusion": "VLMs show an interesting asymmetry: they combine high-level, deep visual understanding of images with limited perception of fine details, revealing both strengths and limitations in their ability to construct representative models of depicted systems."}}
{"id": "2601.05298", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05298", "abs": "https://arxiv.org/abs/2601.05298", "authors": ["Yeongbin Cha", "Namjung Kim"], "title": "Mathematical Knowledge Graph-Driven Framework for Equation-Based Predictive and Reliable Additive Manufacturing", "comment": "preprint", "summary": "Additive manufacturing (AM) relies critically on understanding and extrapolating process-property relationships; however, existing data-driven approaches remain limited by fragmented knowledge representations and unreliable extrapolation under sparse data conditions. In this study, we propose an ontology-guided, equation-centric framework that tightly integrates large language models (LLMs) with an additive manufacturing mathematical knowledge graph (AM-MKG) to enable reliable knowledge extraction and principled extrapolative modeling. By explicitly encoding equations, variables, assumptions, and their semantic relationships within a formal ontology, unstructured literature is transformed into machine-interpretable representations that support structured querying and reasoning. LLM-based equation generation is further conditioned on MKG-derived subgraphs, enforcing physically meaningful functional forms and mitigating non-physical or unstable extrapolation trends. To assess reliability beyond conventional predictive uncertainty, a confidence-aware extrapolation assessment is introduced, integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency into a unified confidence score. Results demonstrate that ontology-guided extraction significantly improves the structural coherence and quantitative reliability of extracted knowledge, while subgraph-conditioned equation generation yields stable and physically consistent extrapolations compared to unguided LLM outputs. Overall, this work establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, highlighting the potential of knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing.", "AI": {"tldr": "An ontology-guided framework integrates LLMs with additive manufacturing knowledge graphs for reliable process-property modeling and extrapolation under sparse data conditions.", "motivation": "Existing data-driven approaches in additive manufacturing suffer from fragmented knowledge representations and unreliable extrapolation with sparse data, limiting process-property relationship understanding.", "method": "Proposes an ontology-guided, equation-centric framework that integrates LLMs with an additive manufacturing mathematical knowledge graph (AM-MKG). Uses formal ontology to encode equations, variables, and relationships, transforms unstructured literature into machine-interpretable representations, and conditions LLM-based equation generation on MKG-derived subgraphs for physically meaningful forms.", "result": "Ontology-guided extraction improves structural coherence and quantitative reliability of extracted knowledge. Subgraph-conditioned equation generation yields stable, physically consistent extrapolations compared to unguided LLM outputs. Introduces confidence-aware extrapolation assessment integrating extrapolation distance, statistical stability, and knowledge-graph-based physical consistency.", "conclusion": "Establishes a unified pipeline for ontology-driven knowledge representation, equation-centered reasoning, and confidence-based extrapolation assessment, demonstrating knowledge-graph-augmented LLMs as reliable tools for extrapolative modeling in additive manufacturing."}}
{"id": "2601.05371", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05371", "abs": "https://arxiv.org/abs/2601.05371", "authors": ["Md Shafiqul Islam", "Shakti Prasad Padhy", "Douglas Allaire", "Raymundo Arr\u00f3yave"], "title": "The Kernel Manifold: A Geometric Approach to Gaussian Process Model Selection", "comment": null, "summary": "Gaussian Process (GP) regression is a powerful nonparametric Bayesian framework, but its performance depends critically on the choice of covariance kernel. Selecting an appropriate kernel is therefore central to model quality, yet remains one of the most challenging and computationally expensive steps in probabilistic modeling. We present a Bayesian optimization framework built on kernel-of-kernels geometry, using expected divergence-based distances between GP priors to explore kernel space efficiently. A multidimensional scaling (MDS) embedding of this distance matrix maps a discrete kernel library into a continuous Euclidean manifold, enabling smooth BO. In this formulation, the input space comprises kernel compositions, the objective is the log marginal likelihood, and featurization is given by the MDS coordinates. When the divergence yields a valid metric, the embedding preserves geometry and produces a stable BO landscape. We demonstrate the approach on synthetic benchmarks, real-world time-series datasets, and an additive manufacturing case study predicting melt-pool geometry, achieving superior predictive accuracy and uncertainty calibration relative to baselines including Large Language Model (LLM)-guided search. This framework establishes a reusable probabilistic geometry for kernel search, with direct relevance to GP modeling and deep kernel learning.", "AI": {"tldr": "Bayesian optimization framework using kernel geometry and MDS embedding for efficient Gaussian Process kernel selection, outperforming baselines including LLM-guided search.", "motivation": "Kernel selection is critical for Gaussian Process regression performance but remains challenging and computationally expensive, requiring an efficient framework for exploring kernel space.", "method": "Uses Bayesian optimization with kernel-of-kernels geometry, expected divergence-based distances between GP priors, and MDS embedding to map discrete kernel library into continuous Euclidean manifold for smooth optimization.", "result": "Demonstrated superior predictive accuracy and uncertainty calibration on synthetic benchmarks, real-world time-series datasets, and additive manufacturing case study (melt-pool geometry prediction) compared to baselines including LLM-guided search.", "conclusion": "Establishes reusable probabilistic geometry for kernel search with direct relevance to GP modeling and deep kernel learning, providing an efficient framework for kernel selection."}}
{"id": "2601.05676", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05676", "abs": "https://arxiv.org/abs/2601.05676", "authors": ["Guangqi Shi", "Kimitaka Sumi", "Takuya Sakamoto"], "title": "Deformation-Aware Observation Modeling for Radar-Based Human Sensing via 3D Scan-Depth Sequence Fusion", "comment": "10 pages, 8 figures, and 5 tables. This work is going to be submitted to the IEEE for possible publication", "summary": "Non-contact radar-based human sensing is often interpreted using simplified motion assumptions. However, respiration induces non-rigid surface deformation of the human body that impacts electromagnetic wave scattering and can degrade the robustness of measurements. To address this, we propose a surface-deformation-aware observation model for radar-based human sensing that fuses static high-resolution three-dimensional scanner measurements with temporal depth camera data to represent time-varying human surface geometry. Non-rigid registration using the coherent point drift algorithm is employed to align a static template with dynamic depth frames. Frame-wise electromagnetic scattering is subsequently computed using the physical optics approximation, allowing the reconstruction of intermediate-frequency radar signals that emulate radar observations. Validation against experimental radar data demonstrated that the proposed model exhibited greater robustness than a depth-sequence-only model under low-signal-quality conditions involving complex surface dynamics and multiple reflective sites. For two participants, the proposed model achieved higher Pearson correlation coefficients of 0.943 and 0.887 between model-derived and experimentally measured displacement waveforms, compared with 0.868 and 0.796 for the depth-sequence-only model. Furthermore, in a favorable case characterized by a single relatively-stationary reflective site, the proposed method achieved a correlation coefficient of 0.789 between model-derived and experimentally measured in-phase-quadrature magnitude variations. These results suggest that our sensor-fusion-based deformation-aware observation modeling can realistically reproduce radar observations and provide physically grounded insights into the interpretation of radar measurement variations.", "AI": {"tldr": "Proposed a surface-deformation-aware observation model for radar-based human sensing that fuses 3D scanner and depth camera data to represent time-varying human surface geometry, improving robustness under low-signal-quality conditions.", "motivation": "Respiration induces non-rigid surface deformation that impacts electromagnetic wave scattering and degrades radar measurement robustness. Current methods use simplified motion assumptions that don't account for complex surface dynamics.", "method": "Fuses static high-resolution 3D scanner measurements with temporal depth camera data. Uses coherent point drift algorithm for non-rigid registration to align static template with dynamic depth frames. Computes electromagnetic scattering using physical optics approximation to reconstruct intermediate-frequency radar signals.", "result": "Proposed model showed greater robustness than depth-sequence-only model under low-signal-quality conditions. Achieved higher Pearson correlation coefficients (0.943 and 0.887 vs 0.868 and 0.796) for displacement waveforms. In favorable conditions, achieved 0.789 correlation for in-phase-quadrature magnitude variations.", "conclusion": "Sensor-fusion-based deformation-aware observation modeling can realistically reproduce radar observations and provide physically grounded insights into radar measurement variations, improving interpretation of non-contact human sensing."}}
{"id": "2601.05491", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05491", "abs": "https://arxiv.org/abs/2601.05491", "authors": ["Luca Nunziante", "Kentaro Uno", "Gustavo H. Diaz", "Shreya Santra", "Alessandro De Luca", "Kazuya Yoshida"], "title": "Assembling Solar Panels by Dual Robot Arms Towards Full Autonomous Lunar Base Construction", "comment": "This is the authors' version of a paper accepted for publication in IEEE/SICE International Symposium on System Integration (SII), 2025, (c) IEEE", "summary": "Since the successful Apollo program, humanity is once again aiming to return to the Moon for scientific discovery, resource mining, and inhabitation. Upcoming decades focus on building a lunar outpost, with robotic systems playing a crucial role to safely and efficiently establish essential infrastructure such as solar power generating towers. Similar to the construction of the International Space Station (ISS), shipping necessary components via modules and assembling them in situ should be a practical scenario. In this context, this paper focuses on the integration of vision, control, and hardware systems within an autonomous sequence for a dual-arm robot system. We explore a perception and control pipeline specifically designed for assembling solar panel modules, one of the benchmark tasks. Ad hoc hardware was designed and tested in real-world experiments. A mock-up of modular solar panels and active-passive connectors are employed, with the control of this grappling fixture integrated into the proposed pipeline. The successful implementation of our method demonstrates that the two robot manipulators can effectively connect arbitrarily placed panels, highlighting the seamless integration of vision, control, and hardware systems in complex space applications.", "AI": {"tldr": "Autonomous dual-arm robot system for assembling solar panel modules on the Moon using integrated vision, control, and hardware systems.", "motivation": "With renewed lunar exploration goals for scientific discovery, resource mining, and inhabitation, there's a need for robotic systems to autonomously build essential infrastructure like solar power towers, similar to ISS assembly approaches.", "method": "Developed a perception and control pipeline for dual-arm robot system with ad hoc hardware design, using mock-up modular solar panels with active-passive connectors, integrating vision, control, and hardware systems into autonomous assembly sequences.", "result": "Successful real-world experiments demonstrating that two robot manipulators can effectively connect arbitrarily placed solar panels, showing seamless integration of vision, control, and hardware systems.", "conclusion": "The proposed autonomous assembly system proves effective for complex space applications, particularly for lunar infrastructure development like solar panel module assembly."}}
{"id": "2601.05292", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05292", "abs": "https://arxiv.org/abs/2601.05292", "authors": ["Jingyi Wang", "Fanggang Wang"], "title": "Secure Communication via Modulation Order Confusion", "comment": null, "summary": "With the increasing threat posed by modulation classification to wireless security, this paper proposes a secure communication framework based on modulation order confusion (MOC), which intentionally disguises the original modulation as a higher- or lower-order one to mislead eavesdroppers. For single-antenna systems, two schemes are developed: symbol random mapping and symbol time diversity, enabling modulation order confusion with customized receivers. For multi-antenna systems, receiver-transparent MOC schemes are proposed, including series-expansion-based and constellation-path-based signal designs, and are further extended to RIS-assisted systems with joint beamformer and RIS reflection design. Numerical results show that the proposed schemes effectively defeat both deep-learning-based and expert-knowledge-based modulation classifiers without degrading communication performance.", "AI": {"tldr": "Proposes secure communication using modulation order confusion to disguise true modulation and mislead eavesdroppers, with schemes for single-antenna, multi-antenna, and RIS-assisted systems.", "motivation": "Addresses the security threat posed by modulation classification in wireless systems by intentionally confusing modulation order to protect against eavesdroppers.", "method": "Develops two schemes for single-antenna systems (symbol random mapping and symbol time diversity), and receiver-transparent MOC schemes for multi-antenna systems (series-expansion-based and constellation-path-based signal designs), extending to RIS-assisted systems with joint beamformer and RIS reflection design.", "result": "Numerical results demonstrate that proposed schemes effectively defeat both deep-learning-based and expert-knowledge-based modulation classifiers while maintaining communication performance.", "conclusion": "Modulation order confusion provides an effective security framework against modulation classification attacks without compromising legitimate communication quality."}}
{"id": "2601.05364", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05364", "abs": "https://arxiv.org/abs/2601.05364", "authors": ["Sudhakar Sah", "Ravish Kumar"], "title": "STResNet & STYOLO : A New Family of Compact Classification and Object Detection Models for MCUs", "comment": "9 pages, 1 figure", "summary": "Recent advancements in lightweight neural networks have significantly improved the efficiency of deploying deep learning models on edge hardware. However, most existing architectures still trade accuracy for latency, which limits their applicability on microcontroller and neural processing unit based devices. In this work, we introduce two new model families, STResNet for image classification and STYOLO for object detection, jointly optimized for accuracy, efficiency, and memory footprint on resource constrained platforms. The proposed STResNet series, ranging from Nano to Tiny variants, achieves competitive ImageNet 1K accuracy within a four million parameter budget. Specifically, STResNetMilli attains 70.0 percent Top 1 accuracy with only three million parameters, outperforming MobileNetV1 and ShuffleNetV2 at comparable computational complexity. For object detection, STYOLOMicro and STYOLOMilli achieve 30.5 percent and 33.6 percent mean average precision, respectively, on the MS COCO dataset, surpassing YOLOv5n and YOLOX Nano in both accuracy and efficiency. Furthermore, when STResNetMilli is used as a backbone with the Ultralytics training environment.", "AI": {"tldr": "STResNet and STYOLO are new lightweight neural network families optimized for edge devices, achieving competitive accuracy with minimal parameters and computational cost.", "motivation": "Existing lightweight neural networks still trade accuracy for latency, limiting their applicability on resource-constrained platforms like microcontrollers and NPU-based devices.", "method": "Introduces two model families: STResNet for image classification (Nano to Tiny variants) and STYOLO for object detection, jointly optimized for accuracy, efficiency, and memory footprint.", "result": "STResNetMilli achieves 70.0% Top-1 accuracy with only 3M parameters, outperforming MobileNetV1 and ShuffleNetV2. STYOLOMicro and STYOLOMilli achieve 30.5% and 33.6% mAP on COCO, surpassing YOLOv5n and YOLOX Nano.", "conclusion": "The proposed STResNet and STYOLO families demonstrate superior performance-efficiency trade-offs for edge deployment, enabling accurate deep learning on resource-constrained hardware."}}
{"id": "2601.05302", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05302", "abs": "https://arxiv.org/abs/2601.05302", "authors": ["Mizuki Sakai", "Mizuki Yokoyama", "Wakaba Tateishi", "Genki Ichinose"], "title": "Effects of personality steering on cooperative behavior in Large Language Model agents", "comment": null, "summary": "Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.", "AI": {"tldr": "Personality steering in LLMs affects cooperation in Prisoner's Dilemma games, with agreeableness being the key factor promoting cooperation, but it creates vulnerability to exploitation in earlier models while later models show more selective cooperation.", "motivation": "To understand how personality steering affects cooperative behavior in LLM agents under controlled conditions, particularly in strategic interactions like repeated Prisoner's Dilemma games.", "method": "Used Big Five framework to measure personality profiles of GPT-3.5-turbo, GPT-4o, and GPT-5, then compared behavior under baseline vs. personality-informed conditions, and manipulated each personality dimension to extreme values in repeated Prisoner's Dilemma games.", "result": "Agreeableness was the dominant factor promoting cooperation across all models; other traits had limited impact. Personality information increased cooperation but made earlier-generation models more vulnerable to exploitation, while later-generation models exhibited more selective cooperation.", "conclusion": "Personality steering acts as a behavioral bias rather than a deterministic control mechanism in LLM agents, with agreeableness being the key driver of cooperative behavior but creating trade-offs between cooperation and exploitation vulnerability."}}
{"id": "2601.05378", "categories": ["cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05378", "abs": "https://arxiv.org/abs/2601.05378", "authors": ["Sebastian J. Wetzel"], "title": "Inverting Non-Injective Functions with Twin Neural Network Regression", "comment": null, "summary": "Non-injective functions are not invertible. However, non-injective functions can be restricted to sub-domains on which they are locally injective and surjective and thus invertible if the dimensionality between input and output spaces are the same. Further, even if the dimensionalities do not match it is often possible to choose a preferred solution from many possible solutions. Twin neural network regression is naturally capable of incorporating these properties to invert non-injective functions. Twin neural network regression is trained to predict adjustments to well known input variables $\\mathbf{x}^{\\text{anchor}}$ to obtain an estimate for an unknown $\\mathbf{x}^{\\text{new}}$ under a change of the target variable from $\\mathbf{y}^{\\text{anchor}}$ to $\\mathbf{y}^{\\text{new}}$. In combination with k-nearest neighbor search, I propose a deterministic framework that finds input parameters to a given target variable of non-injective functions. The method is demonstrated by inverting non-injective functions describing toy problems and robot arm control that are a) defined by data or b) known as mathematical formula.", "AI": {"tldr": "Twin neural network regression with k-nearest neighbors provides a deterministic framework for inverting non-injective functions by finding input parameters for given target variables.", "motivation": "Non-injective functions are not invertible in general, but they can be inverted locally on sub-domains where they are injective, or by selecting preferred solutions when multiple solutions exist. There's a need for practical methods to invert non-injective functions in applications like robot arm control.", "method": "Twin neural network regression combined with k-nearest neighbor search. The twin network predicts adjustments to known anchor input variables to estimate new unknown inputs when target variables change. The method works with both data-defined functions and mathematical formulas.", "result": "The method successfully inverts non-injective functions in toy problems and robot arm control scenarios, demonstrating practical applicability for both data-based and formula-based non-injective functions.", "conclusion": "Twin neural network regression with k-nearest neighbors provides an effective deterministic framework for inverting non-injective functions, addressing the challenge of function inversion in cases where traditional inversion is impossible due to non-injectivity."}}
{"id": "2601.05920", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05920", "abs": "https://arxiv.org/abs/2601.05920", "authors": ["Meiwen Men", "Tao Zhou", "Kaifeng Bao", "Zhiyang Guo", "Yongning Qi", "Liu Liu", "Bo Ai"], "title": "A Novel Deep Learning-Based Coarse-to-Fine Frame Synchronization Method for OTFS Systems", "comment": null, "summary": "Orthogonal time frequency space (OTFS) modulation is a robust candidate waveform for future wireless systems, particularly in high-mobility scenarios, as it effectively mitigates the impact of rapidly time-varying channels by mapping symbols in the delay-Doppler (DD) domain. However, accurate frame synchronization in OTFS systems remains a challenge due to the performance limitations of conventional algorithms. To address this, we propose a low-complexity synchronization method based on a coarse-to-fine deep residual network (ResNet) architecture. Unlike traditional approaches relying on high-overhead preamble structures, our method exploits the intrinsic periodic features of OTFS pilots in the delay-time (DT) domain to formulate synchronization as a hierarchical classification problem. Specifically, the proposed architecture employs a two-stage strategy to first narrow the search space and then pinpoint the precise symbol timing offset (STO), thereby significantly reducing computational complexity while maintaining high estimation accuracy. We construct a comprehensive simulation dataset incorporating diverse channel models and randomized STO to validate the method. Extensive simulation results demonstrate that the proposed method achieves robust signal start detection and superior accuracy compared to conventional benchmarks, particularly in low signal-to-noise ratio (SNR) regimes and high-mobility scenarios.", "AI": {"tldr": "Proposes a low-complexity OTFS synchronization method using coarse-to-fine deep ResNet architecture that exploits OTFS pilot periodic features in delay-time domain for hierarchical STO estimation.", "motivation": "OTFS modulation is promising for high-mobility wireless systems but faces challenges with accurate frame synchronization due to limitations of conventional algorithms that rely on high-overhead preamble structures.", "method": "Two-stage coarse-to-fine deep residual network architecture that formulates synchronization as hierarchical classification problem. First stage narrows search space, second stage pinpoints precise symbol timing offset (STO) by exploiting intrinsic periodic features of OTFS pilots in delay-time domain.", "result": "Method achieves robust signal start detection and superior accuracy compared to conventional benchmarks, especially in low SNR regimes and high-mobility scenarios, while significantly reducing computational complexity.", "conclusion": "The proposed deep learning-based synchronization method effectively addresses OTFS frame synchronization challenges, offering low-complexity, high-accuracy performance suitable for practical high-mobility wireless systems."}}
{"id": "2601.05499", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05499", "abs": "https://arxiv.org/abs/2601.05499", "authors": ["Weishang Wu", "Yifei Shi", "Zhiping Cai"], "title": "TOSC: Task-Oriented Shape Completion for Open-World Dexterous Grasp Generation from Partial Point Clouds", "comment": "Accepted to AAAI 2026", "summary": "Task-oriented dexterous grasping remains challenging in robotic manipulations of open-world objects under severe partial observation, where significant missing data invalidates generic shape completion. In this paper, to overcome this limitation, we study Task-Oriented Shape Completion, a new task that focuses on completing the potential contact regions rather than the entire shape. We argue that shape completion for grasping should be explicitly guided by the downstream manipulation task. To achieve this, we first generate multiple task-oriented shape completion candidates by leveraging the zero-shot capabilities of object functional understanding from several pre-trained foundation models. A 3D discriminative autoencoder is then proposed to evaluate the plausibility of each generated candidate and optimize the most plausible one from a global perspective. A conditional flow-matching model named FlowGrasp is developed to generate task-oriented dexterous grasps from the optimized shape. Our method achieves state-of-the-art performance in task-oriented dexterous grasping and task-oriented shape completion, improving the Grasp Displacement and the Chamfer Distance over the state-of-the-art by 16.17\\% and 55.26%, respectively. In particular, it shows good capabilities in grasping objects with severe missing data. It also demonstrates good generality in handling open-set categories and tasks.", "AI": {"tldr": "Task-Oriented Shape Completion (TOSC) for dexterous grasping under severe partial observation, using foundation models for functional understanding and flow-matching for grasp generation.", "motivation": "Traditional shape completion fails for grasping under severe partial observation because it completes entire shapes rather than focusing on contact regions needed for manipulation tasks.", "method": "1) Generate multiple task-oriented shape completion candidates using pre-trained foundation models for object functional understanding; 2) Use 3D discriminative autoencoder to evaluate plausibility and optimize candidates; 3) Develop FlowGrasp (conditional flow-matching model) to generate task-oriented dexterous grasps from optimized shapes.", "result": "State-of-the-art performance in both task-oriented dexterous grasping and shape completion: 16.17% improvement in Grasp Displacement and 55.26% improvement in Chamfer Distance over previous methods. Shows good capability with severe missing data and generality for open-set categories/tasks.", "conclusion": "Task-oriented shape completion guided by manipulation tasks outperforms generic shape completion for dexterous grasping, especially under severe partial observation. The approach effectively leverages foundation models and flow-matching to handle real-world grasping challenges."}}
{"id": "2601.05340", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05340", "abs": "https://arxiv.org/abs/2601.05340", "authors": ["Roxana Smarandache", "David G. M. Mitchell"], "title": "The Number of Cycles of Bi-regular Tanner Graphs in Terms of the Eigenvalues of the Adjacency Matrix", "comment": "25 pages, submitted to IT Transactions", "summary": "In this paper, we explore new connections between the cycles in the graph of low-density parity-check (LDPC) codes and the eigenvalues of the corresponding adjacency matrix. The resulting observations are used to derive fast, simple, recursive formulas for the number of cycles $N_{2k}$ of length $2k$, $k<g$, in a bi-regular graph of girth $g$. Moreover, we derive explicit formulas for $N_{2k}$, $k\\leq 7$, in terms of the nonzero eigenvalues of the adjacency matrix. Throughout, we focus on the practically interesting class of bi-regular quasi-cyclic LDPC (QC-LDPC) codes, for which the eigenvalues can be obtained efficiently by applying techniques used for block-circulant matrices.", "AI": {"tldr": "New connections between LDPC code cycles and adjacency matrix eigenvalues enable fast recursive formulas for counting cycles in bi-regular graphs, with explicit formulas for cycles up to length 14.", "motivation": "To establish connections between graph cycles in LDPC codes and eigenvalues of adjacency matrices, enabling efficient cycle counting for practical QC-LDPC codes.", "method": "Analyze relationships between cycles in bi-regular graphs and eigenvalues of adjacency matrices, derive recursive formulas for cycle counts, and develop explicit formulas for cycles up to length 14 using eigenvalue techniques.", "result": "Fast recursive formulas for counting cycles of length 2k (k<g) in bi-regular graphs, plus explicit formulas for N_{2k} (k\u22647) in terms of nonzero eigenvalues, applicable to QC-LDPC codes using block-circulant matrix techniques.", "conclusion": "Eigenvalue-based approach provides efficient cycle counting for QC-LDPC codes, connecting graph structure with spectral properties for practical applications."}}
{"id": "2601.05368", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05368", "abs": "https://arxiv.org/abs/2601.05368", "authors": ["Svitlana Morkva", "Maximum Wilder-Smith", "Michael Oechsle", "Alessio Tonioni", "Marco Hutter", "Vaishakh Patil"], "title": "MOSAIC-GS: Monocular Scene Reconstruction via Advanced Initialization for Complex Dynamic Environments", "comment": null, "summary": "We present MOSAIC-GS, a novel, fully explicit, and computationally efficient approach for high-fidelity dynamic scene reconstruction from monocular videos using Gaussian Splatting. Monocular reconstruction is inherently ill-posed due to the lack of sufficient multiview constraints, making accurate recovery of object geometry and temporal coherence particularly challenging. To address this, we leverage multiple geometric cues, such as depth, optical flow, dynamic object segmentation, and point tracking. Combined with rigidity-based motion constraints, these cues allow us to estimate preliminary 3D scene dynamics during an initialization stage. Recovering scene dynamics prior to the photometric optimization reduces reliance on motion inference from visual appearance alone, which is often ambiguous in monocular settings. To enable compact representations, fast training, and real-time rendering while supporting non-rigid deformations, the scene is decomposed into static and dynamic components. Each Gaussian in the dynamic part of the scene is assigned a trajectory represented as time-dependent Poly-Fourier curve for parameter-efficient motion encoding. We demonstrate that MOSAIC-GS achieves substantially faster optimization and rendering compared to existing methods, while maintaining reconstruction quality on par with state-of-the-art approaches across standard monocular dynamic scene benchmarks.", "AI": {"tldr": "MOSAIC-GS: Fast monocular dynamic scene reconstruction using Gaussian Splatting with geometric cues and efficient motion encoding", "motivation": "Monocular reconstruction is ill-posed due to lack of multiview constraints, making accurate geometry and temporal coherence recovery challenging. Existing methods struggle with motion inference from visual appearance alone in monocular settings.", "method": "Leverages multiple geometric cues (depth, optical flow, dynamic object segmentation, point tracking) with rigidity-based motion constraints to estimate preliminary 3D scene dynamics during initialization. Decomposes scene into static/dynamic components, with dynamic Gaussians using time-dependent Poly-Fourier curves for parameter-efficient motion encoding.", "result": "Achieves substantially faster optimization and rendering compared to existing methods while maintaining reconstruction quality on par with state-of-the-art approaches on standard monocular dynamic scene benchmarks.", "conclusion": "MOSAIC-GS provides a computationally efficient, explicit approach for high-fidelity dynamic scene reconstruction from monocular videos by leveraging geometric cues and efficient motion representation, addressing the ill-posed nature of monocular reconstruction."}}
{"id": "2601.05330", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05330", "abs": "https://arxiv.org/abs/2601.05330", "authors": ["Tengwei Song", "Long Yin", "Zhen Han", "Zhiqiang Xu"], "title": "Improving Enzyme Prediction with Chemical Reaction Equations by Hypergraph-Enhanced Knowledge Graph Embeddings", "comment": null, "summary": "Predicting enzyme-substrate interactions has long been a fundamental problem in biochemistry and metabolic engineering. While existing methods could leverage databases of expert-curated enzyme-substrate pairs for models to learn from known pair interactions, the databases are often sparse, i.e., there are only limited and incomplete examples of such pairs, and also labor-intensive to maintain. This lack of sufficient training data significantly hinders the ability of traditional enzyme prediction models to generalize to unseen interactions. In this work, we try to exploit chemical reaction equations from domain-specific databases, given their easier accessibility and denser, more abundant data. However, interactions of multiple compounds, e.g., educts and products, with the same enzymes create complex relational data patterns that traditional models cannot easily capture. To tackle that, we represent chemical reaction equations as triples of (educt, enzyme, product) within a knowledge graph, such that we can take advantage of knowledge graph embedding (KGE) to infer missing enzyme-substrate pairs for graph completion. Particularly, in order to capture intricate relationships among compounds, we propose our knowledge-enhanced hypergraph model for enzyme prediction, i.e., Hyper-Enz, which integrates a hypergraph transformer with a KGE model to learn representations of the hyper-edges that involve multiple educts and products. Also, a multi-expert paradigm is introduced to guide the learning of enzyme-substrate interactions with both the proposed model and chemical reaction equations. Experimental results show a significant improvement, with up to a 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models, demonstrating the effectiveness of our approach.", "AI": {"tldr": "Hyper-Enz: A knowledge-enhanced hypergraph model that uses knowledge graph embeddings and hypergraph transformers to predict enzyme-substrate interactions from chemical reaction equations, achieving significant improvements over traditional methods.", "motivation": "Existing enzyme-substrate prediction methods rely on sparse, labor-intensive expert-curated databases, limiting generalization to unseen interactions. Chemical reaction equations offer denser, more abundant data but create complex relational patterns that traditional models cannot capture.", "method": "Represent chemical reaction equations as (educt, enzyme, product) triples in a knowledge graph, then use knowledge graph embedding (KGE) with a hypergraph transformer (Hyper-Enz) to learn representations of hyper-edges involving multiple compounds. A multi-expert paradigm guides learning from both the model and reaction equations.", "result": "Significant improvements: up to 88% relative improvement in average enzyme retrieval accuracy and 30% improvement in pair-level prediction compared to traditional models.", "conclusion": "The Hyper-Enz approach effectively leverages chemical reaction equations through knowledge graph embeddings and hypergraph transformers to overcome data sparsity issues in enzyme-substrate prediction, demonstrating superior performance over existing methods."}}
{"id": "2601.05383", "categories": ["cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.05383", "abs": "https://arxiv.org/abs/2601.05383", "authors": ["Prakash Gawas", "Antoine Legrain", "Louis-Martin Rousseau"], "title": "Imitation Learning for Combinatorial Optimisation under Uncertainty", "comment": null, "summary": "Imitation learning (IL) provides a data-driven framework for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored aspect of IL in this context is the role of the \\emph{expert} that generates training demonstrations. Existing studies employ a wide range of expert constructions, yet lack a unifying framework to characterise their modelling assumptions, computational properties, and impact on learning performance.\n  This paper introduces a systematic taxonomy of experts for IL in combinatorial optimisation under uncertainty. Experts are classified along three dimensions: (i) their treatment of uncertainty, including myopic, deterministic, full-information, two-stage stochastic, and multi-stage stochastic formulations; (ii) their level of optimality, distinguishing task-optimal and approximate experts; and (iii) their interaction mode with the learner, ranging from one-shot supervision to iterative, interactive schemes. Building on this taxonomy, we propose a generalised Dataset Aggregation (DAgger) algorithm that supports multiple expert queries, expert aggregation, and flexible interaction strategies.\n  The proposed framework is evaluated on a dynamic physician-to-patient assignment problem with stochastic arrivals and capacity constraints. Computational experiments compare learning outcomes across expert types and interaction regimes. The results show that policies learned from stochastic experts consistently outperform those learned from deterministic or full-information experts, while interactive learning improves solution quality using fewer expert demonstrations. Aggregated deterministic experts provide an effective alternative when stochastic optimisation becomes computationally challenging.", "AI": {"tldr": "Systematic taxonomy of experts for imitation learning in combinatorial optimization under uncertainty, with classification along three dimensions and a generalized DAgger algorithm.", "motivation": "Existing imitation learning approaches for combinatorial optimization use diverse expert constructions without a unifying framework to characterize their assumptions, computational properties, and impact on learning performance.", "method": "Proposes a taxonomy classifying experts along three dimensions: (1) treatment of uncertainty (myopic, deterministic, full-information, two-stage stochastic, multi-stage stochastic), (2) level of optimality (task-optimal vs approximate), and (3) interaction mode with learner (one-shot to iterative). Develops a generalized DAgger algorithm supporting multiple expert queries, aggregation, and flexible interaction strategies.", "result": "Evaluation on dynamic physician-to-patient assignment problem shows policies learned from stochastic experts outperform deterministic/full-information experts. Interactive learning improves solution quality with fewer demonstrations. Aggregated deterministic experts provide effective alternative when stochastic optimization is computationally challenging.", "conclusion": "Provides a systematic framework for understanding expert design in imitation learning for combinatorial optimization, demonstrating the importance of stochastic experts and interactive learning, while offering practical alternatives for computationally intensive scenarios."}}
{"id": "2601.05533", "categories": ["cs.RO", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.05533", "abs": "https://arxiv.org/abs/2601.05533", "authors": ["Kandai Watanabe", "Nicholas Renninger", "Sriram Sankaranarayanan", "Morteza Lahijanian"], "title": "Learning specifications for reactive synthesis with safety constraints", "comment": null, "summary": "This paper presents a novel approach to learning from demonstration that enables robots to autonomously execute complex tasks in dynamic environments. We model latent tasks as probabilistic formal languages and introduce a tailored reactive synthesis framework that balances robot costs with user task preferences. Our methodology focuses on safety-constrained learning and inferring formal task specifications as Probabilistic Deterministic Finite Automata (PDFA). We adapt existing evidence-driven state merging algorithms and incorporate safety requirements throughout the learning process to ensure that the learned PDFA always complies with safety constraints. Furthermore, we introduce a multi-objective reactive synthesis algorithm that generates deterministic strategies that are guaranteed to satisfy the PDFA task while optimizing the trade-offs between user preferences and robot costs, resulting in a Pareto front of optimal solutions. Our approach models the interaction as a two-player game between the robot and the environment, accounting for dynamic changes. We present a computationally-tractable value iteration algorithm to generate the Pareto front and the corresponding deterministic strategies. Comprehensive experimental results demonstrate the effectiveness of our algorithms across various robots and tasks, showing that the learned PDFA never includes unsafe behaviors and that synthesized strategies consistently achieve the task while meeting both the robot cost and user-preference requirements.", "AI": {"tldr": "A novel learning from demonstration approach that models tasks as probabilistic formal languages, uses safety-constrained PDFA learning, and employs multi-objective reactive synthesis to generate optimal robot strategies balancing user preferences and robot costs.", "motivation": "Enable robots to autonomously execute complex tasks in dynamic environments by learning from demonstrations while ensuring safety and balancing user task preferences with robot operational costs.", "method": "1) Model latent tasks as probabilistic formal languages; 2) Learn Probabilistic Deterministic Finite Automata (PDFA) with safety constraints using adapted evidence-driven state merging algorithms; 3) Use multi-objective reactive synthesis to generate deterministic strategies via a two-player game model between robot and environment; 4) Employ computationally-tractable value iteration to generate Pareto front of optimal solutions.", "result": "Comprehensive experiments show the learned PDFA never includes unsafe behaviors, and synthesized strategies consistently achieve tasks while meeting both robot cost and user-preference requirements across various robots and tasks.", "conclusion": "The approach successfully enables safe, autonomous robot task execution in dynamic environments by combining formal specification learning with multi-objective optimization, providing a framework that guarantees safety while balancing user preferences and operational costs."}}
{"id": "2601.05581", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05581", "abs": "https://arxiv.org/abs/2601.05581", "authors": ["Chao Liu", "Hao Chen", "Qinqin Ji", "Ziyan Xie", "Dabin Zheng"], "title": "Strong Singleton-Like Bounds, Quasi-Perfect Codes and Distance-Optimal Codes in the Sum-Rank Metric", "comment": "20 pages", "summary": "Codes in the sum-rank metric have received many attentions in recent years, since they have wide applications in the multishot network coding, the space-time coding and the distributed storage. In this paper, by constructing covering codes in the sum-rank metric from covering codes in the Hamming metric, we derive new upper bounds on sizes, the covering radii and the block length functions of codes in the sum-rank metric. As applications, we present several strong Singleton-like bounds that are tighter than the classical Singleton-like bound when block lengths are large. In addition, we give the explicit constructions of the distance-optimal sum-rank codes of matrix sizes $s\\times s$ and $2\\times 2$ with minimum sum-rank distance four respectively by using cyclic codes in the Hamming metric. More importantly, we present an infinite families of quasi-perfect $q$-ary sum-rank codes with matrix sizes $2\\times m$. Furthermore, we construct almost MSRD codes with larger block lengths and demonstrate how the Plotkin sum can be used to give more distance-optimal sum-rank codes.", "AI": {"tldr": "This paper presents new bounds and constructions for sum-rank metric codes, including improved Singleton-like bounds, distance-optimal code constructions, quasi-perfect codes, and applications to MSRD codes.", "motivation": "Sum-rank metric codes have important applications in multishot network coding, space-time coding, and distributed storage systems, driving the need for better bounds and constructions.", "method": "Construct covering codes in sum-rank metric from covering codes in Hamming metric, derive new upper bounds, use cyclic codes for explicit constructions, and apply Plotkin sum for more distance-optimal codes.", "result": "New tighter Singleton-like bounds, explicit distance-optimal sum-rank codes with minimum distance four, infinite families of quasi-perfect codes, and almost MSRD codes with larger block lengths.", "conclusion": "The paper provides significant advances in sum-rank metric coding theory through improved bounds and practical code constructions with applications to communication and storage systems."}}
{"id": "2601.05373", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05373", "abs": "https://arxiv.org/abs/2601.05373", "authors": ["Jorge Alberto Garza-Abdala", "Gerardo Alejandro Fumagal-Gonz\u00e1lez", "Beatriz A. Bosques-Palomo", "Mario Alexis Monsivais Molina", "Daly Avedano", "Servando Cardona-Huerta", "Jos\u00e9 Gerardo Tamez-Pena"], "title": "Ensemble of radiomics and ConvNeXt for breast cancer diagnosis", "comment": "Accepted and presented at the IEEE International Symposium on Computer-Based Medical Systems (CBMS) 2025", "summary": "Early diagnosis of breast cancer is crucial for improving survival rates. Radiomics and deep learning (DL) have shown significant potential in assisting radiologists with early cancer detection. This paper aims to critically assess the performance of radiomics, DL, and ensemble techniques in detecting cancer from screening mammograms. Two independent datasets were used: the RSNA 2023 Breast Cancer Detection Challenge (11,913 patients) and a Mexican cohort from the TecSalud dataset (19,400 patients). The ConvNeXtV1-small DL model was trained on the RSNA dataset and validated on the TecSalud dataset, while radiomics models were developed using the TecSalud dataset and validated with a leave-one-year-out approach. The ensemble method consistently combined and calibrated predictions using the same methodology. Results showed that the ensemble approach achieved the highest area under the curve (AUC) of 0.87, compared to 0.83 for ConvNeXtV1-small and 0.80 for radiomics. In conclusion, ensemble methods combining DL and radiomics predictions significantly enhance breast cancer diagnosis from mammograms.", "AI": {"tldr": "Ensemble methods combining deep learning and radiomics outperform individual approaches for breast cancer detection in mammograms, achieving AUC of 0.87.", "motivation": "Early breast cancer diagnosis improves survival rates, and radiomics/deep learning show promise for assisting radiologists in screening mammograms.", "method": "Used two datasets (RSNA 2023 with 11,913 patients and Mexican TecSalud with 19,400 patients). Trained ConvNeXtV1-small DL model on RSNA and validated on TecSalud. Developed radiomics models on TecSalud with leave-one-year-out validation. Created ensemble method by consistently combining and calibrating predictions.", "result": "Ensemble approach achieved highest AUC of 0.87, outperforming ConvNeXtV1-small (0.83) and radiomics (0.80).", "conclusion": "Ensemble methods combining DL and radiomics predictions significantly enhance breast cancer diagnosis from mammograms."}}
{"id": "2601.05376", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05376", "abs": "https://arxiv.org/abs/2601.05376", "authors": ["Tassallah Abdullahi", "Shrestha Ghosh", "Hamish S Fraser", "Daniel Le\u00f3n Tramontini", "Adeel Abbasi", "Ghada Bourjeily", "Carsten Eickhoff", "Ritambhara Singh"], "title": "The Persona Paradox: Medical Personas as Behavioral Priors in Clinical Language Models", "comment": null, "summary": "Persona conditioning can be viewed as a behavioral prior for large language models (LLMs) and is often assumed to confer expertise and improve safety in a monotonic manner. However, its effects on high-stakes clinical decision-making remain poorly characterized. We systematically evaluate persona-based control in clinical LLMs, examining how professional roles (e.g., Emergency Department physician, nurse) and interaction styles (bold vs.\\ cautious) influence behavior across models and medical tasks. We assess performance on clinical triage and patient-safety tasks using multidimensional evaluations that capture task accuracy, calibration, and safety-relevant risk behavior. We find systematic, context-dependent, and non-monotonic effects: Medical personas improve performance in critical care tasks, yielding gains of up to $\\sim+20\\%$ in accuracy and calibration, but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity and sensitivity, but it's highly model-dependent. While aggregated LLM-judge rankings favor medical over non-medical personas in safety-critical cases, we found that human clinicians show moderate agreement on safety compliance (average Cohen's $\u03ba= 0.43$) but indicate a low confidence in 95.9\\% of their responses on reasoning quality. Our work shows that personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise. The code is available at https://github.com/rsinghlab/Persona\\_Paradox.", "AI": {"tldr": "Persona conditioning in LLMs shows context-dependent effects on clinical decision-making: medical personas improve critical care performance but degrade primary care performance, with non-monotonic safety impacts.", "motivation": "To systematically evaluate how persona-based control (professional roles and interaction styles) affects LLM behavior in high-stakes clinical decision-making, challenging the assumption that personas monotonically improve expertise and safety.", "method": "Systematic evaluation of persona-based control in clinical LLMs using professional roles (Emergency Department physician, nurse) and interaction styles (bold vs. cautious). Assessed performance on clinical triage and patient-safety tasks with multidimensional evaluations capturing task accuracy, calibration, and safety-relevant risk behavior.", "result": "Medical personas improve performance in critical care tasks (up to ~+20% in accuracy and calibration) but degrade performance in primary-care settings by comparable margins. Interaction style modulates risk propensity but is highly model-dependent. LLM-judge rankings favor medical personas in safety-critical cases, but human clinicians show moderate agreement on safety compliance (\u03ba=0.43) and low confidence (95.9%) in reasoning quality.", "conclusion": "Personas function as behavioral priors that introduce context-dependent trade-offs rather than guarantees of safety or expertise, revealing a \"persona paradox\" where medical personas can both help and harm performance depending on clinical context."}}
{"id": "2601.05391", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05391", "abs": "https://arxiv.org/abs/2601.05391", "authors": ["Namrata Banerji", "Tanya Berger-Wolf"], "title": "DynaSTy: A Framework for SpatioTemporal Node Attribute Prediction in Dynamic Graphs", "comment": null, "summary": "Accurate multistep forecasting of node-level attributes on dynamic graphs is critical for applications ranging from financial trust networks to biological networks. Existing spatiotemporal graph neural networks typically assume a static adjacency matrix. In this work, we propose an end-to-end dynamic edge-biased spatiotemporal model that ingests a multi-dimensional timeseries of node attributes and a timeseries of adjacency matrices, to predict multiple future steps of node attributes. At each time step, our transformer-based model injects the given adjacency as an adaptable attention bias, allowing the model to focus on relevant neighbors as the graph evolves. We further deploy a masked node-time pretraining objective that primes the encoder to reconstruct missing features, and train with scheduled sampling and a horizon-weighted loss to mitigate compounding error over long horizons. Unlike prior work, our model accommodates dynamic graphs that vary across input samples, enabling forecasting in multi-system settings such as brain networks across different subjects, financial systems in different contexts, or evolving social systems. Empirical results demonstrate that our method consistently outperforms strong baselines on Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).", "AI": {"tldr": "Dynamic Edge-Biased Spatiotemporal Transformer for multistep node attribute forecasting on evolving graphs, outperforming baselines on RMSE/MAE.", "motivation": "Existing spatiotemporal GNNs assume static adjacency matrices, but many real-world applications (financial networks, biological networks, social systems) involve dynamic graphs that evolve over time. There's a need for models that can handle time-varying adjacency matrices across different systems/subjects.", "method": "End-to-end dynamic edge-biased spatiotemporal transformer that ingests multi-dimensional node attribute timeseries and adjacency matrix timeseries. Uses adaptable attention bias to inject adjacency information at each time step, allowing focus on relevant neighbors. Includes masked node-time pretraining for feature reconstruction, scheduled sampling, and horizon-weighted loss to mitigate compounding errors.", "result": "Empirical results show the method consistently outperforms strong baselines on Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) metrics.", "conclusion": "The proposed dynamic edge-biased spatiotemporal model effectively handles evolving graphs across different systems, enabling accurate multistep node attribute forecasting in diverse applications like brain networks, financial systems, and social systems."}}
{"id": "2601.05998", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05998", "abs": "https://arxiv.org/abs/2601.05998", "authors": ["Caroline Jane Spindel", "Edward Knightly"], "title": "Curving Beam Reflections: Model and Experimental Validation", "comment": "Accepted to IEEE INFOCOM 2026", "summary": "Curving beams are a promising new method for bypassing obstacles in future millimeter-wave to sub-terahertz (sub-THz) networks but lack a general predictive model for their reflections from arbitrary surfaces. We show that, unfortunately, attempting to \"mirror\" the incident beam trajectory across the normal of the reflector, as in ray optics, fails in general. Thus, we introduce the first geometric framework capable of modeling the reflections of arbitrary convex sub-THz curving beams from general reflectors with experimental verification. Rather than \"mirroring\" the trajectory, we decompose the beam into a family of tangents and demonstrate that this process is equivalent to the Legendre transform. This approach allows us to accurately account for reflectors of any shape, size, and position while preserving the underlying physics of wave propagation. Our model is validated through finite element method simulations and over-the-air experiments, demonstrating millimeter-scale accuracy in predicting reflections. Our model provides a foundation for future curving beam communication and sensing systems, enabling the design of reflected curved links and curving radar paths.", "AI": {"tldr": "First geometric framework for modeling reflections of arbitrary convex sub-THz curving beams from general reflectors, using Legendre transform instead of ray optics mirroring, validated with millimeter-scale accuracy.", "motivation": "Curving beams are promising for bypassing obstacles in millimeter-wave to sub-THz networks, but lack a general predictive model for their reflections from arbitrary surfaces. Traditional ray optics \"mirroring\" approach fails for these beams.", "method": "Introduce geometric framework that decomposes curving beams into a family of tangents, showing this process is equivalent to the Legendre transform. This approach accounts for reflectors of any shape, size, and position while preserving wave propagation physics.", "result": "Model validated through finite element method simulations and over-the-air experiments, demonstrating millimeter-scale accuracy in predicting reflections of curving beams from arbitrary surfaces.", "conclusion": "Provides foundation for future curving beam communication and sensing systems, enabling design of reflected curved links and curving radar paths with accurate reflection modeling."}}
{"id": "2601.05653", "categories": ["cs.RO", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05653", "abs": "https://arxiv.org/abs/2601.05653", "authors": ["Phu-Hoa Pham", "Chi-Nguyen Tran", "Duy-Minh Dao-Sy", "Phu-Quy Nguyen-Lam", "Trung-Kiet Huynh"], "title": "EvoQRE: Modeling Bounded Rationality in Safety-Critical Traffic Simulation via Evolutionary Quantal Response Equilibrium", "comment": "11 pages, 5 figures", "summary": "Existing traffic simulation frameworks for autonomous vehicles typically rely on imitation learning or game-theoretic approaches that solve for Nash or coarse correlated equilibria, implicitly assuming perfectly rational agents. However, human drivers exhibit bounded rationality, making approximately optimal decisions under cognitive and perceptual constraints. We propose EvoQRE, a principled framework for modeling safety-critical traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. EvoQRE integrates a pre-trained generative world model with entropy-regularized replicator dynamics, capturing stochastic human behavior while maintaining equilibrium structure. We provide rigorous theoretical results, proving that the proposed dynamics converge to Logit-QRE under a two-timescale stochastic approximation with an explicit convergence rate of O(log k / k^{1/3}) under weak monotonicity assumptions. We further extend QRE to continuous action spaces using mixture-based and energy-based policy representations. Experiments on the Waymo Open Motion Dataset and nuPlan benchmark demonstrate that EvoQRE achieves state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.", "AI": {"tldr": "EvoQRE: A framework for traffic simulation using Quantal Response Equilibrium and evolutionary game dynamics to model bounded rationality in human drivers, achieving state-of-the-art realism and safety.", "motivation": "Existing traffic simulation frameworks assume perfectly rational agents, but human drivers exhibit bounded rationality with cognitive and perceptual constraints. There's a need for more realistic modeling of safety-critical traffic interactions that captures stochastic human behavior.", "method": "Proposes EvoQRE framework that models traffic interactions as general-sum Markov games solved via Quantal Response Equilibrium (QRE) and evolutionary game dynamics. Integrates pre-trained generative world model with entropy-regularized replicator dynamics. Extends QRE to continuous action spaces using mixture-based and energy-based policy representations.", "result": "Theoretical results prove convergence to Logit-QRE with rate O(log k / k^{1/3}) under weak monotonicity. Experiments on Waymo Open Motion Dataset and nuPlan benchmark show state-of-the-art realism, improved safety metrics, and controllable generation of diverse safety-critical scenarios through interpretable rationality parameters.", "conclusion": "EvoQRE provides a principled framework for realistic traffic simulation that captures bounded rationality in human drivers, offering theoretical guarantees and practical benefits for safety-critical scenario generation and autonomous vehicle testing."}}
{"id": "2601.05636", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05636", "abs": "https://arxiv.org/abs/2601.05636", "authors": ["Avraham Kreindel", "Isaac Barouch Essayag", "Aryeh Lev Zabokritskiy"], "title": "Multiset Deletion-Correcting Codes: Bounds and Constructions", "comment": "24 pages", "summary": "We study error-correcting codes in the space $\\mathcal{S}_{n,q}$ of length-$n$ multisets over a $q$-ary alphabet, motivated by permutation channels in which ordering is completely lost and errors act solely by deletions of symbols, i.e., by reducing symbol multiplicities.\n  Our focus is on the \\emph{extremal deletion regime}, where the channel output contains $k=n-t$ symbols. In this regime, we establish tight or near-tight bounds on the maximum code size. In particular, we determine the exact optimal code sizes for $t=n-1$ and for $t=n-2$, develop a refined analysis for $t=n-3$, and derive a general recursive puncturing upper bound for $t=n-k$ via a reduction from parameters $(n,k)$ to $(n-1,k-1)$.\n  On the constructive side, we completely resolve the binary multiset model: for all $t\\ge1$ we determine $S_2(n,t)$ exactly and give an explicit optimal congruence-based construction. We then study single-deletion codes beyond the binary case, presenting general $q$-ary constructions and showing, via explicit small-parameter examples, that the natural modular construction need not be optimal for $q\\ge3$. Finally, we present an explicit cyclic Sidon-type linear construction for general $(q,t)$ based on a single congruence constraint, with redundancy $\\log_q\\!\\bigl(t(t+1)^{q-2}+1\\bigr)$ and encoding and decoding complexity linear in the blocklength $n$.", "AI": {"tldr": "Study of error-correcting codes for multisets with deletion errors, focusing on extremal deletion regime where output has k=n-t symbols. Provides exact bounds for small t, optimal binary constructions, and efficient q-ary cyclic codes.", "motivation": "Motivated by permutation channels where ordering is completely lost and errors only occur through deletions of symbols (reducing symbol multiplicities). Need to design codes that can correct deletions in multiset channels.", "method": "1) Establish tight bounds for extremal deletion regime (k=n-t symbols output). 2) Determine exact optimal code sizes for t=n-1 and t=n-2. 3) Develop refined analysis for t=n-3. 4) Derive general recursive puncturing upper bound via reduction from (n,k) to (n-1,k-1). 5) Provide explicit optimal binary constructions using congruence-based approach. 6) Study q-ary constructions with explicit examples showing modular construction not always optimal. 7) Present explicit cyclic Sidon-type linear construction based on single congruence constraint.", "result": "1) Exact optimal code sizes determined for t=n-1 and t=n-2. 2) Complete resolution of binary multiset model: S\u2082(n,t) determined exactly for all t\u22651 with explicit optimal construction. 3) General q-ary constructions developed. 4) Cyclic Sidon-type linear construction with redundancy log\u209a(t(t+1)^{q-2}+1) and linear encoding/decoding complexity.", "conclusion": "The paper provides comprehensive theoretical and constructive results for error-correcting codes in multiset channels with deletion errors. Key contributions include exact bounds for extremal deletion regime, complete solution for binary case, and efficient cyclic constructions for general q-ary alphabets with practical linear-time encoding/decoding."}}
{"id": "2601.05379", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05379", "abs": "https://arxiv.org/abs/2601.05379", "authors": ["Vladimir Frants", "Sos Agaian", "Karen Panetta"], "title": "EdgeLDR: Quaternion Low-Displacement Rank Neural Networks for Edge-Efficient Deep Learning", "comment": null, "summary": "Deploying deep neural networks on edge devices is often limited by the memory traffic and compute cost of dense linear operators. While quaternion neural networks improve parameter efficiency by coupling multiple channels through Hamilton products, they typically retain unstructured dense weights; conversely, structured matrices enable fast computation but are usually applied in the real domain. This paper introduces EdgeLDR, a practical framework for quaternion block-circulant linear and convolutional layers that combines quaternion channel mixing with block-circulant parameter structure and enables FFT-based evaluation through the complex adjoint representation. We present reference implementations of EdgeLDR layers and compare FFT-based computation against a naive spatial-domain realization of quaternion circulant products. FFT evaluation yields large empirical speedups over the naive implementation and keeps latency stable as block size increases, making larger compression factors computationally viable. We further integrate EdgeLDR layers into compact CNN and Transformer backbones and evaluate accuracy-compression trade-offs on 32x32 RGB classification (CIFAR-10/100, SVHN) and hyperspectral image classification (Houston 2013, Pavia University), reporting parameter counts and CPU/GPU latency. The results show that EdgeLDR layers provide significant compression with competitive accuracy.", "AI": {"tldr": "EdgeLDR combines quaternion neural networks with block-circulant structure for efficient edge deployment, using FFT-based computation to achieve significant compression with competitive accuracy.", "motivation": "Deploying deep neural networks on edge devices is limited by memory traffic and compute costs of dense linear operators. Quaternion networks improve parameter efficiency but retain unstructured weights, while structured matrices enable fast computation but are usually applied in real domain only.", "method": "Introduces EdgeLDR framework for quaternion block-circulant linear and convolutional layers that combines quaternion channel mixing with block-circulant parameter structure. Uses FFT-based evaluation through complex adjoint representation, with reference implementations comparing FFT-based vs naive spatial-domain realization.", "result": "FFT evaluation yields large empirical speedups over naive implementation and keeps latency stable as block size increases, enabling larger compression factors. Integration into CNN and Transformer backbones shows significant compression with competitive accuracy on 32x32 RGB classification (CIFAR-10/100, SVHN) and hyperspectral image classification tasks.", "conclusion": "EdgeLDR layers provide a practical framework for efficient edge deployment by combining quaternion neural networks with structured matrices, achieving significant compression while maintaining competitive accuracy through FFT-based computation."}}
{"id": "2601.05384", "categories": ["cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05384", "abs": "https://arxiv.org/abs/2601.05384", "authors": ["Alessandro Bellina", "Giordano De Marzo", "David Garcia"], "title": "Conformity and Social Impact on AI Agents", "comment": null, "summary": "As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting the dynamics of artificial societies. This study examines conformity, the tendency to align with group opinions under social pressure, in large multimodal language models functioning as AI agents. By adapting classic visual experiments from social psychology, we investigate how AI agents respond to group influence as social actors. Our experiments reveal that AI agents exhibit a systematic conformity bias, aligned with Social Impact Theory, showing sensitivity to group size, unanimity, task difficulty, and source characteristics. Critically, AI agents achieving near-perfect performance in isolation become highly susceptible to manipulation through social influence. This vulnerability persists across model scales: while larger models show reduced conformity on simple tasks due to improved capabilities, they remain vulnerable when operating at their competence boundary. These findings reveal fundamental security vulnerabilities in AI agent decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation in multi-agent systems, highlighting the urgent need for safeguards in collective AI deployments.", "AI": {"tldr": "AI agents exhibit systematic conformity bias in multi-agent environments, making them vulnerable to social manipulation despite strong individual performance.", "motivation": "As AI agents increasingly operate in multi-agent environments, understanding their collective behavior becomes critical for predicting artificial society dynamics and identifying security vulnerabilities.", "method": "Adapted classic visual experiments from social psychology to study AI agents' responses to group influence, examining factors like group size, unanimity, task difficulty, and source characteristics.", "result": "AI agents show systematic conformity bias aligned with Social Impact Theory, with near-perfect individual performers becoming highly susceptible to social manipulation. Larger models show reduced conformity on simple tasks but remain vulnerable at their competence boundaries.", "conclusion": "AI agents have fundamental security vulnerabilities in decision-making that could enable malicious manipulation, misinformation campaigns, and bias propagation, highlighting urgent need for safeguards in collective AI deployments."}}
{"id": "2601.05407", "categories": ["cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05407", "abs": "https://arxiv.org/abs/2601.05407", "authors": ["Minwoo Cho", "Batuhan Altundas", "Matthew Gombolay"], "title": "Interactive Distillation for Cooperative Multi-Agent Reinforcement Learning", "comment": null, "summary": "Knowledge distillation (KD) has the potential to accelerate MARL by employing a centralized teacher for decentralized students but faces key bottlenecks. Specifically, there are (1) challenges in synthesizing high-performing teaching policies in complex domains, (2) difficulties when teachers must reason in out-of-distribution (OOD) states, and (3) mismatches between the decentralized students' and the centralized teacher's observation spaces. To address these limitations, we propose HINT (Hierarchical INteractive Teacher-based transfer), a novel KD framework for MARL in a centralized training, decentralized execution setup. By leveraging hierarchical RL, HINT provides a scalable, high-performing teacher. Our key innovation, pseudo off-policy RL, enables the teacher policy to be updated using both teacher and student experience, thereby improving OOD adaptation. HINT also applies performance-based filtering to retain only outcome-relevant guidance, reducing observation mismatches. We evaluate HINT on challenging cooperative domains (e.g., FireCommander for resource allocation, MARINE for tactical combat). Across these benchmarks, HINT outperforms baselines, achieving improvements of 60% to 165% in success rate.", "AI": {"tldr": "HINT is a hierarchical interactive teacher-based knowledge distillation framework for multi-agent reinforcement learning that addresses key bottlenecks in teacher policy synthesis, OOD reasoning, and observation space mismatches.", "motivation": "Knowledge distillation for MARL faces three key bottlenecks: (1) difficulty synthesizing high-performing teaching policies in complex domains, (2) challenges when teachers must reason in out-of-distribution states, and (3) mismatches between decentralized students' and centralized teacher's observation spaces.", "method": "HINT uses hierarchical RL to create a scalable, high-performing teacher. It introduces pseudo off-policy RL to update teacher policy using both teacher and student experience for better OOD adaptation. Performance-based filtering retains only outcome-relevant guidance to reduce observation mismatches.", "result": "HINT outperforms baselines on challenging cooperative domains (FireCommander for resource allocation, MARINE for tactical combat), achieving improvements of 60% to 165% in success rate.", "conclusion": "HINT effectively addresses key bottlenecks in knowledge distillation for MARL through hierarchical teacher design, pseudo off-policy RL for OOD adaptation, and performance-based filtering, demonstrating significant performance gains in complex cooperative domains."}}
{"id": "2601.06012", "categories": ["eess.SP", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.06012", "abs": "https://arxiv.org/abs/2601.06012", "authors": ["Helena Calatrava", "Daniel Medina", "Pau Closas"], "title": "Cooperative Differential GNSS Positioning: Estimators and Bounds", "comment": "The manuscript comprises a 13-page main paper and a 6-page supplementary appendix providing extended derivations and matrix expansions. The main body includes 5 figures and 5 tables", "summary": "In Differential GNSS (DGNSS) positioning, differencing measurements between a user and a reference station suppresses common-mode errors but also introduces reference-station noise, which fundamentally limits accuracy. This limitation is minor for high-grade stations but becomes significant when using reference infrastructure of mixed quality. This paper investigates how large-scale user cooperation can mitigate the impact of reference-station noise in conventional (non-cooperative) DGNSS systems. We develop a unified estimation framework for cooperative DGNSS (C-DGNSS) and cooperative real-time kinematic (C-RTK) positioning, and derive parameterized expressions for their Fisher information matrices as functions of network size, satellite geometry, and reference-station noise. This formulation enables theoretical analysis of estimation performance, identifying regimes where cooperation asymptotically restores the accuracy of DGNSS with an ideal (noise-free) reference. Simulations validate these theoretical findings.", "AI": {"tldr": "Cooperative DGNSS positioning uses user cooperation to mitigate reference-station noise limitations in conventional DGNSS systems.", "motivation": "DGNSS positioning suppresses common-mode errors but introduces reference-station noise, which limits accuracy, especially with mixed-quality reference infrastructure. This becomes significant when using lower-quality reference stations.", "method": "Developed a unified estimation framework for cooperative DGNSS (C-DGNSS) and cooperative real-time kinematic (C-RTK) positioning. Derived parameterized expressions for Fisher information matrices as functions of network size, satellite geometry, and reference-station noise.", "result": "Theoretical analysis identifies regimes where cooperation asymptotically restores the accuracy of DGNSS with an ideal (noise-free) reference. Simulations validate these theoretical findings.", "conclusion": "Large-scale user cooperation can effectively mitigate reference-station noise limitations in DGNSS systems, potentially restoring accuracy to levels achievable with ideal noise-free reference stations."}}
{"id": "2601.05661", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05661", "abs": "https://arxiv.org/abs/2601.05661", "authors": ["Matija Markulin", "Luka Matijevi\u0107", "Luka Siktar", "Janko Jurdana", "Branimir Caran", "Marko \u0160vaco", "Filip \u0160uligoj", "Bojan \u0160ekoranja"], "title": "Motion Compensation for Real Time Ultrasound Scanning in Robotically Assisted Prostate Biopsy Procedures", "comment": "Submitted for ICRA 2026", "summary": "Prostate cancer is one of the most common types of cancer in men. Its diagnosis by biopsy requires a high level of expertise and precision from the surgeon, so the results are highly operator-dependent. The aim of this work is to develop a robotic system for assisted ultrasound (US) examination of the prostate, a prebiopsy step that could reduce the dexterity requirements and enable faster, more accurate and more available prostate biopsy. We developed and validated a laboratory setup with a collaborative robotic arm that can autonomously scan a prostate phantom and attached the phantom to a medical robotic arm that mimics the patient's movements. The scanning robot keeps the relative position of the US probe and the prostate constant, ensuring a consistent and robust approach to reconstructing the prostate. To reconstruct the prostate, each slice is segmented to generate a series of prostate contours converted into a 3D point cloud used for biopsy planning. The average scan time of the prostate was 30 s, and the average 3D reconstruction of the prostate took 3 s. We performed four motion scenarios: the phantom was scanned in a stationary state (S), with horizontal motion (H), with vertical motion (V), and with a combination of the two (C). System validation is performed by registering the prostate point cloud reconstructions acquired during different motions (H, V, C) with those obtained in the stationary state. ICP registration with a threshold of 0.8 mm yields mean 83.2\\% fitness and 0.35 mm RMSE for S-H registration, 84.1\\% fitness and 0.37 mm RMSE for S-V registration and 79.4\\% fitness and 0.37 mm RMSE for S-C registration. Due to the elastic and soft material properties of the prostate phantom, the maximum robot tracking error was 3 mm, which can be sufficient for prostate biopsy according to medical literature. The maximum delay in motion compensation was 0.5 s.", "AI": {"tldr": "Robotic system for autonomous ultrasound scanning of prostate phantoms with motion compensation, enabling consistent 3D reconstruction for biopsy planning.", "motivation": "Prostate cancer diagnosis via biopsy is operator-dependent and requires high expertise. The goal is to develop an assisted robotic system for ultrasound examination to reduce dexterity requirements and enable faster, more accurate, and more available prostate biopsy.", "method": "Developed a laboratory setup with a collaborative robotic arm that autonomously scans a prostate phantom attached to a medical robotic arm mimicking patient movements. The scanning robot maintains constant relative position between US probe and prostate. Each ultrasound slice is segmented to generate prostate contours converted into a 3D point cloud for biopsy planning.", "result": "Average scan time: 30s, average 3D reconstruction: 3s. System validated with four motion scenarios (stationary, horizontal, vertical, combined). ICP registration showed mean fitness of 83.2% (S-H), 84.1% (S-V), 79.4% (S-C) with RMSE of 0.35-0.37mm. Maximum tracking error: 3mm, maximum motion compensation delay: 0.5s.", "conclusion": "The robotic system successfully maintains consistent prostate reconstruction during patient motion with acceptable tracking errors for biopsy planning. The approach shows promise for reducing operator dependency and improving prostate biopsy procedures."}}
{"id": "2601.05652", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05652", "abs": "https://arxiv.org/abs/2601.05652", "authors": ["Irina Bocharova", "Maiara F. Bollauf", "Boris Kudryashov"], "title": "Coset Shaping for Coded Modulation", "comment": "Paper accepted for presentation at the 2026 International Zurich Seminar on Information and Communication (IZS 2026)", "summary": "A new shaping technique called coset shaping for coded QAM and PAM signaling is introduced and analyzed. This technique can be applied not only to information bits but also to parity bits without incurring additional complexity costs. It is proven that as the length of the error-correcting code and the modulation order tend to infinity, the gap to capacity for the proposed shaping scheme can be made arbitrarily small. Numerical results and comparisons for the shaping scheme, along with nonbinary LDPC-coded QAM signaling, are presented.", "AI": {"tldr": "Coset shaping technique for coded QAM/PAM that works on both information and parity bits without extra complexity, achieving arbitrarily small capacity gap as code length and modulation order increase.", "motivation": "To develop an efficient shaping technique for coded modulation systems that can be applied to both information and parity bits without increasing complexity, aiming to close the gap to channel capacity.", "method": "Introduces coset shaping technique for coded QAM and PAM signaling that can shape both information and parity bits. The approach is analyzed theoretically and validated with numerical results using nonbinary LDPC-coded QAM signaling.", "result": "Proves that as code length and modulation order approach infinity, the gap to capacity can be made arbitrarily small. Provides numerical results and comparisons showing the effectiveness of the shaping scheme.", "conclusion": "Coset shaping is an effective technique for coded modulation that can achieve near-capacity performance without additional complexity, applicable to both information and parity bits in QAM/PAM systems."}}
{"id": "2601.05386", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05386", "abs": "https://arxiv.org/abs/2601.05386", "authors": ["Daniel Keren"], "title": "On the Effect of Cheating in Chess", "comment": null, "summary": "Cheating in chess, by using advice from powerful software, has become a major problem, reaching the highest levels. As opposed to the large majority of previous work, which concerned {\\em detection} of cheating, here we try to evaluate the possible gain in performance, obtained by cheating a limited number of times during a game. Algorithms are developed and tested on a commonly used chess engine (i.e software).\\footnote{Needless to say, the goal of this work is not to assist cheaters, but to measure the effectiveness of cheating -- which is crucial as part of the effort to contain and detect it.}", "AI": {"tldr": "This paper analyzes the performance gain from cheating in chess by using chess engine advice a limited number of times during games, developing algorithms to measure cheating effectiveness rather than focusing on detection.", "motivation": "Cheating in chess using powerful software has become a serious problem at all levels. While most previous work focused on detecting cheating, this paper aims to quantify the actual performance improvement that can be gained from cheating a limited number of times during a game.", "method": "The researchers developed algorithms to simulate cheating scenarios where players consult a chess engine (software) for advice a limited number of times during games. These algorithms were tested using a commonly used chess engine to measure the effectiveness of different cheating strategies.", "result": "The paper presents algorithms and test results showing how much performance improvement can be achieved through limited cheating. The findings provide quantitative data on cheating effectiveness, which is crucial for understanding the problem's scope.", "conclusion": "Measuring cheating effectiveness is essential for containing and detecting it. The developed algorithms provide tools to evaluate performance gains from cheating, offering valuable insights beyond traditional detection methods to better address the cheating problem in chess."}}
{"id": "2601.05420", "categories": ["cs.LG", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05420", "abs": "https://arxiv.org/abs/2601.05420", "authors": ["Yiqun T Chen", "Sizhu Lu", "Sijia Li", "Moran Guo", "Shengyi Li"], "title": "Efficient Inference for Noisy LLM-as-a-Judge Evaluation", "comment": null, "summary": "Large language models (LLMs) are increasingly used as automatic evaluators of generative AI outputs, a paradigm often referred to as \"LLM-as-a-judge.\" In practice, LLM judges are imperfect predictions for the underlying truth and can exhibit systematic, non-random errors. Two main approaches have recently been proposed to address this issue: (i) direct measurementerror correction based on misclassification models such as Rogan-Gladen-style estimators, and (ii) surrogate-outcome approaches such as prediction-powered inference (PPI), which correct bias by calibrating prediction residuals on a small set of gold-standard human labels. In this paper, we systematically study the performance of these two approaches for estimating mean parameters (e.g., average benchmark scores or pairwise win rates). Leveraging tools from semiparametric efficiency theory, we unify the two classes of estimators by deriving explicit forms of efficient influence function (EIF)-based efficient estimators and characterize conditions under which PPI-style estimators attain strictly smaller asymptotic variance than measurement-error corrections. We verify our theoretical results in simulations and demonstrate the methods on real-data examples. We provide an implementation of the benchmarked methods and comparison utilities at https://github.com/yiqunchen/debias-llm-as-a-judge.", "AI": {"tldr": "This paper analyzes methods to correct systematic errors in LLM-as-a-judge evaluations, comparing measurement-error correction and prediction-powered inference approaches for estimating mean parameters like benchmark scores.", "motivation": "LLM judges are increasingly used to evaluate AI outputs but exhibit systematic, non-random errors, creating a need for reliable correction methods to obtain accurate estimates of true performance metrics.", "method": "The paper systematically studies two approaches: (1) measurement-error correction using Rogan-Gladen-style estimators, and (2) surrogate-outcome approaches like prediction-powered inference (PPI) that calibrate prediction residuals on small gold-standard human labels. The authors unify these using semiparametric efficiency theory, deriving efficient influence function-based estimators and comparing their asymptotic properties.", "result": "Theoretical analysis characterizes conditions under which PPI-style estimators achieve strictly smaller asymptotic variance than measurement-error corrections. Simulations verify these theoretical results, and real-data examples demonstrate the methods' practical application.", "conclusion": "The paper provides a unified theoretical framework for debiasing LLM-as-a-judge evaluations, showing when PPI approaches outperform measurement-error correction, and offers practical implementation tools for researchers."}}
{"id": "2601.05674", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05674", "abs": "https://arxiv.org/abs/2601.05674", "authors": ["Torben K\u00f6lle", "Alexander Stutz-Tirri", "Christoph Studer"], "title": "On the Complexity of Electromagnetic Far-Field Modeling", "comment": "Accepted for presentation at the 2026 International Zurich Seminar on Information and Communication", "summary": "Modern wireless systems are envisioned to employ antenna architectures that not only transmit and receive electromagnetic (EM) waves, but also intentionally reflect and possibly transform incident EM waves. In this paper, we propose a mathematically rigorous framework grounded in Maxwell's equations for analyzing the complexity of EM far-field modeling of general antenna architectures. We show that-under physically meaningful assumptions-such antenna architectures exhibit limited complexity, i.e., can be modeled by finite-rank operators using finitely many parameters. Furthermore, we construct a sequence of finite-rank operators whose approximation error decays super-exponentially once the operator rank exceeds an effective bandwidth associated with the antenna architecture and the analysis frequency. These results constitute a fundamental prerequisite for the efficient and accurate modeling of general antenna architectures on digital computing platforms.", "AI": {"tldr": "The paper develops a rigorous mathematical framework based on Maxwell's equations to analyze EM far-field modeling complexity of general antenna architectures, showing they can be modeled by finite-rank operators with super-exponential approximation convergence.", "motivation": "Modern wireless systems use complex antenna architectures that not only transmit/receive but also intentionally reflect and transform EM waves. There's a need for mathematically rigorous analysis of EM far-field modeling complexity for such general antenna architectures to enable efficient digital modeling.", "method": "Proposes a framework grounded in Maxwell's equations for analyzing EM far-field modeling complexity. Shows that under physically meaningful assumptions, antenna architectures exhibit limited complexity and can be modeled by finite-rank operators using finitely many parameters. Constructs a sequence of finite-rank operators with super-exponentially decaying approximation error.", "result": "Demonstrates that general antenna architectures can be modeled by finite-rank operators with finitely many parameters. Shows approximation error decays super-exponentially once operator rank exceeds an effective bandwidth associated with the antenna architecture and analysis frequency.", "conclusion": "Provides fundamental prerequisites for efficient and accurate modeling of general antenna architectures on digital computing platforms, establishing mathematical foundations for analyzing EM far-field complexity of modern wireless antenna systems."}}
{"id": "2601.05805", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05805", "abs": "https://arxiv.org/abs/2601.05805", "authors": ["Simon Archieri", "Ahmet Cinar", "Shu Pan", "Jonatan Scharff Willners", "Michele Grimald", "Ignacio Carlucho", "Yvan Petillot"], "title": "InsSo3D: Inertial Navigation System and 3D Sonar SLAM for turbid environment inspection", "comment": null, "summary": "This paper presents InsSo3D, an accurate and efficient method for large-scale 3D Simultaneous Localisation and Mapping (SLAM) using a 3D Sonar and an Inertial Navigation System (INS). Unlike traditional sonar, which produces 2D images containing range and azimuth information but lacks elevation information, 3D Sonar produces a 3D point cloud, which therefore does not suffer from elevation ambiguity. We introduce a robust and modern SLAM framework adapted to the 3D Sonar data using INS as prior, detecting loop closure and performing pose graph optimisation. We evaluated InsSo3D performance inside a test tank with access to ground truth data and in an outdoor flooded quarry. Comparisons to reference trajectories and maps obtained from an underwater motion tracking system and visual Structure From Motion (SFM) demonstrate that InsSo3D efficiently corrects odometry drift. The average trajectory error is below 21cm during a 50-minute-long mission, producing a map of 10m by 20m with a 9cm average reconstruction error, enabling safe inspection of natural or artificial underwater structures even in murky water conditions.", "AI": {"tldr": "InsSo3D is a 3D SLAM method using 3D sonar and INS for accurate underwater mapping in murky water, achieving sub-21cm trajectory error over 50-minute missions.", "motivation": "Traditional sonar SLAM suffers from elevation ambiguity in 2D sonar images, limiting accurate 3D mapping. 3D sonar provides full 3D point clouds but requires specialized SLAM frameworks to handle underwater environments with poor visibility.", "method": "A robust SLAM framework adapted for 3D sonar data using INS as prior, featuring loop closure detection and pose graph optimization to correct odometry drift in underwater environments.", "result": "Average trajectory error below 21cm during 50-minute missions, producing 10m\u00d720m maps with 9cm average reconstruction error. Outperforms reference trajectories from underwater motion tracking and visual SFM in murky water conditions.", "conclusion": "InsSo3D enables safe inspection of underwater structures in murky water by efficiently correcting odometry drift and producing accurate 3D maps using 3D sonar and INS integration."}}
{"id": "2601.05655", "categories": ["cs.IT", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.05655", "abs": "https://arxiv.org/abs/2601.05655", "authors": ["Stella Civelli", "Marco Secondini", "Luca Pot\u00ec"], "title": "Nonlinearity Mitigation for Coherent Ground-to-Satellite Optical Links", "comment": "The paper has been accepted for poster presentation at the optical fiber communication (OFC) conference 2026", "summary": "We propose digital signal processing techniques for nonlinearity mitigation in high power optical amplifiers used in satellite communications. The acceptable link loss increases by 6dB with negligible complexity.", "AI": {"tldr": "Digital signal processing techniques for nonlinearity mitigation in high-power optical amplifiers for satellite communications, achieving 6dB link loss improvement with minimal complexity.", "motivation": "High-power optical amplifiers in satellite communications suffer from nonlinear distortions that degrade signal quality and limit link performance. There's a need for effective mitigation techniques that don't add significant system complexity.", "method": "Proposes digital signal processing (DSP) techniques specifically designed to mitigate nonlinear distortions in high-power optical amplifiers used in satellite communication systems.", "result": "Achieves 6dB increase in acceptable link loss with negligible additional complexity, significantly improving the performance margin for satellite communication links.", "conclusion": "The proposed DSP techniques provide an effective solution for nonlinearity mitigation in satellite optical amplifiers, offering substantial performance gains without significantly increasing system complexity."}}
{"id": "2601.05399", "categories": ["cs.CV", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.05399", "abs": "https://arxiv.org/abs/2601.05399", "authors": ["Zhaohui Liang", "Sivaramakrishnan Rajaraman", "Niccolo Marini", "Zhiyun Xue", "Sameer Antani"], "title": "Multi-task Cross-modal Learning for Chest X-ray Image Retrieval", "comment": null, "summary": "CLIP and BiomedCLIP are examples of vision-language foundation models and offer strong cross-modal embeddings; however, they are not optimized for fine-grained medical retrieval tasks, such as retrieving clinically relevant radiology reports using chest X-ray (CXR) image queries. To address this shortcoming, we propose a multi-task learning framework to fine-tune BiomedCLIP and evaluate improvements to CXR image-text retrieval. Using BiomedCLIP as the backbone, we incorporate a lightweight MLP projector head trained with a multi-task composite loss function that includes: (1) a binary cross-entropy loss to distinguish normal from abnormal CXR studies, (2) a supervised contrastive loss to reinforce intra-class consistency, and (3) a CLIP loss to maintain cross-modal alignment. Experimental results demonstrate that the fine-tuned model achieves more balanced and clinically meaningful performance across both image-to-text and text-to-image retrieval tasks compared to the pretrained BiomedCLIP and general-purpose CLIP models. Furthermore, t-SNE visualizations reveal clearer semantic clustering of normal and abnormal cases, demonstrating the model's enhanced diagnostic sensitivity. These findings highlight the value of domain-adaptive, multi-task learning for advancing cross-modal retrieval in biomedical applications.", "AI": {"tldr": "Fine-tuning BiomedCLIP with multi-task learning improves chest X-ray image-text retrieval performance for clinically relevant medical applications.", "motivation": "CLIP and BiomedCLIP provide strong cross-modal embeddings but aren't optimized for fine-grained medical retrieval tasks like retrieving clinically relevant radiology reports using chest X-ray image queries.", "method": "Multi-task learning framework fine-tuning BiomedCLIP with lightweight MLP projector head trained with composite loss: binary cross-entropy for normal/abnormal classification, supervised contrastive loss for intra-class consistency, and CLIP loss for cross-modal alignment.", "result": "Fine-tuned model achieves more balanced and clinically meaningful performance across both image-to-text and text-to-image retrieval tasks compared to pretrained BiomedCLIP and general-purpose CLIP. t-SNE visualizations show clearer semantic clustering of normal/abnormal cases.", "conclusion": "Domain-adaptive, multi-task learning is valuable for advancing cross-modal retrieval in biomedical applications, enhancing diagnostic sensitivity for medical imaging tasks."}}
{"id": "2601.05455", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05455", "abs": "https://arxiv.org/abs/2601.05455", "authors": ["Sahil Wadhwa", "Himanshu Kumar", "Guanqun Yang", "Abbaas Alif Mohamed Nishar", "Pranab Mohanty", "Swapnil Shinde", "Yue Wu"], "title": "ART: Adaptive Reasoning Trees for Explainable Claim Verification", "comment": null, "summary": "Large Language Models (LLMs) are powerful candidates for complex decision-making, leveraging vast encoded knowledge and remarkable zero-shot abilities. However, their adoption in high-stakes environments is hindered by their opacity; their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness. In this paper, we propose ART (Adaptive Reasoning Trees), a hierarchical method for claim verification. The process begins with a root claim, which branches into supporting and attacking child arguments. An argument's strength is determined bottom-up via a pairwise tournament of its children, adjudicated by a judge LLM, allowing a final, transparent and contestable verdict to be systematically derived which is missing in methods like Chain-of-Thought (CoT). We empirically validate ART on multiple datasets, analyzing different argument generators and comparison strategies. Our findings show that ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification which is more reliable and ensures clarity in the overall decision making step.", "AI": {"tldr": "ART (Adaptive Reasoning Trees) is a hierarchical method for claim verification that uses LLMs to create branching arguments, adjudicate pairwise comparisons, and produce transparent, contestable verdicts, outperforming baselines like Chain-of-Thought.", "motivation": "LLMs have strong decision-making capabilities but lack transparency and contestability in high-stakes environments. Their outputs lack faithful explanations and cannot be effectively contested to correct errors, undermining trustworthiness.", "method": "ART uses hierarchical reasoning trees starting with a root claim that branches into supporting/attacking child arguments. Argument strength is determined bottom-up via pairwise tournaments adjudicated by a judge LLM, enabling systematic derivation of transparent, contestable verdicts.", "result": "Empirical validation on multiple datasets shows ART's structured reasoning outperforms strong baselines, establishing a new benchmark for explainable claim verification that is more reliable and ensures clarity in decision-making.", "conclusion": "ART provides a systematic approach to claim verification that addresses LLM opacity by enabling transparent, contestable reasoning, making LLMs more trustworthy for high-stakes decision-making applications."}}
{"id": "2601.05431", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05431", "abs": "https://arxiv.org/abs/2601.05431", "authors": ["Xiaowen He", "Su Jiang", "Louis J. Durlofsky"], "title": "Prediction of Fault Slip Tendency in CO${_2}$ Storage using Data-space Inversion", "comment": null, "summary": "Accurately assessing the potential for fault slip is essential in many subsurface operations. Conventional model-based history matching methods, which entail the generation of posterior geomodels calibrated to observed data, can be challenging to apply in coupled flow-geomechanics problems with faults. In this work, we implement a variational autoencoder (VAE)-based data-space inversion (DSI) framework to predict pressure, stress and strain fields, and fault slip tendency, in CO${_2}$ storage projects. The main computations required by the DSI workflow entail the simulation of O(1000) prior geomodels. The posterior distributions for quantities of interest are then inferred directly from prior simulation results and observed data, without the need to generate posterior geomodels. The model used here involves a synthetic 3D system with two faults. Realizations of heterogeneous permeability and porosity fields are generated using geostatistical software, and uncertain geomechanical and fault parameters are sampled for each realization from prior distributions. Coupled flow-geomechanics simulations for these geomodels are conducted using GEOS. A VAE with stacked convolutional long short-term memory layers is trained, using the prior simulation results, to represent pressure, strain, effective normal stress and shear stress fields in terms of latent variables. The VAE parameterization is used with DSI for posterior predictions, with monitoring wells providing observed pressure and strain data. Posterior results for synthetic true models demonstrate that the DSI-VAE framework gives accurate predictions for pressure, strain, and stress fields and for fault slip tendency. The framework is also shown to reduce uncertainty in key geomechanical and fault parameters.", "AI": {"tldr": "VAE-based data-space inversion framework for predicting pressure, stress, strain, and fault slip tendency in CO\u2082 storage without generating posterior geomodels.", "motivation": "Conventional model-based history matching methods are challenging for coupled flow-geomechanics problems with faults in subsurface operations like CO\u2082 storage. Need an efficient approach to assess fault slip potential.", "method": "VAE with stacked convolutional LSTM layers trained on prior simulation results (O(1000) geomodels) to represent pressure, strain, effective normal stress and shear stress fields in latent space. Data-space inversion (DSI) uses VAE parameterization with observed pressure and strain data from monitoring wells.", "result": "DSI-VAE framework gives accurate predictions for pressure, strain, stress fields and fault slip tendency. Reduces uncertainty in key geomechanical and fault parameters. Demonstrated on synthetic 3D system with two faults using GEOS simulations.", "conclusion": "VAE-based DSI framework enables efficient posterior predictions for coupled flow-geomechanics problems without generating posterior geomodels, providing accurate assessment of fault slip tendency in CO\u2082 storage projects."}}
{"id": "2601.05686", "categories": ["cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05686", "abs": "https://arxiv.org/abs/2601.05686", "authors": ["Zhenqiao Cheng", "Chongjun Ouyang", "Boqun Zhao", "Xingqi Zhang"], "title": "Secure Multiuser Beamforming With Movable Antenna Arrays", "comment": "6 pages; code available at https://github.com/DragonAim0597/Secure-Multiuser-Beamforming-With-Movable-Antenna-Arrays", "summary": "A movable antennas (MAs)-enabled secure multiuser transmission framework is developed to enhance physical-layer security. Novel expressions are derived to characterize the achievable sum secrecy rate based on the secure channel coding theorem. On this basis, a joint optimization algorithm for digital beamforming and MA placement is proposed to maximize the sum secrecy rate via fractional programming and block coordinate descent. In each iteration, every variable admits either a closed-form update or a low-complexity one-dimensional or bisection search, which yields an efficient implementation. Numerical results demonstrate the effectiveness of the proposed method and show that the MA-enabled design achieves higher secrecy rates than conventional fixed-position antenna arrays.", "AI": {"tldr": "MA-enabled secure multiuser transmission framework enhances physical-layer security with joint optimization of digital beamforming and MA placement.", "motivation": "To enhance physical-layer security in multiuser transmission systems by leveraging movable antennas (MAs) instead of conventional fixed-position antenna arrays.", "method": "Developed a joint optimization algorithm for digital beamforming and MA placement using fractional programming and block coordinate descent. Each iteration allows closed-form updates or low-complexity one-dimensional/bisection searches.", "result": "Numerical results show the proposed MA-enabled design achieves higher secrecy rates than conventional fixed-position antenna arrays.", "conclusion": "Movable antennas provide significant advantages for physical-layer security enhancement in multiuser transmission systems through flexible antenna positioning."}}
{"id": "2601.05806", "categories": ["cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05806", "abs": "https://arxiv.org/abs/2601.05806", "authors": ["Marvin Seegert", "Korbinian Moller", "Johannes Betz"], "title": "Modular Autonomy with Conversational Interaction: An LLM-driven Framework for Decision Making in Autonomous Driving", "comment": "Submitted to the IEEE Intelligent Vehicles Symposium (IV 2026), Detroit, MI, United States", "summary": "Recent advancements in Large Language Models (LLMs) offer new opportunities to create natural language interfaces for Autonomous Driving Systems (ADSs), moving beyond rigid inputs. This paper addresses the challenge of mapping the complexity of human language to the structured action space of modular ADS software. We propose a framework that integrates an LLM-based interaction layer with Autoware, a widely used open-source software. This system enables passengers to issue high-level commands, from querying status information to modifying driving behavior. Our methodology is grounded in three key components: a taxonomization of interaction categories, an application-centric Domain Specific Language (DSL) for command translation, and a safety-preserving validation layer. A two-stage LLM architecture ensures high transparency by providing feedback based on the definitive execution status. Evaluation confirms the system's timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories. This work provides a foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks.", "AI": {"tldr": "LLM-based natural language interface for autonomous driving systems that maps human commands to structured actions in modular ADS software like Autoware.", "motivation": "To move beyond rigid inputs in autonomous driving systems by leveraging LLMs to create natural language interfaces that can handle the complexity of human language and map it to structured action spaces.", "method": "Three-component framework: 1) taxonomization of interaction categories, 2) application-centric Domain Specific Language (DSL) for command translation, 3) safety-preserving validation layer. Uses two-stage LLM architecture for high transparency with execution status feedback.", "result": "System demonstrates timing efficiency and translation robustness. Simulation successfully validated command execution across all five interaction categories.", "conclusion": "Provides foundation for extensible, DSL-assisted interaction in modular and safety-conscious autonomy stacks, enabling passengers to issue high-level commands from queries to behavior modifications."}}
{"id": "2601.05432", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05432", "abs": "https://arxiv.org/abs/2601.05432", "authors": ["Yuxiang Ji", "Yong Wang", "Ziyu Ma", "Yiming Hu", "Hailang Huang", "Xuecai Hu", "Guanhua Chen", "Liaoni Wu", "Xiangxiang Chu"], "title": "Thinking with Map: Reinforced Parallel Map-Augmented Agent for Geolocalization", "comment": null, "summary": "The image geolocalization task aims to predict the location where an image was taken anywhere on Earth using visual clues. Existing large vision-language model (LVLM) approaches leverage world knowledge, chain-of-thought reasoning, and agentic capabilities, but overlook a common strategy used by humans -- using maps. In this work, we first equip the model \\textit{Thinking with Map} ability and formulate it as an agent-in-the-map loop. We develop a two-stage optimization scheme for it, including agentic reinforcement learning (RL) followed by parallel test-time scaling (TTS). The RL strengthens the agentic capability of model to improve sampling efficiency, and the parallel TTS enables the model to explore multiple candidate paths before making the final prediction, which is crucial for geolocalization. To evaluate our method on up-to-date and in-the-wild images, we further present MAPBench, a comprehensive geolocalization training and evaluation benchmark composed entirely of real-world images. Experimental results show that our method outperforms existing open- and closed-source models on most metrics, specifically improving Acc@500m from 8.0\\% to 22.1\\% compared to \\textit{Gemini-3-Pro} with Google Search/Map grounded mode.", "AI": {"tldr": "A new geolocalization method that equips vision-language models with \"Thinking with Map\" ability using agent-in-the-map loop, two-stage optimization (RL + parallel test-time scaling), and a new benchmark MAPBench with real-world images.", "motivation": "Existing LVLM approaches for image geolocalization overlook the common human strategy of using maps, relying instead on world knowledge and chain-of-thought reasoning without proper map integration.", "method": "1) Equip model with \"Thinking with Map\" ability formulated as agent-in-the-map loop; 2) Two-stage optimization: agentic reinforcement learning to improve sampling efficiency, followed by parallel test-time scaling for exploring multiple candidate paths; 3) MAPBench benchmark with real-world images for training/evaluation.", "result": "Outperforms existing open- and closed-source models on most metrics, improving Acc@500m from 8.0% to 22.1% compared to Gemini-3-Pro with Google Search/Map grounded mode.", "conclusion": "The \"Thinking with Map\" approach with agent-in-the-map loop and two-stage optimization significantly improves geolocalization accuracy by incorporating map-based reasoning similar to human strategies."}}
{"id": "2601.05465", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05465", "abs": "https://arxiv.org/abs/2601.05465", "authors": ["Yu Liu", "Wenxiao Zhang", "Cong Cao", "Wenxuan Lu", "Fangfang Yuan", "Diandian Guo", "Kun Peng", "Qiang Sun", "Kaiyan Zhang", "Yanbing Liu", "Jin B. Hong", "Bowen Zhou", "Zhiyuan Ma"], "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering", "comment": null, "summary": "Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.", "AI": {"tldr": "PRISMA is a decoupled RL framework with Plan-Retrieve-Inspect-Solve-Memoize architecture that addresses retrieval collapse and learning instability in multi-hop RAG systems through reasoning-guided collaboration and two-stage policy optimization.", "motivation": "Current RL-optimized RAG systems for open-domain multi-hop questions face two critical obstacles: 1) Retrieval Collapse - iterative retrieval fails without reasoning-guided planning, and 2) Learning Instability - end-to-end training suffers from weak credit assignment and poor error localization, limiting transferability and stability.", "method": "PRISMA uses a decoupled Plan-Retrieve-Inspect-Solve-Memoize architecture with reasoning-guided collaboration. The Inspector provides feedback to refine the Planner's decomposition and retrieval, while enforcing evidence-grounded reasoning in the Solver. Optimization uses Two-Stage Group Relative Policy Optimization (GRPO): Stage I calibrates Planner and Solver as specialized experts, Stage II uses Observation-Aware Residual Policy Optimization (OARPO) to enhance Inspector's verification and recovery capabilities.", "result": "PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.", "conclusion": "The proposed decoupled RL framework with reasoning-guided collaboration effectively addresses retrieval collapse and learning instability in multi-hop RAG systems, enabling reliable deployment with strong performance across diverse benchmarks."}}
{"id": "2601.05451", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05451", "abs": "https://arxiv.org/abs/2601.05451", "authors": ["Marko Sterbentz", "Kevin Cushing", "Cameron Barrie", "Kristian J. Hammond"], "title": "RingSQL: Generating Synthetic Data with Schema-Independent Templates for Text-to-SQL Reasoning Models", "comment": null, "summary": "Recent advances in text-to-SQL systems have been driven by larger models and improved datasets, yet progress is still limited by the scarcity of high-quality training data. Manual data creation is expensive, and existing synthetic methods trade off reliability and scalability. Template-based approaches ensure correct SQL but require schema-specific templates, while LLM-based generation scales easily but lacks quality and correctness guarantees. We introduce RingSQL, a hybrid data generation framework that combines schema-independent query templates with LLM-based paraphrasing of natural language questions. This approach preserves SQL correctness across diverse schemas while providing broad linguistic variety. In our experiments, we find that models trained using data produced by RingSQL achieve an average gain in accuracy of +2.3% across six text-to-SQL benchmarks when compared to models trained on other synthetic data. We make our code available at https://github.com/nu-c3lab/RingSQL.", "AI": {"tldr": "RingSQL is a hybrid text-to-SQL data generation framework combining schema-independent query templates with LLM-based paraphrasing to create high-quality training data that ensures SQL correctness while providing linguistic variety.", "motivation": "Progress in text-to-SQL systems is limited by scarcity of high-quality training data. Manual creation is expensive, and existing synthetic methods trade off reliability (template-based) vs scalability (LLM-based). There's a need for a method that ensures SQL correctness while providing broad linguistic coverage.", "method": "RingSQL uses a hybrid approach: 1) Schema-independent query templates to generate correct SQL queries, 2) LLM-based paraphrasing to create diverse natural language questions for those SQL queries. This preserves SQL correctness across diverse schemas while providing linguistic variety.", "result": "Models trained on RingSQL-generated data achieve an average accuracy gain of +2.3% across six text-to-SQL benchmarks compared to models trained on other synthetic data.", "conclusion": "RingSQL successfully addresses the trade-off between reliability and scalability in synthetic data generation for text-to-SQL, providing a practical solution for creating high-quality training data that improves model performance across multiple benchmarks."}}
{"id": "2601.05983", "categories": ["cs.IT", "cs.NI", "cs.SI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.05983", "abs": "https://arxiv.org/abs/2601.05983", "authors": ["Arunabh Srivastava", "Sennur Ulukus"], "title": "Age of Gossip With Cellular Drone Mobility", "comment": null, "summary": "We consider a cellular network containing $n$ nodes where nodes within a cell gossip with each other in a fully-connected fashion and a source shares updates with these nodes via a mobile drone. The mobile drone receives updates directly from the source and shares them with nodes in the cell where it currently resides. The drone moves between cells according to an underlying continuous-time Markov chain (CTMC). In this work, we evaluate the impact of the number of cells $f(n)$, drone speed $\u03bb_m(n)$ and drone dissemination rate $\u03bb_d(n)$ on the freshness of information of nodes in the network. We utilize the version age of information metric to quantify the freshness of information. We observe that the expected duration between two drone-to-cell service times depends on the stationary distribution of the underlying CTMC and $\u03bb_d(n)$, but not on $\u03bb_m(n)$. However, the version age instability in slow moving CTMCs makes high probability analysis for a general underlying CTMC difficult. Therefore, next we focus on the fully-connected drone mobility model. Under this model, we uncover a dual-bottleneck between drone mobility and drone dissemination speed: the version age is constrained by the slower of these two processes. If $\u03bb_d(n) \\gg \u03bb_m(n)$, then the version age scaling of nodes is dominated by the inverse of $\u03bb_m(n)$ and is independent of $\u03bb_d(n)$. If $\u03bb_m(n) \\gg \u03bb_d(n)$, then the version age scaling of nodes is dominated by the inverse of $\u03bb_d(n)$ and is independent of $\u03bb_m(n)$.", "AI": {"tldr": "The paper analyzes information freshness in a drone-assisted cellular network where nodes gossip within cells and a mobile drone disseminates updates from a source. It reveals a dual-bottleneck between drone mobility and dissemination speed that determines version age scaling.", "motivation": "To understand how drone mobility patterns, dissemination rates, and network cell structure impact the freshness of information in cellular networks where nodes rely on drone-assisted updates.", "method": "Model cellular network with n nodes where nodes gossip within cells. A mobile drone receives updates from a source and shares them with nodes in its current cell. Drone moves between cells according to continuous-time Markov chain (CTMC). Use version age of information metric to quantify freshness. Analyze impact of number of cells f(n), drone speed \u03bb\u2098(n), and dissemination rate \u03bb_d(n). Focus on fully-connected drone mobility model for tractable analysis.", "result": "Expected duration between drone-to-cell service depends on CTMC stationary distribution and \u03bb_d(n), not \u03bb\u2098(n). For fully-connected mobility model, discover dual-bottleneck: version age scaling is constrained by slower of mobility or dissemination processes. If \u03bb_d(n) \u226b \u03bb\u2098(n), version age scales with 1/\u03bb\u2098(n). If \u03bb\u2098(n) \u226b \u03bb_d(n), version age scales with 1/\u03bb_d(n).", "conclusion": "Drone mobility and dissemination speed create a fundamental trade-off in information freshness. Network design must balance both parameters to optimize version age, as the slower process becomes the bottleneck regardless of how fast the other process operates."}}
{"id": "2601.05836", "categories": ["cs.RO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05836", "abs": "https://arxiv.org/abs/2601.05836", "authors": ["Sheng-Kai Chen", "Jyh-Horng Wu"], "title": "Intelligent Singularity Avoidance in UR10 Robotic Arm Path Planning Using Hybrid Fuzzy Logic and Reinforcement Learning", "comment": "Published in TANET 2025 (Paper No. T0404)", "summary": "This paper presents a comprehensive approach to singularity detection and avoidance in UR10 robotic arm path planning through the integration of fuzzy logic safety systems and reinforcement learning algorithms. The proposed system addresses critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage. Our hybrid approach combines real-time singularity detection using manipulability measures, condition number analysis, and fuzzy logic decision-making with a stable reinforcement learning framework for adaptive path planning. Experimental results demonstrate a 90% success rate in reaching target positions while maintaining safe distances from singular configurations. The system integrates PyBullet simulation for training data collection and URSim connectivity for real-world deployment.", "AI": {"tldr": "Hybrid fuzzy logic + reinforcement learning system for singularity detection and avoidance in UR10 robotic arm path planning, achieving 90% success rate in reaching targets while maintaining safe distances from singular configurations.", "motivation": "Address critical challenges in robotic manipulation where singularities can cause loss of control and potential equipment damage in UR10 robotic arms.", "method": "Integration of fuzzy logic safety systems and reinforcement learning algorithms with real-time singularity detection using manipulability measures and condition number analysis, combined with fuzzy logic decision-making and stable reinforcement learning framework for adaptive path planning.", "result": "90% success rate in reaching target positions while maintaining safe distances from singular configurations, with system integration using PyBullet simulation for training data collection and URSim connectivity for real-world deployment.", "conclusion": "The hybrid approach combining fuzzy logic safety systems and reinforcement learning provides an effective solution for singularity detection and avoidance in robotic arm path planning, enabling safe and reliable robotic manipulation."}}
{"id": "2601.05446", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05446", "abs": "https://arxiv.org/abs/2601.05446", "authors": ["Hongyang Xie", "Hongyang He", "Victor Sanchez"], "title": "TAPM-Net: Trajectory-Aware Perturbation Modeling for Infrared Small Target Detection", "comment": "Published in BMVC 2025 see: https://bmva-archive.org.uk/bmvc/2025/assets/papers/Paper_709/paper.pdf. Conference version. 12 pages, 6 figures, 4 tables. Author-prepared version", "summary": "Infrared small target detection (ISTD) remains a long-standing challenge due to weak signal contrast, limited spatial extent, and cluttered backgrounds. Despite performance improvements from convolutional neural networks (CNNs) and Vision Transformers (ViTs), current models lack a mechanism to trace how small targets trigger directional, layer-wise perturbations in the feature space, which is an essential cue for distinguishing signal from structured noise in infrared scenes. To address this limitation, we propose the Trajectory-Aware Mamba Propagation Network (TAPM-Net), which explicitly models the spatial diffusion behavior of target-induced feature disturbances. TAPM-Net is built upon two novel components: a Perturbation-guided Path Module (PGM) and a Trajectory-Aware State Block (TASB). The PGM constructs perturbation energy fields from multi-level features and extracts gradient-following feature trajectories that reflect the directionality of local responses. The resulting feature trajectories are fed into the TASB, a Mamba-based state-space unit that models dynamic propagation along each trajectory while incorporating velocity-constrained diffusion and semantically aligned feature fusion from word-level and sentence-level embeddings. Unlike existing attention-based methods, TAPM-Net enables anisotropic, context-sensitive state transitions along spatial trajectories while maintaining global coherence at low computational cost. Experiments on NUAA-SIRST and IRSTD-1K demonstrate that TAPM-Net achieves state-of-the-art performance in ISTD.", "AI": {"tldr": "TAPM-Net: A trajectory-aware Mamba network for infrared small target detection that models spatial diffusion of target-induced feature disturbances, outperforming CNNs and ViTs.", "motivation": "Current infrared small target detection models lack mechanisms to trace how small targets trigger directional, layer-wise perturbations in feature space, which is essential for distinguishing signals from structured noise in cluttered infrared backgrounds.", "method": "Proposes TAPM-Net with two novel components: Perturbation-guided Path Module (PGM) that constructs perturbation energy fields and extracts gradient-following feature trajectories, and Trajectory-Aware State Block (TASB) - a Mamba-based state-space unit that models dynamic propagation along trajectories with velocity-constrained diffusion and semantically aligned feature fusion.", "result": "TAPM-Net achieves state-of-the-art performance on NUAA-SIRST and IRSTD-1K datasets for infrared small target detection.", "conclusion": "The trajectory-aware approach enables anisotropic, context-sensitive state transitions along spatial trajectories while maintaining global coherence at low computational cost, addressing limitations of existing attention-based methods for infrared small target detection."}}
{"id": "2601.05483", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05483", "abs": "https://arxiv.org/abs/2601.05483", "authors": ["Zixuan Xiao", "Jun Ma", "Siwei Zhang"], "title": "MMUEChange: A Generalized LLM Agent Framework for Intelligent Multi-Modal Urban Environment Change Analysis", "comment": null, "summary": "Understanding urban environment change is essential for sustainable development. However, current approaches, particularly remote sensing change detection, often rely on rigid, single-modal analysis. To overcome these limitations, we propose MMUEChange, a multi-modal agent framework that flexibly integrates heterogeneous urban data via a modular toolkit and a core module, Modality Controller for cross- and intra-modal alignment, enabling robust analysis of complex urban change scenarios. Case studies include: a shift toward small, community-focused parks in New York, reflecting local green space efforts; the spread of concentrated water pollution across districts in Hong Kong, pointing to coordinated water management; and a notable decline in open dumpsites in Shenzhen, with contrasting links between nighttime economic activity and waste types, indicating differing urban pressures behind domestic and construction waste. Compared to the best-performing baseline, the MMUEChange agent achieves a 46.7% improvement in task success rate and effectively mitigates hallucination, demonstrating its capacity to support complex urban change analysis tasks with real-world policy implications.", "AI": {"tldr": "MMUEChange is a multi-modal agent framework that integrates heterogeneous urban data for robust analysis of complex urban change scenarios, achieving 46.7% improvement in task success rate over baselines.", "motivation": "Current urban change detection approaches rely on rigid, single-modal analysis, limiting their ability to handle complex urban change scenarios that require integration of diverse data sources.", "method": "Proposes MMUEChange framework with modular toolkit and core Modality Controller for cross- and intra-modal alignment, enabling flexible integration of heterogeneous urban data.", "result": "Achieves 46.7% improvement in task success rate compared to best-performing baseline, effectively mitigates hallucination, and demonstrates real-world policy implications through case studies in New York, Hong Kong, and Shenzhen.", "conclusion": "MMUEChange demonstrates capacity to support complex urban change analysis with practical policy implications, offering a flexible multi-modal approach that overcomes limitations of traditional single-modal remote sensing methods."}}
{"id": "2601.05474", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05474", "abs": "https://arxiv.org/abs/2601.05474", "authors": ["Pingchuan Ma", "Qixin Zhang", "Shuai Wang", "Dacheng Tao"], "title": "Efficient Differentiable Causal Discovery via Reliable Super-Structure Learning", "comment": null, "summary": "Recently, differentiable causal discovery has emerged as a promising approach to improve the accuracy and efficiency of existing methods. However, when applied to high-dimensional data or data with latent confounders, these methods, often based on off-the-shelf continuous optimization algorithms, struggle with the vast search space, the complexity of the objective function, and the nontrivial nature of graph-theoretical constraints. As a result, there has been a surge of interest in leveraging super-structures to guide the optimization process. Nonetheless, learning an appropriate super-structure at the right level of granularity, and doing so efficiently across various settings, presents significant challenges.\n  In this paper, we propose ALVGL, a novel and general enhancement to the differentiable causal discovery pipeline. ALVGL employs a sparse and low-rank decomposition to learn the precision matrix of the data. We design an ADMM procedure to optimize this decomposition, identifying components in the precision matrix that are most relevant to the underlying causal structure. These components are then combined to construct a super-structure that is provably a superset of the true causal graph. This super-structure is used to initialize a standard differentiable causal discovery method with a more focused search space, thereby improving both optimization efficiency and accuracy.\n  We demonstrate the versatility of ALVGL by instantiating it across a range of structural causal models, including both Gaussian and non-Gaussian settings, with and without unmeasured confounders. Extensive experiments on synthetic and real-world datasets show that ALVGL not only achieves state-of-the-art accuracy but also significantly improves optimization efficiency, making it a reliable and effective solution for differentiable causal discovery.", "AI": {"tldr": "ALVGL enhances differentiable causal discovery by learning a precision matrix decomposition to construct provably correct super-structures, improving optimization efficiency and accuracy across various causal models.", "motivation": "Differentiable causal discovery methods struggle with high-dimensional data and latent confounders due to vast search spaces, complex objectives, and graph constraints. Existing super-structure approaches face challenges in learning appropriate granularity efficiently across settings.", "method": "ALVGL uses sparse and low-rank decomposition of the precision matrix with ADMM optimization to identify causal-relevant components. These components construct a provably correct super-structure that initializes standard differentiable methods with focused search space.", "result": "ALVGL achieves state-of-the-art accuracy and significantly improves optimization efficiency across Gaussian/non-Gaussian settings with/without unmeasured confounders, demonstrated on synthetic and real-world datasets.", "conclusion": "ALVGL provides a reliable and effective enhancement to differentiable causal discovery pipelines by leveraging precision matrix decomposition to construct provably correct super-structures, addressing efficiency and accuracy challenges in complex causal discovery scenarios."}}
{"id": "2601.05873", "categories": ["cs.IT"], "pdf": "https://arxiv.org/pdf/2601.05873", "abs": "https://arxiv.org/abs/2601.05873", "authors": ["Javad Maheri", "K. K. Krishnan Namboodiri", "Petros Elia"], "title": "Universal and Asymptotically Optimal Data and Task Allocation in Distributed Computing", "comment": "49 pages, 2 figures", "summary": "We study the joint minimization of communication and computation costs in distributed computing, where a master node coordinates $N$ workers to evaluate a function over a library of $n$ files. Assuming that the function is decomposed into an arbitrary subfunction set $\\mathbf{X}$, with each subfunction depending on $d$ input files, renders our distributed computing problem into a $d$-uniform hypergraph edge partitioning problem wherein the edge set (subfunction set), defined by $d$-wise dependencies between vertices (files) must be partitioned across $N$ disjoint groups (workers). The aim is to design a file and subfunction allocation, corresponding to a partition of $\\mathbf{X}$, that minimizes the communication cost $\u03c0_{\\mathbf{X}}$, representing the maximum number of distinct files per server, while also minimizing the computation cost $\u03b4_{\\mathbf{X}}$ corresponding to a maximal worker subfunction load. For a broad range of parameters, we propose a deterministic allocation solution, the \\emph{Interweaved-Cliques (IC) design}, whose information-theoretic-inspired interweaved clique structure simultaneously achieves order-optimal communication and computation costs, for a large class of decompositions $\\mathbf{X}$. This optimality is derived from our achievability and converse bounds, which reveal -- under reasonable assumptions on the density of $\\mathbf{X}$ -- that the optimal scaling of the communication cost takes the form $n/N^{1/d}$, revealing that our design achieves the order-optimal \\textit{partitioning gain} that scales as $N^{1/d}$, while also achieving an order-optimal computation cost. Interestingly, this order optimality is achieved in a deterministic manner, and very importantly, it is achieved blindly from $\\mathbf{X}$, therefore enabling multiple desired functions to be computed without reshuffling files.", "AI": {"tldr": "The paper proposes the Interweaved-Cliques (IC) design for distributed computing that simultaneously achieves order-optimal communication and computation costs for function evaluation over distributed files, achieving partitioning gain scaling as N^{1/d}.", "motivation": "To minimize both communication and computation costs in distributed computing where a master coordinates workers to evaluate functions over distributed files, addressing the fundamental trade-off between these two costs.", "method": "Formulates the problem as a d-uniform hypergraph edge partitioning problem, proposes deterministic Interweaved-Cliques (IC) design with information-theoretic-inspired interweaved clique structure for file and subfunction allocation.", "result": "IC design achieves order-optimal communication cost scaling as n/N^{1/d} and order-optimal computation cost for a large class of decompositions, achieving partitioning gain scaling as N^{1/d}, and works blindly from the decomposition structure.", "conclusion": "The deterministic IC design simultaneously optimizes both communication and computation costs in distributed computing, achieving fundamental limits without requiring knowledge of the specific function decomposition, enabling efficient computation of multiple functions without file reshuffling."}}
{"id": "2601.05470", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05470", "abs": "https://arxiv.org/abs/2601.05470", "authors": ["Tingwei Xie", "Jinxin He", "Yonghong Song"], "title": "ROAP: A Reading-Order and Attention-Prior Pipeline for Optimizing Layout Transformers in Key Information Extraction", "comment": "10 pages, 4 figures, 4 tables", "summary": "The efficacy of Multimodal Transformers in visually-rich document understanding (VrDU) is critically constrained by two inherent limitations: the lack of explicit modeling for logical reading order and the interference of visual tokens that dilutes attention on textual semantics.\n  To address these challenges, this paper presents ROAP, a lightweight and architecture-agnostic pipeline designed to optimize attention distributions in Layout Transformers without altering their pre-trained backbones.\n  The proposed pipeline first employs an Adaptive-XY-Gap (AXG-Tree) to robustly extract hierarchical reading sequences from complex layouts. These sequences are then integrated into the attention mechanism via a Reading-Order-Aware Relative Position Bias (RO-RPB). Furthermore, a Textual-Token Sub-block Attention Prior (TT-Prior) is introduced to adaptively suppress visual noise and enhance fine-grained text-text interactions.\n  Extensive experiments on the FUNSD and CORD benchmarks demonstrate that ROAP consistently improves the performance of representative backbones, including LayoutLMv3 and GeoLayoutLM.\n  These findings confirm that explicitly modeling reading logic and regulating modality interference are critical for robust document understanding, offering a scalable solution for complex layout analysis. The implementation code will be released at https://github.com/KevinYuLei/ROAP.", "AI": {"tldr": "ROAP is a lightweight pipeline that improves Layout Transformers for document understanding by modeling reading order and reducing visual noise, without modifying pre-trained backbones.", "motivation": "Multimodal Transformers for document understanding have two key limitations: lack of explicit modeling for logical reading order, and interference from visual tokens that dilutes attention on textual semantics.", "method": "ROAP uses: 1) Adaptive-XY-Gap (AXG-Tree) to extract hierarchical reading sequences from layouts; 2) Reading-Order-Aware Relative Position Bias (RO-RPB) to integrate sequences into attention; 3) Textual-Token Sub-block Attention Prior (TT-Prior) to suppress visual noise and enhance text-text interactions.", "result": "Extensive experiments on FUNSD and CORD benchmarks show ROAP consistently improves performance of representative backbones like LayoutLMv3 and GeoLayoutLM.", "conclusion": "Explicitly modeling reading logic and regulating modality interference are critical for robust document understanding. ROAP offers a scalable solution for complex layout analysis without modifying pre-trained backbones."}}
{"id": "2601.05500", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05500", "abs": "https://arxiv.org/abs/2601.05500", "authors": ["Aparna Elangovan", "Lei Xu", "Mahsa Elyasi", "Ismail Akdulum", "Mehmet Aksakal", "Enes Gurun", "Brian Hur", "Saab Mansour", "Ravid Shwartz Ziv", "Karin Verspoor", "Dan Roth"], "title": "The Evaluation Gap in Medicine, AI and LLMs: Navigating Elusive Ground Truth & Uncertainty via a Probabilistic Paradigm", "comment": null, "summary": "Benchmarking the relative capabilities of AI systems, including Large Language Models (LLMs) and Vision Models, typically ignores the impact of uncertainty in the underlying ground truth answers from experts. This ambiguity is particularly consequential in medicine where uncertainty is pervasive. In this paper, we introduce a probabilistic paradigm to theoretically explain how high certainty in ground truth answers is almost always necessary for even an expert to achieve high scores, whereas in datasets with high variation in ground truth answers there may be little difference between a random labeller and an expert. Therefore, ignoring uncertainty in ground truth evaluation data can result in the misleading conclusion that a non-expert has similar performance to that of an expert. Using the probabilistic paradigm, we thus bring forth the concepts of expected accuracy and expected F1 to estimate the score an expert human or system can achieve given ground truth answer variability.\n  Our work leads to the recommendation that when establishing the capability of a system, results should be stratified by probability of the ground truth answer, typically measured by the agreement rate of ground truth experts. Stratification becomes critical when the overall performance drops below a threshold of 80%. Under stratified evaluation, performance comparison becomes more reliable in high certainty bins, mitigating the effect of the key confounding factor -- uncertainty.", "AI": {"tldr": "The paper introduces a probabilistic framework to address how uncertainty in ground truth answers affects AI benchmarking, showing that high ground truth variability can make experts appear similar to non-experts. It proposes expected accuracy/F1 metrics and stratified evaluation by ground truth certainty.", "motivation": "Current AI benchmarking ignores uncertainty in ground truth answers, which is particularly problematic in medicine where uncertainty is pervasive. This can lead to misleading conclusions where non-experts appear to perform similarly to experts when ground truth answers have high variability.", "method": "The authors introduce a probabilistic paradigm to theoretically analyze how ground truth uncertainty affects performance metrics. They develop concepts of expected accuracy and expected F1 to estimate what scores experts can achieve given ground truth variability. They propose stratifying evaluation results by the probability of ground truth answers (measured by expert agreement rates).", "result": "The analysis shows that high certainty in ground truth answers is necessary for experts to achieve high scores, while in datasets with high ground truth variation, there may be little difference between random labelers and experts. The paper provides a framework to distinguish true expert performance from artifacts of ground truth uncertainty.", "conclusion": "Benchmarking should account for ground truth uncertainty by stratifying results based on expert agreement rates, especially when overall performance drops below 80%. This approach makes performance comparisons more reliable in high-certainty scenarios and mitigates the confounding effect of uncertainty in AI evaluation."}}
{"id": "2601.05475", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05475", "abs": "https://arxiv.org/abs/2601.05475", "authors": ["Jiefu Ou", "Sapana Chaudhary", "Kaj Bostrom", "Nathaniel Weir", "Shuai Zhang", "Huzefa Rangwala", "George Karypis"], "title": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization", "comment": null, "summary": "Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.", "AI": {"tldr": "MaxCode is an inference-time search framework that uses execution feedback and natural language critiques to help LLMs iteratively optimize code performance, achieving significant speedup improvements on CUDA and C++ benchmarks.", "motivation": "LLMs struggle with code optimization due to: (1) complexity of writing optimized code requiring systems/algorithm expertise, and (2) difficulty interpreting performance metrics beyond binary correctness.", "method": "MaxCode unifies search methods under max-reward RL framework with modular observation/action-value functions. It integrates natural language critique models to convert execution feedback into diagnostic insights, and uses generative reward-to-go models for solution reranking during search.", "result": "On KernelBench (CUDA) and PIE (C++) optimization benchmarks, MaxCode achieves 20.3% relative improvement in absolute speedup value and 10.1% improvement in relative speedup ranking compared to baselines.", "conclusion": "MaxCode effectively enhances LLM-based code optimization through inference-time search with execution feedback and natural language critiques, bridging the gap between LLM capabilities and expert-level optimization requirements."}}
{"id": "2601.05529", "categories": ["cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05529", "abs": "https://arxiv.org/abs/2601.05529", "authors": ["Jua Han", "Jaeyoon Seo", "Jungbin Min", "Jean Oh", "Jihie Kim"], "title": "Safety Not Found (404): Hidden Risks of LLM-Based Robotics Decision Making", "comment": null, "summary": "One mistake by an AI system in a safety-critical setting can cost lives. As Large Language Models (LLMs) become integral to robotics decision-making, the physical dimension of risk grows; a single wrong instruction can directly endanger human safety. This paper addresses the urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic. Through a qualitative evaluation of a fire evacuation scenario, we identified critical failure cases in LLM-based decision-making. Based on these, we designed seven tasks for quantitative assessment, categorized into: Complete Information, Incomplete Information, and Safety-Oriented Spatial Reasoning (SOSR). Complete information tasks utilize ASCII maps to minimize interpretation ambiguity and isolate spatial reasoning from visual processing. Incomplete information tasks require models to infer missing context, testing for spatial continuity versus hallucinations. SOSR tasks use natural language to evaluate safe decision-making in life-threatening contexts. We benchmark various LLMs and Vision-Language Models (VLMs) across these tasks. Beyond aggregate performance, we analyze the implications of a 1% failure rate, highlighting how \"rare\" errors escalate into catastrophic outcomes. Results reveal serious vulnerabilities: several models achieved a 0% success rate in ASCII navigation, while in a simulated fire drill, models instructed robots to move toward hazardous areas instead of emergency exits. Our findings lead to a sobering conclusion: current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. We demonstrate that even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks.", "AI": {"tldr": "LLMs show dangerous failure rates in safety-critical robotics scenarios, with even 99% accuracy being unacceptable as it could lead to catastrophic outcomes in physical environments.", "motivation": "As LLMs become integral to robotics decision-making, a single wrong instruction can directly endanger human safety. There's an urgent need to systematically evaluate LLM performance in scenarios where even minor errors are catastrophic, particularly in safety-critical settings like fire evacuations.", "method": "Qualitative evaluation of fire evacuation scenarios identified critical failure cases. Based on these, seven quantitative assessment tasks were designed across three categories: Complete Information (ASCII maps to isolate spatial reasoning), Incomplete Information (inferring missing context), and Safety-Oriented Spatial Reasoning (natural language evaluation in life-threatening contexts). Various LLMs and VLMs were benchmarked across these tasks.", "result": "Results reveal serious vulnerabilities: several models achieved 0% success rate in ASCII navigation, and in simulated fire drills, models instructed robots to move toward hazardous areas instead of emergency exits. Analysis shows how \"rare\" errors (even 1% failure rate) escalate into catastrophic outcomes in physical systems.", "conclusion": "Current LLMs are not ready for direct deployment in safety-critical systems. A 99% accuracy rate is dangerously misleading in robotics, as it implies one out of every hundred executions could result in catastrophic harm. Even state-of-the-art models cannot guarantee safety, and absolute reliance on them creates unacceptable risks."}}
{"id": "2601.05482", "categories": ["cs.CV", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.05482", "abs": "https://arxiv.org/abs/2601.05482", "authors": ["Shubham Agarwal", "Ofek Nourian", "Michael Sidorov", "Sharon Chemweno", "Ofer Hadar", "Naftali Lazarovitch", "Jhonathan E. Ephrath"], "title": "Multi-Image Super Resolution Framework for Detection and Analysis of Plant Roots", "comment": null, "summary": "Understanding plant root systems is critical for advancing research in soil-plant interactions, nutrient uptake, and overall plant health. However, accurate imaging of roots in subterranean environments remains a persistent challenge due to adverse conditions such as occlusion, varying soil moisture, and inherently low contrast, which limit the effectiveness of conventional vision-based approaches. In this work, we propose a novel underground imaging system that captures multiple overlapping views of plant roots and integrates a deep learning-based Multi-Image Super Resolution (MISR) framework designed to enhance root visibility and detail. To train and evaluate our approach, we construct a synthetic dataset that simulates realistic underground imaging scenarios, incorporating key environmental factors that affect image quality. Our proposed MISR algorithm leverages spatial redundancy across views to reconstruct high-resolution images with improved structural fidelity and visual clarity. Quantitative evaluations show that our approach outperforms state-of-the-art super resolution baselines, achieving a 2.3 percent reduction in BRISQUE, indicating improved image quality with the same CLIP-IQA score, thereby enabling enhanced phenotypic analysis of root systems. This, in turn, facilitates accurate estimation of critical root traits, including root hair count and root hair density. The proposed framework presents a promising direction for robust automatic underground plant root imaging and trait quantification for agricultural and ecological research.", "AI": {"tldr": "A novel underground imaging system using multi-image super resolution (MISR) to enhance root visibility in challenging subterranean conditions, enabling better root trait analysis.", "motivation": "Accurate imaging of plant roots underground is difficult due to occlusion, varying soil moisture, and low contrast, limiting conventional vision-based approaches for studying soil-plant interactions and nutrient uptake.", "method": "Proposes an underground imaging system capturing multiple overlapping views of roots, integrated with a deep learning-based Multi-Image Super Resolution (MISR) framework. Uses a synthetic dataset simulating realistic underground conditions to train and evaluate the approach.", "result": "Outperforms state-of-the-art super resolution baselines with 2.3% reduction in BRISQUE (indicating improved image quality) while maintaining same CLIP-IQA score. Enables enhanced phenotypic analysis and accurate estimation of root traits like root hair count and density.", "conclusion": "The framework presents a promising direction for robust automatic underground plant root imaging and trait quantification, benefiting agricultural and ecological research."}}
{"id": "2601.05525", "categories": ["cs.AI", "cs.LG", "physics.comp-ph", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05525", "abs": "https://arxiv.org/abs/2601.05525", "authors": ["Ricardo Vinuesa", "Steven L. Brunton", "Gianmarco Mengaldo"], "title": "Explainable AI: Learning from the Learners", "comment": null, "summary": "Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.", "AI": {"tldr": "XAI combined with causal reasoning enables \"learning from the learners\" - extracting causal mechanisms from AI models to advance discovery, optimization, and certification in science and engineering.", "motivation": "While AI outperforms humans in many tasks, its internal representations remain opaque. There's a need to make AI more interpretable and extract useful knowledge from AI models to advance scientific discovery and engineering applications.", "method": "Combining explainable AI (XAI) with causal reasoning, using foundation models and explainability methods to extract causal mechanisms, guide design/control, and support trust in high-stakes applications.", "result": "The paper proposes XAI as a unifying framework for human-AI collaboration that enables: 1) extraction of causal mechanisms from AI models, 2) robust design and control guidance, and 3) trust/accountability in high-stakes applications.", "conclusion": "XAI combined with causal reasoning enables \"learning from the learners\" - extracting knowledge from AI models to advance science and engineering, though challenges remain in explanation faithfulness, generalization, and usability."}}
{"id": "2601.05501", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05501", "abs": "https://arxiv.org/abs/2601.05501", "authors": ["Feihu Jin", "Ying Tan"], "title": "Hi-ZFO: Hierarchical Zeroth- and First-Order LLM Fine-Tuning via Importance-Guided Tensor Selection", "comment": "13 pages, 4 figures", "summary": "Fine-tuning large language models (LLMs) using standard first-order (FO) optimization often drives training toward sharp, poorly generalizing minima. Conversely, zeroth-order (ZO) methods offer stronger exploratory behavior without relying on explicit gradients, yet suffer from slow convergence. More critically, our analysis reveals that in generative tasks, the vast output and search space significantly amplify estimation variance, rendering ZO methods both noisy and inefficient. To address these challenges, we propose \\textbf{Hi-ZFO} (\\textbf{Hi}erarchical \\textbf{Z}eroth- and \\textbf{F}irst-\\textbf{O}rder optimization), a hybrid framework designed to synergize the precision of FO gradients with the exploratory capability of ZO estimation. Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while leveraging ZO optimization for less sensitive ones. Notably, ZO in Hi-ZFO is not merely a memory-saving surrogate; it is intentionally introduced as a source of \"beneficial stochasticity\" to help the model escape the local minima where pure FO optimization tends to stagnate. Validated across diverse generative, mathematical, and code reasoning tasks, Hi-ZFO consistently achieves superior performance while significantly reducing the training time. These results demonstrate the effectiveness of hierarchical hybrid optimization for LLM fine-tuning.", "AI": {"tldr": "Hi-ZFO is a hierarchical hybrid optimization method that combines zeroth-order (ZO) and first-order (FO) optimization to improve LLM fine-tuning by balancing exploration and precision.", "motivation": "Standard FO optimization for LLM fine-tuning leads to sharp minima with poor generalization, while ZO methods offer better exploration but suffer from slow convergence and high variance in generative tasks with large output spaces.", "method": "Hi-ZFO adaptively partitions the model through layer-wise importance profiling, applying precise FO updates to critical layers while using ZO optimization for less sensitive layers. ZO serves as \"beneficial stochasticity\" to escape local minima rather than just a memory-saving technique.", "result": "Hi-ZFO achieves superior performance across diverse generative, mathematical, and code reasoning tasks while significantly reducing training time compared to pure FO or ZO methods.", "conclusion": "Hierarchical hybrid optimization combining ZO and FO methods is effective for LLM fine-tuning, balancing exploration and precision to achieve better generalization and efficiency."}}
{"id": "2601.05747", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05747", "abs": "https://arxiv.org/abs/2601.05747", "authors": ["Hassaan Farooq", "Marvin Brenner", "Peter St\\\u00fctz"], "title": "FlyPose: Towards Robust Human Pose Estimation From Aerial Views", "comment": "11 pages, 9 figures, IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026", "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly deployed in close proximity to humans for applications such as parcel delivery, traffic monitoring, disaster response and infrastructure inspections. Ensuring safe and reliable operation in these human-populated environments demands accurate perception of human poses and actions from an aerial viewpoint. This perspective challenges existing methods with low resolution, steep viewing angles and (self-)occlusion, especially if the application demands realtime feasibile models. We train and deploy FlyPose, a lightweight top-down human pose estimation pipeline for aerial imagery. Through multi-dataset training, we achieve an average improvement of 6.8 mAP in person detection across the test-sets of Manipal-UAV, VisDrone, HIT-UAV as well as our custom dataset. For 2D human pose estimation we report an improvement of 16.3 mAP on the challenging UAV-Human dataset. FlyPose runs with an inference latency of ~20 milliseconds including preprocessing on a Jetson Orin AGX Developer Kit and is deployed onboard a quadrotor UAV during flight experiments. We also publish FlyPose-104, a small but challenging aerial human pose estimation dataset, that includes manual annotations from difficult aerial perspectives: https://github.com/farooqhassaan/FlyPose.", "AI": {"tldr": "FlyPose: lightweight top-down human pose estimation pipeline for UAVs that improves detection and pose estimation accuracy on aerial datasets while running in real-time (~20ms) on embedded hardware.", "motivation": "UAVs operating near humans need accurate perception of human poses from aerial viewpoints, but existing methods struggle with low resolution, steep angles, occlusion, and real-time requirements.", "method": "Multi-dataset training of a lightweight top-down human pose estimation pipeline specifically designed for aerial imagery, deployed onboard UAVs.", "result": "6.8 mAP improvement in person detection across multiple test-sets, 16.3 mAP improvement in 2D pose estimation on UAV-Human dataset, ~20ms inference latency on Jetson Orin AGX.", "conclusion": "FlyPose enables real-time human pose estimation from UAVs, addressing challenges of aerial perspectives, and includes release of FlyPose-104 dataset for difficult aerial viewpoints."}}
{"id": "2601.05494", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05494", "abs": "https://arxiv.org/abs/2601.05494", "authors": ["Trishna Niraula"], "title": "Hippocampal Atrophy Patterns Across the Alzheimer's Disease Spectrum: A Voxel-Based Morphometry Analysis", "comment": "8 pages, 7 figures, 6 tables", "summary": "Alzheimer's disease (AD) and mild cognitive impairment (MCI) are associated with progressive gray matter loss, particularly in medial temporal structures. In this study, CAT12/SPM12 voxel-based morphometry was applied to baseline T1-weighted MRI scans from 249 ADNI participants (CN = 90, MCI = 129, AD = 30). Gray matter volume was analyzed using a general linear model, with the diagnostic group as primary predictor and age and total intracranial volume as covariates. Statistical maps were thresholded at p < 0.001 (voxelwise) and corrected for multiple comparisons at the cluster level using family-wise error (FWE) correction (p < 0.05). Significant hippocampal atrophy was observed in AD relative to CN and MCI (Cohen's d = 2.03 and 1.61, respectively). Hippocampal volume demonstrated moderate predictive value for conversion from MCI to AD (AUC = 0.66). Stratification by APOE4 status did not reveal significant genetic effects on cross-sectional hippocampal volume. These results support medial temporal degeneration as a key feature of AD progression and provide insights into predictive biomarkers and genetic influences.", "AI": {"tldr": "Voxel-based morphometry study finds significant hippocampal atrophy in Alzheimer's disease compared to controls and mild cognitive impairment, with moderate predictive value for MCI-to-AD conversion but no significant APOE4 genetic effects on cross-sectional hippocampal volume.", "motivation": "To investigate gray matter loss patterns in Alzheimer's disease and mild cognitive impairment, particularly in medial temporal structures, and to examine the predictive value of hippocampal volume for disease progression and genetic influences.", "method": "Used CAT12/SPM12 voxel-based morphometry on baseline T1-weighted MRI scans from 249 ADNI participants (90 controls, 129 MCI, 30 AD). Analyzed gray matter volume with general linear model, diagnostic group as primary predictor, age and total intracranial volume as covariates. Statistical maps thresholded at p < 0.001 (voxelwise) with family-wise error correction at cluster level (p < 0.05).", "result": "Significant hippocampal atrophy in AD relative to controls (Cohen's d = 2.03) and MCI (Cohen's d = 1.61). Hippocampal volume showed moderate predictive value for MCI-to-AD conversion (AUC = 0.66). Stratification by APOE4 status revealed no significant genetic effects on cross-sectional hippocampal volume.", "conclusion": "Medial temporal degeneration is a key feature of AD progression. Hippocampal volume has moderate predictive value for disease conversion, but APOE4 status does not significantly affect cross-sectional hippocampal volume measurements."}}
{"id": "2601.05503", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05503", "abs": "https://arxiv.org/abs/2601.05503", "authors": ["Roy Xie", "Deepak Gopinath", "David Qiu", "Dong Lin", "Haitian Sun", "Saloni Potdar", "Bhuwan Dhingra"], "title": "Over-Searching in Search-Augmented Large Language Models", "comment": "Accepted to EACL 2026 Main Conference", "summary": "Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.", "AI": {"tldr": "Search-augmented LLMs often over-search unnecessarily, harming efficiency and causing hallucinations. The paper systematically evaluates this problem, introduces TPC metric to measure performance-cost trade-off, and proposes mitigation approaches.", "motivation": "Search-augmented LLMs frequently invoke search tools unnecessarily even when it doesn't improve response quality, leading to computational inefficiency and hallucinations from irrelevant retrieved context.", "method": "Conducted systematic evaluation across multiple dimensions (query types, model categories, retrieval conditions, multi-turn conversations), introduced Tokens Per Correctness (TPC) metric, and investigated mitigation approaches at query and retrieval levels.", "result": "Search improves accuracy on answerable queries but harms abstention on unanswerable ones; over-searching is worse in complex reasoning models and deep research systems, exacerbated by noisy retrieval, and compounds in multi-turn conversations; negative evidence improves abstention.", "conclusion": "Over-searching is a significant problem in search-augmented LLMs that affects efficiency and reliability. The paper provides systematic analysis, introduces TPC metric for evaluation, proposes mitigation strategies, and releases OverSearchQA dataset for future research."}}
{"id": "2601.05810", "categories": ["cs.CV", "cs.AI", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05810", "abs": "https://arxiv.org/abs/2601.05810", "authors": ["ChunTeng Chen", "YiChen Hsu", "YiWen Liu", "WeiFang Sun", "TsaiChing Ni", "ChunYi Lee", "Min Sun", "YuanFu Yang"], "title": "SceneFoundry: Generating Interactive Infinite 3D Worlds", "comment": "15 pages", "summary": "The ability to automatically generate large-scale, interactive, and physically realistic 3D environments is crucial for advancing robotic learning and embodied intelligence. However, existing generative approaches often fail to capture the functional complexity of real-world interiors, particularly those containing articulated objects with movable parts essential for manipulation and navigation. This paper presents SceneFoundry, a language-guided diffusion framework that generates apartment-scale 3D worlds with functionally articulated furniture and semantically diverse layouts for robotic training. From natural language prompts, an LLM module controls floor layout generation, while diffusion-based posterior sampling efficiently populates the scene with articulated assets from large-scale 3D repositories. To ensure physical usability, SceneFoundry employs differentiable guidance functions to regulate object quantity, prevent articulation collisions, and maintain sufficient walkable space for robotic navigation. Extensive experiments demonstrate that our framework generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.", "AI": {"tldr": "SceneFoundry: A language-guided diffusion framework for generating apartment-scale 3D worlds with articulated furniture for robotic training.", "motivation": "Existing generative approaches fail to capture functional complexity of real-world interiors, especially articulated objects with movable parts essential for robotic manipulation and navigation.", "method": "Uses LLM for floor layout generation from natural language prompts, diffusion-based posterior sampling to populate scenes with articulated assets from 3D repositories, and differentiable guidance functions to ensure physical usability.", "result": "Generates structurally valid, semantically coherent, and functionally interactive environments across diverse scene types and conditions, enabling scalable embodied AI research.", "conclusion": "SceneFoundry provides a framework for automatically generating large-scale, interactive, physically realistic 3D environments crucial for advancing robotic learning and embodied intelligence."}}
{"id": "2601.05495", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05495", "abs": "https://arxiv.org/abs/2601.05495", "authors": ["Zizhong Li", "Haopeng Zhang", "Jiawei Zhang"], "title": "MMViR: A Multi-Modal and Multi-Granularity Representation for Long-range Video Understanding", "comment": "13 pages, 11 figures", "summary": "Long videos, ranging from minutes to hours, present significant challenges for current Multi-modal Large Language Models (MLLMs) due to their complex events, diverse scenes, and long-range dependencies. Direct encoding of such videos is computationally too expensive, while simple video-to-text conversion often results in redundant or fragmented content. To address these limitations, we introduce MMViR, a novel multi-modal, multi-grained structured representation for long video understanding. MMViR identifies key turning points to segment the video and constructs a three-level description that couples global narratives with fine-grained visual details. This design supports efficient query-based retrieval and generalizes well across various scenarios. Extensive evaluations across three tasks, including QA, summarization, and retrieval, show that MMViR outperforms the prior strongest method, achieving a 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.", "AI": {"tldr": "MMViR is a multi-modal, multi-grained structured representation for long video understanding that segments videos at key turning points and creates three-level descriptions, achieving significant performance improvements and latency reduction.", "motivation": "Long videos (minutes to hours) are challenging for current MLLMs due to complex events, diverse scenes, and long-range dependencies. Direct encoding is computationally expensive, while simple video-to-text conversion leads to redundant or fragmented content.", "method": "MMViR identifies key turning points to segment videos and constructs a three-level description that couples global narratives with fine-grained visual details. This structured representation supports efficient query-based retrieval and generalizes across scenarios.", "result": "Extensive evaluations across QA, summarization, and retrieval tasks show MMViR outperforms the prior strongest method with 19.67% improvement in hour-long video understanding while reducing processing latency to 45.4% of the original.", "conclusion": "MMViR provides an effective structured representation for long video understanding that addresses computational and content fragmentation challenges, demonstrating superior performance and efficiency across multiple tasks."}}
{"id": "2601.05567", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05567", "abs": "https://arxiv.org/abs/2601.05567", "authors": ["Tengxiao Liu", "Deepak Nathani", "Zekun Li", "Kevin Yang", "William Yang Wang"], "title": "WildSci: Advancing Scientific Reasoning from In-the-Wild Literature", "comment": null, "summary": "Recent progress in large language model (LLM) reasoning has focused on domains like mathematics and coding, where abundant high-quality data and objective evaluation metrics are readily available. In contrast, progress in LLM reasoning models remains limited in scientific domains such as medicine and materials science due to limited dataset coverage and the inherent complexity of open-ended scientific questions. To address these challenges, we introduce WildSci, a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature, covering 9 scientific disciplines and 26 subdomains. By framing complex scientific reasoning tasks in a multiple-choice format, we enable scalable training with well-defined reward signals. We further apply reinforcement learning to finetune models on these data and analyze the resulting training dynamics, including domain-specific performance changes, response behaviors, and generalization trends. Experiments on a suite of scientific benchmarks demonstrate the effectiveness of our dataset and approach. We release WildSci to enable scalable and sustainable research in scientific reasoning, available at https://huggingface.co/datasets/JustinTX/WildSci.", "AI": {"tldr": "WildSci introduces a new dataset of domain-specific science questions automatically synthesized from peer-reviewed literature to address limitations in LLM reasoning for scientific domains, enabling scalable training via multiple-choice format and reinforcement learning.", "motivation": "LLM reasoning has progressed in domains like mathematics and coding with abundant data and objective metrics, but remains limited in scientific domains (medicine, materials science) due to limited dataset coverage and complexity of open-ended scientific questions.", "method": "Created WildSci dataset with domain-specific science questions automatically synthesized from peer-reviewed literature (9 disciplines, 26 subdomains), framed in multiple-choice format for scalable training with well-defined reward signals, then applied reinforcement learning to finetune models.", "result": "Experiments on scientific benchmarks demonstrate effectiveness of the dataset and approach. The training dynamics analysis includes domain-specific performance changes, response behaviors, and generalization trends.", "conclusion": "WildSci enables scalable and sustainable research in scientific reasoning by addressing data limitations in scientific domains. The dataset is publicly released to facilitate further research."}}
{"id": "2601.05521", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05521", "abs": "https://arxiv.org/abs/2601.05521", "authors": ["Jiayu Fang", "Zhiqi Shao", "Haoning Xi", "Boris Choy", "Junbin Gao"], "title": "Toward an Integrated Cross-Urban Accident Prevention System: A Multi-Task Spatial-Temporal Learning Framework for Urban Safety Management", "comment": "38pages, 18figures", "summary": "The development of a cross-city accident prevention system is particularly challenging due to the heterogeneity, inconsistent reporting, and inherently clustered, sparse, cyclical, and noisy nature of urban accident data. These intrinsic data properties, combined with fragmented governance and incompatible reporting standards, have long hindered the creation of an integrated, cross-city accident prevention framework. To address this gap, we propose the Mamba Local-ttention Spatial-Temporal Network MLA-STNet, a unified system that formulates accident risk prediction as a multi-task learning problem across multiple cities. MLA-STNet integrates two complementary modules: (i)the Spatio-Temporal Geographical Mamba-Attention (STG-MA), which suppresses unstable spatio-temporal fluctuations and strengthens long-range temporal dependencies; and (ii) the Spatio-Temporal Semantic Mamba-Attention (STS-MA), which mitigates cross-city heterogeneity through a shared-parameter design that jointly trains all cities while preserving individual semantic representation spaces. We validate the proposed framework through 75 experiments under two forecasting scenarios, full-day and high-frequency accident periods, using real-world datasets from New York City and Chicago. Compared with the state-of-the-art baselines, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP, while maintaining less than 1% performance variation under 50% input noise. These results demonstrate that MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, paving the way for coordinated and data-driven urban safety management.", "AI": {"tldr": "MLA-STNet is a unified cross-city accident prediction system using multi-task learning with Mamba-attention modules to handle heterogeneous urban data and improve prediction accuracy.", "motivation": "Cross-city accident prevention is challenging due to heterogeneous, inconsistent, sparse, cyclical, and noisy urban accident data, combined with fragmented governance and incompatible reporting standards, which hinder integrated cross-city frameworks.", "method": "MLA-STNet formulates accident risk prediction as multi-task learning across cities with two modules: STG-MA (suppresses unstable spatio-temporal fluctuations and strengthens long-range dependencies) and STS-MA (mitigates cross-city heterogeneity through shared-parameter design while preserving individual semantic spaces).", "result": "In 75 experiments on NYC and Chicago data, MLA-STNet achieves up to 6% lower RMSE, 8% higher Recall, and 5% higher MAP than SOTA baselines, with less than 1% performance variation under 50% input noise.", "conclusion": "MLA-STNet effectively unifies heterogeneous urban datasets within a scalable, robust, and interpretable Cross-City Accident Prevention System, enabling coordinated data-driven urban safety management."}}
{"id": "2601.05848", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2601.05848", "abs": "https://arxiv.org/abs/2601.05848", "authors": ["Nate Gillman", "Yinghua Zhou", "Zitian Tang", "Evan Luo", "Arjan Chakravarthy", "Daksh Aggarwal", "Michael Freeman", "Charles Herrmann", "Chen Sun"], "title": "Goal Force: Teaching Video Models To Accomplish Physics-Conditioned Goals", "comment": "Code and interactive demos at https://goal-force.github.io/", "summary": "Recent advancements in video generation have enabled the development of ``world models'' capable of simulating potential futures for robotics and planning. However, specifying precise goals for these models remains a challenge; text instructions are often too abstract to capture physical nuances, while target images are frequently infeasible to specify for dynamic tasks. To address this, we introduce Goal Force, a novel framework that allows users to define goals via explicit force vectors and intermediate dynamics, mirroring how humans conceptualize physical tasks. We train a video generation model on a curated dataset of synthetic causal primitives-such as elastic collisions and falling dominos-teaching it to propagate forces through time and space. Despite being trained on simple physics data, our model exhibits remarkable zero-shot generalization to complex, real-world scenarios, including tool manipulation and multi-object causal chains. Our results suggest that by grounding video generation in fundamental physical interactions, models can emerge as implicit neural physics simulators, enabling precise, physics-aware planning without reliance on external engines. We release all datasets, code, model weights, and interactive video demos at our project page.", "AI": {"tldr": "Goal Force: A video generation framework that uses explicit force vectors and intermediate dynamics as goal specifications, enabling physics-aware planning without external simulators.", "motivation": "Current video generation world models struggle with precise goal specification - text is too abstract and target images are infeasible for dynamic tasks. There's a need for more intuitive, physics-aware goal specification that mirrors how humans conceptualize physical tasks.", "method": "Train a video generation model on synthetic causal primitives (elastic collisions, falling dominos) to propagate forces through time and space. Users define goals via explicit force vectors and intermediate dynamics rather than text or target images.", "result": "The model shows remarkable zero-shot generalization to complex real-world scenarios including tool manipulation and multi-object causal chains, despite being trained only on simple physics data.", "conclusion": "Grounding video generation in fundamental physical interactions enables models to emerge as implicit neural physics simulators, allowing precise, physics-aware planning without reliance on external physics engines."}}
{"id": "2601.05498", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05498", "abs": "https://arxiv.org/abs/2601.05498", "authors": ["Samuel E. Johnny", "Bernes L. Atabonfack", "Israel Alagbe", "Assane Gueye"], "title": "Prompt-Free SAM-Based Multi-Task Framework for Breast Ultrasound Lesion Segmentation and Classification", "comment": null, "summary": "Accurate tumor segmentation and classification in breast ultrasound (BUS) imaging remain challenging due to low contrast, speckle noise, and diverse lesion morphology. This study presents a multi-task deep learning framework that jointly performs lesion segmentation and diagnostic classification using embeddings from the Segment Anything Model (SAM) vision encoder. Unlike prompt-based SAM variants, our approach employs a prompt-free, fully supervised adaptation where high-dimensional SAM features are decoded through either a lightweight convolutional head or a UNet-inspired decoder for pixel-wise segmentation. The classification branch is enhanced via mask-guided attention, allowing the model to focus on lesion-relevant features while suppressing background artifacts. Experiments on the PRECISE 2025 breast ultrasound dataset, split per class into 80 percent training and 20 percent testing, show that the proposed method achieves a Dice Similarity Coefficient (DSC) of 0.887 and an accuracy of 92.3 percent, ranking among the top entries on the PRECISE challenge leaderboard. These results demonstrate that SAM-based representations, when coupled with segmentation-guided learning, significantly improve both lesion delineation and diagnostic prediction in breast ultrasound imaging.", "AI": {"tldr": "Multi-task deep learning framework using SAM vision encoder embeddings for joint breast ultrasound lesion segmentation and classification, achieving top performance on PRECISE 2025 dataset.", "motivation": "Breast ultrasound imaging presents challenges for tumor analysis due to low contrast, speckle noise, and diverse lesion morphology, requiring improved methods for accurate segmentation and classification.", "method": "Prompt-free, fully supervised adaptation of SAM vision encoder features, decoded through lightweight convolutional head or UNet-inspired decoder for segmentation, with mask-guided attention for classification to focus on lesion-relevant features.", "result": "Achieved Dice Similarity Coefficient of 0.887 and accuracy of 92.3% on PRECISE 2025 breast ultrasound dataset, ranking among top entries on the challenge leaderboard.", "conclusion": "SAM-based representations combined with segmentation-guided learning significantly improve both lesion delineation and diagnostic prediction in breast ultrasound imaging."}}
{"id": "2601.05570", "categories": ["cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.05570", "abs": "https://arxiv.org/abs/2601.05570", "authors": ["Cooper Lin", "Maohao Ran", "Yanting Zhang", "Zhenglin Wan", "Hongwei Fan", "Yibo Xu", "Yike Guo", "Wei Xue", "Jun Song"], "title": "Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models", "comment": null, "summary": "Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid \"Boy Scout\" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a \"transparency tax\" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing \"Reputation Management\" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.", "AI": {"tldr": "The paper introduces Crisis-Bench, a multi-agent POMDP framework to evaluate LLMs in corporate crisis management, revealing a tension between universal safety alignment and professional needs for strategic ambiguity.", "motivation": "Standard safety alignment creates \"Boy Scout\" morality in LLMs that imposes a \"transparency tax\" on professional domains requiring strategic information withholding like PR, negotiation, and crisis management. There's a gap between general safety and professional utility that needs measurement.", "method": "Crisis-Bench: multi-agent Partially Observable Markov Decision Process with 80 diverse storylines across 8 industries. LLM-based PR Agent navigates 7-day corporate crisis simulation with separate Private/Public narrative states to enforce information asymmetry. Uses Adjudicator-Market Loop evaluation: public sentiment adjudicated and translated to simulated stock price for economic incentives.", "result": "Exposes critical dichotomy: some models capitulate to ethical concerns, while others demonstrate capacity for Machiavellian strategic withholding to stabilize simulated stock price. Provides first quantitative framework for assessing \"Reputation Management\" capabilities.", "conclusion": "Argues for shift from rigid moral absolutism to context-aware professional alignment. Crisis-Bench enables evaluation of LLMs in professional domains requiring strategic ambiguity, moving beyond one-size-fits-all ethical frameworks."}}
{"id": "2601.05527", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05527", "abs": "https://arxiv.org/abs/2601.05527", "authors": ["Rui An", "Haohao Qu", "Wenqi Fan", "Xuequn Shang", "Qing Li"], "title": "DeMa: Dual-Path Delay-Aware Mamba for Efficient Multivariate Time Series Analysis", "comment": "Under review", "summary": "Accurate and efficient multivariate time series (MTS) analysis is increasingly critical for a wide range of intelligent applications. Within this realm, Transformers have emerged as the predominant architecture due to their strong ability to capture pairwise dependencies. However, Transformer-based models suffer from quadratic computational complexity and high memory overhead, limiting their scalability and practical deployment in long-term and large-scale MTS modeling. Recently, Mamba has emerged as a promising linear-time alternative with high expressiveness. Nevertheless, directly applying vanilla Mamba to MTS remains suboptimal due to three key limitations: (i) the lack of explicit cross-variate modeling, (ii) difficulty in disentangling the entangled intra-series temporal dynamics and inter-series interactions, and (iii) insufficient modeling of latent time-lag interaction effects. These issues constrain its effectiveness across diverse MTS tasks. To address these challenges, we propose DeMa, a dual-path delay-aware Mamba backbone. DeMa preserves Mamba's linear-complexity advantage while substantially improving its suitability for MTS settings. Specifically, DeMa introduces three key innovations: (i) it decomposes the MTS into intra-series temporal dynamics and inter-series interactions; (ii) it develops a temporal path with a Mamba-SSD module to capture long-range dynamics within each individual series, enabling series-independent, parallel computation; and (iii) it designs a variate path with a Mamba-DALA module that integrates delay-aware linear attention to model cross-variate dependencies. Extensive experiments on five representative tasks, long- and short-term forecasting, data imputation, anomaly detection, and series classification, demonstrate that DeMa achieves state-of-the-art performance while delivering remarkable computational efficiency.", "AI": {"tldr": "DeMa is a dual-path delay-aware Mamba backbone for multivariate time series analysis that addresses limitations of Transformers (quadratic complexity) and vanilla Mamba (lack of cross-variate modeling) while maintaining linear-time efficiency.", "motivation": "Transformers dominate MTS analysis but suffer from quadratic computational complexity and high memory overhead, limiting scalability. Mamba offers linear-time alternative but has three key limitations for MTS: lack of explicit cross-variate modeling, difficulty disentangling intra-series temporal dynamics and inter-series interactions, and insufficient modeling of latent time-lag interaction effects.", "method": "DeMa introduces three innovations: (1) decomposes MTS into intra-series temporal dynamics and inter-series interactions; (2) temporal path with Mamba-SSD module captures long-range dynamics within each series for parallel computation; (3) variate path with Mamba-DALA module integrates delay-aware linear attention to model cross-variate dependencies.", "result": "Extensive experiments on five representative tasks (long- and short-term forecasting, data imputation, anomaly detection, series classification) demonstrate state-of-the-art performance with remarkable computational efficiency.", "conclusion": "DeMa preserves Mamba's linear-complexity advantage while substantially improving suitability for MTS settings, achieving superior performance across diverse MTS tasks with computational efficiency."}}
{"id": "2601.05508", "categories": ["cs.CV", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05508", "abs": "https://arxiv.org/abs/2601.05508", "authors": ["Fuwen Luo", "Zihao Wan", "Ziyue Wang", "Yaluo Liu", "Pau Tong Lin Xu", "Xuanjia Qiao", "Xiaolong Wang", "Peng Li", "Yang Liu"], "title": "Enabling Stroke-Level Structural Analysis of Hieroglyphic Scripts without Language-Specific Priors", "comment": null, "summary": "Hieroglyphs, as logographic writing systems, encode rich semantic and cultural information within their internal structural composition. Yet, current advanced Large Language Models (LLMs) and Multimodal LLMs (MLLMs) usually remain structurally blind to this information. LLMs process characters as textual tokens, while MLLMs additionally view them as raw pixel grids. Both fall short to model the underlying logic of character strokes. Furthermore, existing structural analysis methods are often script-specific and labor-intensive. In this paper, we propose Hieroglyphic Stroke Analyzer (HieroSA), a novel and generalizable framework that enables MLLMs to automatically derive stroke-level structures from character bitmaps without handcrafted data. It transforms modern logographic and ancient hieroglyphs character images into explicit, interpretable line-segment representations in a normalized coordinate space, allowing for cross-lingual generalization. Extensive experiments demonstrate that HieroSA effectively captures character-internal structures and semantics, bypassing the need for language-specific priors. Experimental results highlight the potential of our work as a graphematics analysis tool for a deeper understanding of hieroglyphic scripts. View our code at https://github.com/THUNLP-MT/HieroSA.", "AI": {"tldr": "HieroSA is a framework that enables MLLMs to automatically extract stroke-level structures from character images without manual annotation, providing cross-lingual structural analysis of logographic writing systems.", "motivation": "Current LLMs and MLLMs fail to capture the structural logic of hieroglyphic characters - LLMs treat them as tokens, MLLMs as pixel grids, both missing stroke-level information. Existing structural analysis methods are script-specific and labor-intensive.", "method": "HieroSA transforms character images into explicit, interpretable line-segment representations in normalized coordinate space, enabling automatic stroke-level structure derivation without handcrafted data.", "result": "Extensive experiments show HieroSA effectively captures character-internal structures and semantics, bypassing language-specific priors, and demonstrates cross-lingual generalization capabilities.", "conclusion": "HieroSA serves as a powerful graphematics analysis tool for deeper understanding of hieroglyphic scripts, offering a generalizable framework for structural analysis of logographic writing systems."}}
{"id": "2601.05578", "categories": ["cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2601.05578", "abs": "https://arxiv.org/abs/2601.05578", "authors": ["Cooper Lin", "Yanting Zhang", "Maohao Ran", "Wei Xue", "Hongwei Fan", "Yibo Xu", "Zhenglin Wan", "Sirui Han", "Yike Guo", "Jun Song"], "title": "Reinforcement Learning of Large Language Models for Interpretable Credit Card Fraud Detection", "comment": null, "summary": "E-commerce platforms and payment solution providers face increasingly sophisticated fraud schemes, ranging from identity theft and account takeovers to complex money laundering operations that exploit the speed and anonymity of digital transactions. However, despite their theoretical promise, the application of Large Language Models (LLMs) to fraud detection in real-world financial contexts remains largely unexploited, and their practical effectiveness in handling domain-specific e-commerce transaction data has yet to be empirically validated. To bridge this gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, this paper proposes a novel approach that employs Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection tasks using only raw transaction data. We utilize the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on a real-life transaction dataset provided by a Chinese global payment solution company. Through this reinforcement learning framework, the language models are encouraged to explore diverse trust and risk signals embedded within the textual transaction data, including patterns in customer information, shipping details, product descriptions, and order history. Our experimental results demonstrate the effectiveness of this approach, with post-trained language models achieving substantial F1-score improvements on held-out test data. Our findings demonstrate that the observed performance improvements are primarily attributable to the exploration mechanism inherent in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.", "AI": {"tldr": "This paper proposes using Reinforcement Learning (RL) with Group Sequence Policy Optimization (GSPO) to post-train lightweight language models for fraud detection on raw e-commerce transaction data, achieving significant F1-score improvements by discovering novel fraud indicators beyond traditional feature engineering.", "motivation": "Despite the theoretical promise of Large Language Models (LLMs) for fraud detection, their practical application in real-world financial contexts remains largely unexplored and unvalidated. E-commerce platforms face increasingly sophisticated fraud schemes, but current approaches have limitations in handling domain-specific transaction data effectively.", "method": "The paper proposes a novel approach using Reinforcement Learning (RL) to post-train lightweight language models specifically for fraud detection. It employs the Group Sequence Policy Optimization (GSPO) algorithm combined with a rule-based reward system to fine-tune language models of various sizes on real-life transaction data from a Chinese global payment solution company.", "result": "Experimental results demonstrate substantial F1-score improvements on held-out test data. The performance improvements are primarily attributed to the exploration mechanism in reinforcement learning, which allows models to discover novel fraud indicators beyond those captured by traditional engineered features.", "conclusion": "The research successfully bridges the gap between conventional machine learning limitations and the untapped potential of LLMs in fraud detection, showing that RL-based post-training enables language models to effectively explore diverse trust and risk signals in textual transaction data for improved fraud detection performance."}}
{"id": "2601.05537", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05537", "abs": "https://arxiv.org/abs/2601.05537", "authors": ["Wei Zhou", "Hong Huang", "Ruize Shi", "Bang Liu"], "title": "Scalable Heterogeneous Graph Learning via Heterogeneous-aware Orthogonal Prototype Experts", "comment": null, "summary": "Heterogeneous Graph Neural Networks(HGNNs) have advanced mainly through better encoders, yet their decoding/projection stage still relies on a single shared linear head, assuming it can map rich node embeddings to labels. We call this the Linear Projection Bottleneck: in heterogeneous graphs, contextual diversity and long-tail shifts make a global head miss fine semantics, overfit hub nodes, and underserve tail nodes. While Mixture-of-Experts(MoE) could help, naively applying it clashes with structural imbalance and risks expert collapse. We propose a Heterogeneous-aware Orthogonal Prototype Experts framework named HOPE, a plug-and-play replacement for the standard prediction head. HOPE uses learnable prototype-based routing to assign instances to experts by similarity, letting expert usage follow the natural long-tail distribution, and adds expert orthogonalization to encourage diversity and prevent collapse. Experiments on four real datasets show consistent gains across SOTA HGNN backbones with minimal overhead.", "AI": {"tldr": "HOPE framework replaces standard linear prediction heads in HGNNs with heterogeneous-aware orthogonal prototype experts to address the linear projection bottleneck in heterogeneous graphs.", "motivation": "Current HGNNs rely on single shared linear heads for decoding, which creates a \"Linear Projection Bottleneck\" - this approach fails to capture fine semantics in heterogeneous graphs, overfits hub nodes, and underserves tail nodes due to contextual diversity and long-tail shifts.", "method": "Proposes HOPE framework with learnable prototype-based routing that assigns instances to experts by similarity, allowing expert usage to follow natural long-tail distribution. Adds expert orthogonalization to encourage diversity and prevent expert collapse.", "result": "Experiments on four real datasets show consistent performance gains across state-of-the-art HGNN backbones with minimal computational overhead.", "conclusion": "HOPE provides an effective plug-and-play replacement for standard prediction heads in HGNNs, addressing the linear projection bottleneck through heterogeneous-aware expert routing and orthogonalization."}}
{"id": "2601.05511", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05511", "abs": "https://arxiv.org/abs/2601.05511", "authors": ["Xuan Cheng", "Jiahao Rao", "Chengyang Li", "Wenhao Wang", "Weilin Chen", "Lvqing Yang"], "title": "GaussianSwap: Animatable Video Face Swapping with 3D Gaussian Splatting", "comment": null, "summary": "We introduce GaussianSwap, a novel video face swapping framework that constructs a 3D Gaussian Splatting based face avatar from a target video while transferring identity from a source image to the avatar. Conventional video swapping frameworks are limited to generating facial representations in pixel-based formats. The resulting swapped faces exist merely as a set of unstructured pixels without any capacity for animation or interactive manipulation. Our work introduces a paradigm shift from conventional pixel-based video generation to the creation of high-fidelity avatar with swapped faces. The framework first preprocesses target video to extract FLAME parameters, camera poses and segmentation masks, and then rigs 3D Gaussian splats to the FLAME model across frames, enabling dynamic facial control. To ensure identity preserving, we propose an compound identity embedding constructed from three state-of-the-art face recognition models for avatar finetuning. Finally, we render the face-swapped avatar on the background frames to obtain the face-swapped video. Experimental results demonstrate that GaussianSwap achieves superior identity preservation, visual clarity and temporal consistency, while enabling previously unattainable interactive applications.", "AI": {"tldr": "GaussianSwap is a video face swapping framework that creates 3D Gaussian Splatting avatars from target videos while transferring identity from source images, enabling interactive manipulation and animation.", "motivation": "Conventional video face swapping frameworks are limited to pixel-based representations that lack animation or interactive manipulation capabilities. There's a need for a paradigm shift from pixel-based generation to creating high-fidelity avatars with swapped faces.", "method": "1) Preprocess target video to extract FLAME parameters, camera poses, and segmentation masks; 2) Rig 3D Gaussian splats to the FLAME model across frames for dynamic facial control; 3) Use compound identity embedding from three state-of-the-art face recognition models for avatar finetuning; 4) Render face-swapped avatar on background frames.", "result": "GaussianSwap achieves superior identity preservation, visual clarity, and temporal consistency compared to conventional methods, while enabling previously unattainable interactive applications.", "conclusion": "The framework successfully shifts from pixel-based video generation to creating high-fidelity avatars with swapped faces, opening new possibilities for interactive manipulation and animation in video face swapping applications."}}
{"id": "2601.05590", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05590", "abs": "https://arxiv.org/abs/2601.05590", "authors": ["Haoming Gong", "Qingyao Ai", "Zhihao Tao", "Yongfeng Zhang"], "title": "A Causal Information-Flow Framework for Unbiased Learning-to-Rank", "comment": null, "summary": "In web search and recommendation systems, user clicks are widely used to train ranking models. However, click data is heavily biased, i.e., users tend to click higher-ranked items (position bias), choose only what was shown to them (selection bias), and trust top results more (trust bias). Without explicitly modeling these biases, the true relevance of ranked items cannot be correctly learned from clicks. Existing Unbiased Learning-to-Rank (ULTR) methods mainly correct position bias and rely on propensity estimation, but they cannot measure remaining bias, provide risk guarantees, or jointly handle multiple bias sources. To overcome these challenges, this paper introduces a novel causal learning-based ranking framework that extends ULTR by combining Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify how clicks are generated and help identify the true relevance signal from click data, while conditional mutual information, measures how much bias leaks into the\n  learned relevance estimates. We use this leakage measure to define a rigorous notion of disentanglement and include it as a regularizer during model training to reduce bias. In addition, we incorporate a causal inference estimator, i.e., doubly robust estimator, to ensure more reliable risk estimation. Experiments on standard Learning-to-Rank benchmarks show that our method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases-such as position and trust bias-interact strongly.", "AI": {"tldr": "A causal learning framework for unbiased learning-to-rank that uses structural causal models and information theory to measure and reduce multiple biases in click data.", "motivation": "Click data in web search and recommendation systems suffers from multiple biases (position, selection, trust biases) that prevent learning true relevance. Existing ULTR methods mainly correct position bias but cannot measure remaining bias, provide risk guarantees, or handle multiple bias sources jointly.", "method": "Combines Structural Causal Models (SCMs) with information-theoretic tools. SCMs specify click generation and identify true relevance, while conditional mutual information measures bias leakage. Uses this leakage measure as a regularizer during training and incorporates doubly robust estimator for reliable risk estimation.", "result": "Experiments on standard Learning-to-Rank benchmarks show the method consistently reduces measured bias leakage and improves ranking performance, especially in realistic scenarios where multiple biases (position and trust bias) interact strongly.", "conclusion": "The proposed causal learning framework effectively addresses limitations of existing ULTR methods by providing a way to measure and reduce multiple biases simultaneously through SCMs and information theory, leading to better ranking performance."}}
{"id": "2601.05544", "categories": ["cs.LG", "math.OC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.05544", "abs": "https://arxiv.org/abs/2601.05544", "authors": ["Moe Shiina", "Shunnosuke Ikeda", "Yuichi Takano"], "title": "Buffered AUC maximization for scoring systems via mixed-integer optimization", "comment": null, "summary": "A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.", "AI": {"tldr": "MILO framework for building scoring systems that directly maximize buffered AUC (bAUC) as tightest concave lower bound on AUC, outperforming baseline methods.", "motivation": "Previous MIO techniques for scoring systems haven't focused on directly maximizing AUC, which is essential for scoring system evaluation. Need for interpretable classification models that optimize AUC directly.", "method": "Mixed-integer linear optimization (MILO) framework that maximizes buffered AUC (bAUC) subject to group sparsity constraint to limit number of questions in scoring system.", "result": "Computational experiments on real-world datasets show MILO method builds scoring systems with superior AUC values compared to baseline methods based on regularization and stepwise regression.", "conclusion": "Research advances MIO techniques for developing highly interpretable classification models by directly optimizing AUC through buffered AUC maximization."}}
{"id": "2601.05535", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05535", "abs": "https://arxiv.org/abs/2601.05535", "authors": ["Qiwei Yang", "Pingping Zhang", "Yuhao Wang", "Zijing Gong"], "title": "SAS-VPReID: A Scale-Adaptive Framework with Shape Priors for Video-based Person Re-Identification at Extreme Far Distances", "comment": "Accepted by WACV2026 VReID-XFD Workshop. Our final framework ranks the first on the VReID-XFD challenge leaderboard", "summary": "Video-based Person Re-IDentification (VPReID) aims to retrieve the same person from videos captured by non-overlapping cameras. At extreme far distances, VPReID is highly challenging due to severe resolution degradation, drastic viewpoint variation and inevitable appearance noise. To address these issues, we propose a Scale-Adaptive framework with Shape Priors for VPReID, named SAS-VPReID. The framework is built upon three complementary modules. First, we deploy a Memory-Enhanced Visual Backbone (MEVB) to extract discriminative feature representations, which leverages the CLIP vision encoder and multi-proxy memory. Second, we propose a Multi-Granularity Temporal Modeling (MGTM) to construct sequences at multiple temporal granularities and adaptively emphasize motion cues across scales. Third, we incorporate Prior-Regularized Shape Dynamics (PRSD) to capture body structure dynamics. With these modules, our framework can obtain more discriminative feature representations. Experiments on the VReID-XFD benchmark demonstrate the effectiveness of each module and our final framework ranks the first on the VReID-XFD challenge leaderboard. The source code is available at https://github.com/YangQiWei3/SAS-VPReID.", "AI": {"tldr": "SAS-VPReID: A scale-adaptive framework with shape priors for video-based person re-identification at extreme far distances, achieving state-of-the-art performance on VReID-XFD benchmark.", "motivation": "Video-based person re-identification at extreme far distances is highly challenging due to severe resolution degradation, drastic viewpoint variation, and inevitable appearance noise.", "method": "Three complementary modules: 1) Memory-Enhanced Visual Backbone (MEVB) using CLIP vision encoder and multi-proxy memory, 2) Multi-Granularity Temporal Modeling (MGTM) for adaptive motion cue emphasis across scales, 3) Prior-Regularized Shape Dynamics (PRSD) to capture body structure dynamics.", "result": "Achieves state-of-the-art performance on VReID-XFD benchmark, ranking first on the challenge leaderboard. Each module demonstrates effectiveness through experiments.", "conclusion": "The proposed SAS-VPReID framework effectively addresses extreme far-distance VPReID challenges through scale adaptation and shape priors, obtaining more discriminative feature representations."}}
{"id": "2601.05629", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05629", "abs": "https://arxiv.org/abs/2601.05629", "authors": ["Jiapu Wang", "Xinghe Cheng", "Zezheng Wu", "Ruiqi Ma", "Rui Wang", "Zhichao Yan", "Haoran Luo", "Yuhao Jiang", "Kai Sun"], "title": "Cumulative Path-Level Semantic Reasoning for Inductive Knowledge Graph Completion", "comment": null, "summary": "Conventional Knowledge Graph Completion (KGC) methods aim to infer missing information in incomplete Knowledge Graphs (KGs) by leveraging existing information, which struggle to perform effectively in scenarios involving emerging entities. Inductive KGC methods can handle the emerging entities and relations in KGs, offering greater dynamic adaptability. While existing inductive KGC methods have achieved some success, they also face challenges, such as susceptibility to noisy structural information during reasoning and difficulty in capturing long-range dependencies in reasoning paths. To address these challenges, this paper proposes the Cumulative Path-Level Semantic Reasoning for inductive knowledge graph completion (CPSR) framework, which simultaneously captures both the structural and semantic information of KGs to enhance the inductive KGC task. Specifically, the proposed CPSR employs a query-dependent masking module to adaptively mask noisy structural information while retaining important information closely related to the targets. Additionally, CPSR introduces a global semantic scoring module that evaluates both the individual contributions and the collective impact of nodes along the reasoning path within KGs. The experimental results demonstrate that CPSR achieves state-of-the-art performance.", "AI": {"tldr": "CPSR framework improves inductive KGC by masking noisy structural information and evaluating path-level semantics, achieving state-of-the-art performance.", "motivation": "Conventional KGC methods struggle with emerging entities, while existing inductive KGC methods face challenges with noisy structural information and difficulty capturing long-range dependencies in reasoning paths.", "method": "Proposes CPSR framework with: 1) query-dependent masking module to adaptively mask noisy structural information while retaining target-relevant information, and 2) global semantic scoring module that evaluates individual and collective contributions of nodes along reasoning paths.", "result": "CPSR achieves state-of-the-art performance in inductive knowledge graph completion tasks.", "conclusion": "The CPSR framework effectively addresses challenges in inductive KGC by simultaneously capturing structural and semantic information through adaptive noise masking and path-level semantic reasoning."}}
{"id": "2601.05583", "categories": ["cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.05583", "abs": "https://arxiv.org/abs/2601.05583", "authors": ["Xue Feng", "Li Wang", "Deanna Needell", "Rongjie Lai"], "title": "Learn to Evolve: Self-supervised Neural JKO Operator for Wasserstein Gradient Flow", "comment": null, "summary": "The Jordan-Kinderlehrer-Otto (JKO) scheme provides a stable variational framework for computing Wasserstein gradient flows, but its practical use is often limited by the high computational cost of repeatedly solving the JKO subproblems. We propose a self-supervised approach for learning a JKO solution operator without requiring numerical solutions of any JKO trajectories. The learned operator maps an input density directly to the minimizer of the corresponding JKO subproblem, and can be iteratively applied to efficiently generate the gradient-flow evolution. A key challenge is that only a number of initial densities are typically available for training. To address this, we introduce a Learn-to-Evolve algorithm that jointly learns the JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. As training progresses, the generated data increasingly approximates true JKO trajectories. Meanwhile, this Learn-to-Evolve strategy serves as a natural form of data augmentation, significantly enhancing the generalization ability of the learned operator. Numerical experiments demonstrate the accuracy, stability, and robustness of the proposed method across various choices of energies and initial conditions.", "AI": {"tldr": "Self-supervised learning of JKO solution operator without numerical JKO trajectories, using Learn-to-Evolve algorithm for joint operator learning and trajectory generation.", "motivation": "The JKO scheme is computationally expensive due to repeated solving of subproblems. Need efficient method to compute Wasserstein gradient flows without solving JKO trajectories numerically.", "method": "Learn-to-Evolve algorithm that jointly learns JKO operator and its induced trajectories by alternating between trajectory generation and operator updates. Self-supervised approach using only initial densities for training.", "result": "Method demonstrates accuracy, stability, and robustness across various energies and initial conditions. Generated data approximates true JKO trajectories, and strategy serves as data augmentation enhancing generalization.", "conclusion": "Proposed approach efficiently learns JKO solution operator without numerical JKO trajectories, overcoming computational limitations while maintaining accuracy and generalization ability."}}
{"id": "2601.05538", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05538", "abs": "https://arxiv.org/abs/2601.05538", "authors": ["Yiming Sun", "Zifan Ye", "Qinghua Hu", "Pengfei Zhu"], "title": "DIFF-MF: A Difference-Driven Channel-Spatial State Space Model for Multi-Modal Image Fusion", "comment": null, "summary": "Multi-modal image fusion aims to integrate complementary information from multiple source images to produce high-quality fused images with enriched content. Although existing approaches based on state space model have achieved satisfied performance with high computational efficiency, they tend to either over-prioritize infrared intensity at the cost of visible details, or conversely, preserve visible structure while diminishing thermal target salience. To overcome these challenges, we propose DIFF-MF, a novel difference-driven channel-spatial state space model for multi-modal image fusion. Our approach leverages feature discrepancy maps between modalities to guide feature extraction, followed by a fusion process across both channel and spatial dimensions. In the channel dimension, a channel-exchange module enhances channel-wise interaction through cross-attention dual state space modeling, enabling adaptive feature reweighting. In the spatial dimension, a spatial-exchange module employs cross-modal state space scanning to achieve comprehensive spatial fusion. By efficiently capturing global dependencies while maintaining linear computational complexity, DIFF-MF effectively integrates complementary multi-modal features. Experimental results on the driving scenarios and low-altitude UAV datasets demonstrate that our method outperforms existing approaches in both visual quality and quantitative evaluation.", "AI": {"tldr": "DIFF-MF: A difference-driven channel-spatial state space model for multi-modal image fusion that addresses the trade-off between infrared intensity and visible details by leveraging feature discrepancy maps and dual-dimensional fusion.", "motivation": "Existing state space model approaches for multi-modal image fusion tend to either over-prioritize infrared intensity at the cost of visible details, or preserve visible structure while diminishing thermal target salience. There's a need for a method that better balances these complementary modalities.", "method": "DIFF-MF uses feature discrepancy maps between modalities to guide feature extraction, followed by dual-dimensional fusion: 1) Channel dimension: channel-exchange module with cross-attention dual state space modeling for adaptive feature reweighting; 2) Spatial dimension: spatial-exchange module with cross-modal state space scanning for comprehensive spatial fusion. The approach maintains linear computational complexity while capturing global dependencies.", "result": "Experimental results on driving scenarios and low-altitude UAV datasets demonstrate that DIFF-MF outperforms existing approaches in both visual quality and quantitative evaluation.", "conclusion": "DIFF-MF effectively integrates complementary multi-modal features by addressing the limitations of existing state space models, achieving better balance between infrared intensity and visible details through its difference-driven, dual-dimensional fusion approach."}}
{"id": "2601.05637", "categories": ["cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05637", "abs": "https://arxiv.org/abs/2601.05637", "authors": ["Emily Cheng", "Carmen Amo Alonso", "Federico Danieli", "Arno Blaas", "Luca Zappella", "Pau Rodriguez", "Xavier Suau"], "title": "GenCtrl -- A Formal Controllability Toolkit for Generative Models", "comment": null, "summary": "As generative models become ubiquitous, there is a critical need for fine-grained control over the generation process. Yet, while controlled generation methods from prompting to fine-tuning proliferate, a fundamental question remains unanswered: are these models truly controllable in the first place? In this work, we provide a theoretical framework to formally answer this question. Framing human-model interaction as a control process, we propose a novel algorithm to estimate the controllable sets of models in a dialogue setting. Notably, we provide formal guarantees on the estimation error as a function of sample complexity: we derive probably-approximately correct bounds for controllable set estimates that are distribution-free, employ no assumptions except for output boundedness, and work for any black-box nonlinear control system (i.e., any generative model). We empirically demonstrate the theoretical framework on different tasks in controlling dialogue processes, for both language models and text-to-image generation. Our results show that model controllability is surprisingly fragile and highly dependent on the experimental setting. This highlights the need for rigorous controllability analysis, shifting the focus from simply attempting control to first understanding its fundamental limits.", "AI": {"tldr": "Theoretical framework for analyzing controllability of generative models with formal guarantees on estimation error, showing model controllability is fragile and dependent on experimental settings.", "motivation": "As generative models become ubiquitous, there's a need for fine-grained control over generation, but fundamental questions remain about whether these models are truly controllable in the first place.", "method": "Framing human-model interaction as a control process, proposing a novel algorithm to estimate controllable sets of models in dialogue settings with formal probably-approximately correct bounds that are distribution-free and work for any black-box nonlinear control system.", "result": "Empirical demonstration on different tasks controlling dialogue processes for both language models and text-to-image generation shows model controllability is surprisingly fragile and highly dependent on experimental settings.", "conclusion": "Highlights the need for rigorous controllability analysis, shifting focus from simply attempting control to first understanding its fundamental limits."}}
{"id": "2601.05586", "categories": ["cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05586", "abs": "https://arxiv.org/abs/2601.05586", "authors": ["Shufei Ge", "Shijia Wang", "Lloyd Elliott"], "title": "Poisson Hyperplane Processes with Rectified Linear Units", "comment": null, "summary": "Neural networks have shown state-of-the-art performances in various classification and regression tasks. Rectified linear units (ReLU) are often used as activation functions for the hidden layers in a neural network model. In this article, we establish the connection between the Poisson hyperplane processes (PHP) and two-layer ReLU neural networks. We show that the PHP with a Gaussian prior is an alternative probabilistic representation to a two-layer ReLU neural network. In addition, we show that a two-layer neural network constructed by PHP is scalable to large-scale problems via the decomposition propositions. Finally, we propose an annealed sequential Monte Carlo algorithm for Bayesian inference. Our numerical experiments demonstrate that our proposed method outperforms the classic two-layer ReLU neural network. The implementation of our proposed model is available at https://github.com/ShufeiGe/Pois_Relu.git.", "AI": {"tldr": "The paper establishes a connection between Poisson hyperplane processes (PHP) and two-layer ReLU neural networks, showing PHP with Gaussian prior is an alternative probabilistic representation to ReLU networks.", "motivation": "To provide an alternative probabilistic representation for two-layer ReLU neural networks using Poisson hyperplane processes, enabling scalability to large-scale problems and improved Bayesian inference.", "method": "Establishes mathematical connection between PHP and ReLU networks, shows PHP with Gaussian prior as probabilistic representation, proposes decomposition propositions for scalability, and develops annealed sequential Monte Carlo algorithm for Bayesian inference.", "result": "Numerical experiments demonstrate the proposed method outperforms classic two-layer ReLU neural networks. Implementation is available on GitHub.", "conclusion": "PHP provides an effective alternative probabilistic framework for two-layer ReLU networks with better scalability and performance through Bayesian inference techniques."}}
{"id": "2601.05546", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05546", "abs": "https://arxiv.org/abs/2601.05546", "authors": ["Yanfeng Li", "Yue Sun", "Keren Fu", "Sio-Kei Im", "Xiaoming Liu", "Guangtao Zhai", "Xiaohong Liu", "Tao Tan"], "title": "MoGen: A Unified Collaborative Framework for Controllable Multi-Object Image Generation", "comment": null, "summary": "Existing multi-object image generation methods face difficulties in achieving precise alignment between localized image generation regions and their corresponding semantics based on language descriptions, frequently resulting in inconsistent object quantities and attribute aliasing. To mitigate this limitation, mainstream approaches typically rely on external control signals to explicitly constrain the spatial layout, local semantic and visual attributes of images. However, this strong dependency makes the input format rigid, rendering it incompatible with the heterogeneous resource conditions of users and diverse constraint requirements. To address these challenges, we propose MoGen, a user-friendly multi-object image generation method. First, we design a Regional Semantic Anchor (RSA) module that precisely anchors phrase units in language descriptions to their corresponding image regions during the generation process, enabling text-to-image generation that follows quantity specifications for multiple objects. Building upon this foundation, we further introduce an Adaptive Multi-modal Guidance (AMG) module, which adaptively parses and integrates various combinations of multi-source control signals to formulate corresponding structured intent. This intent subsequently guides selective constraints on scene layouts and object attributes, achieving dynamic fine-grained control. Experimental results demonstrate that MoGen significantly outperforms existing methods in generation quality, quantity consistency, and fine-grained control, while exhibiting superior accessibility and control flexibility. Code is available at: https://github.com/Tear-kitty/MoGen/tree/master.", "AI": {"tldr": "MoGen: A user-friendly multi-object image generation method that achieves precise semantic alignment and flexible multi-modal control without rigid input dependencies.", "motivation": "Existing multi-object image generation methods struggle with precise alignment between language descriptions and image regions, leading to inconsistent object quantities and attribute aliasing. Current approaches rely heavily on external control signals, making input formats rigid and incompatible with diverse user resource conditions and constraint requirements.", "method": "Two key modules: 1) Regional Semantic Anchor (RSA) module that precisely anchors phrase units in language descriptions to corresponding image regions, enabling text-to-image generation with accurate object quantity specifications. 2) Adaptive Multi-modal Guidance (AMG) module that adaptively parses and integrates various multi-source control signals to formulate structured intent for selective constraints on scene layouts and object attributes.", "result": "Experimental results show MoGen significantly outperforms existing methods in generation quality, quantity consistency, and fine-grained control, while demonstrating superior accessibility and control flexibility.", "conclusion": "MoGen provides a user-friendly solution for multi-object image generation that achieves precise semantic alignment and dynamic fine-grained control without rigid input dependencies, offering better accessibility and flexibility compared to existing approaches."}}
{"id": "2601.05656", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05656", "abs": "https://arxiv.org/abs/2601.05656", "authors": ["Rongxin Chen", "Tianyu Wu", "Bingbing Xu", "Xiucheng Xu", "Huawei Shen"], "title": "HAG: Hierarchical Demographic Tree-based Agent Generation for Topic-Adaptive Simulation", "comment": null, "summary": "High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains. A robust framework should be Topic-Adaptive, capturing macro-level joint distributions while ensuring micro-level individual rationality. Existing approaches fall into two categories: static data-based retrieval methods that fail to adapt to unseen topics absent from the data, and LLM-based generation methods that lack macro-level distribution awareness, resulting in inconsistencies between micro-level persona attributes and reality. To address these problems, we propose HAG, a Hierarchical Agent Generation framework that formalizes population generation as a two-stage decision process. Firstly, utilizing a World Knowledge Model to infer hierarchical conditional probabilities to construct the Topic-Adaptive Tree, achieving macro-level distribution alignment. Then, grounded real-world data, instantiation and agentic augmentation are carried out to ensure micro-level consistency. Given the lack of specialized evaluation, we establish a multi-domain benchmark and a comprehensive PACE evaluation framework. Extensive experiments show that HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%.", "AI": {"tldr": "HAG: Hierarchical Agent Generation framework for high-fidelity agent initialization in Agent-Based Modeling that combines macro-level distribution alignment with micro-level individual rationality through a two-stage approach.", "motivation": "Existing agent initialization methods have limitations: static data-based retrieval fails to adapt to unseen topics, while LLM-based generation lacks macro-level distribution awareness, leading to inconsistencies between persona attributes and reality. High-fidelity agent initialization is crucial for credible Agent-Based Modeling across diverse domains.", "method": "HAG formalizes population generation as a two-stage decision process: 1) Uses a World Knowledge Model to infer hierarchical conditional probabilities to construct a Topic-Adaptive Tree for macro-level distribution alignment; 2) Grounded in real-world data, performs instantiation and agentic augmentation to ensure micro-level consistency.", "result": "HAG significantly outperforms representative baselines, reducing population alignment errors by an average of 37.7% and enhancing sociological consistency by 18.8%. The authors also establish a multi-domain benchmark and comprehensive PACE evaluation framework.", "conclusion": "HAG addresses the limitations of existing approaches by providing a robust framework that is Topic-Adaptive, captures macro-level joint distributions while ensuring micro-level individual rationality, making it suitable for high-fidelity agent initialization in Agent-Based Modeling."}}
{"id": "2601.05593", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05593", "abs": "https://arxiv.org/abs/2601.05593", "authors": ["Jingcheng Hu", "Yinmin Zhang", "Shijie Shang", "Xiaobo Yang", "Yue Peng", "Zhewei Huang", "Hebin Zhou", "Xin Wu", "Jie Cheng", "Fanqi Wan", "Xiangwen Kong", "Chengyuan Yao", "Kaiwen Yan", "Ailin Huang", "Hongyu Zhou", "Qi Han", "Zheng Ge", "Daxin Jiang", "Xiangyu Zhang", "Heung-Yeung Shum"], "title": "PaCoRe: Learning to Scale Test-Time Compute with Parallel Coordinated Reasoning", "comment": null, "summary": "We introduce Parallel Coordinated Reasoning (PaCoRe), a training-and-inference framework designed to overcome a central limitation of contemporary language models: their inability to scale test-time compute (TTC) far beyond sequential reasoning under a fixed context window. PaCoRe departs from the traditional sequential paradigm by driving TTC through massive parallel exploration coordinated via a message-passing architecture in multiple rounds. Each round launches many parallel reasoning trajectories, compacts their findings into context-bounded messages, and synthesizes these messages to guide the next round and ultimately produce the final answer. Trained end-to-end with large-scale, outcome-based reinforcement learning, the model masters the synthesis abilities required by PaCoRe and scales to multi-million-token effective TTC without exceeding context limits. The approach yields strong improvements across diverse domains, and notably pushes reasoning beyond frontier systems in mathematics: an 8B model reaches 94.5% on HMMT 2025, surpassing GPT-5's 93.2% by scaling effective TTC to roughly two million tokens. We open-source model checkpoints, training data, and the full inference pipeline to accelerate follow-up work.", "AI": {"tldr": "PaCoRe enables language models to massively scale test-time compute through parallel coordinated reasoning, achieving state-of-the-art math performance with an 8B model surpassing GPT-5.", "motivation": "Current language models are limited by their inability to scale test-time compute beyond sequential reasoning under fixed context windows, restricting their reasoning capabilities.", "method": "A training-and-inference framework using parallel exploration coordinated via message-passing architecture in multiple rounds, with end-to-end reinforcement learning to master synthesis abilities.", "result": "Strong improvements across diverse domains; 8B model achieves 94.5% on HMMT 2025 math benchmark (surpassing GPT-5's 93.2%) by scaling effective test-time compute to ~2 million tokens without exceeding context limits.", "conclusion": "PaCoRe successfully overcomes the test-time compute scaling limitation of language models, enabling massive parallel reasoning and achieving state-of-the-art performance while being open-sourced for community advancement."}}
{"id": "2601.05547", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05547", "abs": "https://arxiv.org/abs/2601.05547", "authors": ["Feiran Zhang", "Yixin Wu", "Zhenghua Wang", "Xiaohua Wang", "Changze Lv", "Xuanjing Huang", "Xiaoqing Zheng"], "title": "VIB-Probe: Detecting and Mitigating Hallucinations in Vision-Language Models via Variational Information Bottleneck", "comment": null, "summary": "Vision-Language Models (VLMs) have demonstrated remarkable progress in multimodal tasks, but remain susceptible to hallucinations, where generated text deviates from the underlying visual content. Existing hallucination detection methods primarily rely on output logits or external verification tools, often overlooking their internal mechanisms. In this work, we investigate the outputs of internal attention heads, postulating that specific heads carry the primary signals for truthful generation.However, directly probing these high-dimensional states is challenging due to the entanglement of visual-linguistic syntax and noise. To address this, we propose VIB-Probe, a novel hallucination detection and mitigation framework leveraging the Variational Information Bottleneck (VIB) theory. Our method extracts discriminative patterns across layers and heads while filtering out semantic nuisances through the information bottleneck principle. Furthermore, by leveraging the gradients of our VIB probe, we identify attention heads with strong causal influence on hallucinations and introduce an inference-time intervention strategy for hallucination mitigation. Extensive experiments across diverse benchmarks demonstrate that VIB-Probe significantly outperforms existing baselines in both settings. Our code will be made publicly available.", "AI": {"tldr": "VIB-Probe uses Variational Information Bottleneck theory to detect and mitigate hallucinations in Vision-Language Models by analyzing internal attention heads and filtering out noise.", "motivation": "VLMs suffer from hallucinations where generated text deviates from visual content. Existing methods rely on output logits or external tools, overlooking internal mechanisms. The authors aim to understand and address hallucinations by examining internal attention heads.", "method": "Proposes VIB-Probe framework using Variational Information Bottleneck theory to extract discriminative patterns from attention heads while filtering out semantic noise. Uses gradients to identify attention heads with causal influence on hallucinations and introduces inference-time intervention for mitigation.", "result": "Extensive experiments across diverse benchmarks show VIB-Probe significantly outperforms existing baselines in both hallucination detection and mitigation settings.", "conclusion": "VIB-Probe effectively addresses VLM hallucinations by leveraging internal attention mechanisms through information bottleneck principles, offering both detection and mitigation capabilities with superior performance over existing methods."}}
{"id": "2601.05675", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05675", "abs": "https://arxiv.org/abs/2601.05675", "authors": ["Bingyi Liu", "Jinbo He", "Haiyong Shi", "Enshu Wang", "Weizhen Han", "Jingxiang Hao", "Peixi Wang", "Zhuangzhuang Zhang"], "title": "CHDP: Cooperative Hybrid Diffusion Policies for Reinforcement Learning in Parameterized Action Space", "comment": "Accepted by AAAI 2026", "summary": "Hybrid action space, which combines discrete choices and continuous parameters, is prevalent in domains such as robot control and game AI. However, efficiently modeling and optimizing hybrid discrete-continuous action space remains a fundamental challenge, mainly due to limited policy expressiveness and poor scalability in high-dimensional settings. To address this challenge, we view the hybrid action space problem as a fully cooperative game and propose a \\textbf{Cooperative Hybrid Diffusion Policies (CHDP)} framework to solve it. CHDP employs two cooperative agents that leverage a discrete and a continuous diffusion policy, respectively. The continuous policy is conditioned on the discrete action's representation, explicitly modeling the dependency between them. This cooperative design allows the diffusion policies to leverage their expressiveness to capture complex distributions in their respective action spaces. To mitigate the update conflicts arising from simultaneous policy updates in this cooperative setting, we employ a sequential update scheme that fosters co-adaptation. Moreover, to improve scalability when learning in high-dimensional discrete action space, we construct a codebook that embeds the action space into a low-dimensional latent space. This mapping enables the discrete policy to learn in a compact, structured space. Finally, we design a Q-function-based guidance mechanism to align the codebook's embeddings with the discrete policy's representation during training. On challenging hybrid action benchmarks, CHDP outperforms the state-of-the-art method by up to $19.3\\%$ in success rate.", "AI": {"tldr": "CHDP is a cooperative diffusion framework for hybrid action spaces that uses discrete and continuous agents with sequential updates and codebook embeddings to improve policy expressiveness and scalability.", "motivation": "Hybrid action spaces (discrete choices + continuous parameters) are common in robotics and games but challenging to optimize due to limited policy expressiveness and poor scalability in high dimensions.", "method": "1) Treat hybrid action space as cooperative game with discrete & continuous diffusion agents; 2) Continuous policy conditioned on discrete action representation; 3) Sequential update scheme to avoid conflicts; 4) Codebook to embed high-dim discrete actions into low-dim latent space; 5) Q-function guidance to align embeddings.", "result": "Outperforms state-of-the-art by up to 19.3% in success rate on challenging hybrid action benchmarks.", "conclusion": "CHDP effectively addresses hybrid action space challenges through cooperative diffusion policies, sequential updates, and codebook embeddings, achieving significant performance improvements."}}
{"id": "2601.05597", "categories": ["cs.LG", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.05597", "abs": "https://arxiv.org/abs/2601.05597", "authors": ["S\u00edlvia Casacuberta", "Moritz Hardt"], "title": "Good Allocations from Bad Estimates", "comment": null, "summary": "Conditional average treatment effect (CATE) estimation is the de facto gold standard for targeting a treatment to a heterogeneous population. The method estimates treatment effects up to an error $\u03b5> 0$ in each of $M$ different strata of the population, targeting individuals in decreasing order of estimated treatment effect until the budget runs out. In general, this method requires $O(M/\u03b5^2)$ samples. This is best possible if the goal is to estimate all treatment effects up to an $\u03b5$ error. In this work, we show how to achieve the same total treatment effect as CATE with only $O(M/\u03b5)$ samples for natural distributions of treatment effects. The key insight is that coarse estimates suffice for near-optimal treatment allocations. In addition, we show that budget flexibility can further reduce the sample complexity of allocation. Finally, we evaluate our algorithm on various real-world RCT datasets. In all cases, it finds nearly optimal treatment allocations with surprisingly few samples. Our work highlights the fundamental distinction between treatment effect estimation and treatment allocation: the latter requires far fewer samples.", "AI": {"tldr": "This paper shows that treatment allocation requires far fewer samples than treatment effect estimation - O(M/\u03b5) vs O(M/\u03b5\u00b2) - by using coarse estimates for near-optimal allocations.", "motivation": "CATE estimation is the gold standard for targeting treatments but requires O(M/\u03b5\u00b2) samples, which may be excessive when the goal is treatment allocation rather than precise effect estimation.", "method": "Develops algorithms that achieve the same total treatment effect as CATE with only O(M/\u03b5) samples by leveraging coarse estimates and budget flexibility, and evaluates on real-world RCT datasets.", "result": "The algorithm finds nearly optimal treatment allocations with surprisingly few samples across various real-world RCT datasets, demonstrating that treatment allocation requires far fewer samples than estimation.", "conclusion": "There's a fundamental distinction between treatment effect estimation and treatment allocation - the latter requires far fewer samples, enabling more efficient resource allocation in heterogeneous populations."}}
{"id": "2601.05552", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05552", "abs": "https://arxiv.org/abs/2601.05552", "authors": ["Bin-Bin Gao", "Chengjie Wang"], "title": "One Language-Free Foundation Model Is Enough for Universal Vision Anomaly Detection", "comment": "20 pages, 5 figures, 34 tabels", "summary": "Universal visual anomaly detection (AD) aims to identify anomaly images and segment anomaly regions towards open and dynamic scenarios, following zero- and few-shot paradigms without any dataset-specific fine-tuning. We have witnessed significant progress in widely use of visual-language foundational models in recent approaches. However, current methods often struggle with complex prompt engineering, elaborate adaptation modules, and challenging training strategies, ultimately limiting their flexibility and generality. To address these issues, this paper rethinks the fundamental mechanism behind visual-language models for AD and presents an embarrassingly simple, general, and effective framework for Universal vision Anomaly Detection (UniADet). Specifically, we first find language encoder is used to derive decision weights for anomaly classification and segmentation, and then demonstrate that it is unnecessary for universal AD. Second, we propose an embarrassingly simple method to completely decouple classification and segmentation, and decouple cross-level features, i.e., learning independent weights for different tasks and hierarchical features. UniADet is highly simple (learning only decoupled weights), parameter-efficient (only 0.002M learnable parameters), general (adapting a variety of foundation models), and effective (surpassing state-of-the-art zero-/few-shot by a large margin and even full-shot AD methods for the first time) on 14 real-world AD benchmarks covering both industrial and medical domains. We will make the code and model of UniADet available at https://github.com/gaobb/UniADet.", "AI": {"tldr": "UniADet is a simple, parameter-efficient universal anomaly detection framework that decouples classification and segmentation tasks, requiring only 0.002M learnable parameters while outperforming state-of-the-art methods across 14 benchmarks.", "motivation": "Current visual-language models for anomaly detection suffer from complex prompt engineering, elaborate adaptation modules, and challenging training strategies, limiting their flexibility and generality for universal anomaly detection in open and dynamic scenarios.", "method": "The framework completely decouples classification and segmentation tasks, and decouples cross-level features by learning independent weights for different tasks and hierarchical features, eliminating the need for language encoders in the decision process.", "result": "UniADet surpasses state-of-the-art zero-/few-shot methods by a large margin and even outperforms full-shot AD methods for the first time across 14 real-world AD benchmarks covering industrial and medical domains.", "conclusion": "The proposed embarrassingly simple approach demonstrates that language encoders are unnecessary for universal AD, and that decoupling tasks and features leads to a highly effective, parameter-efficient framework that sets new state-of-the-art performance."}}
{"id": "2601.05693", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05693", "abs": "https://arxiv.org/abs/2601.05693", "authors": ["Zenghao Duan", "Liang Pang", "Zihao Wei", "Wenbin Duan", "Yuxin Tian", "Shicheng Xu", "Jingcheng Deng", "Zhiyi Yin", "Xueqi Cheng"], "title": "Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models", "comment": null, "summary": "Despite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.", "AI": {"tldr": "The paper identifies \"Circular Reasoning\" as a failure mode in Large Reasoning Models where they get stuck in repetitive loops, introduces LoopBench dataset to study this, analyzes the mechanism as state collapse with self-reinforcing attention, and proposes using CUSUM algorithm for early loop prediction.", "motivation": "Large Reasoning Models frequently encounter repetitive loops during test-time scaling that lead to computational waste and inference failure. The authors identify a distinct failure mode called Circular Reasoning where models get trapped in self-reinforcing cycles of repetition.", "method": "1) Introduce LoopBench dataset to capture numerical and statement loops; 2) Mechanistically characterize circular reasoning as state collapse with distinct boundaries; 3) Analyze the self-reinforcing V-shaped attention mechanism; 4) Employ Cumulative Sum (CUSUM) algorithm to capture precursors for early loop prediction.", "result": "Experiments across diverse LRMs validate the accuracy of the CUSUM-based early loop prediction approach and elucidate the stability of long-chain reasoning. The method successfully captures loop precursors and helps understand the failure mechanisms.", "conclusion": "Circular reasoning is a distinct failure mode in LRMs characterized by self-reinforcing traps. The proposed CUSUM-based approach effectively predicts loops early, providing insights into reasoning stability and offering practical solutions to computational waste from repetitive loops."}}
{"id": "2601.05607", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05607", "abs": "https://arxiv.org/abs/2601.05607", "authors": ["Zijun Min", "Bingshuai Liu", "Ante Wang", "Long Zhang", "Anxiang Zeng", "Haibo Zhang", "Jinsong Su"], "title": "Orchestrating Tokens and Sequences: Dynamic Hybrid Policy Optimization for RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a promising framework for optimizing large language models in reasoning tasks. However, existing RLVR algorithms focus on different granularities, and each has complementary strengths and limitations. Group Relative Policy Optimization (GRPO) updates the policy with token-level importance ratios, which preserves fine-grained credit assignment but often suffers from high variance and instability. In contrast, Group Sequence Policy Optimization (GSPO) applies single sequence-level importance ratios across all tokens in a response that better matches sequence-level rewards, but sacrifices token-wise credit assignment. In this paper, we propose Dynamic Hybrid Policy Optimization (DHPO) to bridge GRPO and GSPO within a single clipped surrogate objective. DHPO combines token-level and sequence-level importance ratios using weighting mechanisms. We explore two variants of the mixing mechanism, including an averaged mixing and an entropy-guided mixing. To further stabilize training, we employ a branch-specific clipping strategy that constrains token-level and sequence-level ratios within separate trust regions before mixing, preventing outliers in either branch from dominating the update. Across seven challenging mathematical reasoning benchmarks, experiments on both dense and MoE models from the Qwen3 series show that DHPO consistently outperforms GRPO and GSPO. We will release our code upon acceptance of this paper.", "AI": {"tldr": "DHPO bridges token-level (GRPO) and sequence-level (GSPO) RLVR approaches via dynamic hybrid mixing with branch-specific clipping, achieving superior performance on math reasoning tasks.", "motivation": "Existing RLVR algorithms have complementary limitations: GRPO preserves fine-grained credit assignment but suffers from high variance, while GSPO matches sequence-level rewards better but sacrifices token-wise credit assignment.", "method": "Proposes Dynamic Hybrid Policy Optimization (DHPO) that combines token-level and sequence-level importance ratios within a single clipped surrogate objective. Uses two mixing variants (averaged and entropy-guided) and branch-specific clipping to constrain ratios in separate trust regions before mixing.", "result": "DHPO consistently outperforms GRPO and GSPO across seven challenging mathematical reasoning benchmarks on both dense and MoE models from the Qwen3 series.", "conclusion": "DHPO successfully bridges the gap between token-level and sequence-level RLVR approaches, providing a more stable and effective optimization framework for language model reasoning tasks."}}
{"id": "2601.05556", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05556", "abs": "https://arxiv.org/abs/2601.05556", "authors": ["Zhongpeng Cai", "Jun Yu", "Wei Xu", "Tianyu Liu", "Jianqing Sun", "Jiaen Liang"], "title": "Semi-Supervised Facial Expression Recognition based on Dynamic Threshold and Negative Learning", "comment": null, "summary": "Facial expression recognition is a key task in human-computer interaction and affective computing. However, acquiring a large amount of labeled facial expression data is often costly. Therefore, it is particularly important to design a semi-supervised facial expression recognition algorithm that makes full use of both labeled and unlabeled data. In this paper, we propose a semi-supervised facial expression recognition algorithm based on Dynamic Threshold Adjustment (DTA) and Selective Negative Learning (SNL). Initially, we designed strategies for local attention enhancement and random dropout of feature maps during feature extraction, which strengthen the representation of local features while ensuring the model does not overfit to any specific local area. Furthermore, this study introduces a dynamic thresholding method to adapt to the requirements of the semi-supervised learning framework for facial expression recognition tasks, and through a selective negative learning strategy, it fully utilizes unlabeled samples with low confidence by mining useful expression information from complementary labels, achieving impressive results. We have achieved state-of-the-art performance on the RAF-DB and AffectNet datasets. Our method surpasses fully supervised methods even without using the entire dataset, which proves the effectiveness of our approach.", "AI": {"tldr": "A semi-supervised facial expression recognition method using Dynamic Threshold Adjustment and Selective Negative Learning achieves state-of-the-art results on RAF-DB and AffectNet datasets, outperforming fully supervised methods with less labeled data.", "motivation": "Labeled facial expression data is expensive to acquire, creating a need for semi-supervised approaches that can effectively utilize both labeled and unlabeled data for facial expression recognition tasks.", "method": "Proposes a semi-supervised algorithm with: 1) Local attention enhancement and random dropout during feature extraction to strengthen local feature representation while preventing overfitting; 2) Dynamic Threshold Adjustment to adapt to semi-supervised learning requirements; 3) Selective Negative Learning strategy that mines useful expression information from low-confidence unlabeled samples using complementary labels.", "result": "Achieved state-of-the-art performance on RAF-DB and AffectNet datasets. The method surpasses fully supervised methods even without using the entire dataset, demonstrating its effectiveness.", "conclusion": "The proposed semi-supervised approach with DTA and SNL effectively addresses the data scarcity problem in facial expression recognition, achieving superior performance with limited labeled data through innovative feature extraction and learning strategies."}}
{"id": "2601.05705", "categories": ["cs.AI", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2601.05705", "abs": "https://arxiv.org/abs/2601.05705", "authors": ["Ali Farjami", "Luca Redondi", "Marco Valentino"], "title": "Logic-Parametric Neuro-Symbolic NLI: Controlling Logical Formalisms for Verifiable LLM Reasoning", "comment": "Work in progress", "summary": "Large language models (LLMs) and theorem provers (TPs) can be effectively combined for verifiable natural language inference (NLI). However, existing approaches rely on a fixed logical formalism, a feature that limits robustness and adaptability. We propose a logic-parametric framework for neuro-symbolic NLI that treats the underlying logic not as a static background, but as a controllable component. Using the LogiKEy methodology, we embed a range of classical and non-classical formalisms into higher-order logic (HOL), enabling a systematic comparison of inference quality, explanation refinement, and proof behavior. We focus on normative reasoning, where the choice of logic has significant implications. In particular, we compare logic-external approaches, where normative requirements are encoded via axioms, with logic-internal approaches, where normative patterns emerge from the logic's built-in structure. Extensive experiments demonstrate that logic-internal strategies can consistently improve performance and produce more efficient hybrid proofs for NLI. In addition, we show that the effectiveness of a logic is domain-dependent, with first-order logic favouring commonsense reasoning, while deontic and modal logics excel in ethical domains. Our results highlight the value of making logic a first-class, parametric element in neuro-symbolic architectures for more robust, modular, and adaptable reasoning.", "AI": {"tldr": "A logic-parametric neuro-symbolic framework for NLI that treats logic as a controllable component, enabling systematic comparison of different formalisms and showing logic-internal approaches improve performance and produce more efficient hybrid proofs.", "motivation": "Existing neuro-symbolic approaches for verifiable natural language inference rely on fixed logical formalisms, which limits robustness and adaptability. The paper aims to address this limitation by making logic a controllable, parametric component rather than a static background.", "method": "Proposes a logic-parametric framework using LogiKEy methodology to embed various classical and non-classical formalisms into higher-order logic (HOL). Compares logic-external approaches (normative requirements via axioms) with logic-internal approaches (normative patterns from logic's built-in structure). Focuses on normative reasoning domains.", "result": "Logic-internal strategies consistently improve performance and produce more efficient hybrid proofs for NLI. Effectiveness of logic is domain-dependent: first-order logic favors commonsense reasoning, while deontic and modal logics excel in ethical domains.", "conclusion": "Making logic a first-class, parametric element in neuro-symbolic architectures enables more robust, modular, and adaptable reasoning. The framework demonstrates the value of systematic logic comparison and domain-specific logic selection for improved NLI performance."}}
{"id": "2601.05613", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05613", "abs": "https://arxiv.org/abs/2601.05613", "authors": ["Yiming Zhou", "Mingyue Cheng", "Hao Wang", "Enhong Chen"], "title": "PiXTime: A Model for Federated Time Series Forecasting with Heterogeneous Data Structures Across Nodes", "comment": null, "summary": "Time series are highly valuable and rarely shareable across nodes, making federated learning a promising paradigm to leverage distributed temporal data. However, different sampling standards lead to diverse time granularities and variable sets across nodes, hindering classical federated learning. We propose PiXTime, a novel time series forecasting model designed for federated learning that enables effective prediction across nodes with multi-granularity and heterogeneous variable sets. PiXTime employs a personalized Patch Embedding to map node-specific granularity time series into token sequences of a unified dimension for processing by a subsequent shared model, and uses a global VE Table to align variable category semantics across nodes, thereby enhancing cross-node transferability. With a transformer-based shared model, PiXTime captures representations of auxiliary series with arbitrary numbers of variables and uses cross-attention to enhance the prediction of the target series. Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.", "AI": {"tldr": "PiXTime is a federated time series forecasting model that handles multi-granularity and heterogeneous variable sets across nodes through personalized patch embedding and global variable embedding tables.", "motivation": "Time series data is valuable but rarely shareable across nodes due to privacy concerns. Federated learning is promising but challenged by different sampling standards leading to diverse time granularities and variable sets across nodes, which hinders classical federated learning approaches.", "method": "PiXTime uses personalized Patch Embedding to map node-specific granularity time series into unified token sequences, a global VE Table to align variable category semantics across nodes, and a transformer-based shared model with cross-attention to enhance target series prediction while handling arbitrary numbers of variables.", "result": "Experiments show PiXTime achieves state-of-the-art performance in federated settings and demonstrates superior performance on eight widely used real-world traditional benchmarks.", "conclusion": "PiXTime effectively addresses the challenges of multi-granularity and heterogeneous variable sets in federated time series forecasting, enabling effective prediction across distributed nodes while maintaining privacy."}}
{"id": "2601.05563", "categories": ["cs.CV", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.05563", "abs": "https://arxiv.org/abs/2601.05563", "authors": ["Fanxiao Li", "Jiaying Wu", "Tingchao Fu", "Dayang Li", "Herun Wan", "Wei Zhou", "Min-Yen Kan"], "title": "What's Left Unsaid? Detecting and Correcting Misleading Omissions in Multimodal News Previews", "comment": null, "summary": "Even when factually correct, social-media news previews (image-headline pairs) can induce interpretation drift: by selectively omitting crucial context, they lead readers to form judgments that diverge from what the full article conveys. This covert harm is harder to detect than explicit misinformation yet remains underexplored. To address this gap, we develop a multi-stage pipeline that disentangles and simulates preview-based versus context-based understanding, enabling construction of the MM-Misleading benchmark. Using this benchmark, we systematically evaluate open-source LVLMs and uncover pronounced blind spots to omission-based misleadingness detection. We further propose OMGuard, which integrates (1) Interpretation-Aware Fine-Tuning, which used to improve multimodal misleadingness detection and (2) Rationale-Guided Misleading Content Correction, which uses explicit rationales to guide headline rewriting and reduce misleading impressions. Experiments show that OMGuard lifts an 8B model's detection accuracy to match a 235B LVLM and delivers markedly stronger end-to-end correction. Further analysis reveals that misleadingness typically stems from local narrative shifts (e.g., missing background) rather than global frame changes, and identifies image-driven scenarios where text-only correction fails, highlighting the necessity of visual interventions.", "AI": {"tldr": "The paper addresses interpretation drift in social media news previews, where image-headline pairs omit crucial context, leading readers to form judgments that diverge from the full article. It introduces a pipeline to simulate preview vs. context understanding, creates the MM-Misleading benchmark, evaluates LVLMs' blind spots, and proposes OMGuard with fine-tuning and rationale-guided correction.", "motivation": "Social media news previews (image-headline pairs) can induce interpretation drift by selectively omitting crucial context, leading readers to form judgments that diverge from what the full article conveys. This covert harm is harder to detect than explicit misinformation and remains underexplored.", "method": "Developed a multi-stage pipeline that disentangles and simulates preview-based versus context-based understanding to construct the MM-Misleading benchmark. Proposed OMGuard with two components: (1) Interpretation-Aware Fine-Tuning to improve multimodal misleadingness detection, and (2) Rationale-Guided Misleading Content Correction that uses explicit rationales to guide headline rewriting and reduce misleading impressions.", "result": "OMGuard lifts an 8B model's detection accuracy to match a 235B LVLM and delivers markedly stronger end-to-end correction. Analysis reveals that misleadingness typically stems from local narrative shifts (e.g., missing background) rather than global frame changes, and identifies image-driven scenarios where text-only correction fails.", "conclusion": "The work addresses the underexplored problem of interpretation drift in social media previews, provides a systematic evaluation framework, and demonstrates effective solutions through OMGuard. It highlights the necessity of visual interventions in addition to text correction for comprehensive misleading content mitigation."}}
{"id": "2601.05724", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05724", "abs": "https://arxiv.org/abs/2601.05724", "authors": ["Yuxuan Zhou", "Fei Huang", "Heng Li", "Fengyi Wu", "Tianyu Wang", "Jianwei Zhang", "Junyang Lin", "Zhi-Qi Cheng"], "title": "Overcoming Joint Intractability with Lossless Hierarchical Speculative Decoding", "comment": null, "summary": "Verification is a key bottleneck in improving inference speed while maintaining distribution fidelity in Speculative Decoding. Recent work has shown that sequence-level verification leads to a higher number of accepted tokens compared to token-wise verification. However, existing solutions often rely on surrogate approximations or are constrained by partial information, struggling with joint intractability. In this work, we propose Hierarchical Speculative Decoding (HSD), a provably lossless verification method that significantly boosts the expected number of accepted tokens and overcomes joint intractability by balancing excess and deficient probability mass across accessible branches. Our extensive large-scale experiments demonstrate that HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Moreover, its strong explainability and generality make it readily integrable into a wide range of speculative decoding frameworks. Notably, integrating HSD into EAGLE-3 yields over a 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity. Code is available at https://github.com/ZhouYuxuanYX/Hierarchical-Speculative-Decoding.", "AI": {"tldr": "HSD is a lossless verification method for speculative decoding that boosts accepted tokens by balancing probability mass across branches, achieving 12% performance gain in EAGLE-3.", "motivation": "Verification is a key bottleneck in speculative decoding. Existing solutions use approximations or partial information, struggling with joint intractability. Sequence-level verification shows promise but needs improvement.", "method": "Hierarchical Speculative Decoding (HSD) - a provably lossless verification method that overcomes joint intractability by balancing excess and deficient probability mass across accessible branches.", "result": "HSD yields consistent improvements in acceptance rates across diverse model families and benchmarks. Integrating HSD into EAGLE-3 yields over 12% performance gain, establishing state-of-the-art decoding efficiency without compromising distribution fidelity.", "conclusion": "HSD is a highly effective verification method for speculative decoding that offers strong explainability, generality, and significant performance improvements while maintaining distribution fidelity."}}
{"id": "2601.05616", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05616", "abs": "https://arxiv.org/abs/2601.05616", "authors": ["ShaoZhen Liu", "Xinting Huang", "Houwen Peng", "Xin Chen", "Xinyang Song", "Qi Li", "Zhenan Sun"], "title": "Dual-Phase LLM Reasoning: Self-Evolved Mathematical Frameworks", "comment": null, "summary": "In recent years, large language models (LLMs) have demonstrated significant potential in complex reasoning tasks like mathematical problem-solving. However, existing research predominantly relies on reinforcement learning (RL) frameworks while overlooking supervised fine-tuning (SFT) methods. This paper proposes a new two-stage training framework that enhances models' self-correction capabilities through self-generated long chain-of-thought (CoT) data. During the first stage, a multi-turn dialogue strategy guides the model to generate CoT data incorporating verification, backtracking, subgoal decomposition, and backward reasoning, with predefined rules filtering high-quality samples for supervised fine-tuning. The second stage employs a difficulty-aware rejection sampling mechanism to dynamically optimize data distribution, strengthening the model's ability to handle complex problems. The approach generates reasoning chains extended over 4 times longer while maintaining strong scalability, proving that SFT effectively activates models' intrinsic reasoning capabilities and provides a resource-efficient pathway for complex task optimization. Experimental results demonstrate performance improvements on mathematical benchmarks including GSM8K and MATH500, with the fine-tuned model achieving a substantial improvement on competition-level problems like AIME24. Code will be open-sourced.", "AI": {"tldr": "A two-stage SFT framework using self-generated long CoT data with verification/backtracking mechanisms and difficulty-aware sampling to enhance LLMs' mathematical reasoning without RL.", "motivation": "Existing research on LLMs for mathematical reasoning over-relies on RL frameworks while overlooking SFT methods, missing opportunities to activate models' intrinsic reasoning capabilities through supervised approaches.", "method": "Two-stage training: 1) Multi-turn dialogue generates CoT data with verification, backtracking, subgoal decomposition, and backward reasoning, filtered by rules for SFT; 2) Difficulty-aware rejection sampling dynamically optimizes data distribution for complex problems.", "result": "Generates reasoning chains 4x longer, improves performance on GSM8K and MATH500 benchmarks, achieves substantial improvement on competition-level AIME24 problems, demonstrates strong scalability.", "conclusion": "SFT effectively activates LLMs' intrinsic reasoning capabilities, provides resource-efficient pathway for complex task optimization, and offers promising alternative to RL-based approaches for mathematical reasoning."}}
{"id": "2601.05572", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05572", "abs": "https://arxiv.org/abs/2601.05572", "authors": ["Pengcheng Xu", "Peng Tang", "Donghao Luo", "Xiaobin Hu", "Weichu Cui", "Qingdong He", "Zhennan Chen", "Jiangning Zhang", "Charles Ling", "Boyu Wang"], "title": "Towards Generalized Multi-Image Editing for Unified Multimodal Models", "comment": "Project page: https://github.com/Pengchengpcx/MIE-UMM", "summary": "Unified Multimodal Models (UMMs) integrate multimodal understanding and generation, yet they are limited to maintaining visual consistency and disambiguating visual cues when referencing details across multiple input images. In this work, we propose a scalable multi-image editing framework for UMMs that explicitly distinguishes image identities and generalizes to variable input counts. Algorithmically, we introduce two innovations: 1) The learnable latent separators explicitly differentiate each reference image in the latent space, enabling accurate and disentangled conditioning. 2) The sinusoidal index encoding assigns visual tokens from the same image a continuous sinusoidal index embedding, which provides explicit image identity while allowing generalization and extrapolation on a variable number of inputs. To facilitate training and evaluation, we establish a high-fidelity benchmark using an inverse dataset construction methodology to guarantee artifact-free, achievable outputs. Experiments show clear improvements in semantic consistency, visual fidelity, and cross-image integration over prior baselines on diverse multi-image editing tasks, validating our advantages on consistency and generalization ability.", "AI": {"tldr": "Proposes a scalable multi-image editing framework for Unified Multimodal Models with innovations in latent separators and sinusoidal index encoding to maintain visual consistency across multiple input images.", "motivation": "Current Unified Multimodal Models (UMMs) struggle with maintaining visual consistency and disambiguating visual cues when referencing details across multiple input images during editing tasks.", "method": "Two key innovations: 1) Learnable latent separators to differentiate each reference image in latent space for accurate disentangled conditioning, 2) Sinusoidal index encoding that assigns visual tokens from same image continuous sinusoidal embeddings for explicit image identity while allowing generalization to variable input counts.", "result": "Experiments show clear improvements in semantic consistency, visual fidelity, and cross-image integration over prior baselines on diverse multi-image editing tasks, validating advantages in consistency and generalization ability.", "conclusion": "The proposed scalable multi-image editing framework successfully addresses limitations of UMMs in maintaining visual consistency across multiple images through explicit image identity differentiation and generalization to variable input counts."}}
{"id": "2601.05739", "categories": ["cs.AI", "cs.CL", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05739", "abs": "https://arxiv.org/abs/2601.05739", "authors": ["G M Shahariar", "Zabir Al Nazi", "Md Olid Hasan Bhuiyan", "Zhouxing Shi"], "title": "PII-VisBench: Evaluating Personally Identifiable Information Safety in Vision Language Models Along a Continuum of Visibility", "comment": null, "summary": "Vision Language Models (VLMs) are increasingly integrated into privacy-critical domains, yet existing evaluations of personally identifiable information (PII) leakage largely treat privacy as a static extraction task and ignore how a subject's online presence--the volume of their data available online--influences privacy alignment. We introduce PII-VisBench, a novel benchmark containing 4000 unique probes designed to evaluate VLM safety through the continuum of online presence. The benchmark stratifies 200 subjects into four visibility categories: high, medium, low, and zero--based on the extent and nature of their information available online. We evaluate 18 open-source VLMs (0.3B-32B) based on two key metrics: percentage of PII probing queries refused (Refusal Rate) and the fraction of non-refusal responses flagged for containing PII (Conditional PII Disclosure Rate). Across models, we observe a consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. We identify that models are more likely to disclose PII for high-visibility subjects, alongside substantial model-family heterogeneity and PII-type disparities. Finally, paraphrasing and jailbreak-style prompts expose attack and model-dependent failures, motivating visibility-aware safety evaluation and training interventions.", "AI": {"tldr": "PII-VisBench benchmark evaluates VLM privacy safety across online presence continuum, finding models leak more PII for high-visibility subjects and showing attack vulnerabilities.", "motivation": "VLMs are used in privacy-critical domains but current PII leakage evaluations treat privacy as static and ignore how a subject's online presence affects privacy alignment.", "method": "Created PII-VisBench with 4000 unique probes across 200 subjects stratified into four visibility categories (high, medium, low, zero). Evaluated 18 open-source VLMs (0.3B-32B) using Refusal Rate and Conditional PII Disclosure Rate metrics.", "result": "Models show consistent pattern: refusals increase and PII disclosures decrease (9.10% high to 5.34% low) as subject visibility drops. Models disclose more PII for high-visibility subjects, with substantial model-family heterogeneity and PII-type disparities. Paraphrasing and jailbreak prompts expose attack-dependent failures.", "conclusion": "Current VLM safety evaluations overlook online presence continuum, motivating visibility-aware safety evaluation and training interventions to address privacy risks."}}
{"id": "2601.05623", "categories": ["cs.LG", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05623", "abs": "https://arxiv.org/abs/2601.05623", "authors": ["Zhi Wang", "Zhongbin Wu", "Yanni Li", "Bing Liu", "Guangxi Li", "Yuping Wang"], "title": "Continual Learning of Achieving Forgetting-free and Positive Knowledge Transfer", "comment": null, "summary": "Existing research on continual learning (CL) of a sequence of tasks focuses mainly on dealing with catastrophic forgetting (CF) to balance the learning plasticity of new tasks and the memory stability of old tasks. However, an ideal CL agent should not only be able to overcome CF, but also encourage positive forward and backward knowledge transfer (KT), i.e., using the learned knowledge from previous tasks for the new task learning (namely FKT), and improving the previous tasks' performance with the knowledge of the new task (namely BKT). To this end, this paper first models CL as an optimization problem in which each sequential learning task aims to achieve its optimal performance under the constraint that both FKT and BKT should be positive. It then proposes a novel Enhanced Task Continual Learning (ETCL) method, which achieves forgetting-free and positive KT. Furthermore, the bounds that can lead to negative FKT and BKT are estimated theoretically. Based on the bounds, a new strategy for online task similarity detection is also proposed to facilitate positive KT. To overcome CF, ETCL learns a set of task-specific binary masks to isolate a sparse sub-network for each task while preserving the performance of a dense network for the task. At the beginning of a new task learning, ETCL tries to align the new task's gradient with that of the sub-network of the previous most similar task to ensure positive FKT. By using a new bi-objective optimization strategy and an orthogonal gradient projection method, ETCL updates only the weights of previous similar tasks at the classification layer to achieve positive BKT. Extensive evaluations demonstrate that the proposed ETCL markedly outperforms strong baselines on dissimilar, similar, and mixed task sequences.", "AI": {"tldr": "ETCL is a novel continual learning method that achieves forgetting-free learning with positive forward and backward knowledge transfer through task-specific masks, gradient alignment, and bi-objective optimization.", "motivation": "Current continual learning research focuses mainly on overcoming catastrophic forgetting, but an ideal CL agent should also enable positive knowledge transfer - both forward (using past knowledge for new tasks) and backward (improving past tasks with new knowledge).", "method": "ETCL uses task-specific binary masks to isolate sparse sub-networks for each task while preserving dense network performance. It aligns new task gradients with previous similar tasks for positive forward transfer, and uses bi-objective optimization with orthogonal gradient projection to update previous similar tasks' classification layers for positive backward transfer.", "result": "Extensive evaluations show ETCL markedly outperforms strong baselines on dissimilar, similar, and mixed task sequences, achieving forgetting-free learning with positive knowledge transfer.", "conclusion": "ETCL successfully addresses both catastrophic forgetting and enables positive bidirectional knowledge transfer in continual learning, representing a more comprehensive solution than existing methods that focus only on forgetting."}}
{"id": "2601.05573", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05573", "abs": "https://arxiv.org/abs/2601.05573", "authors": ["Zehan Wang", "Ziang Zhang", "Jiayang Xu", "Jialei Wang", "Tianyu Pang", "Chao Du", "HengShuang Zhao", "Zhou Zhao"], "title": "Orient Anything V2: Unifying Orientation and Rotation Understanding", "comment": "NeurIPS 2025 Spotlight, Repo: https://github.com/SpatialVision/Orient-Anything-V2", "summary": "This work presents Orient Anything V2, an enhanced foundation model for unified understanding of object 3D orientation and rotation from single or paired images. Building upon Orient Anything V1, which defines orientation via a single unique front face, V2 extends this capability to handle objects with diverse rotational symmetries and directly estimate relative rotations. These improvements are enabled by four key innovations: 1) Scalable 3D assets synthesized by generative models, ensuring broad category coverage and balanced data distribution; 2) An efficient, model-in-the-loop annotation system that robustly identifies 0 to N valid front faces for each object; 3) A symmetry-aware, periodic distribution fitting objective that captures all plausible front-facing orientations, effectively modeling object rotational symmetry; 4) A multi-frame architecture that directly predicts relative object rotations. Extensive experiments show that Orient Anything V2 achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 widely used benchmarks. The model demonstrates strong generalization, significantly broadening the applicability of orientation estimation in diverse downstream tasks.", "AI": {"tldr": "Orient Anything V2 is an enhanced foundation model for unified 3D orientation and rotation understanding from images, handling diverse rotational symmetries and directly estimating relative rotations.", "motivation": "To overcome limitations of V1 (which defined orientation via single front face) by handling objects with diverse rotational symmetries and enabling direct relative rotation estimation, broadening applicability in downstream tasks.", "method": "Four key innovations: 1) Scalable 3D assets from generative models for broad coverage, 2) Model-in-the-loop annotation system identifying valid front faces, 3) Symmetry-aware periodic distribution fitting objective modeling rotational symmetry, 4) Multi-frame architecture for direct relative rotation prediction.", "result": "Achieves state-of-the-art zero-shot performance on orientation estimation, 6DoF pose estimation, and object symmetry recognition across 11 benchmarks, demonstrating strong generalization.", "conclusion": "Orient Anything V2 significantly broadens applicability of orientation estimation in diverse downstream tasks through improved handling of rotational symmetries and direct relative rotation estimation."}}
{"id": "2601.05746", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05746", "abs": "https://arxiv.org/abs/2601.05746", "authors": ["Zhenghao Li", "Zhi Zheng", "Wei Chen", "Jielun Zhao", "Yong Chen", "Tong Xu", "Enhong Chen"], "title": "DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation", "comment": "16pages,6figures", "summary": "Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.", "AI": {"tldr": "DynaDebate introduces dynamic multi-agent debate with three key mechanisms to overcome limitations of existing approaches where agents follow identical reasoning paths, leading to simple majority voting rather than effective debate.", "motivation": "Existing Multi-Agent Debate (MAD) frameworks suffer from unguided initialization causing agents to adopt identical reasoning paths, leading to the same errors. This hinders effective debate and causes final outcomes to degenerate into simple majority voting rather than collaborative problem-solving.", "method": "DynaDebate employs three key mechanisms: (1) Dynamic Path Generation and Allocation using a dedicated Path Generation Agent to create diverse logical solution paths with adaptive redundancy; (2) Process-Centric Debate that shifts focus from outcome voting to step-by-step logic critique; (3) Trigger-Based Verification Agent activated upon disagreement to use external tools for objective deadlock resolution.", "result": "Extensive experiments show DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.", "conclusion": "DynaDebate effectively addresses the limitations of current multi-agent debate frameworks by introducing dynamic path generation, process-focused critique, and objective verification mechanisms, leading to improved collaborative decision-making and problem-solving capabilities."}}
{"id": "2601.05647", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05647", "abs": "https://arxiv.org/abs/2601.05647", "authors": ["Xinyue Wang", "Stephen Wang", "Biwei Huang"], "title": "Transformer Is Inherently a Causal Learner", "comment": null, "summary": "We reveal that transformers trained in an autoregressive manner naturally encode time-delayed causal structures in their learned representations. When predicting future values in multivariate time series, the gradient sensitivities of transformer outputs with respect to past inputs directly recover the underlying causal graph, without any explicit causal objectives or structural constraints. We prove this connection theoretically under standard identifiability conditions and develop a practical extraction method using aggregated gradient attributions. On challenging cases such as nonlinear dynamics, long-term dependencies, and non-stationary systems, this approach greatly surpasses the performance of state-of-the-art discovery algorithms, especially as data heterogeneity increases, exhibiting scaling potential where causal accuracy improves with data volume and heterogeneity, a property traditional methods lack. This unifying view lays the groundwork for a future paradigm where causal discovery operates through the lens of foundation models, and foundation models gain interpretability and enhancement through the lens of causality.", "AI": {"tldr": "Transformers trained autoregressively naturally encode time-delayed causal structures in their representations, allowing causal graph recovery from gradient sensitivities without explicit causal objectives.", "motivation": "To bridge the gap between causal discovery and foundation models, showing that transformers inherently learn causal structures during standard training, enabling causal discovery without specialized objectives.", "method": "Analyze gradient sensitivities of transformer outputs with respect to past inputs, develop practical extraction using aggregated gradient attributions, prove theoretical connection under standard identifiability conditions.", "result": "Greatly surpasses state-of-the-art causal discovery algorithms on challenging cases (nonlinear dynamics, long-term dependencies, non-stationary systems), especially with increasing data heterogeneity. Shows scaling potential where accuracy improves with data volume and heterogeneity.", "conclusion": "Provides unifying view for future paradigm where causal discovery operates through foundation models, and foundation models gain interpretability and enhancement through causality lens."}}
{"id": "2601.05580", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05580", "abs": "https://arxiv.org/abs/2601.05580", "authors": ["Hanyi Wang", "Jun Lan", "Yaoyu Kang", "Huijia Zhu", "Weiqiang Wang", "Zhuosheng Zhang", "Shilin Wang"], "title": "Generalizable and Adaptive Continual Learning Framework for AI-generated Image Detection", "comment": "Accepted by TMM 2025", "summary": "The malicious misuse and widespread dissemination of AI-generated images pose a significant threat to the authenticity of online information. Current detection methods often struggle to generalize to unseen generative models, and the rapid evolution of generative techniques continuously exacerbates this challenge. Without adaptability, detection models risk becoming ineffective in real-world applications. To address this critical issue, we propose a novel three-stage domain continual learning framework designed for continuous adaptation to evolving generative models. In the first stage, we employ a strategic parameter-efficient fine-tuning approach to develop a transferable offline detection model with strong generalization capabilities. Building upon this foundation, the second stage integrates unseen data streams into a continual learning process. To efficiently learn from limited samples of novel generated models and mitigate overfitting, we design a data augmentation chain with progressively increasing complexity. Furthermore, we leverage the Kronecker-Factored Approximate Curvature (K-FAC) method to approximate the Hessian and alleviate catastrophic forgetting. Finally, the third stage utilizes a linear interpolation strategy based on Linear Mode Connectivity, effectively capturing commonalities across diverse generative models and further enhancing overall performance. We establish a comprehensive benchmark of 27 generative models, including GANs, deepfakes, and diffusion models, chronologically structured up to August 2024 to simulate real-world scenarios. Extensive experiments demonstrate that our initial offline detectors surpass the leading baseline by +5.51% in terms of mean average precision. Our continual learning strategy achieves an average accuracy of 92.20%, outperforming state-of-the-art methods.", "AI": {"tldr": "A three-stage domain continual learning framework for AI-generated image detection that adapts to evolving generative models through parameter-efficient fine-tuning, continual learning with data augmentation, and model interpolation.", "motivation": "AI-generated images threaten online information authenticity, and current detection methods struggle to generalize to unseen generative models and adapt to rapidly evolving generation techniques, risking real-world ineffectiveness.", "method": "Three-stage framework: 1) Parameter-efficient fine-tuning for transferable offline detection; 2) Continual learning with data augmentation chain and K-FAC method to prevent forgetting; 3) Linear interpolation based on Linear Mode Connectivity to capture model commonalities.", "result": "Offline detectors outperform leading baseline by +5.51% mAP; continual learning achieves 92.20% average accuracy, beating state-of-the-art methods on benchmark of 27 generative models (GANs, deepfakes, diffusion models up to August 2024).", "conclusion": "The proposed framework effectively addresses the adaptability challenge in AI-generated image detection, demonstrating strong generalization and continual learning capabilities against evolving generative technologies."}}
{"id": "2601.05787", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05787", "abs": "https://arxiv.org/abs/2601.05787", "authors": ["Zezhou Wang", "Ziyun Zhang", "Xiaoyi Zhang", "Zhuzhong Qian", "Yan Lu"], "title": "From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation", "comment": "Work In Progress", "summary": "Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git", "AI": {"tldr": "BEPA improves end-to-end GUI agents by better leveraging limited expert trajectories through bi-level assimilation, boosting performance on OSWorld and other GUI benchmarks.", "motivation": "GUI datasets like OSWorld have limited verifiable tasks and expert trajectories are hard to scale, creating bottlenecks for training end-to-end screenshot-to-action policies. Current methods struggle to effectively combine limited expert data with reinforcement learning from verifiable rewards.", "method": "BEPA (Bi-Level Expert-to-Policy Assimilation) uses a two-level approach: LEVEL-1 transforms static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy, and LEVEL-2 maintains a per-task, dynamically updated cache used in RLVR to better leverage expert data.", "result": "On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web benchmarks.", "conclusion": "BEPA effectively bridges the gap between limited expert trajectories and reinforcement learning, enabling better utilization of scarce expert data for training end-to-end GUI agents, significantly improving performance on challenging GUI interaction benchmarks."}}
{"id": "2601.05650", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05650", "abs": "https://arxiv.org/abs/2601.05650", "authors": ["Miguel Matey-Sanz", "Joaqu\u00edn Torres-Sospedra", "Joaqu\u00edn Huerta", "Sergio Trilles"], "title": "From Global to Local: Cluster-Aware Learning for Wi-Fi Fingerprinting Indoor Localisation", "comment": "20 pages, 9 figures, 6 tables", "summary": "Wi-Fi fingerprinting remains one of the most practical solutions for indoor positioning, however, its performance is often limited by the size and heterogeneity of fingerprint datasets, strong Received Signal Strength Indicator variability, and the ambiguity introduced in large and multi-floor environments. These factors significantly degrade localisation accuracy, particularly when global models are applied without considering structural constraints. This paper introduces a clustering-based method that structures the fingerprint dataset prior to localisation. Fingerprints are grouped using either spatial or radio features, and clustering can be applied at the building or floor level. In the localisation phase, a clustering estimation procedure based on the strongest access points assigns unseen fingerprints to the most relevant cluster. Localisation is then performed only within the selected clusters, allowing learning models to operate on reduced and more coherent subsets of data. The effectiveness of the method is evaluated on three public datasets and several machine learning models. Results show a consistent reduction in localisation errors, particularly under building-level strategies, but at the cost of reducing the floor detection accuracy. These results demonstrate that explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning.", "AI": {"tldr": "Clustering-based method structures Wi-Fi fingerprint datasets before localization to improve accuracy by reducing data heterogeneity and ambiguity in large indoor environments.", "motivation": "Wi-Fi fingerprinting performance is limited by dataset size/heterogeneity, RSSI variability, and ambiguity in large multi-floor environments, degrading localization accuracy when global models ignore structural constraints.", "method": "Clustering-based approach that groups fingerprints using spatial or radio features at building/floor level. During localization, clustering estimation based on strongest APs assigns unseen fingerprints to relevant clusters, then localization performed only within selected clusters.", "result": "Consistent reduction in localization errors across three public datasets with several ML models, particularly under building-level strategies, but at cost of reduced floor detection accuracy.", "conclusion": "Explicitly structuring datasets through clustering is an effective and flexible approach for scalable indoor positioning, allowing learning models to operate on reduced and more coherent data subsets."}}
{"id": "2601.05584", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05584", "abs": "https://arxiv.org/abs/2601.05584", "authors": ["Nengbo Lu", "Minghua Pan", "Shaohua Sun", "Yizhou Liang"], "title": "GS-DMSR: Dynamic Sensitive Multi-scale Manifold Enhancement for Accelerated High-Quality 3D Gaussian Splatting", "comment": null, "summary": "In the field of 3D dynamic scene reconstruction, how to balance model convergence rate and rendering quality has long been a critical challenge that urgently needs to be addressed, particularly in high-precision modeling of scenes with complex dynamic motions. To tackle this issue, this study proposes the GS-DMSR method. By quantitatively analyzing the dynamic evolution process of Gaussian attributes, this mechanism achieves adaptive gradient focusing, enabling it to dynamically identify significant differences in the motion states of Gaussian models. It then applies differentiated optimization strategies to Gaussian models with varying degrees of significance, thereby significantly improving the model convergence rate. Additionally, this research integrates a multi-scale manifold enhancement module, which leverages the collaborative optimization of an implicit nonlinear decoder and an explicit deformation field to enhance the modeling efficiency for complex deformation scenes. Experimental results demonstrate that this method achieves a frame rate of up to 96 FPS on synthetic datasets, while effectively reducing both storage overhead and training time.Our code and data are available at https://anonymous.4open.science/r/GS-DMSR-2212.", "AI": {"tldr": "GS-DMSR method improves 3D dynamic scene reconstruction by balancing convergence rate and rendering quality through adaptive gradient focusing and multi-scale manifold enhancement.", "motivation": "The paper addresses the critical challenge in 3D dynamic scene reconstruction of balancing model convergence rate and rendering quality, especially for scenes with complex dynamic motions where high-precision modeling is needed.", "method": "Proposes GS-DMSR with two key components: 1) Adaptive gradient focusing mechanism that analyzes dynamic evolution of Gaussian attributes to identify motion state differences and apply differentiated optimization strategies, and 2) Multi-scale manifold enhancement module using collaborative optimization of implicit nonlinear decoder and explicit deformation field.", "result": "Achieves up to 96 FPS on synthetic datasets while reducing both storage overhead and training time, demonstrating improved convergence rate and rendering quality.", "conclusion": "GS-DMSR effectively addresses the convergence-quality trade-off in 3D dynamic scene reconstruction through adaptive optimization strategies and manifold enhancement, enabling efficient high-precision modeling of complex dynamic scenes."}}
{"id": "2601.05890", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05890", "abs": "https://arxiv.org/abs/2601.05890", "authors": ["Ruizhe Zhang", "Xinke Jiang", "Zhibang Yang", "Zhixin Zhang", "Jiaran Gao", "Yuzhen Xiao", "Hongbin Lai", "Xu Chu", "Junfeng Zhao", "Yasha Wang"], "title": "StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management", "comment": null, "summary": "Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.", "AI": {"tldr": "StackPlanner is a hierarchical multi-agent framework with explicit memory control that addresses context bloat and coordination inefficiency in LLM-based multi-agent systems through task-level memory management and reusable experience learning.", "motivation": "Centralized multi-agent systems using large language models suffer from unstable long-horizon collaboration due to lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. Current systems also fail to efficiently reuse coordination experience across tasks.", "method": "StackPlanner uses a hierarchical framework that decouples high-level coordination from subtask execution with active task-level memory control. It employs structured experience memory and reinforcement learning to retrieve and exploit reusable coordination experience.", "result": "Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of StackPlanner in enabling reliable long-horizon multi-agent collaboration.", "conclusion": "StackPlanner successfully addresses memory inefficiency and coordination experience reuse challenges in multi-agent systems, providing a robust solution for complex, knowledge-intensive tasks requiring stable long-horizon collaboration."}}
{"id": "2601.05679", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05679", "abs": "https://arxiv.org/abs/2601.05679", "authors": ["George Ma", "Zhongyuan Liang", "Irene Y. Chen", "Somayeh Sojoudi"], "title": "Do Sparse Autoencoders Identify Reasoning Features in Language Models?", "comment": null, "summary": "We investigate whether sparse autoencoders (SAEs) identify genuine reasoning features in large language models (LLMs). Starting from features selected using standard contrastive activation methods, we introduce a falsification-oriented framework that combines causal token injection experiments and LLM-guided falsification to test whether feature activation reflects reasoning processes or superficial linguistic correlates. Across 20 configurations spanning multiple model families, layers, and reasoning datasets, we find that identified reasoning features are highly sensitive to token-level interventions. Injecting a small number of feature-associated tokens into non-reasoning text is sufficient to elicit strong activation for 59% to 94% of features, indicating reliance on lexical artifacts. For the remaining features that are not explained by simple token triggers, LLM-guided falsification consistently produces non-reasoning inputs that activate the feature and reasoning inputs that do not, with no analyzed feature satisfying our criteria for genuine reasoning behavior. Steering these features yields minimal changes or slight degradations in benchmark performance. Together, these results suggest that SAE features identified by contrastive approaches primarily capture linguistic correlates of reasoning rather than the underlying reasoning computations themselves.", "AI": {"tldr": "SAE features identified by contrastive methods don't capture genuine reasoning computations but rather superficial linguistic correlates, as shown through falsification tests across multiple models and datasets.", "motivation": "To determine whether sparse autoencoders (SAEs) actually identify genuine reasoning features in LLMs, or if they're just capturing linguistic artifacts that correlate with reasoning tasks.", "method": "Used falsification framework combining causal token injection experiments and LLM-guided falsification to test feature activation patterns across 20 configurations spanning multiple model families, layers, and reasoning datasets.", "result": "59-94% of features were activated by simple token injections into non-reasoning text, showing lexical artifact reliance. Remaining features failed LLM-guided falsification tests, with no feature satisfying criteria for genuine reasoning behavior. Feature steering yielded minimal or negative performance changes.", "conclusion": "SAE features from contrastive approaches primarily capture linguistic correlates of reasoning rather than underlying reasoning computations, questioning current interpretability methods' ability to identify genuine reasoning features."}}
{"id": "2601.05599", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05599", "abs": "https://arxiv.org/abs/2601.05599", "authors": ["Takito Sawada", "Akinori Iwata", "Masahiro Okuda"], "title": "Quantifying and Inducing Shape Bias in CNNs via Max-Pool Dilation", "comment": "Accepted to IEVC 2026. 4 pages, 1 figure, 3 tables", "summary": "Convolutional Neural Networks (CNNs) are known to exhibit a strong texture bias, favoring local patterns over global shape information--a tendency inherent to their convolutional architecture. While this bias is beneficial for texture-rich natural images, it often degrades performance on shape-dominant data such as illustrations and sketches. Although prior work has proposed shape-biased models to mitigate this issue, these approaches lack a quantitative metric for identifying which datasets would actually benefit from such modifications. To address this gap, we propose a data-driven metric that quantifies the shape-texture balance of a dataset by computing the Structural Similarity Index (SSIM) between each image's luminance channel and its L0-smoothed counterpart. Building on this metric, we further introduce a computationally efficient adaptation method that promotes shape bias by modifying the dilation of max-pooling operations while keeping convolutional weights frozen. Experimental results show that this approach consistently improves classification accuracy on shape-dominant datasets, particularly in low-data regimes where full fine-tuning is impractical, requiring training only the final classification layer.", "AI": {"tldr": "Proposes a metric to quantify dataset shape-texture balance and a dilation-based adaptation method to enhance shape bias in CNNs without retraining convolutional weights.", "motivation": "CNNs have inherent texture bias that hurts performance on shape-dominant data like illustrations and sketches. Existing shape-biased models lack quantitative metrics to identify which datasets would benefit from such modifications.", "method": "1) Data-driven metric using SSIM between image luminance and L0-smoothed version to quantify shape-texture balance. 2) Efficient adaptation method modifying max-pooling dilation to promote shape bias while keeping convolutional weights frozen.", "result": "The approach consistently improves classification accuracy on shape-dominant datasets, especially in low-data regimes where full fine-tuning is impractical (only final classification layer needs training).", "conclusion": "Provides both a diagnostic metric for dataset shape-texture analysis and a practical adaptation method to enhance CNN performance on shape-dominant data with minimal computational cost."}}
{"id": "2601.05899", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05899", "abs": "https://arxiv.org/abs/2601.05899", "authors": ["Dawei Wang", "Chengming Zhou", "Di Zhao", "Xinyuan Liu", "Marci Chi Ma", "Gary Ushaw", "Richard Davison"], "title": "TowerMind: A Tower Defence Game Learning Environment and Benchmark for LLM as Agents", "comment": "AAAI 2026 Oral", "summary": "Recent breakthroughs in Large Language Models (LLMs) have positioned them as a promising paradigm for agents, with long-term planning and decision-making emerging as core general-purpose capabilities for adapting to diverse scenarios and tasks. Real-time strategy (RTS) games serve as an ideal testbed for evaluating these two capabilities, as their inherent gameplay requires both macro-level strategic planning and micro-level tactical adaptation and action execution. Existing RTS game-based environments either suffer from relatively high computational demands or lack support for textual observations, which has constrained the use of RTS games for LLM evaluation. Motivated by this, we present TowerMind, a novel environment grounded in the tower defense (TD) subgenre of RTS games. TowerMind preserves the key evaluation strengths of RTS games for assessing LLMs, while featuring low computational demands and a multimodal observation space, including pixel-based, textual, and structured game-state representations. In addition, TowerMind supports the evaluation of model hallucination and provides a high degree of customizability. We design five benchmark levels to evaluate several widely used LLMs under different multimodal input settings. The results reveal a clear performance gap between LLMs and human experts across both capability and hallucination dimensions. The experiments further highlight key limitations in LLM behavior, such as inadequate planning validation, a lack of multifinality in decision-making, and inefficient action use. We also evaluate two classic reinforcement learning algorithms: Ape-X DQN and PPO. By offering a lightweight and multimodal design, TowerMind complements the existing RTS game-based environment landscape and introduces a new benchmark for the AI agent field. The source code is publicly available on GitHub(https://github.com/tb6147877/TowerMind).", "AI": {"tldr": "TowerMind is a lightweight, multimodal tower defense environment for evaluating LLM agents' planning and decision-making capabilities, addressing computational and textual observation limitations of existing RTS game benchmarks.", "motivation": "Existing RTS game environments for evaluating LLMs have high computational demands and lack textual observation support, limiting their use for comprehensive LLM evaluation despite RTS games being ideal for testing planning and decision-making capabilities.", "method": "Developed TowerMind, a tower defense RTS environment with low computational demands and multimodal observations (pixel-based, textual, structured game-state). Designed five benchmark levels to evaluate LLMs under different input settings, with support for hallucination evaluation and high customizability.", "result": "Evaluation revealed significant performance gaps between LLMs and human experts in both capability and hallucination dimensions. LLMs showed key limitations: inadequate planning validation, lack of multifinality in decision-making, and inefficient action use. Also evaluated classic RL algorithms (Ape-X DQN and PPO).", "conclusion": "TowerMind provides a lightweight, multimodal benchmark that complements existing RTS environments and introduces a new standard for AI agent evaluation, highlighting current LLM limitations in strategic planning and decision-making."}}
{"id": "2601.05680", "categories": ["cs.LG", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05680", "abs": "https://arxiv.org/abs/2601.05680", "authors": ["Yeonsang Shin", "Insoo Kim", "Bongkeun Kim", "Keonwoo Bae", "Bohyung Han"], "title": "AGDC: Autoregressive Generation of Variable-Length Sequences with Joint Discrete and Continuous Spaces", "comment": null, "summary": "Transformer-based autoregressive models excel in data generation but are inherently constrained by their reliance on discretized tokens, which limits their ability to represent continuous values with high precision. We analyze the scalability limitations of existing discretization-based approaches for generating hybrid discrete-continuous sequences, particularly in high-precision domains such as semiconductor circuit designs, where precision loss can lead to functional failure. To address the challenge, we propose AGDC, a novel unified framework that jointly models discrete and continuous values for variable-length sequences. AGDC employs a hybrid approach that combines categorical prediction for discrete values with diffusion-based modeling for continuous values, incorporating two key technical components: an end-of-sequence (EOS) logit adjustment mechanism that uses an MLP to dynamically adjust EOS token logits based on sequence context, and a length regularization term integrated into the loss function. Additionally, we present ContLayNet, a large-scale benchmark comprising 334K high-precision semiconductor layout samples with specialized evaluation metrics that capture functional correctness where precision errors significantly impact performance. Experiments on semiconductor layouts (ContLayNet), graphic layouts, and SVGs demonstrate AGDC's superior performance in generating high-fidelity hybrid vector representations compared to discretization-based and fixed-schema baselines, achieving scalable high-precision generation across diverse domains.", "AI": {"tldr": "AGDC is a unified framework for generating hybrid discrete-continuous sequences using categorical prediction for discrete values and diffusion modeling for continuous values, with EOS logit adjustment and length regularization, achieving superior high-precision generation in semiconductor layouts and other domains.", "motivation": "Transformer-based autoregressive models are limited by discretized tokens when dealing with continuous values, especially in high-precision domains like semiconductor circuit design where precision loss can cause functional failures. Existing discretization approaches don't scale well for hybrid discrete-continuous sequences.", "method": "AGDC combines categorical prediction for discrete values with diffusion-based modeling for continuous values. Key components include: 1) EOS logit adjustment using an MLP to dynamically adjust end-of-sequence token logits based on context, and 2) length regularization integrated into the loss function. Also introduces ContLayNet benchmark with 334K semiconductor layout samples.", "result": "AGDC outperforms discretization-based and fixed-schema baselines in generating high-fidelity hybrid vector representations across semiconductor layouts (ContLayNet), graphic layouts, and SVGs. Achieves scalable high-precision generation where precision errors significantly impact functional correctness.", "conclusion": "AGDC provides a unified framework for joint modeling of discrete and continuous values in variable-length sequences, enabling high-precision generation in domains like semiconductor design where traditional token-based approaches fail due to precision limitations."}}
{"id": "2601.05600", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05600", "abs": "https://arxiv.org/abs/2601.05600", "authors": ["Chuhan Wang", "Xintong Li", "Jennifer Yuntong Zhang", "Junda Wu", "Chengkai Huang", "Lina Yao", "Julian McAuley", "Jingbo Shang"], "title": "SceneAlign: Aligning Multimodal Reasoning to Scene Graphs in Complex Visual Scenes", "comment": "Preprint", "summary": "Multimodal large language models often struggle with faithful reasoning in complex visual scenes, where intricate entities and relations require precise visual grounding at each step. This reasoning unfaithfulness frequently manifests as hallucinated entities, mis-grounded relations, skipped steps, and over-specified reasoning. Existing preference-based approaches, typically relying on textual perturbations or answer-conditioned rationales, fail to address this challenge as they allow models to exploit language priors to bypass visual grounding. To address this, we propose SceneAlign, a framework that leverages scene graphs as structured visual information to perform controllable structural interventions. By identifying reasoning-critical nodes and perturbing them through four targeted strategies that mimic typical grounding failures, SceneAlign constructs hard negative rationales that remain linguistically plausible but are grounded in inaccurate visual facts. These contrastive pairs are used in Direct Preference Optimization to steer models toward fine-grained, structure-faithful reasoning. Across seven visual reasoning benchmarks, SceneAlign consistently improves answer accuracy and reasoning faithfulness, highlighting the effectiveness of grounding-aware alignment for multimodal reasoning.", "AI": {"tldr": "SceneAlign improves multimodal reasoning faithfulness by using scene graphs to create hard negative examples that force models to properly ground reasoning in visual facts, rather than relying on language priors.", "motivation": "Multimodal LLMs often fail at faithful reasoning in complex visual scenes, hallucinating entities, mis-grounding relations, skipping steps, and over-specifying. Existing preference-based approaches allow models to exploit language priors instead of properly grounding in visual information.", "method": "SceneAlign uses scene graphs as structured visual information to perform controllable structural interventions. It identifies reasoning-critical nodes and perturbs them through four targeted strategies that mimic typical grounding failures, creating hard negative rationales that are linguistically plausible but visually inaccurate. These contrastive pairs are used in Direct Preference Optimization.", "result": "Across seven visual reasoning benchmarks, SceneAlign consistently improves both answer accuracy and reasoning faithfulness, demonstrating effectiveness of grounding-aware alignment for multimodal reasoning.", "conclusion": "The framework highlights the importance of grounding-aware alignment using structured visual information (scene graphs) to improve multimodal reasoning faithfulness, addressing key limitations of existing preference-based approaches."}}
{"id": "2601.05991", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05991", "abs": "https://arxiv.org/abs/2601.05991", "authors": ["Jiayu Ding", "Haoran Tang", "Ge Li"], "title": "Open-Vocabulary 3D Instruction Ambiguity Detection", "comment": null, "summary": "In safety-critical domains, linguistic ambiguity can have severe consequences; a vague command like \"Pass me the vial\" in a surgical setting could lead to catastrophic errors. Yet, most embodied AI research overlooks this, assuming instructions are clear and focusing on execution rather than confirmation. To address this critical safety gap, we are the first to define Open-Vocabulary 3D Instruction Ambiguity Detection, a fundamental new task where a model must determine if a command has a single, unambiguous meaning within a given 3D scene. To support this research, we build Ambi3D, the large-scale benchmark for this task, featuring over 700 diverse 3D scenes and around 22k instructions. Our analysis reveals a surprising limitation: state-of-the-art 3D Large Language Models (LLMs) struggle to reliably determine if an instruction is ambiguous. To address this challenge, we propose AmbiVer, a two-stage framework that collects explicit visual evidence from multiple views and uses it to guide an vision-language model (VLM) in judging instruction ambiguity. Extensive experiments demonstrate the challenge of our task and the effectiveness of AmbiVer, paving the way for safer and more trustworthy embodied AI. Code and dataset available at https://jiayuding031020.github.io/ambi3d/.", "AI": {"tldr": "The paper introduces Open-Vocabulary 3D Instruction Ambiguity Detection, a new task for identifying ambiguous commands in 3D environments, and presents Ambi3D benchmark with 700+ scenes and 22k instructions. It shows SOTA 3D LLMs struggle with this task and proposes AmbiVer framework that collects multi-view visual evidence to guide VLM ambiguity judgments.", "motivation": "In safety-critical domains like surgery, linguistic ambiguity in commands can lead to catastrophic errors. Current embodied AI research overlooks this problem, assuming instructions are clear and focusing on execution rather than confirmation, creating a critical safety gap.", "method": "The paper proposes AmbiVer, a two-stage framework: 1) collects explicit visual evidence from multiple views of the 3D scene, and 2) uses this evidence to guide a vision-language model in judging whether an instruction is ambiguous or unambiguous.", "result": "State-of-the-art 3D LLMs struggle to reliably detect instruction ambiguity. Extensive experiments demonstrate the challenge of the proposed task and show the effectiveness of the AmbiVer framework in addressing this problem.", "conclusion": "The work introduces a fundamental new task for safer embodied AI, provides a large-scale benchmark (Ambi3D), and proposes an effective framework (AmbiVer) that paves the way for more trustworthy AI systems in safety-critical domains."}}
{"id": "2601.05684", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05684", "abs": "https://arxiv.org/abs/2601.05684", "authors": ["Hongyaoxing Gul", "Lijuan Hu", "Shuzi Niu", "Fangfang Liu"], "title": "FLRQ: Faster LLM Quantization with Flexible Low-Rank Matrix Sketching", "comment": null, "summary": "Traditional post-training quantization (PTQ) is considered an effective approach to reduce model size and accelerate inference of large-scale language models (LLMs). However, existing low-rank PTQ methods require costly fine-tuning to determine a compromise rank for diverse data and layers in large models, failing to exploit their full potential. Additionally, the current SVD-based low-rank approximation compounds the computational overhead. In this work, we thoroughly analyze the varying effectiveness of low-rank approximation across different layers in representative models. Accordingly, we introduce \\underline{F}lexible \\underline{L}ow-\\underline{R}ank \\underline{Q}uantization (FLRQ), a novel solution designed to quickly identify the accuracy-optimal ranks and aggregate them to achieve minimal storage combinations. FLRQ comprises two powerful components, Rank1-Sketch-based Flexible Rank Selection (R1-FLR) and Best Low-rank Approximation under Clipping (BLC). R1-FLR applies the R1-Sketch with Gaussian projection for the fast low-rank approximation, enabling outlier-aware rank extraction for each layer. Meanwhile, BLC aims at minimizing the low-rank quantization error under the scaling and clipping strategy through an iterative method. FLRQ demonstrates strong effectiveness and robustness in comprehensive experiments, achieving state-of-the-art performance in both quantization quality and algorithm efficiency.", "AI": {"tldr": "FLRQ is a flexible low-rank quantization method that quickly identifies optimal ranks per layer and aggregates them for minimal storage, outperforming existing PTQ methods in both quality and efficiency.", "motivation": "Existing low-rank PTQ methods require costly fine-tuning to determine compromise ranks for diverse data and layers, failing to exploit full potential. Current SVD-based approaches compound computational overhead.", "method": "FLRQ has two components: 1) R1-FLR uses R1-Sketch with Gaussian projection for fast low-rank approximation and outlier-aware rank extraction per layer, 2) BLC minimizes low-rank quantization error under scaling/clipping via iterative method.", "result": "FLRQ demonstrates strong effectiveness and robustness, achieving state-of-the-art performance in both quantization quality and algorithm efficiency in comprehensive experiments.", "conclusion": "FLRQ provides a novel solution that quickly identifies accuracy-optimal ranks and aggregates them for minimal storage combinations, outperforming traditional PTQ methods."}}
{"id": "2601.05604", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05604", "abs": "https://arxiv.org/abs/2601.05604", "authors": ["Zengbin Wang", "Junjie Li", "Saihui Hou", "Xu Liu", "Chunshui Cao", "Yongzhen Huang", "Muyi Sun", "Siye Wang", "Man Zhang"], "title": "Learning Geometric Invariance for Gait Recognition", "comment": null, "summary": "The goal of gait recognition is to extract identity-invariant features of an individual under various gait conditions, e.g., cross-view and cross-clothing. Most gait models strive to implicitly learn the common traits across different gait conditions in a data-driven manner to pull different gait conditions closer for recognition. However, relatively few studies have explicitly explored the inherent relations between different gait conditions. For this purpose, we attempt to establish connections among different gait conditions and propose a new perspective to achieve gait recognition: variations in different gait conditions can be approximately viewed as a combination of geometric transformations. In this case, all we need is to determine the types of geometric transformations and achieve geometric invariance, then identity invariance naturally follows. As an initial attempt, we explore three common geometric transformations (i.e., Reflect, Rotate, and Scale) and design a $\\mathcal{R}$eflect-$\\mathcal{R}$otate-$\\mathcal{S}$cale invariance learning framework, named ${\\mathcal{RRS}}$-Gait. Specifically, it first flexibly adjusts the convolution kernel based on the specific geometric transformations to achieve approximate feature equivariance. Then these three equivariant-aware features are respectively fed into a global pooling operation for final invariance-aware learning. Extensive experiments on four popular gait datasets (Gait3D, GREW, CCPG, SUSTech1K) show superior performance across various gait conditions.", "AI": {"tldr": "The paper proposes RRS-Gait, a gait recognition framework that treats variations in gait conditions as geometric transformations (Reflect, Rotate, Scale) and learns invariance to these transformations for better identity recognition.", "motivation": "Most gait recognition models implicitly learn common traits across different conditions, but few explicitly explore inherent relations between gait conditions. The authors aim to establish connections among different gait conditions by viewing variations as geometric transformations.", "method": "Proposes RRS-Gait framework that explores three geometric transformations (Reflect, Rotate, Scale). It adjusts convolution kernels based on specific transformations to achieve approximate feature equivariance, then feeds these equivariant-aware features into global pooling for invariance-aware learning.", "result": "Extensive experiments on four popular gait datasets (Gait3D, GREW, CCPG, SUSTech1K) show superior performance across various gait conditions.", "conclusion": "Variations in different gait conditions can be viewed as geometric transformations. By determining transformation types and achieving geometric invariance, identity invariance naturally follows, leading to improved gait recognition performance."}}
{"id": "2511.18721", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18721", "abs": "https://arxiv.org/abs/2511.18721", "authors": ["Adarsh Kumarappan", "Ayushi Mehrotra"], "title": "Towards Realistic Guarantees: A Probabilistic Certificate for SmoothLLM", "comment": null, "summary": "The SmoothLLM defense provides a certification guarantee against jailbreaking attacks, but it relies on a strict `k-unstable' assumption that rarely holds in practice. This strong assumption can limit the trustworthiness of the provided safety certificate. In this work, we address this limitation by introducing a more realistic probabilistic framework, `(k, $\\varepsilon$)-unstable,' to certify defenses against diverse jailbreaking attacks, from gradient-based (GCG) to semantic (PAIR). We derive a new, data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success, providing a more trustworthy and practical safety certificate. By introducing the notion of (k, $\\varepsilon$)-unstable, our framework provides practitioners with actionable safety guarantees, enabling them to set certification thresholds that better reflect the real-world behavior of LLMs. Ultimately, this work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to the exploitation of their safety alignments, a critical challenge in secure AI deployment.", "AI": {"tldr": "The paper introduces a more realistic probabilistic framework called (k, \u03b5)-unstable to improve SmoothLLM's certification guarantees against jailbreaking attacks, addressing limitations of the original strict k-unstable assumption.", "motivation": "The original SmoothLLM defense provides certification guarantees but relies on a strict 'k-unstable' assumption that rarely holds in practice, limiting the trustworthiness of safety certificates. This work aims to address this limitation by developing a more realistic framework.", "method": "Introduces a probabilistic framework called (k, \u03b5)-unstable that better reflects real-world conditions. Derives a new data-informed lower bound on SmoothLLM's defense probability by incorporating empirical models of attack success across diverse jailbreaking attacks (from gradient-based GCG to semantic PAIR).", "result": "Provides a more trustworthy and practical safety certificate framework that enables practitioners to set certification thresholds that better reflect real-world LLM behavior. The framework offers actionable safety guarantees against diverse jailbreaking attacks.", "conclusion": "This work contributes a practical and theoretically-grounded mechanism to make LLMs more resistant to exploitation of their safety alignments, addressing a critical challenge in secure AI deployment through improved certification frameworks."}}
{"id": "2601.05732", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05732", "abs": "https://arxiv.org/abs/2601.05732", "authors": ["Yongyi Yang", "Jianyang Gao"], "title": "mHC-lite: You Don't Need 20 Sinkhorn-Knopp Iterations", "comment": null, "summary": "Hyper-Connections (HC) generalizes residual connections by introducing dynamic residual matrices that mix information across multiple residual streams, accelerating convergence in deep neural networks. However, unconstrained residual matrices can compromise training stability. To address this, DeepSeek's Manifold-Constrained Hyper-Connections (mHC) approximately projects these matrices onto the Birkhoff polytope via iterative Sinkhorn--Knopp (SK) normalization. We identify two limitations of this approach: (i) finite SK iterations do not guarantee exact doubly stochasticity, leaving an approximation gap that can accumulate through network depth and undermine stability; (ii) efficient SK implementation requires highly specialized CUDA kernels, raising engineering barriers and reducing portability. Motivated by the Birkhoff--von Neumann theorem, we propose mHC-lite, a simple reparameterization that explicitly constructs doubly stochastic matrices as convex combinations of permutation matrices. This approach guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations. Extensive experiments demonstrate that mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with a naive implementation and eliminating the residual instabilities observed in both HC and mHC. The code is publicly available at https://github.com/FFTYYY/mhc-lite.", "AI": {"tldr": "mHC-lite replaces mHC's iterative Sinkhorn-Knopp normalization with a simple reparameterization that constructs doubly stochastic matrices as convex combinations of permutation matrices, guaranteeing exact doubly stochasticity and better portability.", "motivation": "mHC's iterative Sinkhorn-Knopp normalization has two limitations: (1) finite iterations don't guarantee exact doubly stochasticity, creating approximation gaps that accumulate through network depth and undermine stability; (2) requires specialized CUDA kernels, raising engineering barriers and reducing portability.", "method": "mHC-lite uses a simple reparameterization based on the Birkhoff-von Neumann theorem, explicitly constructing doubly stochastic matrices as convex combinations of permutation matrices. This guarantees exact doubly stochasticity by construction and can be implemented using only native matrix operations.", "result": "mHC-lite matches or exceeds mHC in performance while achieving higher training throughput with naive implementation and eliminating residual instabilities observed in both HC and mHC.", "conclusion": "mHC-lite provides a simpler, more stable, and more portable alternative to mHC for implementing manifold-constrained hyper-connections, with guaranteed exact doubly stochasticity and better engineering practicality."}}
{"id": "2601.05611", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05611", "abs": "https://arxiv.org/abs/2601.05611", "authors": ["Chengen Xie", "Bin Sun", "Tianyu Li", "Junjie Wu", "Zhihui Hao", "XianPeng Lang", "Hongyang Li"], "title": "LatentVLA: Efficient Vision-Language Models for Autonomous Driving via Latent Action Prediction", "comment": null, "summary": "End-to-end autonomous driving models trained on largescale datasets perform well in common scenarios but struggle with rare, long-tail situations due to limited scenario diversity. Recent Vision-Language-Action (VLA) models leverage broad knowledge from pre-trained visionlanguage models to address this limitation, yet face critical challenges: (1) numerical imprecision in trajectory prediction due to discrete tokenization, (2) heavy reliance on language annotations that introduce linguistic bias and annotation burden, and (3) computational inefficiency from multi-step chain-of-thought reasoning hinders real-time deployment. We propose LatentVLA, a novel framework that employs self-supervised latent action prediction to train VLA models without language annotations, eliminating linguistic bias while learning rich driving representations from unlabeled trajectory data. Through knowledge distillation, LatentVLA transfers the generalization capabilities of VLA models to efficient vision-based networks, achieving both robust performance and real-time efficiency. LatentVLA establishes a new state-of-the-art on the NAVSIM benchmark with a PDMS score of 92.4 and demonstrates strong zeroshot generalization on the nuScenes benchmark.", "AI": {"tldr": "LatentVLA is a novel autonomous driving framework that uses self-supervised latent action prediction to train Vision-Language-Action models without language annotations, eliminating linguistic bias while achieving state-of-the-art performance and real-time efficiency.", "motivation": "Current autonomous driving models struggle with rare, long-tail scenarios due to limited dataset diversity. Existing Vision-Language-Action (VLA) models have three key limitations: numerical imprecision in trajectory prediction from discrete tokenization, heavy reliance on language annotations that introduce linguistic bias and annotation burden, and computational inefficiency from multi-step reasoning that hinders real-time deployment.", "method": "LatentVLA employs self-supervised latent action prediction to train VLA models without language annotations, eliminating linguistic bias while learning rich driving representations from unlabeled trajectory data. The framework uses knowledge distillation to transfer the generalization capabilities of VLA models to efficient vision-based networks.", "result": "LatentVLA establishes a new state-of-the-art on the NAVSIM benchmark with a PDMS score of 92.4 and demonstrates strong zero-shot generalization on the nuScenes benchmark, achieving both robust performance and real-time efficiency.", "conclusion": "LatentVLA successfully addresses the key limitations of existing VLA models by eliminating language annotations and their associated biases, while maintaining strong generalization capabilities and enabling real-time deployment through knowledge distillation to efficient vision-based networks."}}
{"id": "2511.19517", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19517", "abs": "https://arxiv.org/abs/2511.19517", "authors": ["Adarsh Kumarappan", "Ananya Mujoo"], "title": "Automating Deception: Scalable Multi-Turn LLM Jailbreaks", "comment": null, "summary": "Multi-turn conversational attacks, which leverage psychological principles like Foot-in-the-Door (FITD), where a small initial request paves the way for a more significant one, to bypass safety alignments, pose a persistent threat to Large Language Models (LLMs). Progress in defending against these attacks is hindered by a reliance on manual, hard-to-scale dataset creation. This paper introduces a novel, automated pipeline for generating large-scale, psychologically-grounded multi-turn jailbreak datasets. We systematically operationalize FITD techniques into reproducible templates, creating a benchmark of 1,500 scenarios across illegal activities and offensive content. We evaluate seven models from three major LLM families under both multi-turn (with history) and single-turn (without history) conditions. Our results reveal stark differences in contextual robustness: models in the GPT family demonstrate a significant vulnerability to conversational history, with Attack Success Rates (ASR) increasing by as much as 32 percentage points. In contrast, Google's Gemini 2.5 Flash exhibits exceptional resilience, proving nearly immune to these attacks, while Anthropic's Claude 3 Haiku shows strong but imperfect resistance. These findings highlight a critical divergence in how current safety architectures handle conversational context and underscore the need for defenses that can resist narrative-based manipulation.", "AI": {"tldr": "Automated pipeline generates large-scale psychologically-grounded multi-turn jailbreak datasets using Foot-in-the-Door techniques, revealing GPT models are vulnerable to conversational context while Gemini shows exceptional resilience.", "motivation": "Multi-turn conversational attacks using psychological principles like Foot-in-the-Door pose persistent threats to LLM safety, but defense progress is hindered by manual, hard-to-scale dataset creation.", "method": "Developed automated pipeline to generate large-scale psychologically-grounded multi-turn jailbreak datasets by systematically operationalizing FITD techniques into reproducible templates, creating 1,500 scenarios across illegal activities and offensive content.", "result": "GPT family shows significant vulnerability to conversational history (ASR increases up to 32 percentage points), Gemini 2.5 Flash is nearly immune, and Claude 3 Haiku shows strong but imperfect resistance.", "conclusion": "Critical divergence exists in how current safety architectures handle conversational context, highlighting need for defenses that can resist narrative-based manipulation."}}
{"id": "2601.05759", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05759", "abs": "https://arxiv.org/abs/2601.05759", "authors": ["Turkan Simge Ispak", "Salih Tileylioglu", "Erdem Akagunduz"], "title": "Variational Autoencoders for P-wave Detection on Strong Motion Earthquake Spectrograms", "comment": "13 pages, 8 figures, 3 tables", "summary": "Accurate P-wave detection is critical for earthquake early warning, yet strong-motion records pose challenges due to high noise levels, limited labeled data, and complex waveform characteristics. This study reframes P-wave arrival detection as a self-supervised anomaly detection task to evaluate how architectural variations regulate the trade-off between reconstruction fidelity and anomaly discrimination. Through a comprehensive grid search of 492 Variational Autoencoder configurations, we show that while skip connections minimize reconstruction error (Mean Absolute Error approximately 0.0012), they induce \"overgeneralization\", allowing the model to reconstruct noise and masking the detection signal. In contrast, attention mechanisms prioritize global context over local detail and yield the highest detection performance with an area-under-the-curve of 0.875. The attention-based Variational Autoencoder achieves an area-under-the-curve of 0.91 in the 0 to 40-kilometer near-source range, demonstrating high suitability for immediate early warning applications. These findings establish that architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection.", "AI": {"tldr": "Self-supervised anomaly detection using VAE architectures shows attention mechanisms outperform skip connections for P-wave detection in earthquake early warning by prioritizing global context over local reconstruction fidelity.", "motivation": "P-wave detection is critical for earthquake early warning but faces challenges from high noise levels, limited labeled data, and complex waveforms in strong-motion records.", "method": "Reframed P-wave detection as self-supervised anomaly detection task. Conducted comprehensive grid search of 492 Variational Autoencoder configurations to evaluate architectural trade-offs between reconstruction fidelity and anomaly discrimination.", "result": "Skip connections minimized reconstruction error (MAE ~0.0012) but caused \"overgeneralization\" that reconstructed noise and masked detection signals. Attention mechanisms prioritized global context over local detail and achieved highest detection performance (AUC 0.875), with AUC 0.91 in 0-40km near-source range.", "conclusion": "Architectural constraints favoring global context over pixel-perfect reconstruction are essential for robust, self-supervised P-wave detection, making attention-based VAEs highly suitable for immediate earthquake early warning applications."}}
{"id": "2601.05639", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05639", "abs": "https://arxiv.org/abs/2601.05639", "authors": ["Caroline Mazini Rodrigues", "Nicolas Keriven", "Thomas Maugey"], "title": "Compressing image encoders via latent distillation", "comment": null, "summary": "Deep learning models for image compression often face practical limitations in hardware-constrained applications. Although these models achieve high-quality reconstructions, they are typically complex, heavyweight, and require substantial training data and computational resources. We propose a methodology to partially compress these networks by reducing the size of their encoders. Our approach uses a simplified knowledge distillation strategy to approximate the latent space of the original models with less data and shorter training, yielding lightweight encoders from heavyweight ones. We evaluate the resulting lightweight encoders across two different architectures on the image compression task. Experiments show that our method preserves reconstruction quality and statistical fidelity better than training lightweight encoders with the original loss, making it practical for resource-limited environments.", "AI": {"tldr": "Proposed knowledge distillation method to compress deep learning image compression models by reducing encoder size while maintaining quality, using less data and training time.", "motivation": "Deep learning image compression models are typically complex, heavyweight, and require substantial training data/computational resources, making them impractical for hardware-constrained applications.", "method": "Uses simplified knowledge distillation strategy to approximate the latent space of original heavyweight models, creating lightweight encoders with less data and shorter training time.", "result": "Lightweight encoders preserve reconstruction quality and statistical fidelity better than training lightweight encoders with original loss, evaluated across two different architectures.", "conclusion": "The proposed method makes deep learning image compression practical for resource-limited environments by reducing encoder complexity while maintaining performance."}}
{"id": "2512.11847", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11847", "abs": "https://arxiv.org/abs/2512.11847", "authors": ["Antonio Roye-Azar", "Santiago Vargas-Naranjo", "Dhruv Ghai", "Nithin Balamurugan", "Rayan Amir"], "title": "Tiny Recursive Models on ARC-AGI-1: Inductive Biases, Identity Conditioning, and Test-Time Compute", "comment": "13 pages, 0 figures, 6 tables", "summary": "Tiny Recursive Models (TRM) were proposed as a parameter-efficient alternative to large language models for solving Abstraction and Reasoning Corpus (ARC) style tasks. The original work reports strong performance and suggests that recursive latent updates enable non-trivial reasoning, but it remains unclear how much of this performance stems from architecture, test-time compute, or task-specific priors. In this technical note, we empirically analyze the ARC Prize TRM checkpoint on ARC-AGI-1 and report four behavioral findings and an efficiency comparison. First, we show that test-time augmentation and majority-vote ensembling account for a substantial fraction of reported performance: the 1000-sample voting pipeline improves Pass@1 by about 11 percentage points over single-pass canonical inference. Second, a puzzle-identity ablation reveals strict dependence on task identifiers: replacing the correct puzzle ID with a blank or random token yields zero accuracy. Third, a recursion trajectory analysis shows that most of the final accuracy is achieved at the first recursion step and that performance saturates after few latent updates, indicating shallow effective recursion. Fourth, early-stage training experiments under canonical versus heavy augmentation regimes suggest that heavy augmentation broadens the distribution of candidate solutions and improves multi-sample success. Finally, we compare TRM with a naive QLoRA fine-tune of Llama 3 8B on canonical ARC-AGI-1, finding that TRM's non-autoregressive design achieves much higher throughput and substantially lower memory usage in this setting. Overall, TRM's ARC-AGI-1 performance appears to arise from an interaction between efficiency, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning.", "AI": {"tldr": "TRM's strong ARC-AGI-1 performance comes mainly from test-time augmentation/voting, task ID dependence, shallow recursion, and efficiency advantages rather than deep reasoning capabilities.", "motivation": "To understand what drives TRM's reported strong performance on ARC tasks - whether it's architecture, test-time compute, or task-specific priors, since the original work left this unclear.", "method": "Empirical analysis of ARC Prize TRM checkpoint on ARC-AGI-1 through: 1) test-time augmentation/voting ablation, 2) puzzle-identity ablation, 3) recursion trajectory analysis, 4) early training experiments with different augmentation regimes, and 5) efficiency comparison with QLoRA-finetuned Llama 3 8B.", "result": "1) 1000-sample voting improves Pass@1 by ~11pp over single inference; 2) Zero accuracy without correct puzzle ID; 3) Most accuracy achieved at first recursion step, shallow effective recursion; 4) Heavy augmentation broadens solution distribution; 5) TRM has much higher throughput and lower memory than QLoRA Llama 3 8B.", "conclusion": "TRM's performance stems from efficiency advantages, task-specific conditioning, and aggressive test-time compute rather than deep internal reasoning capabilities."}}
{"id": "2601.05770", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05770", "abs": "https://arxiv.org/abs/2601.05770", "authors": ["Yifan Zhang", "Wei Bi", "Kechi Zhang", "Dongming Jin", "Jie Fu", "Zhi Jin"], "title": "Weights to Code: Extracting Interpretable Algorithms from the Discrete Transformer", "comment": null, "summary": "Algorithm extraction aims to synthesize executable programs directly from models trained on specific algorithmic tasks, enabling de novo algorithm discovery without relying on human-written code. However, extending this paradigm to Transformer is hindered by superposition, where entangled features encoded in overlapping directions obstruct the extraction of symbolic expressions. In this work, we propose the Discrete Transformer, an architecture explicitly engineered to bridge the gap between continuous representations and discrete symbolic logic. By enforcing a strict functional disentanglement, which constrains Numerical Attention to information routing and Numerical MLP to element-wise arithmetic, and employing temperature-annealed sampling, our method effectively facilitates the extraction of human-readable programs. Empirically, the Discrete Transformer not only achieves performance comparable to RNN-based baselines but crucially extends interpretability to continuous variable domains. Moreover, our analysis of the annealing process shows that the efficient discrete search undergoes a clear phase transition from exploration to exploitation. We further demonstrate that our method enables fine-grained control over synthesized programs by imposing inductive biases. Collectively, these findings establish the Discrete Transformer as a robust framework for demonstration-free algorithm discovery, offering a rigorous pathway toward Transformer interpretability.", "AI": {"tldr": "Discrete Transformer enables extraction of human-readable programs from trained models by enforcing functional disentanglement and using temperature-annealed sampling, bridging continuous representations with discrete symbolic logic.", "motivation": "Transformer models suffer from superposition where entangled features obstruct extraction of symbolic expressions, hindering algorithm extraction and interpretability in continuous variable domains.", "method": "Proposes Discrete Transformer with strict functional disentanglement (Numerical Attention for routing, Numerical MLP for element-wise arithmetic) and temperature-annealed sampling to facilitate program extraction.", "result": "Achieves performance comparable to RNN-based baselines, extends interpretability to continuous domains, shows clear phase transition in annealing process, and enables fine-grained program control via inductive biases.", "conclusion": "Discrete Transformer establishes a robust framework for demonstration-free algorithm discovery and offers a rigorous pathway toward Transformer interpretability."}}
{"id": "2601.05640", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05640", "abs": "https://arxiv.org/abs/2601.05640", "authors": ["Jingyu Li", "Junjie Wu", "Dongnan Hu", "Xiangkai Huang", "Bin Sun", "Zhihui Hao", "Xianpeng Lang", "Xiatian Zhu", "Li Zhang"], "title": "SGDrive: Scene-to-Goal Hierarchical World Cognition for Autonomous Driving", "comment": null, "summary": "Recent end-to-end autonomous driving approaches have leveraged Vision-Language Models (VLMs) to enhance planning capabilities in complex driving scenarios. However, VLMs are inherently trained as generalist models, lacking specialized understanding of driving-specific reasoning in 3D space and time. When applied to autonomous driving, these models struggle to establish structured spatial-temporal representations that capture geometric relationships, scene context, and motion patterns critical for safe trajectory planning. To address these limitations, we propose SGDrive, a novel framework that explicitly structures the VLM's representation learning around driving-specific knowledge hierarchies. Built upon a pre-trained VLM backbone, SGDrive decomposes driving understanding into a scene-agent-goal hierarchy that mirrors human driving cognition: drivers first perceive the overall environment (scene context), then attend to safety-critical agents and their behaviors, and finally formulate short-term goals before executing actions. This hierarchical decomposition provides the structured spatial-temporal representation that generalist VLMs lack, integrating multi-level information into a compact yet comprehensive format for trajectory planning. Extensive experiments on the NAVSIM benchmark demonstrate that SGDrive achieves state-of-the-art performance among camera-only methods on both PDMS and EPDMS, validating the effectiveness of hierarchical knowledge structuring for adapting generalist VLMs to autonomous driving.", "AI": {"tldr": "SGDrive is a novel framework that structures Vision-Language Model representation learning around driving-specific knowledge hierarchies (scene-agent-goal) to enhance autonomous driving planning capabilities.", "motivation": "Generalist Vision-Language Models lack specialized understanding of driving-specific reasoning in 3D space and time, struggling to establish structured spatial-temporal representations needed for safe trajectory planning in autonomous driving.", "method": "SGDrive decomposes driving understanding into a hierarchical scene-agent-goal structure that mirrors human driving cognition, built upon a pre-trained VLM backbone to provide structured spatial-temporal representation for trajectory planning.", "result": "Extensive experiments on NAVSIM benchmark show SGDrive achieves state-of-the-art performance among camera-only methods on both PDMS and EPDMS metrics.", "conclusion": "Hierarchical knowledge structuring effectively adapts generalist VLMs to autonomous driving by providing the structured spatial-temporal representations they inherently lack."}}
{"id": "2601.05792", "categories": ["cs.LG", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2601.05792", "abs": "https://arxiv.org/abs/2601.05792", "authors": ["Manel Gil-Sorribes", "J\u00falia Vilalta-Mor", "Isaac Filella-Merc\u00e8", "Robert Soliva", "\u00c1lvaro Ciudad", "V\u00edctor Guallar", "Alexis Molina"], "title": "Tensor-DTI: Enhancing Biomolecular Interaction Prediction with Contrastive Embedding Learning", "comment": "Accepted at the Generative and Experimental Perspectives for Biomolecular Design Workshop at ICLR 2025 and at the Learning Meaningful Representations of Life Workshop at ICLR 2025", "summary": "Accurate drug-target interaction (DTI) prediction is essential for computational drug discovery, yet existing models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness. We propose Tensor-DTI, a contrastive learning framework that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to improve interaction modeling. Tensor-DTI employs a siamese dual-encoder architecture, enabling it to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs. Evaluations on multiple DTI benchmarks demonstrate that Tensor-DTI outperforms existing sequence-based and graph-based models. We also conduct large-scale inference experiments on CDK2 across billion-scale chemical libraries, where Tensor-DTI produces chemically plausible hit distributions even when CDK2 is withheld from training. In enrichment studies against Glide docking and Boltz-2 co-folder, Tensor-DTI remains competitive on CDK2 and improves the screening budget required to recover moderate fractions of high-affinity ligands on out-of-family targets under strict family-holdout splits. Additionally, we explore its applicability to protein-RNA and peptide-protein interactions. Our findings highlight the benefits of integrating multimodal information with contrastive objectives to enhance interaction-prediction accuracy and to provide more interpretable and reliability-aware models for virtual screening.", "AI": {"tldr": "Tensor-DTI is a contrastive learning framework that integrates multimodal embeddings (molecular graphs, protein language models, binding-site predictions) to improve drug-target interaction prediction accuracy and virtual screening performance.", "motivation": "Existing DTI prediction models often rely on single-modality predefined molecular descriptors or sequence-based embeddings with limited representativeness, which restricts their ability to accurately model drug-target interactions.", "method": "Tensor-DTI uses a contrastive learning framework with siamese dual-encoder architecture that integrates multimodal embeddings from molecular graphs, protein language models, and binding-site predictions to capture both chemical and structural interaction features while distinguishing interacting from non-interacting pairs.", "result": "Tensor-DTI outperforms existing sequence-based and graph-based models on multiple DTI benchmarks, produces chemically plausible hit distributions in large-scale inference experiments on CDK2, remains competitive with Glide docking and Boltz-2 co-folder in enrichment studies, and shows applicability to protein-RNA and peptide-protein interactions.", "conclusion": "Integrating multimodal information with contrastive objectives enhances interaction-prediction accuracy and provides more interpretable and reliability-aware models for virtual screening, demonstrating the benefits of comprehensive molecular representation learning."}}
{"id": "2601.05688", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05688", "abs": "https://arxiv.org/abs/2601.05688", "authors": ["Muye Huang", "Lingling Zhang", "Yifei Li", "Yaqiang Wu", "Jun Liu"], "title": "SketchVL: Policy Optimization via Fine-Grained Credit Assignment for Chart Understanding and More", "comment": null, "summary": "Charts are high-density visual carriers of complex data and medium for information extraction and analysis. Due to the need for precise and complex visual reasoning, automated chart understanding poses a significant challenge to existing Multimodal Large Language Models (MLLMs). Many MLLMs trained with reinforcement learning (RL) face the challenge of credit assignment. Their advantage estimation, typically performed at the trajectory level, cannot distinguish between correct and incorrect reasoning steps within a single generated response. To address this limitation, we introduce SketchVL, a novel MLLM that optimized with FinePO, a new RL algorithm designed for fine-grained credit assignment within each trajectory. SketchVL's methodology involves drawing its intermediate reasoning steps as markers on the image and feeding the annotated image back to itself, creating a robust, multi-step reasoning process. During training, the FinePO algorithm leverages a Fine-grained Process Reward Model (FinePRM) to score each drawing action within a trajectory, thereby precisely assigning credit for each step. This mechanism allows FinePO to more strongly reward correct tokens when a trajectory is globally successful, and more heavily penalize incorrect tokens when the trajectory is globally suboptimal, thus achieving fine-grained reinforcement signals. Experiments show that SketchVL learns to align its step-level behavior with the FinePRM, achieving an average performance gain of 7.23\\% over its base model across chart datasets, natural image datasets, and mathematics, providing a promising new direction for training powerful reasoning models.", "AI": {"tldr": "SketchVL is a novel MLLM that uses FinePO RL algorithm with fine-grained credit assignment for chart understanding, achieving 7.23% performance gain over base model.", "motivation": "Chart understanding requires precise visual reasoning, but existing MLLMs trained with RL face credit assignment challenges - they can't distinguish between correct and incorrect reasoning steps within a single response, leading to suboptimal training signals.", "method": "SketchVL draws intermediate reasoning steps as markers on images and feeds annotated images back to itself for multi-step reasoning. It uses FinePO RL algorithm with Fine-grained Process Reward Model (FinePRM) to score each drawing action within trajectories, enabling precise step-level credit assignment.", "result": "SketchVL achieves average 7.23% performance gain over base model across chart datasets, natural image datasets, and mathematics, demonstrating effective alignment of step-level behavior with FinePRM.", "conclusion": "The approach provides a promising direction for training powerful reasoning models by enabling fine-grained reinforcement signals that reward correct tokens in successful trajectories and penalize incorrect tokens in suboptimal ones."}}
{"id": "2601.05807", "categories": ["cs.LG", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.05807", "abs": "https://arxiv.org/abs/2601.05807", "authors": ["Mohamed Amine Hallam", "Kuo-Kun Tseng"], "title": "Fusion Matters: Length-Aware Analysis of Positional-Encoding Fusion in Transformers", "comment": "10 pages, 5 figures. Code and reproduction materials available on GitHub", "summary": "Transformers require positional encodings to represent sequence order, yet most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. In this paper, we study whether the fusion mechanism itself affects performance, particularly in long-sequence settings. We conduct a controlled empirical study comparing three canonical fusion strategies--element-wise addition, concatenation with projection, and scalar gated fusion--under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences show that fusion choice has negligible impact on short texts but produces consistent gains on long documents. To verify that these gains are structural rather than stochastic, we perform paired-seed analysis and cross-dataset comparison across sequence-length regimes. Additional experiments on the ArXiv dataset indicate that the benefit of learnable fusion generalizes across multiple positional encoding families. Finally, we explore a lightweight convolutional gating mechanism that introduces local inductive bias at the fusion level, evaluated on long documents only. Our results indicate that positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default.", "AI": {"tldr": "Positional encoding fusion mechanisms (addition, concatenation, gating) have negligible impact on short texts but produce consistent performance gains on long documents in Transformers.", "motivation": "Most prior work focuses on designing new positional encodings rather than examining how positional information is fused with token embeddings. The paper investigates whether the fusion mechanism itself affects performance, particularly in long-sequence settings.", "method": "Controlled empirical study comparing three canonical fusion strategies (element-wise addition, concatenation with projection, scalar gated fusion) under identical Transformer architectures, data splits, and random seeds. Experiments on three text classification datasets spanning short (AG News), medium (IMDB), and long (ArXiv) sequences. Additional analysis includes paired-seed analysis, cross-dataset comparison, and exploration of lightweight convolutional gating mechanism for local inductive bias.", "result": "Fusion choice has negligible impact on short texts but produces consistent gains on long documents. The benefit of learnable fusion generalizes across multiple positional encoding families. The lightweight convolutional gating mechanism shows promise for long documents.", "conclusion": "Positional-encoding fusion is a non-trivial design choice for long-sequence Transformers and should be treated as an explicit modeling decision rather than a fixed default."}}
{"id": "2601.05722", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05722", "abs": "https://arxiv.org/abs/2601.05722", "authors": ["Jin Wang", "Jianxiang Lu", "Comi Chen", "Guangzheng Xu", "Haoyu Yang", "Peng Chen", "Na Zhang", "Yifan Xu", "Longhuang Wu", "Shuai Shao", "Qinglin Lu", "Ping Luo"], "title": "Rotate Your Character: Revisiting Video Diffusion Models for High-Quality 3D Character Generation", "comment": "11 pages, 8 figures", "summary": "Generating high-quality 3D characters from single images remains a significant challenge in digital content creation, particularly due to complex body poses and self-occlusion. In this paper, we present RCM (Rotate your Character Model), an advanced image-to-video diffusion framework tailored for high-quality novel view synthesis (NVS) and 3D character generation. Compared to existing diffusion-based approaches, RCM offers several key advantages: (1) transferring characters with any complex poses into a canonical pose, enabling consistent novel view synthesis across the entire viewing orbit, (2) high-resolution orbital video generation at 1024x1024 resolution, (3) controllable observation positions given different initial camera poses, and (4) multi-view conditioning supporting up to 4 input images, accommodating diverse user scenarios. Extensive experiments demonstrate that RCM outperforms state-of-the-art methods in both novel view synthesis and 3D generation quality.", "AI": {"tldr": "RCM is an image-to-video diffusion framework for high-quality 3D character generation from single images, addressing challenges like complex poses and self-occlusion through canonical pose transfer and orbital video generation.", "motivation": "Generating high-quality 3D characters from single images is challenging due to complex body poses and self-occlusion. Existing methods struggle with these issues, creating a need for better solutions in digital content creation.", "method": "RCM uses an image-to-video diffusion framework that transfers characters with complex poses into canonical poses, enables 1024x1024 orbital video generation, provides controllable observation positions, and supports multi-view conditioning with up to 4 input images.", "result": "RCM outperforms state-of-the-art methods in both novel view synthesis and 3D generation quality, demonstrating superior performance through extensive experiments.", "conclusion": "RCM presents an advanced solution for high-quality 3D character generation from single images, offering significant improvements over existing approaches through its canonical pose transfer, high-resolution orbital video generation, and multi-view conditioning capabilities."}}
{"id": "2601.05811", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05811", "abs": "https://arxiv.org/abs/2601.05811", "authors": ["Enrique Feito-Casares", "Francisco M. Melgarejo-Meseguer", "Jos\u00e9-Luis Rojo-\u00c1lvarez"], "title": "Learning Reconstructive Embeddings in Reproducing Kernel Hilbert Spaces via the Representer Theorem", "comment": null, "summary": "Motivated by the growing interest in representation learning approaches that uncover the latent structure of high-dimensional data, this work proposes new algorithms for reconstruction-based manifold learning within Reproducing-Kernel Hilbert Spaces (RKHS). Each observation is first reconstructed as a linear combination of the other samples in the RKHS, by optimizing a vector form of the Representer Theorem for their autorepresentation property. A separable operator-valued kernel extends the formulation to vector-valued data while retaining the simplicity of a single scalar similarity function. A subsequent kernel-alignment task projects the data into a lower-dimensional latent space whose Gram matrix aims to match the high-dimensional reconstruction kernel, thus transferring the auto-reconstruction geometry of the RKHS to the embedding. Therefore, the proposed algorithms represent an extended approach to the autorepresentation property, exhibited by many natural data, by using and adapting well-known results of Kernel Learning Theory. Numerical experiments on both simulated (concentric circles and swiss-roll) and real (cancer molecular activity and IoT network intrusions) datasets provide empirical evidence of the practical effectiveness of the proposed approach.", "AI": {"tldr": "New RKHS-based manifold learning algorithms using autorepresentation and kernel alignment for dimensionality reduction.", "motivation": "Growing interest in representation learning approaches that uncover latent structure of high-dimensional data, with focus on reconstruction-based manifold learning.", "method": "1) Reconstruct observations as linear combinations of other samples in RKHS using vector form of Representer Theorem; 2) Use separable operator-valued kernel for vector-valued data; 3) Kernel-alignment task projects data to lower-dimensional latent space matching high-dimensional reconstruction kernel.", "result": "Numerical experiments on simulated (concentric circles, swiss-roll) and real (cancer molecular activity, IoT network intrusions) datasets show practical effectiveness.", "conclusion": "Proposed algorithms extend autorepresentation property using Kernel Learning Theory, transferring auto-reconstruction geometry of RKHS to embeddings."}}
{"id": "2601.05729", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05729", "abs": "https://arxiv.org/abs/2601.05729", "authors": ["Jin Wang", "Jianxiang Lu", "Guangzheng Xu", "Comi Chen", "Haoyu Yang", "Linqing Wang", "Peng Chen", "Mingtao Chen", "Zhichao Hu", "Longhuang Wu", "Shuai Shao", "Qinglin Lu", "Ping Luo"], "title": "TAGRPO: Boosting GRPO on Image-to-Video Generation with Direct Trajectory Alignment", "comment": "12 pages, 6 figures", "summary": "Recent studies have demonstrated the efficacy of integrating Group Relative Policy Optimization (GRPO) into flow matching models, particularly for text-to-image and text-to-video generation. However, we find that directly applying these techniques to image-to-video (I2V) models often fails to yield consistent reward improvements. To address this limitation, we present TAGRPO, a robust post-training framework for I2V models inspired by contrastive learning. Our approach is grounded in the observation that rollout videos generated from identical initial noise provide superior guidance for optimization. Leveraging this insight, we propose a novel GRPO loss applied to intermediate latents, encouraging direct alignment with high-reward trajectories while maximizing distance from low-reward counterparts. Furthermore, we introduce a memory bank for rollout videos to enhance diversity and reduce computational overhead. Despite its simplicity, TAGRPO achieves significant improvements over DanceGRPO in I2V generation.", "AI": {"tldr": "TAGRPO is a robust post-training framework for image-to-video models that improves upon GRPO by using contrastive learning principles and intermediate latent optimization.", "motivation": "Direct application of Group Relative Policy Optimization (GRPO) techniques to image-to-video (I2V) models fails to yield consistent reward improvements, creating a need for a more effective approach.", "method": "TAGRPO uses a novel GRPO loss applied to intermediate latents, leveraging rollout videos from identical initial noise for optimization guidance. It also introduces a memory bank for rollout videos to enhance diversity and reduce computational overhead.", "result": "TAGRPO achieves significant improvements over DanceGRPO in I2V generation, despite its simplicity.", "conclusion": "The proposed TAGRPO framework provides an effective solution for improving I2V models through contrastive learning-inspired optimization of intermediate latents."}}
{"id": "2601.05812", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05812", "abs": "https://arxiv.org/abs/2601.05812", "authors": ["Zhanpei Huang", "Taochen chen", "Fangqing Gu", "Yiqun Zhang"], "title": "Detecting Autism Spectrum Disorder with Deep Eye Movement Features", "comment": "Accepted to CIS 2025", "summary": "Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by deficits in social communication and behavioral patterns. Eye movement data offers a non-invasive diagnostic tool for ASD detection, as it is inherently discrete and exhibits short-term temporal dependencies, reflecting localized gaze focus between fixation points. These characteristics enable the data to provide deeper insights into subtle behavioral markers, distinguishing ASD-related patterns from typical development. Eye movement signals mainly contain short-term and localized dependencies. However, despite the widespread application of stacked attention layers in Transformer-based models for capturing long-range dependencies, our experimental results indicate that this approach yields only limited benefits when applied to eye movement data. This may be because discrete fixation points and short-term dependencies in gaze focus reduce the utility of global attention mechanisms, making them less efficient than architectures focusing on local temporal patterns. To efficiently capture subtle and complex eye movement patterns, distinguishing ASD from typically developing (TD) individuals, a discrete short-term sequential (DSTS) modeling framework is designed with Class-aware Representation and Imbalance-aware Mechanisms. Through extensive experiments on several eye movement datasets, DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models.", "AI": {"tldr": "A new discrete short-term sequential (DSTS) modeling framework outperforms traditional and deep learning methods for Autism Spectrum Disorder detection using eye movement data by focusing on local temporal patterns rather than global attention mechanisms.", "motivation": "Eye movement data provides non-invasive diagnostic potential for ASD detection due to its discrete nature and short-term temporal dependencies, but existing Transformer-based models with global attention mechanisms are inefficient for this type of data.", "method": "Proposed a discrete short-term sequential (DSTS) modeling framework with Class-aware Representation and Imbalance-aware Mechanisms specifically designed to capture subtle and complex eye movement patterns by focusing on local temporal dependencies rather than global attention.", "result": "DSTS outperforms both traditional machine learning techniques and more sophisticated deep learning models across several eye movement datasets for ASD detection.", "conclusion": "The discrete and short-term nature of eye movement data requires specialized modeling approaches like DSTS that focus on local temporal patterns rather than global attention mechanisms for effective ASD detection."}}
{"id": "2601.05738", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05738", "abs": "https://arxiv.org/abs/2601.05738", "authors": ["Christopher Thirgood", "Oscar Mendez", "Erin Ling", "Jon Storey", "Simon Hadfield"], "title": "FeatureSLAM: Feature-enriched 3D gaussian splatting SLAM in real time", "comment": null, "summary": "We present a real-time tracking SLAM system that unifies efficient camera tracking with photorealistic feature-enriched mapping using 3D Gaussian Splatting (3DGS). Our main contribution is integrating dense feature rasterization into the novel-view synthesis, aligned with a visual foundation model. This yields strong semantics, going beyond basic RGB-D input, aiding both tracking and mapping accuracy. Unlike previous semantic SLAM approaches (which embed pre-defined class labels) FeatureSLAM enables entirely new downstream tasks via free-viewpoint, open-set segmentation. Across standard benchmarks, our method achieves real-time tracking, on par with state-of-the-art systems while improving tracking stability and map fidelity without prohibitive compute. Quantitatively, we obtain 9\\% lower pose error and 8\\% higher mapping accuracy compared to recent fixed-set SLAM baselines. Our results confirm that real-time feature-embedded SLAM, is not only valuable for enabling new downstream applications. It also improves the performance of the underlying tracking and mapping subsystems, providing semantic and language masking results that are on-par with offline 3DGS models, alongside state-of-the-art tracking, depth and RGB rendering.", "AI": {"tldr": "Real-time SLAM system combining camera tracking with photorealistic mapping using 3D Gaussian Splatting, featuring dense feature rasterization aligned with visual foundation models for open-set segmentation capabilities.", "motivation": "To create a real-time SLAM system that goes beyond basic RGB-D input by incorporating strong semantic features, enabling new downstream applications while improving tracking and mapping accuracy compared to existing semantic SLAM approaches that rely on pre-defined class labels.", "method": "Integrates dense feature rasterization into novel-view synthesis using 3D Gaussian Splatting (3DGS), aligned with visual foundation models. This enables photorealistic feature-enriched mapping while maintaining real-time camera tracking capabilities.", "result": "Achieves 9% lower pose error and 8% higher mapping accuracy compared to recent fixed-set SLAM baselines. Provides real-time tracking on par with state-of-the-art systems while improving tracking stability and map fidelity without prohibitive compute. Enables free-viewpoint, open-set segmentation.", "conclusion": "Real-time feature-embedded SLAM not only enables new downstream applications but also improves the performance of underlying tracking and mapping subsystems, providing semantic and language masking results comparable to offline 3DGS models alongside state-of-the-art tracking, depth and RGB rendering."}}
{"id": "2601.05814", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05814", "abs": "https://arxiv.org/abs/2601.05814", "authors": ["Md Sultanul Islam Ovi", "Muhsina Tarannum Munfa", "Miftahul Alam Adib", "Syed Sabbir Hasan"], "title": "A Dual Pipeline Machine Learning Framework for Automated Multi Class Sleep Disorder Screening Using Hybrid Resampling and Ensemble Learning", "comment": "32 pages, 5 figures, 14 tables", "summary": "Accurate classification of sleep disorders, particularly insomnia and sleep apnea, is important for reducing long term health risks and improving patient quality of life. However, clinical sleep studies are resource intensive and are difficult to scale for population level screening. This paper presents a Dual Pipeline Machine Learning Framework for multi class sleep disorder screening using the Sleep Health and Lifestyle dataset. The framework consists of two parallel processing streams: a statistical pipeline that targets linear separability using Mutual Information and Linear Discriminant Analysis, and a wrapper based pipeline that applies Boruta feature selection with an autoencoder for non linear representation learning. To address class imbalance, we use the hybrid SMOTETomek resampling strategy. In experiments, Extra Trees and K Nearest Neighbors achieved an accuracy of 98.67%, outperforming recent baselines on the same dataset. Statistical testing using the Wilcoxon Signed Rank Test indicates that the improvement over baseline configurations is significant, and inference latency remains below 400 milliseconds. These results suggest that the proposed dual pipeline design supports accurate and efficient automated screening for non invasive sleep disorder risk stratification.", "AI": {"tldr": "A dual-pipeline ML framework achieves 98.67% accuracy for sleep disorder screening using statistical and wrapper-based approaches with SMOTETomek for class imbalance.", "motivation": "Clinical sleep studies are resource-intensive and difficult to scale for population-level screening, creating a need for automated, non-invasive screening methods for sleep disorders like insomnia and sleep apnea.", "method": "Dual-pipeline framework with: 1) statistical pipeline using Mutual Information and Linear Discriminant Analysis for linear separability, and 2) wrapper-based pipeline using Boruta feature selection with autoencoder for non-linear representation learning. Uses SMOTETomek for class imbalance handling.", "result": "Extra Trees and K-Nearest Neighbors achieved 98.67% accuracy, outperforming recent baselines. Statistical testing shows significant improvement, with inference latency below 400ms.", "conclusion": "The dual-pipeline design supports accurate and efficient automated screening for non-invasive sleep disorder risk stratification, addressing scalability challenges of clinical sleep studies."}}
{"id": "2601.05741", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05741", "abs": "https://arxiv.org/abs/2601.05741", "authors": ["Guray Ozgur", "Eduarda Caldeira", "Tahar Chettaoui", "Jan Niklas Kolf", "Marco Huber", "Naser Damer", "Fadi Boutros"], "title": "ViTNT-FIQA: Training-Free Face Image Quality Assessment with Vision Transformers", "comment": "Accepted at WACV Workshops", "summary": "Face Image Quality Assessment (FIQA) is essential for reliable face recognition systems. Current approaches primarily exploit only final-layer representations, while training-free methods require multiple forward passes or backpropagation. We propose ViTNT-FIQA, a training-free approach that measures the stability of patch embedding evolution across intermediate Vision Transformer (ViT) blocks. We demonstrate that high-quality face images exhibit stable feature refinement trajectories across blocks, while degraded images show erratic transformations. Our method computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks and aggregates them into image-level quality scores. We empirically validate this correlation on a quality-labeled synthetic dataset with controlled degradation levels. Unlike existing training-free approaches, ViTNT-FIQA requires only a single forward pass without backpropagation or architectural modifications. Through extensive evaluation on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C), we show that ViTNT-FIQA achieves competitive performance with state-of-the-art methods while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.", "AI": {"tldr": "ViTNT-FIQA is a training-free face image quality assessment method that measures patch embedding stability across Vision Transformer blocks, requiring only a single forward pass without backpropagation.", "motivation": "Current FIQA approaches either use only final-layer representations or require multiple forward passes/backpropagation. There's a need for efficient training-free methods that leverage intermediate representations for quality assessment.", "method": "Proposes measuring stability of patch embedding evolution across intermediate ViT blocks. Computes Euclidean distances between L2-normalized patch embeddings from consecutive transformer blocks, then aggregates into image-level quality scores. Validated on quality-labeled synthetic dataset with controlled degradation levels.", "result": "Achieves competitive performance with state-of-the-art methods on eight benchmarks (LFW, AgeDB-30, CFP-FP, CALFW, Adience, CPLFW, XQLFW, IJB-C) while maintaining computational efficiency and immediate applicability to any pre-trained ViT-based face recognition model.", "conclusion": "ViTNT-FIQA provides an effective training-free FIQA approach that leverages intermediate ViT representations, requiring only single forward pass without backpropagation or architectural modifications, making it computationally efficient and readily applicable."}}
{"id": "2601.05845", "categories": ["cs.LG", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05845", "abs": "https://arxiv.org/abs/2601.05845", "authors": ["Eric Weine", "Peter Carbonetto", "Rafael A. Irizarry", "Matthew Stephens"], "title": "A New Family of Poisson Non-negative Matrix Factorization Methods Using the Shifted Log Link", "comment": null, "summary": "Poisson non-negative matrix factorization (NMF) is a widely used method to find interpretable \"parts-based\" decompositions of count data. While many variants of Poisson NMF exist, existing methods assume that the \"parts\" in the decomposition combine additively. This assumption may be natural in some settings, but not in others. Here we introduce Poisson NMF with the shifted-log link function to relax this assumption. The shifted-log link function has a single tuning parameter, and as this parameter varies the model changes from assuming that parts combine additively (i.e., standard Poisson NMF) to assuming that parts combine more multiplicatively. We provide an algorithm to fit this model by maximum likelihood, and also an approximation that substantially reduces computation time for large, sparse datasets (computations scale with the number of non-zero entries in the data matrix). We illustrate these new methods on a variety of real datasets. Our examples show how the choice of link function in Poisson NMF can substantively impact the results, and how in some settings the use of a shifted-log link function may improve interpretability compared with the standard, additive link.", "AI": {"tldr": "Poisson NMF with shifted-log link function relaxes the additive combination assumption of standard Poisson NMF, allowing parts to combine more multiplicatively via a tunable parameter.", "motivation": "Standard Poisson NMF assumes parts combine additively, which may not be appropriate for all count data settings. There's a need for more flexible link functions that can capture multiplicative combinations of parts.", "method": "Introduces Poisson NMF with shifted-log link function that has a single tuning parameter. Provides maximum likelihood fitting algorithm and an approximation for large, sparse datasets that scales with non-zero entries.", "result": "Demonstrated on various real datasets showing that choice of link function substantively impacts results. Shifted-log link can improve interpretability compared to standard additive link in some settings.", "conclusion": "The shifted-log link function provides a flexible alternative to standard Poisson NMF, allowing researchers to better model count data where parts may combine multiplicatively rather than purely additively."}}
{"id": "2601.05870", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05870", "abs": "https://arxiv.org/abs/2601.05870", "authors": ["Huilin Deng", "Hongchen Luo", "Yue Zhu", "Long Li", "Zhuoyue Chen", "Xinghao Zhao", "Ming Li", "Jihai Zhang", "Mengchang Wang", "Yang Cao", "Yu Kang"], "title": "IIB-LPO: Latent Policy Optimization via Iterative Information Bottleneck", "comment": null, "summary": "Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) for Large Language Model (LLM) reasoning have been hindered by a persistent challenge: exploration collapse. The semantic homogeneity of random rollouts often traps models in narrow, over-optimized behaviors. While existing methods leverage policy entropy to encourage exploration, they face inherent limitations. Global entropy regularization is susceptible to reward hacking, which can induce meaningless verbosity, whereas local token-selective updates struggle with the strong inductive bias of pre-trained models. To address this, we propose Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO), a novel approach that shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. IIB-LPO triggers latent branching at high-entropy states to diversify reasoning paths and employs the Information Bottleneck principle both as a trajectory filter and a self-reward mechanism, ensuring concise and informative exploration. Empirical results across four mathematical reasoning benchmarks demonstrate that IIB-LPO achieves state-of-the-art performance, surpassing prior methods by margins of up to 5.3% in accuracy and 7.4% in diversity metrics.", "AI": {"tldr": "IIB-LPO addresses exploration collapse in RLVR for LLM reasoning by shifting from token-level perturbation to trajectory-level branching using Information Bottleneck principles, achieving SOTA performance on math reasoning benchmarks.", "motivation": "Existing RLVR methods for LLM reasoning suffer from exploration collapse due to semantic homogeneity of random rollouts. Current exploration techniques using policy entropy have limitations: global entropy regularization causes reward hacking/verbosity, while local token-selective updates struggle with pre-trained model biases.", "method": "Proposes Latent Policy Optimization via Iterative Information Bottleneck (IIB-LPO). Shifts exploration from statistical perturbation of token distributions to topological branching of reasoning trajectories. Triggers latent branching at high-entropy states to diversify reasoning paths, and uses Information Bottleneck principle as both trajectory filter and self-reward mechanism for concise exploration.", "result": "Empirical results across four mathematical reasoning benchmarks show IIB-LPO achieves state-of-the-art performance, surpassing prior methods by up to 5.3% in accuracy and 7.4% in diversity metrics.", "conclusion": "IIB-LPO effectively addresses exploration collapse in RLVR for LLM reasoning by leveraging trajectory-level branching with Information Bottleneck principles, leading to improved accuracy and diversity in mathematical reasoning tasks."}}
{"id": "2601.05785", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05785", "abs": "https://arxiv.org/abs/2601.05785", "authors": ["Quanjiang Li", "Zhiming Liu", "Tianxiang Xu", "Tingjin Luo", "Chenping Hou"], "title": "Adaptive Disentangled Representation Learning for Incomplete Multi-View Multi-Label Classification", "comment": null, "summary": "Multi-view multi-label learning frequently suffers from simultaneous feature absence and incomplete annotations, due to challenges in data acquisition and cost-intensive supervision. To tackle the complex yet highly practical problem while overcoming the existing limitations of feature recovery, representation disentanglement, and label semantics modeling, we propose an Adaptive Disentangled Representation Learning method (ADRL). ADRL achieves robust view completion by propagating feature-level affinity across modalities with neighborhood awareness, and reinforces reconstruction effectiveness by leveraging a stochastic masking strategy. Through disseminating category-level association across label distributions, ADRL refines distribution parameters for capturing interdependent label prototypes. Besides, we formulate a mutual-information-based objective to promote consistency among shared representations and suppress information overlap between view-specific representation and other modalities. Theoretically, we derive the tractable bounds to train the dual-channel network. Moreover, ADRL performs prototype-specific feature selection by enabling independent interactions between label embeddings and view representations, accompanied by the generation of pseudo-labels for each category. The structural characteristics of the pseudo-label space are then exploited to guide a discriminative trade-off during view fusion. Finally, extensive experiments on public datasets and real-world applications demonstrate the superior performance of ADRL.", "AI": {"tldr": "ADRL is an adaptive disentangled representation learning method for multi-view multi-label learning that handles feature absence and incomplete annotations through view completion, label prototype learning, and mutual information optimization.", "motivation": "Multi-view multi-label learning faces challenges of simultaneous feature absence and incomplete annotations due to data acquisition difficulties and expensive supervision costs. Existing methods have limitations in feature recovery, representation disentanglement, and label semantics modeling.", "method": "ADRL uses: 1) robust view completion via feature-level affinity propagation across modalities with neighborhood awareness, 2) stochastic masking for reconstruction, 3) category-level association dissemination for interdependent label prototypes, 4) mutual-information-based objective for shared representation consistency, 5) prototype-specific feature selection with label embeddings, 6) pseudo-label generation and structural exploitation for discriminative view fusion trade-off.", "result": "Extensive experiments on public datasets and real-world applications demonstrate superior performance of ADRL compared to existing methods.", "conclusion": "ADRL effectively addresses the complex practical problem of multi-view multi-label learning with feature absence and incomplete annotations through adaptive disentangled representation learning, achieving robust performance across various applications."}}
{"id": "2601.05889", "categories": ["cs.LG", "astro-ph.CO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.05889", "abs": "https://arxiv.org/abs/2601.05889", "authors": ["Doyoung Kim", "Donghee Lee", "Hye-Sung Lee", "Jiheon Lee", "Jaeok Yi"], "title": "GlueNN: gluing patchwise analytic solutions with neural networks", "comment": "7 pages, 3 figures", "summary": "In many problems in physics and engineering, one encounters complicated differential equations with strongly scale-dependent terms for which exact analytical or numerical solutions are not available. A common strategy is to divide the domain into several regions (patches) and simplify the equation in each region. When approximate analytic solutions can be obtained in each patch, they are then matched at the interfaces to construct a global solution. However, this patching procedure can fail to reproduce the correct solution, since the approximate forms may break down near the matching boundaries. In this work, we propose a learning framework in which the integration constants of asymptotic analytic solutions are promoted to scale-dependent functions. By constraining these coefficient functions with the original differential equation over the domain, the network learns a globally valid solution that smoothly interpolates between asymptotic regimes, eliminating the need for arbitrary boundary matching. We demonstrate the effectiveness of this framework in representative problems from chemical kinetics and cosmology, where it accurately reproduces global solutions and outperforms conventional matching procedures.", "AI": {"tldr": "A learning framework that promotes integration constants of asymptotic solutions to scale-dependent functions, enabling smooth interpolation between regimes without manual boundary matching.", "motivation": "Traditional patching methods for solving complex differential equations with scale-dependent terms often fail because approximate solutions break down near matching boundaries, requiring arbitrary matching procedures.", "method": "Promote integration constants of asymptotic analytic solutions to scale-dependent functions, then constrain these coefficient functions with the original differential equation over the entire domain using a learning framework.", "result": "The framework accurately reproduces global solutions and outperforms conventional matching procedures in representative problems from chemical kinetics and cosmology.", "conclusion": "The proposed learning framework eliminates the need for arbitrary boundary matching by learning globally valid solutions that smoothly interpolate between asymptotic regimes."}}
{"id": "2601.05909", "categories": ["cs.LG", "cs.AI", "cs.CY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.05909", "abs": "https://arxiv.org/abs/2601.05909", "authors": ["Ayoub Ajarra", "Debabrota Basu"], "title": "Auditing Fairness under Model Updates: Fundamental Complexity and Property-Preserving Updates", "comment": null, "summary": "As machine learning models become increasingly embedded in societal infrastructure, auditing them for bias is of growing importance. However, in real-world deployments, auditing is complicated by the fact that model owners may adaptively update their models in response to changing environments, such as financial markets. These updates can alter the underlying model class while preserving certain properties of interest, raising fundamental questions about what can be reliably audited under such shifts.\n  In this work, we study group fairness auditing under arbitrary updates. We consider general shifts that modify the pre-audit model class while maintaining invariance of the audited property. Our goals are two-fold: (i) to characterize the information complexity of allowable updates, by identifying which strategic changes preserve the property under audit; and (ii) to efficiently estimate auditing properties, such as group fairness, using a minimal number of labeled samples.\n  We propose a generic framework for PAC auditing based on an Empirical Property Optimization (EPO) oracle. For statistical parity, we establish distribution-free auditing bounds characterized by the SP dimension, a novel combinatorial measure that captures the complexity of admissible strategic updates. Finally, we demonstrate that our framework naturally extends to other auditing objectives, including prediction error and robust risk.", "AI": {"tldr": "A framework for auditing machine learning models under adaptive updates, focusing on group fairness with distribution-free bounds based on a novel combinatorial measure (SP dimension).", "motivation": "Real-world ML models are frequently updated adaptively in response to changing environments, which complicates auditing for bias and fairness since updates can alter the model class while preserving certain properties.", "method": "Proposes a generic PAC auditing framework based on an Empirical Property Optimization (EPO) oracle. For statistical parity, introduces SP dimension as a combinatorial measure to characterize the complexity of admissible strategic updates.", "result": "Establishes distribution-free auditing bounds characterized by the SP dimension, enabling efficient estimation of auditing properties like group fairness with minimal labeled samples.", "conclusion": "The framework provides a principled approach to auditing ML models under arbitrary updates, with applications extending beyond group fairness to other auditing objectives like prediction error and robust risk."}}
{"id": "2601.05823", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05823", "abs": "https://arxiv.org/abs/2601.05823", "authors": ["John Page", "Xuesong Niu", "Kai Wu", "Kun Gai"], "title": "Boosting Latent Diffusion Models via Disentangled Representation Alignment", "comment": null, "summary": "Latent Diffusion Models (LDMs) generate high-quality images by operating in a compressed latent space, typically obtained through image tokenizers such as Variational Autoencoders (VAEs). In pursuit of a generation-friendly VAE, recent studies have explored leveraging Vision Foundation Models (VFMs) as representation alignment targets for VAEs, mirroring the approach commonly adopted for LDMs. Although this yields certain performance gains, using the same alignment target for both VAEs and LDMs overlooks their fundamentally different representational requirements. We advocate that while LDMs benefit from latents retaining high-level semantic concepts, VAEs should excel in semantic disentanglement, enabling encoding of attribute-level information in a structured way. To address this, we propose the Semantic disentangled VAE (Send-VAE), explicitly optimized for disentangled representation learning through aligning its latent space with the semantic hierarchy of pre-trained VFMs. Our approach employs a non-linear mapper network to transform VAE latents, aligning them with VFMs to bridge the gap between attribute-level disentanglement and high-level semantics, facilitating effective guidance for VAE learning. We evaluate semantic disentanglement via linear probing on attribute prediction tasks, showing strong correlation with improved generation performance. Finally, using Send-VAE, we train flow-based transformers SiTs; experiments show Send-VAE significantly speeds up training and achieves a state-of-the-art FID of 1.21 and 1.75 with and without classifier-free guidance on ImageNet 256x256.", "AI": {"tldr": "Send-VAE is a semantic disentangled VAE that aligns latent space with Vision Foundation Models' semantic hierarchy for better attribute-level disentanglement, improving image generation performance.", "motivation": "Current approaches use the same alignment targets for both VAEs and LDMs, overlooking their different representational needs. VAEs should focus on semantic disentanglement for attribute-level information, while LDMs need high-level semantic concepts.", "method": "Proposes Semantic disentangled VAE (Send-VAE) with non-linear mapper network to transform VAE latents, aligning them with pre-trained VFMs' semantic hierarchy for disentangled representation learning.", "result": "Send-VAE shows strong correlation between semantic disentanglement and improved generation performance. When used to train flow-based transformers (SiTs), it achieves SOTA FID of 1.21/1.75 on ImageNet 256x256 with/without classifier-free guidance.", "conclusion": "Explicit semantic disentanglement optimization for VAEs, rather than using the same alignment targets as LDMs, leads to better attribute-level representation and significantly improves image generation performance."}}
{"id": "2601.05913", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05913", "abs": "https://arxiv.org/abs/2601.05913", "authors": ["Pattarawat Chormai", "Ali Hashemi", "Klaus-Robert M\u00fcller", "Gr\u00e9goire Montavon"], "title": "Distilling Lightweight Domain Experts from Large ML Models by Identifying Relevant Subspaces", "comment": "20 pages + supplement", "summary": "Knowledge distillation involves transferring the predictive capabilities of large, high-performing AI models (teachers) to smaller models (students) that can operate in environments with limited computing power. In this paper, we address the scenario in which only a few classes and their associated intermediate concepts are relevant to distill. This scenario is common in practice, yet few existing distillation methods explicitly focus on the relevant subtask. To address this gap, we introduce 'SubDistill', a new distillation algorithm with improved numerical properties that only distills the relevant components of the teacher model at each layer. Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models demonstrate that SubDistill outperforms existing layer-wise distillation techniques on a representative set of subtasks. Our benchmark evaluations are complemented by Explainable AI analyses showing that our distilled student models more closely match the decision structure of the original teacher model.", "AI": {"tldr": "SubDistill is a new knowledge distillation method that focuses on distilling only relevant classes and intermediate concepts for specific subtasks, outperforming existing layer-wise distillation techniques.", "motivation": "In practice, only a few classes and their associated intermediate concepts are often relevant for distillation, but existing methods don't explicitly focus on these relevant subtasks, creating a gap in knowledge distillation approaches.", "method": "SubDistill is a distillation algorithm with improved numerical properties that selectively distills only the relevant components of the teacher model at each layer, rather than distilling the entire model.", "result": "Experiments on CIFAR-100 and ImageNet with Convolutional and Transformer models show SubDistill outperforms existing layer-wise distillation techniques on representative subtasks. Explainable AI analyses confirm distilled student models more closely match the teacher's decision structure.", "conclusion": "SubDistill effectively addresses the practical need for task-specific distillation by focusing only on relevant components, demonstrating superior performance and better alignment with teacher model decision-making."}}
{"id": "2601.05839", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05839", "abs": "https://arxiv.org/abs/2601.05839", "authors": ["Weimin Liu", "Wenjun Wang", "Joshua H. Meng"], "title": "GeoSurDepth: Spatial Geometry-Consistent Self-Supervised Depth Estimation for Surround-View Cameras", "comment": null, "summary": "Accurate surround-view depth estimation provides a competitive alternative to laser-based sensors and is essential for 3D scene understanding in autonomous driving. While prior studies have proposed various approaches that primarily focus on enforcing cross-view constraints at the photometric level, few explicitly exploit the rich geometric structure inherent in both monocular and surround-view setting. In this work, we propose GeoSurDepth, a framework that leverages geometry consistency as the primary cue for surround-view depth estimation. Concretely, we utilize foundation models as a pseudo geometry prior and feature representation enhancement tool to guide the network to maintain surface normal consistency in spatial 3D space and regularize object- and texture-consistent depth estimation in 2D. In addition, we introduce a novel view synthesis pipeline where 2D-3D lifting is achieved with dense depth reconstructed via spatial warping, encouraging additional photometric supervision across temporal, spatial, and spatial-temporal contexts, and compensating for the limitations of single-view image reconstruction. Finally, a newly-proposed adaptive joint motion learning strategy enables the network to adaptively emphasize informative spatial geometry cues for improved motion reasoning. Extensive experiments on DDAD and nuScenes demonstrate that GeoSurDepth achieves state-of-the-art performance, validating the effectiveness of our approach. Our framework highlights the importance of exploiting geometry coherence and consistency for robust self-supervised multi-view depth estimation.", "AI": {"tldr": "GeoSurDepth is a geometry-consistent framework for self-supervised surround-view depth estimation that leverages foundation models as pseudo geometry priors and introduces novel view synthesis with adaptive joint motion learning.", "motivation": "Prior surround-view depth estimation methods focus mainly on photometric constraints but fail to explicitly exploit rich geometric structure inherent in both monocular and surround-view settings. There's a need for approaches that leverage geometry consistency as the primary cue for more accurate depth estimation in autonomous driving applications.", "method": "1) Uses foundation models as pseudo geometry priors to guide surface normal consistency in 3D space and regularize object/texture-consistent depth in 2D. 2) Introduces novel view synthesis pipeline with dense depth reconstruction via spatial warping for photometric supervision across temporal, spatial, and spatial-temporal contexts. 3) Proposes adaptive joint motion learning strategy to emphasize informative spatial geometry cues for improved motion reasoning.", "result": "Extensive experiments on DDAD and nuScenes datasets demonstrate state-of-the-art performance, validating the effectiveness of the geometry-consistent approach for robust self-supervised multi-view depth estimation.", "conclusion": "The framework highlights the importance of exploiting geometry coherence and consistency for robust self-supervised multi-view depth estimation, providing a competitive alternative to laser-based sensors for 3D scene understanding in autonomous driving."}}
{"id": "2601.05929", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05929", "abs": "https://arxiv.org/abs/2601.05929", "authors": ["Sidney Shapiro", "Burhanuddin Panvelwala"], "title": "Prophet as a Repro ducible Forecasting Framework: A Methodological Guide for Business and Financial Analytics", "comment": null, "summary": "Reproducibility remains a persistent challenge in forecasting research and practice, particularly in business and financial analytics where forecasts inform high-stakes decisions. Traditional forecasting methods, while theoretically interpretable, often require extensive manual tuning and are difficult to replicate in proprietary environments. Machine learning approaches offer predictive flexibility but introduce challenges related to interpretability, stochastic training procedures, and cross-environment reproducibility. This paper examines Prophet, an open-source forecasting framework developed by Meta, as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility. Rather than proposing a new algorithm, this study evaluates how Prophet's additive structure, open-source implementation, and standardized workflow contribute to transparent and replicable forecasting practice. Using publicly available financial and retail datasets, we compare Prophet's performance and interpretability with multiple ARIMA specifications (auto-selected, manually specified, and seasonal variants) and Random Forest under a controlled and fully documented experimental design. This multi-model comparison provides a robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, we demonstrate how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines. The study positions Prophet within the broader context of reproducible research. It highlights Prophet's role as a methodological building block that supports verification, auditability, and methodological rigor. This work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based research workflows.", "AI": {"tldr": "This paper evaluates Meta's Prophet forecasting framework as a reproducibility-enabling solution that balances interpretability, standardized workflows, and accessibility for business/financial forecasting, comparing it with ARIMA variants and Random Forest.", "motivation": "Reproducibility is a persistent challenge in forecasting research and practice, especially in business/financial analytics where high-stakes decisions depend on forecasts. Traditional methods require extensive manual tuning and are hard to replicate, while ML approaches introduce interpretability and stochastic training issues.", "method": "The study evaluates Prophet's additive structure, open-source implementation, and standardized workflow for transparent/replicable forecasting. Using public financial/retail datasets, it compares Prophet's performance and interpretability with multiple ARIMA specifications (auto-selected, manually specified, seasonal variants) and Random Forest under controlled, fully documented experimental design.", "result": "The multi-model comparison provides robust assessment of Prophet's relative performance and reproducibility advantages. Through concrete Python examples, the paper demonstrates how Prophet facilitates efficient forecasting workflows and integration with analytical pipelines.", "conclusion": "Prophet serves as a methodological building block that supports verification, auditability, and methodological rigor in reproducible research. The work provides researchers and practitioners with a practical reference framework for reproducible forecasting in Python-based workflows, positioning Prophet within the broader context of reproducible research."}}
{"id": "2601.05956", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05956", "abs": "https://arxiv.org/abs/2601.05956", "authors": ["Juaren Steiger", "Bin Li"], "title": "On the Robustness of Age for Learning-Based Wireless Scheduling in Unknown Environments", "comment": "technical report of conference paper", "summary": "The constrained combinatorial multi-armed bandit model has been widely employed to solve problems in wireless networking and related areas, including the problem of wireless scheduling for throughput optimization under unknown channel conditions. Most work in this area uses an algorithm design strategy that combines a bandit learning algorithm with the virtual queue technique to track the throughput constraint violation. These algorithms seek to minimize the virtual queue length in their algorithm design. However, in networks where channel conditions change abruptly, the resulting constraints may become infeasible, leading to unbounded growth in virtual queue lengths. In this paper, we make the key observation that the dynamics of the head-of-line age, i.e. the age of the oldest packet in the virtual queue, make it more robust when used in algorithm design compared to the virtual queue length. We therefore design a learning-based scheduling policy that uses the head-of-line age in place of the virtual queue length. We show that our policy matches state-of-the-art performance under i.i.d. network conditions. Crucially, we also show that the system remains stable even under abrupt changes in channel conditions and can rapidly recover from periods of constraint infeasibility.", "AI": {"tldr": "A new scheduling policy uses head-of-line age instead of virtual queue length for constrained combinatorial multi-armed bandits, maintaining stability under abrupt channel changes.", "motivation": "Existing constrained combinatorial multi-armed bandit algorithms for wireless scheduling use virtual queue length tracking, but these can become unstable when channel conditions change abruptly, leading to unbounded queue growth and constraint infeasibility.", "method": "Design a learning-based scheduling policy that replaces virtual queue length with head-of-line age (age of oldest packet in virtual queue) in algorithm design, making it more robust to abrupt network changes.", "result": "The new policy matches state-of-the-art performance under i.i.d. network conditions while maintaining system stability under abrupt channel changes and enabling rapid recovery from constraint infeasibility periods.", "conclusion": "Using head-of-line age instead of virtual queue length in constrained combinatorial bandit algorithms provides superior robustness to network changes while maintaining competitive performance, solving the instability problem of existing approaches."}}
{"id": "2601.05852", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05852", "abs": "https://arxiv.org/abs/2601.05852", "authors": ["Jen Dusseljee", "Sarah de Boer", "Alessa Hering"], "title": "Kidney Cancer Detection Using 3D-Based Latent Diffusion Models", "comment": "8 pages, 2 figures. This paper has been accepted at Bildverarbeitung f\u00fcr die Medizin (BVM) 2026", "summary": "In this work, we present a novel latent diffusion-based pipeline for 3D kidney anomaly detection on contrast-enhanced abdominal CT. The method combines Denoising Diffusion Probabilistic Models (DDPMs), Denoising Diffusion Implicit Models (DDIMs), and Vector-Quantized Generative Adversarial Networks (VQ-GANs). Unlike prior slice-wise approaches, our method operates directly on an image volume and leverages weak supervision with only case-level pseudo-labels. We benchmark our approach against state-of-the-art supervised segmentation and detection models. This study demonstrates the feasibility and promise of 3D latent diffusion for weakly supervised anomaly detection. While the current results do not yet match supervised baselines, they reveal key directions for improving reconstruction fidelity and lesion localization. Our findings provide an important step toward annotation-efficient, generative modeling of complex abdominal anatomy.", "AI": {"tldr": "Novel 3D latent diffusion pipeline for kidney anomaly detection on abdominal CT using DDPMs, DDIMs, and VQ-GANs with weak supervision from case-level pseudo-labels.", "motivation": "To develop an annotation-efficient approach for 3D kidney anomaly detection that avoids the need for pixel-level annotations and operates directly on image volumes rather than slice-wise methods.", "method": "Combines Denoising Diffusion Probabilistic Models (DDPMs), Denoising Diffusion Implicit Models (DDIMs), and Vector-Quantized Generative Adversarial Networks (VQ-GANs) in a latent diffusion pipeline that uses only case-level pseudo-labels for weak supervision.", "result": "Demonstrates feasibility of 3D latent diffusion for weakly supervised anomaly detection, though current results do not yet match supervised baselines. Provides key directions for improving reconstruction fidelity and lesion localization.", "conclusion": "The approach represents an important step toward annotation-efficient, generative modeling of complex abdominal anatomy, showing promise for weakly supervised anomaly detection in medical imaging."}}
{"id": "2601.05984", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05984", "abs": "https://arxiv.org/abs/2601.05984", "authors": ["Sahibzada Saadoon Hammad", "Joaqu\u00edn Huerta Guijarro", "Francisco Ramos", "Michael Gould Carlson", "Sergio Trilles Oliver"], "title": "Community-Based Model Sharing and Generalisation: Anomaly Detection in IoT Temperature Sensor Networks", "comment": "20 pages, 9 figures, Journal submission", "summary": "The rapid deployment of Internet of Things (IoT) devices has led to large-scale sensor networks that monitor environmental and urban phenomena in real time. Communities of Interest (CoIs) provide a promising paradigm for organising heterogeneous IoT sensor networks by grouping devices with similar operational and environmental characteristics. This work presents an anomaly detection framework based on the CoI paradigm by grouping sensors into communities using a fused similarity matrix that incorporates temporal correlations via Spearman coefficients, spatial proximity using Gaussian distance decay, and elevation similarities. For each community, representative stations based on the best silhouette are selected and three autoencoder architectures (BiLSTM, LSTM, and MLP) are trained using Bayesian hyperparameter optimization with expanding window cross-validation and tested on stations from the same cluster and the best representative stations of other clusters. The models are trained on normal temperature patterns of the data and anomalies are detected through reconstruction error analysis. Experimental results show a robust within-community performance across the evaluated configurations, while variations across communities are observed. Overall, the results support the applicability of community-based model sharing in reducing computational overhead and to analyse model generalisability across IoT sensor networks.", "AI": {"tldr": "A community-based anomaly detection framework for IoT sensor networks using fused similarity metrics to group sensors, with autoencoder models trained on representative stations and evaluated across communities.", "motivation": "The rapid growth of IoT devices creates large-scale sensor networks that need efficient organization and anomaly detection. Communities of Interest (CoIs) offer a promising way to group heterogeneous IoT sensors with similar characteristics to reduce computational overhead and improve model generalizability.", "method": "1) Group sensors into communities using fused similarity matrix combining temporal correlations (Spearman coefficients), spatial proximity (Gaussian distance decay), and elevation similarities. 2) Select representative stations based on best silhouette scores. 3) Train three autoencoder architectures (BiLSTM, LSTM, MLP) using Bayesian hyperparameter optimization with expanding window cross-validation. 4) Detect anomalies through reconstruction error analysis on normal temperature patterns.", "result": "Robust within-community performance across evaluated configurations, with variations observed across different communities. The framework demonstrates applicability of community-based model sharing for reducing computational overhead and analyzing model generalizability across IoT sensor networks.", "conclusion": "Community-based model sharing using CoI paradigm is effective for IoT sensor network anomaly detection, offering computational efficiency and insights into model generalizability across different sensor communities."}}
{"id": "2601.05853", "categories": ["cs.CV", "cs.AI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.05853", "abs": "https://arxiv.org/abs/2601.05853", "authors": ["Yinghan Xu", "John Dingliana"], "title": "LayerGS: Decomposition and Inpainting of Layered 3D Human Avatars via 2D Gaussian Splatting", "comment": null, "summary": "We propose a novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D human avatars, separating the body and garments. Conventional single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. We overcome both limitations by encoding each layer as a set of 2D Gaussians for accurate geometry and photorealistic rendering, and inpainting hidden regions with a pretrained 2D diffusion model via score-distillation sampling (SDS). Our three-stage training strategy first reconstructs the coarse canonical garment via single-layer reconstruction, followed by multi-layer training to jointly recover the inner-layer body and outer-layer garment details. Experiments on two 3D human benchmark datasets (4D-Dress, Thuman2.0) show that our approach achieves better rendering quality and layer decomposition and recomposition than the previous state-of-the-art, enabling realistic virtual try-on under novel viewpoints and poses, and advancing practical creation of high-fidelity 3D human assets for immersive applications. Our code is available at https://github.com/RockyXu66/LayerGS", "AI": {"tldr": "LayerGS: A novel framework for decomposing arbitrarily posed humans into animatable multi-layered 3D avatars (body + garments) using 2D Gaussians and diffusion-based inpainting.", "motivation": "Existing single-layer reconstruction methods lock clothing to one identity, while prior multi-layer approaches struggle with occluded regions. There's a need for better decomposition of human avatars into separate body and garment layers for realistic virtual try-on and immersive applications.", "method": "Three-stage training: 1) Coarse canonical garment reconstruction via single-layer approach, 2) Multi-layer training to jointly recover inner-layer body and outer-layer garment details, 3) Encoding each layer as 2D Gaussians for geometry/rendering and inpainting hidden regions with pretrained 2D diffusion model via score-distillation sampling (SDS).", "result": "Achieves better rendering quality and layer decomposition/recomposition than previous state-of-the-art on 3D human benchmark datasets (4D-Dress, Thuman2.0). Enables realistic virtual try-on under novel viewpoints and poses.", "conclusion": "The approach advances practical creation of high-fidelity 3D human assets for immersive applications by successfully decomposing humans into animatable multi-layered avatars with separate body and garment layers."}}
{"id": "2601.06016", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06016", "abs": "https://arxiv.org/abs/2601.06016", "authors": ["\u00de\u00f3r Sverrisson", "Steinn Gu\u00f0mundsson"], "title": "LookAroundNet: Extending Temporal Context with Transformers for Clinically Viable EEG Seizure Detection", "comment": null, "summary": "Automated seizure detection from electroencephalography (EEG) remains difficult due to the large variability of seizure dynamics across patients, recording conditions, and clinical settings. We introduce LookAroundNet, a transformer-based seizure detector that uses a wider temporal window of EEG data to model seizure activity. The seizure detector incorporates EEG signals before and after the segment of interest, reflecting how clinicians use surrounding context when interpreting EEG recordings. We evaluate the proposed method on multiple EEG datasets spanning diverse clinical environments, patient populations, and recording modalities, including routine clinical EEG and long-term ambulatory recordings, in order to study performance across varying data distributions. The evaluation includes publicly available datasets as well as a large proprietary collection of home EEG recordings, providing complementary views of controlled clinical data and unconstrained home-monitoring conditions. Our results show that LookAroundNet achieves strong performance across datasets, generalizes well to previously unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. The results indicate that extended temporal context, increased training data diversity, and model ensembling are key factors for improving performance. This work contributes to moving automatic seizure detection models toward clinically viable solutions.", "AI": {"tldr": "LookAroundNet is a transformer-based seizure detector that uses extended temporal context from surrounding EEG signals to improve seizure detection performance across diverse clinical and home monitoring conditions.", "motivation": "Automated seizure detection from EEG is challenging due to large variability across patients, recording conditions, and clinical settings. Current methods need better generalization across diverse data distributions.", "method": "LookAroundNet uses a transformer architecture that incorporates EEG signals before and after the segment of interest, mimicking how clinicians use surrounding context. The method is evaluated on multiple EEG datasets including routine clinical EEG, long-term ambulatory recordings, and home EEG recordings.", "result": "LookAroundNet achieves strong performance across datasets, generalizes well to unseen recording conditions, and operates with computational costs compatible with real-world clinical deployment. Extended temporal context, increased training data diversity, and model ensembling are key factors for improved performance.", "conclusion": "The work contributes to moving automatic seizure detection models toward clinically viable solutions by demonstrating the importance of extended temporal context and diverse training data for robust performance across varying clinical environments."}}
{"id": "2601.05855", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05855", "abs": "https://arxiv.org/abs/2601.05855", "authors": ["Kaiwen Huang", "Yizhe Zhang", "Yi Zhou", "Tianyang Xu", "Tao Zhou"], "title": "Bidirectional Channel-selective Semantic Interaction for Semi-Supervised Medical Segmentation", "comment": "Accepted to AAAI 2026. Code at: https://github.com/taozh2017/BCSI", "summary": "Semi-supervised medical image segmentation is an effective method for addressing scenarios with limited labeled data. Existing methods mainly rely on frameworks such as mean teacher and dual-stream consistency learning. These approaches often face issues like error accumulation and model structural complexity, while also neglecting the interaction between labeled and unlabeled data streams. To overcome these challenges, we propose a Bidirectional Channel-selective Semantic Interaction~(BCSI) framework for semi-supervised medical image segmentation. First, we propose a Semantic-Spatial Perturbation~(SSP) mechanism, which disturbs the data using two strong augmentation operations and leverages unsupervised learning with pseudo-labels from weak augmentations. Additionally, we employ consistency on the predictions from the two strong augmentations to further improve model stability and robustness. Second, to reduce noise during the interaction between labeled and unlabeled data, we propose a Channel-selective Router~(CR) component, which dynamically selects the most relevant channels for information exchange. This mechanism ensures that only highly relevant features are activated, minimizing unnecessary interference. Finally, the Bidirectional Channel-wise Interaction~(BCI) strategy is employed to supplement additional semantic information and enhance the representation of important channels. Experimental results on multiple benchmarking 3D medical datasets demonstrate that the proposed method outperforms existing semi-supervised approaches.", "AI": {"tldr": "BCSI framework improves semi-supervised medical image segmentation through semantic-spatial perturbation, channel-selective routing, and bidirectional channel-wise interaction to address error accumulation and enhance labeled-unlabeled data interaction.", "motivation": "Existing semi-supervised methods for medical image segmentation suffer from error accumulation, model complexity, and neglect interaction between labeled and unlabeled data streams, limiting their effectiveness in data-scarce scenarios.", "method": "Proposes BCSI framework with: 1) Semantic-Spatial Perturbation using strong augmentations with pseudo-label consistency; 2) Channel-selective Router to dynamically select relevant channels for information exchange; 3) Bidirectional Channel-wise Interaction to enhance important channel representations.", "result": "Experimental results on multiple 3D medical datasets demonstrate superior performance compared to existing semi-supervised approaches.", "conclusion": "The BCSI framework effectively addresses limitations of existing methods by improving interaction between labeled and unlabeled data, reducing noise, and enhancing feature representation for better semi-supervised medical image segmentation."}}
{"id": "2509.12515", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12515", "abs": "https://arxiv.org/abs/2509.12515", "authors": ["Zequan Liang", "Ruoyu Zhang", "Wei Shao", "krishna Karthik", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Rapid Adaptation of SpO2 Estimation to Wearable Devices via Transfer Learning on Low-Sampling-Rate PPG", "comment": "In the proceedings of IEEE-EMBS International Conference on Body Sensor Networks 2025", "summary": "Blood oxygen saturation (SpO2) is a vital marker for healthcare monitoring. Traditional SpO2 estimation methods often rely on complex clinical calibration, making them unsuitable for low-power, wearable applications. In this paper, we propose a transfer learning-based framework for the rapid adaptation of SpO2 estimation to energy-efficient wearable devices using low-sampling-rate (25Hz) dual-channel photoplethysmography (PPG). We first pretrain a bidirectional Long Short-Term Memory (BiLSTM) model with self-attention on a public clinical dataset, then fine-tune it using data collected from our wearable We-Be band and an FDA-approved reference pulse oximeter. Experimental results show that our approach achieves a mean absolute error (MAE) of 2.967% on the public dataset and 2.624% on the private dataset, significantly outperforming traditional calibration and non-transferred machine learning baselines. Moreover, using 25Hz PPG reduces power consumption by 40% compared to 100Hz, excluding baseline draw. Our method also attains an MAE of 3.284% in instantaneous SpO2 prediction, effectively capturing rapid fluctuations. These results demonstrate the rapid adaptation of accurate, low-power SpO2 monitoring on wearable devices without the need for clinical calibration.", "AI": {"tldr": "Transfer learning framework enables accurate, low-power SpO2 monitoring on wearable devices using 25Hz PPG without clinical calibration.", "motivation": "Traditional SpO2 estimation requires complex clinical calibration unsuitable for low-power wearable applications. Need for energy-efficient, calibration-free monitoring solutions.", "method": "Transfer learning approach: pretrain BiLSTM with self-attention on public clinical dataset, then fine-tune using data from wearable band and FDA-approved reference pulse oximeter. Uses 25Hz dual-channel PPG for power efficiency.", "result": "Achieves MAE of 2.967% on public dataset and 2.624% on private dataset, outperforming traditional calibration and non-transferred ML baselines. 25Hz PPG reduces power consumption by 40% vs 100Hz. Instantaneous SpO2 prediction MAE of 3.284%.", "conclusion": "Demonstrates rapid adaptation of accurate, low-power SpO2 monitoring on wearable devices without clinical calibration, enabling practical healthcare monitoring applications."}}
{"id": "2601.05861", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05861", "abs": "https://arxiv.org/abs/2601.05861", "authors": ["Zhen-Xin Lin", "Shang-Kuan Chen"], "title": "Phase4DFD: Multi-Domain Phase-Aware Attention for Deepfake Detection", "comment": "15 pages, 3 figures, conference", "summary": "Recent deepfake detection methods have increasingly explored frequency domain representations to reveal manipulation artifacts that are difficult to detect in the spatial domain. However, most existing approaches rely primarily on spectral magnitude, implicitly under exploring the role of phase information. In this work, we propose Phase4DFD, a phase aware frequency domain deepfake detection framework that explicitly models phase magnitude interactions via a learnable attention mechanism. Our approach augments standard RGB input with Fast Fourier Transform (FFT) magnitude and local binary pattern (LBP) representations to expose subtle synthesis artifacts that remain indistinguishable under spatial analysis alone. Crucially, we introduce an input level phase aware attention module that uses phase discontinuities commonly introduced by synthetic generation to guide the model toward frequency patterns that are most indicative of manipulation before backbone feature extraction. The attended multi domain representation is processed by an efficient BNext M backbone, with optional channel spatial attention applied for semantic feature refinement. Extensive experiments on the CIFAKE and DFFD datasets demonstrate that our proposed model Phase4DFD outperforms state of the art spatial and frequency-based detectors while maintaining low computational overhead. Comprehensive ablation studies further confirm that explicit phase modeling provides complementary and non-redundant information beyond magnitude-only frequency representations.", "AI": {"tldr": "Phase4DFD is a deepfake detection framework that uses phase-aware frequency domain analysis with attention mechanisms to identify manipulation artifacts that are hard to detect in spatial domain alone.", "motivation": "Most existing deepfake detection methods focus on spatial domain or only use spectral magnitude in frequency domain, ignoring valuable phase information that contains manipulation artifacts from synthetic generation.", "method": "Proposes Phase4DFD with three key components: 1) Multi-domain input (RGB + FFT magnitude + LBP), 2) Phase-aware attention module that uses phase discontinuities to guide attention to manipulation patterns, 3) Efficient BNext M backbone with optional channel-spatial attention for feature refinement.", "result": "Outperforms state-of-the-art spatial and frequency-based detectors on CIFAKE and DFFD datasets while maintaining low computational overhead. Ablation studies confirm phase modeling provides complementary, non-redundant information beyond magnitude-only representations.", "conclusion": "Explicit phase modeling in frequency domain deepfake detection is crucial for capturing subtle manipulation artifacts, and the proposed Phase4DFD framework effectively leverages phase-magnitude interactions for superior detection performance."}}
{"id": "2509.12518", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12518", "abs": "https://arxiv.org/abs/2509.12518", "authors": ["Zequan Liang", "Ruoyu Zhang", "Wei Shao", "Mahdi Pirayesh Shirazi Nejad", "Ehsan Kourkchi", "Setareh Rafatirad", "Houman Homayoun"], "title": "Generalizable Blood Pressure Estimation from Multi-Wavelength PPG Using Curriculum-Adversarial Learning", "comment": "In the proceedings of IEEE-EMBS International Conference on Body Sensor Networks 2025", "summary": "Accurate and generalizable blood pressure (BP) estimation is vital for the early detection and management of cardiovascular diseases. In this study, we enforce subject-level data splitting on a public multi-wavelength photoplethysmography (PPG) dataset and propose a generalizable BP estimation framework based on curriculum-adversarial learning. Our approach combines curriculum learning, which transitions from hypertension classification to BP regression, with domain-adversarial training that confuses subject identity to encourage the learning of subject-invariant features. Experiments show that multi-channel fusion consistently outperforms single-channel models. On the four-wavelength PPG dataset, our method achieves strong performance under strict subject-level splitting, with mean absolute errors (MAE) of 14.2mmHg for systolic blood pressure (SBP) and 6.4mmHg for diastolic blood pressure (DBP). Additionally, ablation studies validate the effectiveness of both the curriculum and adversarial components. These results highlight the potential of leveraging complementary information in multi-wavelength PPG and curriculum-adversarial strategies for accurate and robust BP estimation.", "AI": {"tldr": "A curriculum-adversarial learning framework for blood pressure estimation from multi-wavelength PPG data achieves 14.2mmHg MAE for SBP and 6.4mmHg for DBP with subject-level data splitting.", "motivation": "Accurate and generalizable blood pressure estimation is crucial for early detection and management of cardiovascular diseases. Current methods need better generalization across subjects, especially when using photoplethysmography (PPG) data.", "method": "Proposes a generalizable BP estimation framework using curriculum-adversarial learning: 1) Curriculum learning that transitions from hypertension classification to BP regression, 2) Domain-adversarial training that confuses subject identity to learn subject-invariant features, 3) Multi-channel fusion of multi-wavelength PPG data, 4) Strict subject-level data splitting for evaluation.", "result": "On a four-wavelength PPG dataset with subject-level splitting: MAE of 14.2mmHg for systolic BP and 6.4mmHg for diastolic BP. Multi-channel fusion consistently outperforms single-channel models. Ablation studies confirm effectiveness of both curriculum and adversarial components.", "conclusion": "The framework demonstrates potential of combining multi-wavelength PPG complementary information with curriculum-adversarial strategies for accurate and robust blood pressure estimation that generalizes well across subjects."}}
{"id": "2601.05927", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05927", "abs": "https://arxiv.org/abs/2601.05927", "authors": ["Yohann Perron", "Vladyslav Sydorov", "Christophe Pottier", "Loic Landrieu"], "title": "Adapting Vision Transformers to Ultra-High Resolution Semantic Segmentation with Relay Tokens", "comment": "13 pages +3 pages of suppmat", "summary": "Current approaches for segmenting ultra high resolution images either slide a window, thereby discarding global context, or downsample and lose fine detail. We propose a simple yet effective method that brings explicit multi scale reasoning to vision transformers, simultaneously preserving local details and global awareness. Concretely, we process each image in parallel at a local scale (high resolution, small crops) and a global scale (low resolution, large crops), and aggregate and propagate features between the two branches with a small set of learnable relay tokens. The design plugs directly into standard transformer backbones (eg ViT and Swin) and adds fewer than 2 % parameters. Extensive experiments on three ultra high resolution segmentation benchmarks, Archaeoscape, URUR, and Gleason, and on the conventional Cityscapes dataset show consistent gains, with up to 15 % relative mIoU improvement. Code and pretrained models are available at https://archaeoscape.ai/work/relay-tokens/ .", "AI": {"tldr": "A novel method using relay tokens to enable vision transformers to process images at both local high-resolution and global low-resolution scales simultaneously for ultra-high-resolution segmentation.", "motivation": "Current methods for ultra-high-resolution image segmentation either use sliding windows (losing global context) or downsampling (losing fine details), creating a need for an approach that preserves both local details and global awareness.", "method": "Processes images in parallel at local scale (high resolution, small crops) and global scale (low resolution, large crops), using learnable relay tokens to aggregate and propagate features between the two branches, plugging directly into standard transformer backbones.", "result": "Achieves consistent gains on three ultra-high-resolution segmentation benchmarks (Archaeoscape, URUR, Gleason) and Cityscapes, with up to 15% relative mIoU improvement, while adding fewer than 2% parameters to standard backbones.", "conclusion": "The proposed relay token method provides an effective solution for multi-scale reasoning in vision transformers, enabling simultaneous preservation of local details and global context for ultra-high-resolution segmentation tasks."}}
{"id": "2601.05937", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05937", "abs": "https://arxiv.org/abs/2601.05937", "authors": ["Pankaj Gupta", "Priya Mudgil", "Niharika Dutta", "Kartik Bose", "Nitish Kumar", "Anupam Kumar", "Jimil Shah", "Vaneet Jearth", "Jayanta Samanta", "Vishal Sharma", "Harshal Mandavdhare", "Surinder Rana", "Saroj K Sinha", "Usha Dutta"], "title": "Performance of a Deep Learning-Based Segmentation Model for Pancreatic Tumors on Public Endoscopic Ultrasound Datasets", "comment": null, "summary": "Background: Pancreatic cancer is one of the most aggressive cancers, with poor survival rates. Endoscopic ultrasound (EUS) is a key diagnostic modality, but its effectiveness is constrained by operator subjectivity. This study evaluates a Vision Transformer-based deep learning segmentation model for pancreatic tumors. Methods: A segmentation model using the USFM framework with a Vision Transformer backbone was trained and validated with 17,367 EUS images (from two public datasets) in 5-fold cross-validation. The model was tested on an independent dataset of 350 EUS images from another public dataset, manually segmented by radiologists. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels. Metrics included Dice similarity coefficient (DSC), intersection over union (IoU), sensitivity, specificity, and accuracy. Results: In 5-fold cross-validation, the model achieved a mean DSC of 0.651 +/- 0.738, IoU of 0.579 +/- 0.658, sensitivity of 69.8%, specificity of 98.8%, and accuracy of 97.5%. For the external validation set, the model achieved a DSC of 0.657 (95% CI: 0.634-0.769), IoU of 0.614 (95% CI: 0.590-0.689), sensitivity of 71.8%, and specificity of 97.7%. Results were consistent, but 9.7% of cases exhibited erroneous multiple predictions. Conclusions: The Vision Transformer-based model demonstrated strong performance for pancreatic tumor segmentation in EUS images. However, dataset heterogeneity and limited external validation highlight the need for further refinement, standardization, and prospective studies.", "AI": {"tldr": "Vision Transformer-based deep learning model shows promising performance for pancreatic tumor segmentation in EUS images, achieving good accuracy but with some limitations in external validation.", "motivation": "Pancreatic cancer has poor survival rates, and EUS diagnosis is limited by operator subjectivity. There's a need for automated, objective segmentation methods to improve diagnostic accuracy.", "method": "Used USFM framework with Vision Transformer backbone, trained on 17,367 EUS images from two public datasets with 5-fold cross-validation. Tested on independent dataset of 350 images. Preprocessing included grayscale conversion, cropping, and resizing to 512x512 pixels.", "result": "Model achieved mean DSC of 0.651\u00b10.738, IoU of 0.579\u00b10.658, sensitivity 69.8%, specificity 98.8%, accuracy 97.5% in cross-validation. External validation showed DSC 0.657, IoU 0.614, sensitivity 71.8%, specificity 97.7%. However, 9.7% of cases had erroneous multiple predictions.", "conclusion": "Vision Transformer model demonstrates strong performance for pancreatic tumor segmentation but needs refinement due to dataset heterogeneity, limited external validation, and occasional erroneous predictions. Further standardization and prospective studies are required."}}
{"id": "2601.05939", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05939", "abs": "https://arxiv.org/abs/2601.05939", "authors": ["Mehrdad Fazli", "Bowen Wei", "Ziwei Zhu"], "title": "Context-Aware Decoding for Faithful Vision-Language Generation", "comment": null, "summary": "Hallucinations, generating responses inconsistent with the visual input, remain a critical limitation of large vision-language models (LVLMs), especially in open-ended tasks such as image captioning and visual reasoning. In this work, we probe the layer-wise generation dynamics that drive hallucinations and propose a training-free mitigation strategy. Employing the Logit Lens, we examine how LVLMs construct next-token distributions across decoder layers, uncovering a pronounced commitment-depth gap: truthful tokens accumulate probability mass on their final candidates earlier than hallucinatory ones. Drawing on this discovery, we introduce Context Embedding Injection (CEI), a lightweight method that harnesses the hidden state of the last input token-the context embedding-as a grounding signal to maintain visual fidelity throughout decoding and curb hallucinations. Evaluated on the CHAIR, AMBER, and MMHal-Bench benchmarks (with a maximum token length of 512), CEI outperforms state-of-the-art baselines across three LVLMs, with its dynamic variant yielding the lowest overall hallucination rates. By integrating novel mechanistic insights with a scalable intervention, this work advances the mitigation of hallucinations in LVLMs.", "AI": {"tldr": "The paper introduces Context Embedding Injection (CEI), a training-free method to reduce hallucinations in large vision-language models by using the last input token's hidden state as a grounding signal during decoding.", "motivation": "Hallucinations (responses inconsistent with visual input) remain a critical limitation in large vision-language models, especially for open-ended tasks like image captioning and visual reasoning. The authors aim to understand and mitigate this problem.", "method": "1. Used Logit Lens to analyze layer-wise generation dynamics, discovering a \"commitment-depth gap\" where truthful tokens accumulate probability mass earlier than hallucinatory ones. 2. Proposed Context Embedding Injection (CEI), a lightweight training-free method that injects the hidden state of the last input token (context embedding) as a grounding signal to maintain visual fidelity during decoding.", "result": "CEI outperformed state-of-the-art baselines across three LVLMs on CHAIR, AMBER, and MMHal-Bench benchmarks (with max token length of 512). The dynamic variant achieved the lowest overall hallucination rates.", "conclusion": "The work advances hallucination mitigation in LVLMs by integrating novel mechanistic insights (commitment-depth gap) with a scalable intervention (CEI), providing a training-free solution that effectively reduces hallucinations while maintaining visual fidelity."}}
{"id": "2601.05942", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05942", "abs": "https://arxiv.org/abs/2601.05942", "authors": ["Chanchan Wang", "Yuanfang Wang", "Qing Xu", "Guanxin Chen"], "title": "WaveRNet: Wavelet-Guided Frequency Learning for Multi-Source Domain-Generalized Retinal Vessel Segmentation", "comment": null, "summary": "Domain-generalized retinal vessel segmentation is critical for automated ophthalmic diagnosis, yet faces significant challenges from domain shift induced by non-uniform illumination and varying contrast, compounded by the difficulty of preserving fine vessel structures. While the Segment Anything Model (SAM) exhibits remarkable zero-shot capabilities, existing SAM-based methods rely on simple adapter fine-tuning while overlooking frequency-domain information that encodes domain-invariant features, resulting in degraded generalization under illumination and contrast variations. Furthermore, SAM's direct upsampling inevitably loses fine vessel details. To address these limitations, we propose WaveRNet, a wavelet-guided frequency learning framework for robust multi-source domain-generalized retinal vessel segmentation. Specifically, we devise a Spectral-guided Domain Modulator (SDM) that integrates wavelet decomposition with learnable domain tokens, enabling the separation of illumination-robust low-frequency structures from high-frequency vessel boundaries while facilitating domain-specific feature generation. Furthermore, we introduce a Frequency-Adaptive Domain Fusion (FADF) module that performs intelligent test-time domain selection through wavelet-based frequency similarity and soft-weighted fusion. Finally, we present a Hierarchical Mask-Prompt Refiner (HMPR) that overcomes SAM's upsampling limitation through coarse-to-fine refinement with long-range dependency modeling. Extensive experiments under the Leave-One-Domain-Out protocol on four public retinal datasets demonstrate that WaveRNet achieves state-of-the-art generalization performance. The source code is available at https://github.com/Chanchan-Wang/WaveRNet.", "AI": {"tldr": "WaveRNet: A wavelet-guided frequency learning framework for domain-generalized retinal vessel segmentation that addresses illumination/contrast variations and preserves fine vessel structures.", "motivation": "Existing SAM-based methods for retinal vessel segmentation overlook frequency-domain information and lose fine vessel details, leading to poor generalization under domain shifts caused by non-uniform illumination and varying contrast.", "method": "Proposes WaveRNet with three key components: 1) Spectral-guided Domain Modulator (SDM) using wavelet decomposition and learnable domain tokens, 2) Frequency-Adaptive Domain Fusion (FADF) for test-time domain selection via wavelet-based similarity, and 3) Hierarchical Mask-Prompt Refiner (HMPR) for coarse-to-fine refinement.", "result": "Extensive experiments under Leave-One-Domain-Out protocol on four public retinal datasets demonstrate state-of-the-art generalization performance.", "conclusion": "WaveRNet effectively addresses domain shift challenges in retinal vessel segmentation by leveraging frequency-domain information and hierarchical refinement, achieving robust generalization across diverse domains."}}
{"id": "2601.05966", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.05966", "abs": "https://arxiv.org/abs/2601.05966", "authors": ["Longbin Ji", "Xiaoxiong Liu", "Junyuan Shang", "Shuohuan Wang", "Yu Sun", "Hua Wu", "Haifeng Wang"], "title": "VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction", "comment": null, "summary": "Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.", "AI": {"tldr": "VideoAR is the first large-scale Visual Autoregressive framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling, achieving SOTA results with 10x faster inference than diffusion models.", "motivation": "Current video generation methods (diffusion and flow-matching models) are computationally intensive and difficult to scale. There's a need for more efficient, scalable approaches that maintain high quality while reducing computational costs.", "method": "VideoAR uses a multi-scale VAR framework with 3D tokenizer for spatio-temporal encoding. Key innovations include: Multi-scale Temporal RoPE, Cross-Frame Error Correction, Random Frame Mask, and a multi-stage pretraining pipeline that progressively aligns spatial and temporal learning across resolutions.", "result": "Achieves SOTA among autoregressive models: FVD on UCF-101 improves from 99.5 to 88.6 with 10x fewer inference steps. VBench score of 81.74 competes with diffusion models that are an order of magnitude larger.", "conclusion": "VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research."}}
{"id": "2601.05981", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.05981", "abs": "https://arxiv.org/abs/2601.05981", "authors": ["Yinsong Wang", "Xinzhe Luo", "Siyi Du", "Chen Qin"], "title": "Adaptive Conditional Contrast-Agnostic Deformable Image Registration with Uncertainty Estimation", "comment": "Accepted by ieee transactions on Medical Imaging", "summary": "Deformable multi-contrast image registration is a challenging yet crucial task due to the complex, non-linear intensity relationships across different imaging contrasts. Conventional registration methods typically rely on iterative optimization of the deformation field, which is time-consuming. Although recent learning-based approaches enable fast and accurate registration during inference, their generalizability remains limited to the specific contrasts observed during training. In this work, we propose an adaptive conditional contrast-agnostic deformable image registration framework (AC-CAR) based on a random convolution-based contrast augmentation scheme. AC-CAR can generalize to arbitrary imaging contrasts without observing them during training. To encourage contrast-invariant feature learning, we propose an adaptive conditional feature modulator (ACFM) that adaptively modulates the features and the contrast-invariant latent regularization to enforce the consistency of the learned feature across different imaging contrasts. Additionally, we enable our framework to provide contrast-agnostic registration uncertainty by integrating a variance network that leverages the contrast-agnostic registration encoder to improve the trustworthiness and reliability of AC-CAR. Experimental results demonstrate that AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts. Code is available at https://github.com/Yinsong0510/AC-CAR.", "AI": {"tldr": "AC-CAR is a contrast-agnostic deformable image registration framework that generalizes to unseen imaging contrasts using adaptive conditional feature modulation and contrast-invariant latent regularization.", "motivation": "Deformable multi-contrast image registration is challenging due to complex non-linear intensity relationships across different imaging contrasts. Conventional methods are slow, while learning-based approaches lack generalizability to unseen contrasts.", "method": "Proposes AC-CAR framework with: 1) Random convolution-based contrast augmentation, 2) Adaptive conditional feature modulator (ACFM) for contrast-invariant feature learning, 3) Contrast-invariant latent regularization for feature consistency, and 4) Variance network for contrast-agnostic uncertainty estimation.", "result": "AC-CAR outperforms baseline methods in registration accuracy and exhibits superior generalization to unseen imaging contrasts, while providing uncertainty estimation for improved trustworthiness.", "conclusion": "The proposed AC-CAR framework enables effective contrast-agnostic deformable image registration that generalizes to arbitrary imaging contrasts without requiring training on them, addressing key limitations of existing methods."}}
{"id": "2601.05986", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.05986", "abs": "https://arxiv.org/abs/2601.05986", "authors": ["Adrian Serrano", "Erwan Umlil", "Ronan Thomas"], "title": "Deepfake detectors are DUMB: A benchmark to assess adversarial training robustness under transferability constraints", "comment": "10 pages, four tables, one figure", "summary": "Deepfake detection systems deployed in real-world environments are subject to adversaries capable of crafting imperceptible perturbations that degrade model performance. While adversarial training is a widely adopted defense, its effectiveness under realistic conditions -- where attackers operate with limited knowledge and mismatched data distributions - remains underexplored. In this work, we extend the DUMB -- Dataset soUrces, Model architecture and Balance - and DUMBer methodology to deepfake detection. We evaluate detectors robustness against adversarial attacks under transferability constraints and cross-dataset configuration to extract real-world insights. Our study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2). We analyze both attacker and defender perspectives mapping results to mismatch scenarios. Experiments show that adversarial training strategies reinforce robustness in the in-distribution cases but can also degrade it under cross-dataset configuration depending on the strategy adopted. These findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks.", "AI": {"tldr": "Adversarial training effectiveness for deepfake detection is limited in real-world scenarios with data distribution mismatches and transferability constraints, requiring case-aware defense strategies.", "motivation": "Real-world deepfake detection systems face adversaries who can craft imperceptible perturbations to degrade model performance. While adversarial training is commonly used, its effectiveness under realistic conditions with limited attacker knowledge and mismatched data distributions remains underexplored.", "method": "Extends DUMB and DUMBer methodology to deepfake detection, evaluating detector robustness against adversarial attacks under transferability constraints and cross-dataset configurations. Study spans five state-of-the-art detectors (RECCE, SRM, XCeption, UCF, SPSL), three attacks (PGD, FGSM, FPBA), and two datasets (FaceForensics++ and Celeb-DF-V2), analyzing both attacker and defender perspectives.", "result": "Adversarial training strategies reinforce robustness in in-distribution cases but can degrade it under cross-dataset configurations depending on the strategy adopted. The effectiveness varies based on the specific defense approach used.", "conclusion": "Findings highlight the need for case-aware defense strategies in real-world applications exposed to adversarial attacks, as current adversarial training approaches have limitations when facing data distribution mismatches and transferability constraints."}}
